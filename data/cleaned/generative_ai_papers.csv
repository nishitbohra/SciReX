id,title,abstract,authors,categories,published,link,cleaned_title,cleaned_abstract,title_tokens,abstract_tokens,title_token_count,abstract_token_count,potential_datasets
2504.13173v1,"It's All Connected: A Journey Through Test-Time Memorization,   Attentional Bias, Retention, and Online Optimization","Designing efficient and effective architectural backbones has been in the core of research efforts to enhance the capability of foundation models. Inspired by the human cognitive phenomenon of attentional bias-the natural tendency to prioritize certain events or stimuli-we reconceptualize neural architectures, including Transformers, Titans, and modern linear recurrent neural networks as associative memory modules that learn a mapping of keys and values using an internal objective, referred to as attentional bias. Surprisingly, we observed that most existing sequence models leverage either (1) dot-product similarity, or (2) L2 regression objectives as their attentional bias. Going beyond these objectives, we present a set of alternative attentional bias configurations along with their effective approximations to stabilize their training procedure. We then reinterpret forgetting mechanisms in modern deep learning architectures as a form of retention regularization, providing a novel set of forget gates for sequence models. Building upon these insights, we present Miras, a general framework to design deep learning architectures based on four choices of: (i) associative memory architecture, (ii) attentional bias objective, (iii) retention gate, and (iv) memory learning algorithm. We present three novel sequence models-Moneta, Yaad, and Memora-that go beyond the power of existing linear RNNs while maintaining a fast parallelizable training process. Our experiments show different design choices in Miras yield models with varying strengths. For example, certain instances of Miras achieve exceptional performance in special tasks such as language modeling, commonsense reasoning, and recall intensive tasks, even outperforming Transformers and other modern linear recurrent models.","Ali Behrouz, Meisam Razaviyayn, Peilin Zhong, Vahab Mirrokni","cs.LG, cs.AI",2025-04-17T17:59:33Z,http://arxiv.org/abs/2504.13173v1,it s all connected a journey through test time memorization attentional bias retention and online optimization,designing efficient and effective architectural backbones has been in the core of research efforts to enhance the capability of foundation models inspired by the human cognitive phenomenon of attentional bias the natural tendency to prioritize certain events or stimuli we reconceptualize neural architectures including transformers titans and modern linear recurrent neural networks as associative memory modules that learn a mapping of keys and values using an internal objective referred to as attentional bias surprisingly we observed that most existing sequence models leverage either dot product similarity or l regression objectives as their attentional bias going beyond these objectives we present a set of alternative attentional bias configurations along with their effective approximations to stabilize their training procedure we then reinterpret forgetting mechanisms in modern deep learning architectures as a form of retention regularization providing a novel set of forget gates for sequence models building upon these insights we present miras a general framework to design deep learning architectures based on four choices of i associative memory architecture ii attentional bias objective iii retention gate and iv memory learning algorithm we present three novel sequence models moneta yaad and memora that go beyond the power of existing linear rnns while maintaining a fast parallelizable training process our experiments show different design choices in miras yield models with varying strengths for example certain instances of miras achieve exceptional performance in special tasks such as language modeling commonsense reasoning and recall intensive tasks even outperforming transformers and other modern linear recurrent models,"['it', 's', 'all', 'connected', 'a', 'journey', 'through', 'test', 'time', 'memorization', 'attentional', 'bias', 'retention', 'and', 'online', 'optimization']","['designing', 'efficient', 'and', 'effective', 'architectural', 'backbones', 'has', 'been', 'in', 'the', 'core', 'of', 'research', 'efforts', 'to', 'enhance', 'the', 'capability', 'of', 'foundation', 'models', 'inspired', 'by', 'the', 'human', 'cognitive', 'phenomenon', 'of', 'attentional', 'bias', 'the', 'natural', 'tendency', 'to', 'prioritize', 'certain', 'events', 'or', 'stimuli', 'we', 'reconceptualize', 'neural', 'architectures', 'including', 'transformers', 'titans', 'and', 'modern', 'linear', 'recurrent', 'neural', 'networks', 'as', 'associative', 'memory', 'modules', 'that', 'learn', 'a', 'mapping', 'of', 'keys', 'and', 'values', 'using', 'an', 'internal', 'objective', 'referred', 'to', 'as', 'attentional', 'bias', 'surprisingly', 'we', 'observed', 'that', 'most', 'existing', 'sequence', 'models', 'leverage', 'either', 'dot', 'product', 'similarity', 'or', 'l', 'regression', 'objectives', 'as', 'their', 'attentional', 'bias', 'going', 'beyond', 'these', 'objectives', 'we', 'present', 'a', 'set', 'of', 'alternative', 'attentional', 'bias', 'configurations', 'along', 'with', 'their', 'effective', 'approximations', 'to', 'stabilize', 'their', 'training', 'procedure', 'we', 'then', 'reinterpret', 'forgetting', 'mechanisms', 'in', 'modern', 'deep', 'learning', 'architectures', 'as', 'a', 'form', 'of', 'retention', 'regularization', 'providing', 'a', 'novel', 'set', 'of', 'forget', 'gates', 'for', 'sequence', 'models', 'building', 'upon', 'these', 'insights', 'we', 'present', 'miras', 'a', 'general', 'framework', 'to', 'design', 'deep', 'learning', 'architectures', 'based', 'on', 'four', 'choices', 'of', 'i', 'associative', 'memory', 'architecture', 'ii', 'attentional', 'bias', 'objective', 'iii', 'retention', 'gate', 'and', 'iv', 'memory', 'learning', 'algorithm', 'we', 'present', 'three', 'novel', 'sequence', 'models', 'moneta', 'yaad', 'and', 'memora', 'that', 'go', 'beyond', 'the', 'power', 'of', 'existing', 'linear', 'rnns', 'while', 'maintaining', 'a', 'fast', 'parallelizable', 'training', 'process', 'our', 'experiments', 'show', 'different', 'design', 'choices', 'in', 'miras', 'yield', 'models', 'with', 'varying', 'strengths', 'for', 'example', 'certain', 'instances', 'of', 'miras', 'achieve', 'exceptional', 'performance', 'in', 'special', 'tasks', 'such', 'as', 'language', 'modeling', 'commonsense', 'reasoning', 'and', 'recall', 'intensive', 'tasks', 'even', 'outperforming', 'transformers', 'and', 'other', 'modern', 'linear', 'recurrent', 'models']",16,249,"['Designing', 'Our', 'Transformers', 'Yaad', 'RNNs', 'Going', 'Moneta', 'Memora', 'Titans', 'Inspired', 'Surprisingly', 'Building', 'Miras']"
2504.13146v1,Antidistillation Sampling,"Frontier models that generate extended reasoning traces inadvertently produce rich token sequences that can facilitate model distillation. Recognizing this vulnerability, model owners may seek sampling strategies that limit the effectiveness of distillation without compromising model performance. \emph{Antidistillation sampling} provides exactly this capability. By strategically modifying a model's next-token probability distribution, antidistillation sampling poisons reasoning traces, rendering them significantly less effective for distillation while preserving the model's practical utility. For further details, see https://antidistillation.com.","Yash Savani, Asher Trockman, Zhili Feng, Avi Schwarzschild, Alexander Robey, Marc Finzi, J. Zico Kolter","cs.AI, cs.CL",2025-04-17T17:54:14Z,http://arxiv.org/abs/2504.13146v1,antidistillation sampling,frontier models that generate extended reasoning traces inadvertently produce rich token sequences that can facilitate model distillation recognizing this vulnerability model owners may seek sampling strategies that limit the effectiveness of distillation without compromising model performance antidistillation sampling provides exactly this capability by strategically modifying a model s next token probability distribution antidistillation sampling poisons reasoning traces rendering them significantly less effective for distillation while preserving the model s practical utility for further details see,"['antidistillation', 'sampling']","['frontier', 'models', 'that', 'generate', 'extended', 'reasoning', 'traces', 'inadvertently', 'produce', 'rich', 'token', 'sequences', 'that', 'can', 'facilitate', 'model', 'distillation', 'recognizing', 'this', 'vulnerability', 'model', 'owners', 'may', 'seek', 'sampling', 'strategies', 'that', 'limit', 'the', 'effectiveness', 'of', 'distillation', 'without', 'compromising', 'model', 'performance', 'antidistillation', 'sampling', 'provides', 'exactly', 'this', 'capability', 'by', 'strategically', 'modifying', 'a', 'model', 's', 'next', 'token', 'probability', 'distribution', 'antidistillation', 'sampling', 'poisons', 'reasoning', 'traces', 'rendering', 'them', 'significantly', 'less', 'effective', 'for', 'distillation', 'while', 'preserving', 'the', 'model', 's', 'practical', 'utility', 'for', 'further', 'details', 'see']",2,75,"['Frontier', 'Antidistillation', 'Recognizing']"
2504.13145v1,Exploring Expert Failures Improves LLM Agent Tuning,"Large Language Models (LLMs) have shown tremendous potential as agents, excelling at tasks that require multiple rounds of reasoning and interactions. Rejection Sampling Fine-Tuning (RFT) has emerged as an effective method for finetuning LLMs as agents: it first imitates expert-generated successful trajectories and further improves agentic skills through iterative fine-tuning on successful, self-generated trajectories. However, since the expert (e.g., GPT-4) succeeds primarily on simpler subtasks and RFT inherently favors simpler scenarios, many complex subtasks remain unsolved and persistently out-of-distribution (OOD). Upon investigating these challenging subtasks, we discovered that previously failed expert trajectories can often provide valuable guidance, e.g., plans and key actions, that can significantly improve agent exploration efficiency and acquisition of critical skills. Motivated by these observations, we propose Exploring Expert Failures (EEF), which identifies beneficial actions from failed expert trajectories and integrates them into the training dataset. Potentially harmful actions are meticulously excluded to prevent contamination of the model learning process. By leveraging the beneficial actions in expert failures, EEF successfully solves some previously unsolvable subtasks and improves agent tuning performance. Remarkably, our approach achieved a 62\% win rate in WebShop, outperforming RFT (53. 6\%) and GPT-4 (35. 6\%), and to the best of our knowledge, setting a new state-of-the-art as the first method to surpass a score of 0.81 in WebShop and exceed 81 in SciWorld.","Li-Cheng Lan, Andrew Bai, Minhao Cheng, Ruochen Wang, Cho-Jui Hsieh, Tianyi Zhou",cs.AI,2025-04-17T17:53:54Z,http://arxiv.org/abs/2504.13145v1,exploring expert failures improves llm agent tuning,large language models llms have shown tremendous potential as agents excelling at tasks that require multiple rounds of reasoning and interactions rejection sampling fine tuning rft has emerged as an effective method for finetuning llms as agents it first imitates expert generated successful trajectories and further improves agentic skills through iterative fine tuning on successful self generated trajectories however since the expert e g gpt succeeds primarily on simpler subtasks and rft inherently favors simpler scenarios many complex subtasks remain unsolved and persistently out of distribution ood upon investigating these challenging subtasks we discovered that previously failed expert trajectories can often provide valuable guidance e g plans and key actions that can significantly improve agent exploration efficiency and acquisition of critical skills motivated by these observations we propose exploring expert failures eef which identifies beneficial actions from failed expert trajectories and integrates them into the training dataset potentially harmful actions are meticulously excluded to prevent contamination of the model learning process by leveraging the beneficial actions in expert failures eef successfully solves some previously unsolvable subtasks and improves agent tuning performance remarkably our approach achieved a win rate in webshop outperforming rft and gpt and to the best of our knowledge setting a new state of the art as the first method to surpass a score of in webshop and exceed in sciworld,"['exploring', 'expert', 'failures', 'improves', 'llm', 'agent', 'tuning']","['large', 'language', 'models', 'llms', 'have', 'shown', 'tremendous', 'potential', 'as', 'agents', 'excelling', 'at', 'tasks', 'that', 'require', 'multiple', 'rounds', 'of', 'reasoning', 'and', 'interactions', 'rejection', 'sampling', 'fine', 'tuning', 'rft', 'has', 'emerged', 'as', 'an', 'effective', 'method', 'for', 'finetuning', 'llms', 'as', 'agents', 'it', 'first', 'imitates', 'expert', 'generated', 'successful', 'trajectories', 'and', 'further', 'improves', 'agentic', 'skills', 'through', 'iterative', 'fine', 'tuning', 'on', 'successful', 'self', 'generated', 'trajectories', 'however', 'since', 'the', 'expert', 'e', 'g', 'gpt', 'succeeds', 'primarily', 'on', 'simpler', 'subtasks', 'and', 'rft', 'inherently', 'favors', 'simpler', 'scenarios', 'many', 'complex', 'subtasks', 'remain', 'unsolved', 'and', 'persistently', 'out', 'of', 'distribution', 'ood', 'upon', 'investigating', 'these', 'challenging', 'subtasks', 'we', 'discovered', 'that', 'previously', 'failed', 'expert', 'trajectories', 'can', 'often', 'provide', 'valuable', 'guidance', 'e', 'g', 'plans', 'and', 'key', 'actions', 'that', 'can', 'significantly', 'improve', 'agent', 'exploration', 'efficiency', 'and', 'acquisition', 'of', 'critical', 'skills', 'motivated', 'by', 'these', 'observations', 'we', 'propose', 'exploring', 'expert', 'failures', 'eef', 'which', 'identifies', 'beneficial', 'actions', 'from', 'failed', 'expert', 'trajectories', 'and', 'integrates', 'them', 'into', 'the', 'training', 'dataset', 'potentially', 'harmful', 'actions', 'are', 'meticulously', 'excluded', 'to', 'prevent', 'contamination', 'of', 'the', 'model', 'learning', 'process', 'by', 'leveraging', 'the', 'beneficial', 'actions', 'in', 'expert', 'failures', 'eef', 'successfully', 'solves', 'some', 'previously', 'unsolvable', 'subtasks', 'and', 'improves', 'agent', 'tuning', 'performance', 'remarkably', 'our', 'approach', 'achieved', 'a', 'win', 'rate', 'in', 'webshop', 'outperforming', 'rft', 'and', 'gpt', 'and', 'to', 'the', 'best', 'of', 'our', 'knowledge', 'setting', 'a', 'new', 'state', 'of', 'the', 'art', 'as', 'the', 'first', 'method', 'to', 'surpass', 'a', 'score', 'of', 'in', 'webshop', 'and', 'exceed', 'in', 'sciworld']",7,223,"['RFT', 'Expert', 'Fine', 'Exploring', 'Language', 'GPT-4', 'Failures', 'LLMs', 'However', 'Sampling', 'Motivated', 'Large', 'OOD', 'Upon', 'SciWorld', 'EEF', 'Rejection', 'WebShop', 'Models', 'Potentially', 'Remarkably', 'Tuning']"
2504.13143v1,$\texttt{Complex-Edit}$: CoT-Like Instruction Generation for   Complexity-Controllable Image Editing Benchmark,"We introduce $\texttt{Complex-Edit}$, a comprehensive benchmark designed to systematically evaluate instruction-based image editing models across instructions of varying complexity. To develop this benchmark, we harness GPT-4o to automatically collect a diverse set of editing instructions at scale. Our approach follows a well-structured ``Chain-of-Edit'' pipeline: we first generate individual atomic editing tasks independently and then integrate them to form cohesive, complex instructions. Additionally, we introduce a suite of metrics to assess various aspects of editing performance, along with a VLM-based auto-evaluation pipeline that supports large-scale assessments. Our benchmark yields several notable insights: 1) Open-source models significantly underperform relative to proprietary, closed-source models, with the performance gap widening as instruction complexity increases; 2) Increased instructional complexity primarily impairs the models' ability to retain key elements from the input images and to preserve the overall aesthetic quality; 3) Decomposing a complex instruction into a sequence of atomic steps, executed in a step-by-step manner, substantially degrades performance across multiple metrics; 4) A straightforward Best-of-N selection strategy improves results for both direct editing and the step-by-step sequential approach; and 5) We observe a ``curse of synthetic data'': when synthetic data is involved in model training, the edited images from such models tend to appear increasingly synthetic as the complexity of the editing instructions rises -- a phenomenon that intriguingly also manifests in the latest GPT-4o outputs.","Siwei Yang, Mude Hui, Bingchen Zhao, Yuyin Zhou, Nataniel Ruiz, Cihang Xie","cs.CV, cs.AI",2025-04-17T17:51:59Z,http://arxiv.org/abs/2504.13143v1,complex edit cot like instruction generation for complexity controllable image editing benchmark,we introduce complex edit a comprehensive benchmark designed to systematically evaluate instruction based image editing models across instructions of varying complexity to develop this benchmark we harness gpt o to automatically collect a diverse set of editing instructions at scale our approach follows a well structured chain of edit pipeline we first generate individual atomic editing tasks independently and then integrate them to form cohesive complex instructions additionally we introduce a suite of metrics to assess various aspects of editing performance along with a vlm based auto evaluation pipeline that supports large scale assessments our benchmark yields several notable insights open source models significantly underperform relative to proprietary closed source models with the performance gap widening as instruction complexity increases increased instructional complexity primarily impairs the models ability to retain key elements from the input images and to preserve the overall aesthetic quality decomposing a complex instruction into a sequence of atomic steps executed in a step by step manner substantially degrades performance across multiple metrics a straightforward best of n selection strategy improves results for both direct editing and the step by step sequential approach and we observe a curse of synthetic data when synthetic data is involved in model training the edited images from such models tend to appear increasingly synthetic as the complexity of the editing instructions rises a phenomenon that intriguingly also manifests in the latest gpt o outputs,"['complex', 'edit', 'cot', 'like', 'instruction', 'generation', 'for', 'complexity', 'controllable', 'image', 'editing', 'benchmark']","['we', 'introduce', 'complex', 'edit', 'a', 'comprehensive', 'benchmark', 'designed', 'to', 'systematically', 'evaluate', 'instruction', 'based', 'image', 'editing', 'models', 'across', 'instructions', 'of', 'varying', 'complexity', 'to', 'develop', 'this', 'benchmark', 'we', 'harness', 'gpt', 'o', 'to', 'automatically', 'collect', 'a', 'diverse', 'set', 'of', 'editing', 'instructions', 'at', 'scale', 'our', 'approach', 'follows', 'a', 'well', 'structured', 'chain', 'of', 'edit', 'pipeline', 'we', 'first', 'generate', 'individual', 'atomic', 'editing', 'tasks', 'independently', 'and', 'then', 'integrate', 'them', 'to', 'form', 'cohesive', 'complex', 'instructions', 'additionally', 'we', 'introduce', 'a', 'suite', 'of', 'metrics', 'to', 'assess', 'various', 'aspects', 'of', 'editing', 'performance', 'along', 'with', 'a', 'vlm', 'based', 'auto', 'evaluation', 'pipeline', 'that', 'supports', 'large', 'scale', 'assessments', 'our', 'benchmark', 'yields', 'several', 'notable', 'insights', 'open', 'source', 'models', 'significantly', 'underperform', 'relative', 'to', 'proprietary', 'closed', 'source', 'models', 'with', 'the', 'performance', 'gap', 'widening', 'as', 'instruction', 'complexity', 'increases', 'increased', 'instructional', 'complexity', 'primarily', 'impairs', 'the', 'models', 'ability', 'to', 'retain', 'key', 'elements', 'from', 'the', 'input', 'images', 'and', 'to', 'preserve', 'the', 'overall', 'aesthetic', 'quality', 'decomposing', 'a', 'complex', 'instruction', 'into', 'a', 'sequence', 'of', 'atomic', 'steps', 'executed', 'in', 'a', 'step', 'by', 'step', 'manner', 'substantially', 'degrades', 'performance', 'across', 'multiple', 'metrics', 'a', 'straightforward', 'best', 'of', 'n', 'selection', 'strategy', 'improves', 'results', 'for', 'both', 'direct', 'editing', 'and', 'the', 'step', 'by', 'step', 'sequential', 'approach', 'and', 'we', 'observe', 'a', 'curse', 'of', 'synthetic', 'data', 'when', 'synthetic', 'data', 'is', 'involved', 'in', 'model', 'training', 'the', 'edited', 'images', 'from', 'such', 'models', 'tend', 'to', 'appear', 'increasingly', 'synthetic', 'as', 'the', 'complexity', 'of', 'the', 'editing', 'instructions', 'rises', 'a', 'phenomenon', 'that', 'intriguingly', 'also', 'manifests', 'in', 'the', 'latest', 'gpt', 'o', 'outputs']",12,233,"['Complex', 'Chain', 'Decomposing', 'Open', 'Best', 'Edit', 'VLM-based', 'Additionally', 'Our', 'Increased', 'GPT-4o']"
2504.13139v1,Syntactic and Semantic Control of Large Language Models via Sequential   Monte Carlo,"A wide range of LM applications require generating text that conforms to syntactic or semantic constraints. Imposing such constraints can be naturally framed as probabilistic conditioning, but exact generation from the resulting distribution -- which can differ substantially from the LM's base distribution -- is generally intractable. In this work, we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time, and efficiently reallocate computational resources in light of new information during the course of generation. By comparing to a number of alternatives and ablations on four challenging domains -- Python code generation for data science, text-to-SQL, goal inference, and molecule synthesis -- we demonstrate that, with little overhead, our approach allows small open-source language models to outperform models over 8x larger, as well as closed-source, fine-tuned ones. In support of the probabilistic perspective, we show that these performance improvements are driven by better approximation to the posterior distribution. Our system builds on the framework of Lew et al. (2023) and integrates with its language model probabilistic programming language, giving users a simple, programmable way to apply SMC to a broad variety of controlled generation problems.","Jo√£o Loula, Benjamin LeBrun, Li Du, Ben Lipkin, Clemente Pasti, Gabriel Grand, Tianyu Liu, Yahya Emara, Marjorie Freedman, Jason Eisner, Ryan Cotterel, Vikash Mansinghka, Alexander K. Lew, Tim Vieira, Timothy J. O'Donnell","cs.CL, cs.AI, cs.LG",2025-04-17T17:49:40Z,http://arxiv.org/abs/2504.13139v1,syntactic and semantic control of large language models via sequential monte carlo,a wide range of lm applications require generating text that conforms to syntactic or semantic constraints imposing such constraints can be naturally framed as probabilistic conditioning but exact generation from the resulting distribution which can differ substantially from the lm s base distribution is generally intractable in this work we develop an architecture for controlled lm generation based on sequential monte carlo smc our smc framework allows us to flexibly incorporate domain and problem specific constraints at inference time and efficiently reallocate computational resources in light of new information during the course of generation by comparing to a number of alternatives and ablations on four challenging domains python code generation for data science text to sql goal inference and molecule synthesis we demonstrate that with little overhead our approach allows small open source language models to outperform models over x larger as well as closed source fine tuned ones in support of the probabilistic perspective we show that these performance improvements are driven by better approximation to the posterior distribution our system builds on the framework of lew et al and integrates with its language model probabilistic programming language giving users a simple programmable way to apply smc to a broad variety of controlled generation problems,"['syntactic', 'and', 'semantic', 'control', 'of', 'large', 'language', 'models', 'via', 'sequential', 'monte', 'carlo']","['a', 'wide', 'range', 'of', 'lm', 'applications', 'require', 'generating', 'text', 'that', 'conforms', 'to', 'syntactic', 'or', 'semantic', 'constraints', 'imposing', 'such', 'constraints', 'can', 'be', 'naturally', 'framed', 'as', 'probabilistic', 'conditioning', 'but', 'exact', 'generation', 'from', 'the', 'resulting', 'distribution', 'which', 'can', 'differ', 'substantially', 'from', 'the', 'lm', 's', 'base', 'distribution', 'is', 'generally', 'intractable', 'in', 'this', 'work', 'we', 'develop', 'an', 'architecture', 'for', 'controlled', 'lm', 'generation', 'based', 'on', 'sequential', 'monte', 'carlo', 'smc', 'our', 'smc', 'framework', 'allows', 'us', 'to', 'flexibly', 'incorporate', 'domain', 'and', 'problem', 'specific', 'constraints', 'at', 'inference', 'time', 'and', 'efficiently', 'reallocate', 'computational', 'resources', 'in', 'light', 'of', 'new', 'information', 'during', 'the', 'course', 'of', 'generation', 'by', 'comparing', 'to', 'a', 'number', 'of', 'alternatives', 'and', 'ablations', 'on', 'four', 'challenging', 'domains', 'python', 'code', 'generation', 'for', 'data', 'science', 'text', 'to', 'sql', 'goal', 'inference', 'and', 'molecule', 'synthesis', 'we', 'demonstrate', 'that', 'with', 'little', 'overhead', 'our', 'approach', 'allows', 'small', 'open', 'source', 'language', 'models', 'to', 'outperform', 'models', 'over', 'x', 'larger', 'as', 'well', 'as', 'closed', 'source', 'fine', 'tuned', 'ones', 'in', 'support', 'of', 'the', 'probabilistic', 'perspective', 'we', 'show', 'that', 'these', 'performance', 'improvements', 'are', 'driven', 'by', 'better', 'approximation', 'to', 'the', 'posterior', 'distribution', 'our', 'system', 'builds', 'on', 'the', 'framework', 'of', 'lew', 'et', 'al', 'and', 'integrates', 'with', 'its', 'language', 'model', 'probabilistic', 'programming', 'language', 'giving', 'users', 'a', 'simple', 'programmable', 'way', 'to', 'apply', 'smc', 'to', 'a', 'broad', 'variety', 'of', 'controlled', 'generation', 'problems']",12,206,"['Imposing', '2023', 'Lew', 'Carlo', 'Python', 'Monte', 'SMC', 'SQL', 'Our']"
2504.13131v1,NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and   Enhancement: Methods and Results,"This paper presents a review for the NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and Enhancement. The challenge comprises two tracks: (i) Efficient Video Quality Assessment (KVQ), and (ii) Diffusion-based Image Super-Resolution (KwaiSR). Track 1 aims to advance the development of lightweight and efficient video quality assessment (VQA) models, with an emphasis on eliminating reliance on model ensembles, redundant weights, and other computationally expensive components in the previous IQA/VQA competitions. Track 2 introduces a new short-form UGC dataset tailored for single image super-resolution, i.e., the KwaiSR dataset. It consists of 1,800 synthetically generated S-UGC image pairs and 1,900 real-world S-UGC images, which are split into training, validation, and test sets using a ratio of 8:1:1. The primary objective of the challenge is to drive research that benefits the user experience of short-form UGC platforms such as Kwai and TikTok. This challenge attracted 266 participants and received 18 valid final submissions with corresponding fact sheets, significantly contributing to the progress of short-form UGC VQA and image superresolution. The project is publicly available at https://github.com/lixinustc/KVQE- ChallengeCVPR-NTIRE2025.","Xin Li, Kun Yuan, Bingchen Li, Fengbin Guan, Yizhen Shao, Zihao Yu, Xijun Wang, Yiting Lu, Wei Luo, Suhang Yao, Ming Sun, Chao Zhou, Zhibo Chen, Radu Timofte, Yabin Zhang, Ao-Xiang Zhang, Tianwu Zhi, Jianzhao Liu, Yang Li, Jingwen Xu, Yiting Liao, Yushen Zuo, Mingyang Wu, Renjie Li, Shengyun Zhong, Zhengzhong Tu, Yufan Liu, Xiangguang Chen, Zuowei Cao, Minhao Tang, Shan Liu, Kexin Zhang, Jingfen Xie, Yan Wang, Kai Chen, Shijie Zhao, Yunchen Zhang, Xiangkai Xu, Hong Gao, Ji Shi, Yiming Bao, Xiugang Dong, Xiangsheng Zhou, Yaofeng Tu, Ying Liang, Yiwen Wang, Xinning Chai, Yuxuan Zhang, Zhengxue Cheng, Yingsheng Qin, Yucai Yang, Rong Xie, Li Song, Wei Sun, Kang Fu, Linhan Cao, Dandan Zhu, Kaiwei Zhang, Yucheng Zhu, Zicheng Zhang, Menghan Hu, Xiongkuo Min, Guangtao Zhai, Zhi Jin, Jiawei Wu, Wei Wang, Wenjian Zhang, Yuhai Lan, Gaoxiong Yi, Hengyuan Na, Wang Luo, Di Wu, MingYin Bai, Jiawang Du, Zilong Lu, Zhenyu Jiang, Hui Zeng, Ziguan Cui, Zongliang Gan, Guijin Tang, Xinglin Xie, Kehuan Song, Xiaoqiang Lu, Licheng Jiao, Fang Liu, Xu Liu, Puhua Chen, Ha Thu Nguyen, Katrien De Moor, Seyed Ali Amirshahi, Mohamed-Chaker Larabi, Qi Tang, Linfeng He, Zhiyong Gao, Zixuan Gao, Guohua Zhang, Zhiye Huang, Yi Deng, Qingmiao Jiang, Lu Chen, Yi Yang, Xi Liao, Nourine Mohammed Nadir, Yuxuan Jiang, Qiang Zhu, Siyue Teng, Fan Zhang, Shuyuan Zhu, Bing Zeng, David Bull, Meiqin Liu, Chao Yao, Yao Zhao","eess.IV, cs.AI, cs.CV",2025-04-17T17:45:34Z,http://arxiv.org/abs/2504.13131v1,ntire challenge on short form ugc video quality assessment and enhancement methods and results,this paper presents a review for the ntire challenge on short form ugc video quality assessment and enhancement the challenge comprises two tracks i efficient video quality assessment kvq and ii diffusion based image super resolution kwaisr track aims to advance the development of lightweight and efficient video quality assessment vqa models with an emphasis on eliminating reliance on model ensembles redundant weights and other computationally expensive components in the previous iqa vqa competitions track introduces a new short form ugc dataset tailored for single image super resolution i e the kwaisr dataset it consists of synthetically generated s ugc image pairs and real world s ugc images which are split into training validation and test sets using a ratio of the primary objective of the challenge is to drive research that benefits the user experience of short form ugc platforms such as kwai and tiktok this challenge attracted participants and received valid final submissions with corresponding fact sheets significantly contributing to the progress of short form ugc vqa and image superresolution the project is publicly available at challengecvpr ntire,"['ntire', 'challenge', 'on', 'short', 'form', 'ugc', 'video', 'quality', 'assessment', 'and', 'enhancement', 'methods', 'and', 'results']","['this', 'paper', 'presents', 'a', 'review', 'for', 'the', 'ntire', 'challenge', 'on', 'short', 'form', 'ugc', 'video', 'quality', 'assessment', 'and', 'enhancement', 'the', 'challenge', 'comprises', 'two', 'tracks', 'i', 'efficient', 'video', 'quality', 'assessment', 'kvq', 'and', 'ii', 'diffusion', 'based', 'image', 'super', 'resolution', 'kwaisr', 'track', 'aims', 'to', 'advance', 'the', 'development', 'of', 'lightweight', 'and', 'efficient', 'video', 'quality', 'assessment', 'vqa', 'models', 'with', 'an', 'emphasis', 'on', 'eliminating', 'reliance', 'on', 'model', 'ensembles', 'redundant', 'weights', 'and', 'other', 'computationally', 'expensive', 'components', 'in', 'the', 'previous', 'iqa', 'vqa', 'competitions', 'track', 'introduces', 'a', 'new', 'short', 'form', 'ugc', 'dataset', 'tailored', 'for', 'single', 'image', 'super', 'resolution', 'i', 'e', 'the', 'kwaisr', 'dataset', 'it', 'consists', 'of', 'synthetically', 'generated', 's', 'ugc', 'image', 'pairs', 'and', 'real', 'world', 's', 'ugc', 'images', 'which', 'are', 'split', 'into', 'training', 'validation', 'and', 'test', 'sets', 'using', 'a', 'ratio', 'of', 'the', 'primary', 'objective', 'of', 'the', 'challenge', 'is', 'to', 'drive', 'research', 'that', 'benefits', 'the', 'user', 'experience', 'of', 'short', 'form', 'ugc', 'platforms', 'such', 'as', 'kwai', 'and', 'tiktok', 'this', 'challenge', 'attracted', 'participants', 'and', 'received', 'valid', 'final', 'submissions', 'with', 'corresponding', 'fact', 'sheets', 'significantly', 'contributing', 'to', 'the', 'progress', 'of', 'short', 'form', 'ugc', 'vqa', 'and', 'image', 'superresolution', 'the', 'project', 'is', 'publicly', 'available', 'at', 'challengecvpr', 'ntire']",14,180,"['Efficient', 'Challenge', 'UGC', 'Image', '2025', 'Resolution', 'NTIRE2025', '800', '266', '900', 'KwaiSR', 'Quality', 'Enhancement', 'VQA', 'ChallengeCVPR', 'Super', 'Diffusion', 'Track', 'NTIRE', 'Assessment', 'IQA', 'Kwai', 'KVQ', 'KVQE', 'S-UGC', 'TikTok', 'Short', 'Video']"
2504.13129v1,Science-T2I: Addressing Scientific Illusions in Image Synthesis,"We present a novel approach to integrating scientific knowledge into generative models, enhancing their realism and consistency in image synthesis. First, we introduce Science-T2I, an expert-annotated adversarial dataset comprising adversarial 20k image pairs with 9k prompts, covering wide distinct scientific knowledge categories. Leveraging Science-T2I, we present SciScore, an end-to-end reward model that refines the assessment of generated images based on scientific knowledge, which is achieved by augmenting both the scientific comprehension and visual capabilities of pre-trained CLIP model. Additionally, based on SciScore, we propose a two-stage training framework, comprising a supervised fine-tuning phase and a masked online fine-tuning phase, to incorporate scientific knowledge into existing generative models. Through comprehensive experiments, we demonstrate the effectiveness of our framework in establishing new standards for evaluating the scientific realism of generated content. Specifically, SciScore attains performance comparable to human-level, demonstrating a 5% improvement similar to evaluations conducted by experienced human evaluators. Furthermore, by applying our proposed fine-tuning method to FLUX, we achieve a performance enhancement exceeding 50% on SciScore.","Jialuo Li, Wenhao Chai, Xingyu Fu, Haiyang Xu, Saining Xie","cs.CV, cs.AI, cs.LG",2025-04-17T17:44:19Z,http://arxiv.org/abs/2504.13129v1,science t i addressing scientific illusions in image synthesis,we present a novel approach to integrating scientific knowledge into generative models enhancing their realism and consistency in image synthesis first we introduce science t i an expert annotated adversarial dataset comprising adversarial k image pairs with k prompts covering wide distinct scientific knowledge categories leveraging science t i we present sciscore an end to end reward model that refines the assessment of generated images based on scientific knowledge which is achieved by augmenting both the scientific comprehension and visual capabilities of pre trained clip model additionally based on sciscore we propose a two stage training framework comprising a supervised fine tuning phase and a masked online fine tuning phase to incorporate scientific knowledge into existing generative models through comprehensive experiments we demonstrate the effectiveness of our framework in establishing new standards for evaluating the scientific realism of generated content specifically sciscore attains performance comparable to human level demonstrating a improvement similar to evaluations conducted by experienced human evaluators furthermore by applying our proposed fine tuning method to flux we achieve a performance enhancement exceeding on sciscore,"['science', 't', 'i', 'addressing', 'scientific', 'illusions', 'in', 'image', 'synthesis']","['we', 'present', 'a', 'novel', 'approach', 'to', 'integrating', 'scientific', 'knowledge', 'into', 'generative', 'models', 'enhancing', 'their', 'realism', 'and', 'consistency', 'in', 'image', 'synthesis', 'first', 'we', 'introduce', 'science', 't', 'i', 'an', 'expert', 'annotated', 'adversarial', 'dataset', 'comprising', 'adversarial', 'k', 'image', 'pairs', 'with', 'k', 'prompts', 'covering', 'wide', 'distinct', 'scientific', 'knowledge', 'categories', 'leveraging', 'science', 't', 'i', 'we', 'present', 'sciscore', 'an', 'end', 'to', 'end', 'reward', 'model', 'that', 'refines', 'the', 'assessment', 'of', 'generated', 'images', 'based', 'on', 'scientific', 'knowledge', 'which', 'is', 'achieved', 'by', 'augmenting', 'both', 'the', 'scientific', 'comprehension', 'and', 'visual', 'capabilities', 'of', 'pre', 'trained', 'clip', 'model', 'additionally', 'based', 'on', 'sciscore', 'we', 'propose', 'a', 'two', 'stage', 'training', 'framework', 'comprising', 'a', 'supervised', 'fine', 'tuning', 'phase', 'and', 'a', 'masked', 'online', 'fine', 'tuning', 'phase', 'to', 'incorporate', 'scientific', 'knowledge', 'into', 'existing', 'generative', 'models', 'through', 'comprehensive', 'experiments', 'we', 'demonstrate', 'the', 'effectiveness', 'of', 'our', 'framework', 'in', 'establishing', 'new', 'standards', 'for', 'evaluating', 'the', 'scientific', 'realism', 'of', 'generated', 'content', 'specifically', 'sciscore', 'attains', 'performance', 'comparable', 'to', 'human', 'level', 'demonstrating', 'a', 'improvement', 'similar', 'to', 'evaluations', 'conducted', 'by', 'experienced', 'human', 'evaluators', 'furthermore', 'by', 'applying', 'our', 'proposed', 'fine', 'tuning', 'method', 'to', 'flux', 'we', 'achieve', 'a', 'performance', 'enhancement', 'exceeding', 'on', 'sciscore']",9,177,"['Through', 'Leveraging', 'T2I', 'SciScore', 'FLUX', '20k', 'First', 'Science', 'Furthermore', 'Additionally', 'Specifically', 'CLIP']"
2504.13128v1,FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on   Technical Documents,"We introduce FreshStack, a reusable framework for automatically building information retrieval (IR) evaluation benchmarks from community-asked questions and answers. FreshStack conducts the following steps: (1) automatic corpus collection from code and technical documentation, (2) nugget generation from community-asked questions and answers, and (3) nugget-level support, retrieving documents using a fusion of retrieval techniques and hybrid architectures. We use FreshStack to build five datasets on fast-growing, recent, and niche topics to ensure the tasks are sufficiently challenging. On FreshStack, existing retrieval models, when applied out-of-the-box, significantly underperform oracle approaches on all five topics, denoting plenty of headroom to improve IR quality. In addition, we identify cases where rerankers do not clearly improve first-stage retrieval accuracy (two out of five topics). We hope that FreshStack will facilitate future work toward constructing realistic, scalable, and uncontaminated IR and RAG evaluation benchmarks. FreshStack datasets are available at: https://fresh-stack.github.io.","Nandan Thakur, Jimmy Lin, Sam Havens, Michael Carbin, Omar Khattab, Andrew Drozdov","cs.IR, cs.AI, cs.CL",2025-04-17T17:44:06Z,http://arxiv.org/abs/2504.13128v1,freshstack building realistic benchmarks for evaluating retrieval on technical documents,we introduce freshstack a reusable framework for automatically building information retrieval ir evaluation benchmarks from community asked questions and answers freshstack conducts the following steps automatic corpus collection from code and technical documentation nugget generation from community asked questions and answers and nugget level support retrieving documents using a fusion of retrieval techniques and hybrid architectures we use freshstack to build five datasets on fast growing recent and niche topics to ensure the tasks are sufficiently challenging on freshstack existing retrieval models when applied out of the box significantly underperform oracle approaches on all five topics denoting plenty of headroom to improve ir quality in addition we identify cases where rerankers do not clearly improve first stage retrieval accuracy two out of five topics we hope that freshstack will facilitate future work toward constructing realistic scalable and uncontaminated ir and rag evaluation benchmarks freshstack datasets are available at,"['freshstack', 'building', 'realistic', 'benchmarks', 'for', 'evaluating', 'retrieval', 'on', 'technical', 'documents']","['we', 'introduce', 'freshstack', 'a', 'reusable', 'framework', 'for', 'automatically', 'building', 'information', 'retrieval', 'ir', 'evaluation', 'benchmarks', 'from', 'community', 'asked', 'questions', 'and', 'answers', 'freshstack', 'conducts', 'the', 'following', 'steps', 'automatic', 'corpus', 'collection', 'from', 'code', 'and', 'technical', 'documentation', 'nugget', 'generation', 'from', 'community', 'asked', 'questions', 'and', 'answers', 'and', 'nugget', 'level', 'support', 'retrieving', 'documents', 'using', 'a', 'fusion', 'of', 'retrieval', 'techniques', 'and', 'hybrid', 'architectures', 'we', 'use', 'freshstack', 'to', 'build', 'five', 'datasets', 'on', 'fast', 'growing', 'recent', 'and', 'niche', 'topics', 'to', 'ensure', 'the', 'tasks', 'are', 'sufficiently', 'challenging', 'on', 'freshstack', 'existing', 'retrieval', 'models', 'when', 'applied', 'out', 'of', 'the', 'box', 'significantly', 'underperform', 'oracle', 'approaches', 'on', 'all', 'five', 'topics', 'denoting', 'plenty', 'of', 'headroom', 'to', 'improve', 'ir', 'quality', 'in', 'addition', 'we', 'identify', 'cases', 'where', 'rerankers', 'do', 'not', 'clearly', 'improve', 'first', 'stage', 'retrieval', 'accuracy', 'two', 'out', 'of', 'five', 'topics', 'we', 'hope', 'that', 'freshstack', 'will', 'facilitate', 'future', 'work', 'toward', 'constructing', 'realistic', 'scalable', 'and', 'uncontaminated', 'ir', 'and', 'rag', 'evaluation', 'benchmarks', 'freshstack', 'datasets', 'are', 'available', 'at']",10,148,"['RAG', 'FreshStack']"
2504.13123v1,Low-hallucination Synthetic Captions for Large-Scale Vision-Language   Model Pre-training,"In recent years, the field of vision-language model pre-training has experienced rapid advancements, driven primarily by the continuous enhancement of textual capabilities in large language models. However, existing training paradigms for multimodal large language models heavily rely on high-quality image-text pairs. As models and data scales grow exponentially, the availability of such meticulously curated data has become increasingly scarce and saturated, thereby severely limiting further advancements in this domain. This study investigates scalable caption generation techniques for vision-language model pre-training and demonstrates that large-scale low-hallucination synthetic captions can serve dual purposes: 1) acting as a viable alternative to real-world data for pre-training paradigms and 2) achieving superior performance enhancement when integrated into vision-language models through empirical validation. This paper presents three key contributions: 1) a novel pipeline for generating high-quality, low-hallucination, and knowledge-rich synthetic captions. Our continuous DPO methodology yields remarkable results in reducing hallucinations. Specifically, the non-hallucination caption rate on a held-out test set increases from 48.2% to 77.9% for a 7B-size model. 2) Comprehensive empirical validation reveals that our synthetic captions confer superior pre-training advantages over their counterparts. Across 35 vision language tasks, the model trained with our data achieves a significant performance gain of at least 6.2% compared to alt-text pairs and other previous work. Meanwhile, it also offers considerable support in the text-to-image domain. With our dataset, the FID score is reduced by 17.1 on a real-world validation benchmark and 13.3 on the MSCOCO validation benchmark. 3) We will release Hunyuan-Recap100M, a low-hallucination and knowledge-intensive synthetic caption dataset.","Xinsong Zhang, Yarong Zeng, Xinting Huang, Hu Hu, Runquan Xie, Han Hu, Zhanhui Kang","cs.CV, cs.AI",2025-04-17T17:40:06Z,http://arxiv.org/abs/2504.13123v1,low hallucination synthetic captions for large scale vision language model pre training,in recent years the field of vision language model pre training has experienced rapid advancements driven primarily by the continuous enhancement of textual capabilities in large language models however existing training paradigms for multimodal large language models heavily rely on high quality image text pairs as models and data scales grow exponentially the availability of such meticulously curated data has become increasingly scarce and saturated thereby severely limiting further advancements in this domain this study investigates scalable caption generation techniques for vision language model pre training and demonstrates that large scale low hallucination synthetic captions can serve dual purposes acting as a viable alternative to real world data for pre training paradigms and achieving superior performance enhancement when integrated into vision language models through empirical validation this paper presents three key contributions a novel pipeline for generating high quality low hallucination and knowledge rich synthetic captions our continuous dpo methodology yields remarkable results in reducing hallucinations specifically the non hallucination caption rate on a held out test set increases from to for a b size model comprehensive empirical validation reveals that our synthetic captions confer superior pre training advantages over their counterparts across vision language tasks the model trained with our data achieves a significant performance gain of at least compared to alt text pairs and other previous work meanwhile it also offers considerable support in the text to image domain with our dataset the fid score is reduced by on a real world validation benchmark and on the mscoco validation benchmark we will release hunyuan recap m a low hallucination and knowledge intensive synthetic caption dataset,"['low', 'hallucination', 'synthetic', 'captions', 'for', 'large', 'scale', 'vision', 'language', 'model', 'pre', 'training']","['in', 'recent', 'years', 'the', 'field', 'of', 'vision', 'language', 'model', 'pre', 'training', 'has', 'experienced', 'rapid', 'advancements', 'driven', 'primarily', 'by', 'the', 'continuous', 'enhancement', 'of', 'textual', 'capabilities', 'in', 'large', 'language', 'models', 'however', 'existing', 'training', 'paradigms', 'for', 'multimodal', 'large', 'language', 'models', 'heavily', 'rely', 'on', 'high', 'quality', 'image', 'text', 'pairs', 'as', 'models', 'and', 'data', 'scales', 'grow', 'exponentially', 'the', 'availability', 'of', 'such', 'meticulously', 'curated', 'data', 'has', 'become', 'increasingly', 'scarce', 'and', 'saturated', 'thereby', 'severely', 'limiting', 'further', 'advancements', 'in', 'this', 'domain', 'this', 'study', 'investigates', 'scalable', 'caption', 'generation', 'techniques', 'for', 'vision', 'language', 'model', 'pre', 'training', 'and', 'demonstrates', 'that', 'large', 'scale', 'low', 'hallucination', 'synthetic', 'captions', 'can', 'serve', 'dual', 'purposes', 'acting', 'as', 'a', 'viable', 'alternative', 'to', 'real', 'world', 'data', 'for', 'pre', 'training', 'paradigms', 'and', 'achieving', 'superior', 'performance', 'enhancement', 'when', 'integrated', 'into', 'vision', 'language', 'models', 'through', 'empirical', 'validation', 'this', 'paper', 'presents', 'three', 'key', 'contributions', 'a', 'novel', 'pipeline', 'for', 'generating', 'high', 'quality', 'low', 'hallucination', 'and', 'knowledge', 'rich', 'synthetic', 'captions', 'our', 'continuous', 'dpo', 'methodology', 'yields', 'remarkable', 'results', 'in', 'reducing', 'hallucinations', 'specifically', 'the', 'non', 'hallucination', 'caption', 'rate', 'on', 'a', 'held', 'out', 'test', 'set', 'increases', 'from', 'to', 'for', 'a', 'b', 'size', 'model', 'comprehensive', 'empirical', 'validation', 'reveals', 'that', 'our', 'synthetic', 'captions', 'confer', 'superior', 'pre', 'training', 'advantages', 'over', 'their', 'counterparts', 'across', 'vision', 'language', 'tasks', 'the', 'model', 'trained', 'with', 'our', 'data', 'achieves', 'a', 'significant', 'performance', 'gain', 'of', 'at', 'least', 'compared', 'to', 'alt', 'text', 'pairs', 'and', 'other', 'previous', 'work', 'meanwhile', 'it', 'also', 'offers', 'considerable', 'support', 'in', 'the', 'text', 'to', 'image', 'domain', 'with', 'our', 'dataset', 'the', 'fid', 'score', 'is', 'reduced', 'by', 'on', 'a', 'real', 'world', 'validation', 'benchmark', 'and', 'on', 'the', 'mscoco', 'validation', 'benchmark', 'we', 'will', 'release', 'hunyuan', 'recap', 'm', 'a', 'low', 'hallucination', 'and', 'knowledge', 'intensive', 'synthetic', 'caption', 'dataset']",12,267,"['Recap100M', 'FID', 'Comprehensive', 'Hunyuan', 'DPO', 'MSCOCO', '7B-size', 'However', 'Across', 'Meanwhile', 'Specifically', 'Our']"
2504.13120v1,Probing and Inducing Combinational Creativity in Vision-Language Models,"The ability to combine existing concepts into novel ideas stands as a fundamental hallmark of human intelligence. Recent advances in Vision-Language Models (VLMs) like GPT-4V and DALLE-3 have sparked debate about whether their outputs reflect combinational creativity--defined by M. A. Boden (1998) as synthesizing novel ideas through combining existing concepts--or sophisticated pattern matching of training data. Drawing inspiration from cognitive science, we investigate the combinational creativity of VLMs from the lens of concept blending. We propose the Identification-Explanation-Implication (IEI) framework, which decomposes creative processes into three levels: identifying input spaces, extracting shared attributes, and deriving novel semantic implications. To validate this framework, we curate CreativeMashup, a high-quality dataset of 666 artist-generated visual mashups annotated according to the IEI framework. Through extensive experiments, we demonstrate that in comprehension tasks, best VLMs have surpassed average human performance while falling short of expert-level understanding; in generation tasks, incorporating our IEI framework into the generation pipeline significantly enhances the creative quality of VLMs outputs. Our findings establish both a theoretical foundation for evaluating artificial creativity and practical guidelines for improving creative generation in VLMs.","Yongqian Peng, Yuxi Ma, Mengmeng Wang, Yuxuan Wang, Yizhou Wang, Chi Zhang, Yixin Zhu, Zilong Zheng","cs.CV, cs.AI, cs.CL",2025-04-17T17:38:18Z,http://arxiv.org/abs/2504.13120v1,probing and inducing combinational creativity in vision language models,the ability to combine existing concepts into novel ideas stands as a fundamental hallmark of human intelligence recent advances in vision language models vlms like gpt v and dalle have sparked debate about whether their outputs reflect combinational creativity defined by m a boden as synthesizing novel ideas through combining existing concepts or sophisticated pattern matching of training data drawing inspiration from cognitive science we investigate the combinational creativity of vlms from the lens of concept blending we propose the identification explanation implication iei framework which decomposes creative processes into three levels identifying input spaces extracting shared attributes and deriving novel semantic implications to validate this framework we curate creativemashup a high quality dataset of artist generated visual mashups annotated according to the iei framework through extensive experiments we demonstrate that in comprehension tasks best vlms have surpassed average human performance while falling short of expert level understanding in generation tasks incorporating our iei framework into the generation pipeline significantly enhances the creative quality of vlms outputs our findings establish both a theoretical foundation for evaluating artificial creativity and practical guidelines for improving creative generation in vlms,"['probing', 'and', 'inducing', 'combinational', 'creativity', 'in', 'vision', 'language', 'models']","['the', 'ability', 'to', 'combine', 'existing', 'concepts', 'into', 'novel', 'ideas', 'stands', 'as', 'a', 'fundamental', 'hallmark', 'of', 'human', 'intelligence', 'recent', 'advances', 'in', 'vision', 'language', 'models', 'vlms', 'like', 'gpt', 'v', 'and', 'dalle', 'have', 'sparked', 'debate', 'about', 'whether', 'their', 'outputs', 'reflect', 'combinational', 'creativity', 'defined', 'by', 'm', 'a', 'boden', 'as', 'synthesizing', 'novel', 'ideas', 'through', 'combining', 'existing', 'concepts', 'or', 'sophisticated', 'pattern', 'matching', 'of', 'training', 'data', 'drawing', 'inspiration', 'from', 'cognitive', 'science', 'we', 'investigate', 'the', 'combinational', 'creativity', 'of', 'vlms', 'from', 'the', 'lens', 'of', 'concept', 'blending', 'we', 'propose', 'the', 'identification', 'explanation', 'implication', 'iei', 'framework', 'which', 'decomposes', 'creative', 'processes', 'into', 'three', 'levels', 'identifying', 'input', 'spaces', 'extracting', 'shared', 'attributes', 'and', 'deriving', 'novel', 'semantic', 'implications', 'to', 'validate', 'this', 'framework', 'we', 'curate', 'creativemashup', 'a', 'high', 'quality', 'dataset', 'of', 'artist', 'generated', 'visual', 'mashups', 'annotated', 'according', 'to', 'the', 'iei', 'framework', 'through', 'extensive', 'experiments', 'we', 'demonstrate', 'that', 'in', 'comprehension', 'tasks', 'best', 'vlms', 'have', 'surpassed', 'average', 'human', 'performance', 'while', 'falling', 'short', 'of', 'expert', 'level', 'understanding', 'in', 'generation', 'tasks', 'incorporating', 'our', 'iei', 'framework', 'into', 'the', 'generation', 'pipeline', 'significantly', 'enhances', 'the', 'creative', 'quality', 'of', 'vlms', 'outputs', 'our', 'findings', 'establish', 'both', 'a', 'theoretical', 'foundation', 'for', 'evaluating', 'artificial', 'creativity', 'and', 'practical', 'guidelines', 'for', 'improving', 'creative', 'generation', 'in', 'vlms']",9,187,"['Through', 'Explanation', 'Recent', 'Identification', 'IEI', 'Drawing', 'GPT-4V', 'DALLE-3', 'Models', '1998', 'Vision', 'Language', 'Our', 'Boden', '666', 'Implication', 'CreativeMashup', 'VLMs']"
2504.13079v1,Retrieval-Augmented Generation with Conflicting Evidence,"Large language model (LLM) agents are increasingly employing retrieval-augmented generation (RAG) to improve the factuality of their responses. However, in practice, these systems often need to handle ambiguous user queries and potentially conflicting information from multiple sources while also suppressing inaccurate information from noisy or irrelevant documents. Prior work has generally studied and addressed these challenges in isolation, considering only one aspect at a time, such as handling ambiguity or robustness to noise and misinformation. We instead consider multiple factors simultaneously, proposing (i) RAMDocs (Retrieval with Ambiguity and Misinformation in Documents), a new dataset that simulates complex and realistic scenarios for conflicting evidence for a user query, including ambiguity, misinformation, and noise; and (ii) MADAM-RAG, a multi-agent approach in which LLM agents debate over the merits of an answer over multiple rounds, allowing an aggregator to collate responses corresponding to disambiguated entities while discarding misinformation and noise, thereby handling diverse sources of conflict jointly. We demonstrate the effectiveness of MADAM-RAG using both closed and open-source models on AmbigDocs -- which requires presenting all valid answers for ambiguous queries -- improving over strong RAG baselines by up to 11.40% and on FaithEval -- which requires suppressing misinformation -- where we improve by up to 15.80% (absolute) with Llama3.3-70B-Instruct. Furthermore, we find that RAMDocs poses a challenge for existing RAG baselines (Llama3.3-70B-Instruct only obtains 32.60 exact match score). While MADAM-RAG begins to address these conflicting factors, our analysis indicates that a substantial gap remains especially when increasing the level of imbalance in supporting evidence and misinformation.","Han Wang, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal","cs.CL, cs.AI",2025-04-17T16:46:11Z,http://arxiv.org/abs/2504.13079v1,retrieval augmented generation with conflicting evidence,large language model llm agents are increasingly employing retrieval augmented generation rag to improve the factuality of their responses however in practice these systems often need to handle ambiguous user queries and potentially conflicting information from multiple sources while also suppressing inaccurate information from noisy or irrelevant documents prior work has generally studied and addressed these challenges in isolation considering only one aspect at a time such as handling ambiguity or robustness to noise and misinformation we instead consider multiple factors simultaneously proposing i ramdocs retrieval with ambiguity and misinformation in documents a new dataset that simulates complex and realistic scenarios for conflicting evidence for a user query including ambiguity misinformation and noise and ii madam rag a multi agent approach in which llm agents debate over the merits of an answer over multiple rounds allowing an aggregator to collate responses corresponding to disambiguated entities while discarding misinformation and noise thereby handling diverse sources of conflict jointly we demonstrate the effectiveness of madam rag using both closed and open source models on ambigdocs which requires presenting all valid answers for ambiguous queries improving over strong rag baselines by up to and on faitheval which requires suppressing misinformation where we improve by up to absolute with llama b instruct furthermore we find that ramdocs poses a challenge for existing rag baselines llama b instruct only obtains exact match score while madam rag begins to address these conflicting factors our analysis indicates that a substantial gap remains especially when increasing the level of imbalance in supporting evidence and misinformation,"['retrieval', 'augmented', 'generation', 'with', 'conflicting', 'evidence']","['large', 'language', 'model', 'llm', 'agents', 'are', 'increasingly', 'employing', 'retrieval', 'augmented', 'generation', 'rag', 'to', 'improve', 'the', 'factuality', 'of', 'their', 'responses', 'however', 'in', 'practice', 'these', 'systems', 'often', 'need', 'to', 'handle', 'ambiguous', 'user', 'queries', 'and', 'potentially', 'conflicting', 'information', 'from', 'multiple', 'sources', 'while', 'also', 'suppressing', 'inaccurate', 'information', 'from', 'noisy', 'or', 'irrelevant', 'documents', 'prior', 'work', 'has', 'generally', 'studied', 'and', 'addressed', 'these', 'challenges', 'in', 'isolation', 'considering', 'only', 'one', 'aspect', 'at', 'a', 'time', 'such', 'as', 'handling', 'ambiguity', 'or', 'robustness', 'to', 'noise', 'and', 'misinformation', 'we', 'instead', 'consider', 'multiple', 'factors', 'simultaneously', 'proposing', 'i', 'ramdocs', 'retrieval', 'with', 'ambiguity', 'and', 'misinformation', 'in', 'documents', 'a', 'new', 'dataset', 'that', 'simulates', 'complex', 'and', 'realistic', 'scenarios', 'for', 'conflicting', 'evidence', 'for', 'a', 'user', 'query', 'including', 'ambiguity', 'misinformation', 'and', 'noise', 'and', 'ii', 'madam', 'rag', 'a', 'multi', 'agent', 'approach', 'in', 'which', 'llm', 'agents', 'debate', 'over', 'the', 'merits', 'of', 'an', 'answer', 'over', 'multiple', 'rounds', 'allowing', 'an', 'aggregator', 'to', 'collate', 'responses', 'corresponding', 'to', 'disambiguated', 'entities', 'while', 'discarding', 'misinformation', 'and', 'noise', 'thereby', 'handling', 'diverse', 'sources', 'of', 'conflict', 'jointly', 'we', 'demonstrate', 'the', 'effectiveness', 'of', 'madam', 'rag', 'using', 'both', 'closed', 'and', 'open', 'source', 'models', 'on', 'ambigdocs', 'which', 'requires', 'presenting', 'all', 'valid', 'answers', 'for', 'ambiguous', 'queries', 'improving', 'over', 'strong', 'rag', 'baselines', 'by', 'up', 'to', 'and', 'on', 'faitheval', 'which', 'requires', 'suppressing', 'misinformation', 'where', 'we', 'improve', 'by', 'up', 'to', 'absolute', 'with', 'llama', 'b', 'instruct', 'furthermore', 'we', 'find', 'that', 'ramdocs', 'poses', 'a', 'challenge', 'for', 'existing', 'rag', 'baselines', 'llama', 'b', 'instruct', 'only', 'obtains', 'exact', 'match', 'score', 'while', 'madam', 'rag', 'begins', 'to', 'address', 'these', 'conflicting', 'factors', 'our', 'analysis', 'indicates', 'that', 'a', 'substantial', 'gap', 'remains', 'especially', 'when', 'increasing', 'the', 'level', 'of', 'imbalance', 'in', 'supporting', 'evidence', 'and', 'misinformation']",6,257,"['3-70B', 'RAG', 'RAMDocs', 'LLM', 'While', 'However', 'Documents', 'FaithEval', 'Llama3', 'Furthermore', 'AmbigDocs', 'Retrieval', 'Instruct', 'Large', 'Prior', 'MADAM-RAG', 'Ambiguity', 'Misinformation']"
2504.13078v1,Enhancing Person-to-Person Virtual Try-On with Multi-Garment Virtual   Try-Off,"Computer vision is transforming fashion through Virtual Try-On (VTON) and Virtual Try-Off (VTOFF). VTON generates images of a person in a specified garment using a target photo and a standardized garment image, while a more challenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a photo of another person wearing the garment. VTOFF, on the other hand, extracts standardized garment images from clothed individuals. We introduce TryOffDiff, a diffusion-based VTOFF model. Built on a latent diffusion framework with SigLIP image conditioning, it effectively captures garment properties like texture, shape, and patterns. TryOffDiff achieves state-of-the-art results on VITON-HD and strong performance on DressCode dataset, covering upper-body, lower-body, and dresses. Enhanced with class-specific embeddings, it pioneers multi-garment VTOFF, the first of its kind. When paired with VTON models, it improves p2p-VTON by minimizing unwanted attribute transfer, such as skin color. Code is available at: https://rizavelioglu.github.io/tryoffdiff/","Riza Velioglu, Petra Bevandic, Robin Chan, Barbara Hammer","cs.CV, cs.AI",2025-04-17T16:45:18Z,http://arxiv.org/abs/2504.13078v1,enhancing person to person virtual try on with multi garment virtual try off,computer vision is transforming fashion through virtual try on vton and virtual try off vtoff vton generates images of a person in a specified garment using a target photo and a standardized garment image while a more challenging variant person to person virtual try on p p vton uses a photo of another person wearing the garment vtoff on the other hand extracts standardized garment images from clothed individuals we introduce tryoffdiff a diffusion based vtoff model built on a latent diffusion framework with siglip image conditioning it effectively captures garment properties like texture shape and patterns tryoffdiff achieves state of the art results on viton hd and strong performance on dresscode dataset covering upper body lower body and dresses enhanced with class specific embeddings it pioneers multi garment vtoff the first of its kind when paired with vton models it improves p p vton by minimizing unwanted attribute transfer such as skin color code is available at,"['enhancing', 'person', 'to', 'person', 'virtual', 'try', 'on', 'with', 'multi', 'garment', 'virtual', 'try', 'off']","['computer', 'vision', 'is', 'transforming', 'fashion', 'through', 'virtual', 'try', 'on', 'vton', 'and', 'virtual', 'try', 'off', 'vtoff', 'vton', 'generates', 'images', 'of', 'a', 'person', 'in', 'a', 'specified', 'garment', 'using', 'a', 'target', 'photo', 'and', 'a', 'standardized', 'garment', 'image', 'while', 'a', 'more', 'challenging', 'variant', 'person', 'to', 'person', 'virtual', 'try', 'on', 'p', 'p', 'vton', 'uses', 'a', 'photo', 'of', 'another', 'person', 'wearing', 'the', 'garment', 'vtoff', 'on', 'the', 'other', 'hand', 'extracts', 'standardized', 'garment', 'images', 'from', 'clothed', 'individuals', 'we', 'introduce', 'tryoffdiff', 'a', 'diffusion', 'based', 'vtoff', 'model', 'built', 'on', 'a', 'latent', 'diffusion', 'framework', 'with', 'siglip', 'image', 'conditioning', 'it', 'effectively', 'captures', 'garment', 'properties', 'like', 'texture', 'shape', 'and', 'patterns', 'tryoffdiff', 'achieves', 'state', 'of', 'the', 'art', 'results', 'on', 'viton', 'hd', 'and', 'strong', 'performance', 'on', 'dresscode', 'dataset', 'covering', 'upper', 'body', 'lower', 'body', 'and', 'dresses', 'enhanced', 'with', 'class', 'specific', 'embeddings', 'it', 'pioneers', 'multi', 'garment', 'vtoff', 'the', 'first', 'of', 'its', 'kind', 'when', 'paired', 'with', 'vton', 'models', 'it', 'improves', 'p', 'p', 'vton', 'by', 'minimizing', 'unwanted', 'attribute', 'transfer', 'such', 'as', 'skin', 'color', 'code', 'is', 'available', 'at']",13,158,"['DressCode', 'Person', 'VTOFF', 'SigLIP', 'Off', 'Virtual', 'VTON', 'Built', 'Computer', 'Code', 'TryOffDiff', 'VITON-HD', 'When', 'Try', 'Enhanced']"
2504.13059v1,RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins,"In the rapidly advancing field of robotics, dual-arm coordination and complex object manipulation are essential capabilities for developing advanced autonomous systems. However, the scarcity of diverse, high-quality demonstration data and real-world-aligned evaluation benchmarks severely limits such development. To address this, we introduce RoboTwin, a generative digital twin framework that uses 3D generative foundation models and large language models to produce diverse expert datasets and provide a real-world-aligned evaluation platform for dual-arm robotic tasks. Specifically, RoboTwin creates varied digital twins of objects from single 2D images, generating realistic and interactive scenarios. It also introduces a spatial relation-aware code generation framework that combines object annotations with large language models to break down tasks, determine spatial constraints, and generate precise robotic movement code. Our framework offers a comprehensive benchmark with both simulated and real-world data, enabling standardized evaluation and better alignment between simulated training and real-world performance. We validated our approach using the open-source COBOT Magic Robot platform. Policies pre-trained on RoboTwin-generated data and fine-tuned with limited real-world samples demonstrate significant potential for enhancing dual-arm robotic manipulation systems by improving success rates by over 70% for single-arm tasks and over 40% for dual-arm tasks compared to models trained solely on real-world data.","Yao Mu, Tianxing Chen, Zanxin Chen, Shijia Peng, Zhiqian Lan, Zeyu Gao, Zhixuan Liang, Qiaojun Yu, Yude Zou, Mingkun Xu, Lunkai Lin, Zhiqiang Xie, Mingyu Ding, Ping Luo","cs.RO, cs.AI, cs.CL",2025-04-17T16:14:24Z,http://arxiv.org/abs/2504.13059v1,robotwin dual arm robot benchmark with generative digital twins,in the rapidly advancing field of robotics dual arm coordination and complex object manipulation are essential capabilities for developing advanced autonomous systems however the scarcity of diverse high quality demonstration data and real world aligned evaluation benchmarks severely limits such development to address this we introduce robotwin a generative digital twin framework that uses d generative foundation models and large language models to produce diverse expert datasets and provide a real world aligned evaluation platform for dual arm robotic tasks specifically robotwin creates varied digital twins of objects from single d images generating realistic and interactive scenarios it also introduces a spatial relation aware code generation framework that combines object annotations with large language models to break down tasks determine spatial constraints and generate precise robotic movement code our framework offers a comprehensive benchmark with both simulated and real world data enabling standardized evaluation and better alignment between simulated training and real world performance we validated our approach using the open source cobot magic robot platform policies pre trained on robotwin generated data and fine tuned with limited real world samples demonstrate significant potential for enhancing dual arm robotic manipulation systems by improving success rates by over for single arm tasks and over for dual arm tasks compared to models trained solely on real world data,"['robotwin', 'dual', 'arm', 'robot', 'benchmark', 'with', 'generative', 'digital', 'twins']","['in', 'the', 'rapidly', 'advancing', 'field', 'of', 'robotics', 'dual', 'arm', 'coordination', 'and', 'complex', 'object', 'manipulation', 'are', 'essential', 'capabilities', 'for', 'developing', 'advanced', 'autonomous', 'systems', 'however', 'the', 'scarcity', 'of', 'diverse', 'high', 'quality', 'demonstration', 'data', 'and', 'real', 'world', 'aligned', 'evaluation', 'benchmarks', 'severely', 'limits', 'such', 'development', 'to', 'address', 'this', 'we', 'introduce', 'robotwin', 'a', 'generative', 'digital', 'twin', 'framework', 'that', 'uses', 'd', 'generative', 'foundation', 'models', 'and', 'large', 'language', 'models', 'to', 'produce', 'diverse', 'expert', 'datasets', 'and', 'provide', 'a', 'real', 'world', 'aligned', 'evaluation', 'platform', 'for', 'dual', 'arm', 'robotic', 'tasks', 'specifically', 'robotwin', 'creates', 'varied', 'digital', 'twins', 'of', 'objects', 'from', 'single', 'd', 'images', 'generating', 'realistic', 'and', 'interactive', 'scenarios', 'it', 'also', 'introduces', 'a', 'spatial', 'relation', 'aware', 'code', 'generation', 'framework', 'that', 'combines', 'object', 'annotations', 'with', 'large', 'language', 'models', 'to', 'break', 'down', 'tasks', 'determine', 'spatial', 'constraints', 'and', 'generate', 'precise', 'robotic', 'movement', 'code', 'our', 'framework', 'offers', 'a', 'comprehensive', 'benchmark', 'with', 'both', 'simulated', 'and', 'real', 'world', 'data', 'enabling', 'standardized', 'evaluation', 'and', 'better', 'alignment', 'between', 'simulated', 'training', 'and', 'real', 'world', 'performance', 'we', 'validated', 'our', 'approach', 'using', 'the', 'open', 'source', 'cobot', 'magic', 'robot', 'platform', 'policies', 'pre', 'trained', 'on', 'robotwin', 'generated', 'data', 'and', 'fine', 'tuned', 'with', 'limited', 'real', 'world', 'samples', 'demonstrate', 'significant', 'potential', 'for', 'enhancing', 'dual', 'arm', 'robotic', 'manipulation', 'systems', 'by', 'improving', 'success', 'rates', 'by', 'over', 'for', 'single', 'arm', 'tasks', 'and', 'over', 'for', 'dual', 'arm', 'tasks', 'compared', 'to', 'models', 'trained', 'solely', 'on', 'real', 'world', 'data']",9,216,"['Robot', 'RoboTwin', 'Magic', 'However', 'COBOT', 'Specifically', 'Our', 'Policies']"
2504.13054v1,Aspect-Based Summarization with Self-Aspect Retrieval Enhanced   Generation,"Aspect-based summarization aims to generate summaries tailored to specific aspects, addressing the resource constraints and limited generalizability of traditional summarization approaches. Recently, large language models have shown promise in this task without the need for training. However, they rely excessively on prompt engineering and face token limits and hallucination challenges, especially with in-context learning. To address these challenges, in this paper, we propose a novel framework for aspect-based summarization: Self-Aspect Retrieval Enhanced Summary Generation. Rather than relying solely on in-context learning, given an aspect, we employ an embedding-driven retrieval mechanism to identify its relevant text segments. This approach extracts the pertinent content while avoiding unnecessary details, thereby mitigating the challenge of token limits. Moreover, our framework optimizes token usage by deleting unrelated parts of the text and ensuring that the model generates output strictly based on the given aspect. With extensive experiments on benchmark datasets, we demonstrate that our framework not only achieves superior performance but also effectively mitigates the token limitation problem.","Yichao Feng, Shuai Zhao, Yueqiu Li, Luwei Xiao, Xiaobao Wu, Anh Tuan Luu","cs.CL, cs.AI",2025-04-17T16:09:57Z,http://arxiv.org/abs/2504.13054v1,aspect based summarization with self aspect retrieval enhanced generation,aspect based summarization aims to generate summaries tailored to specific aspects addressing the resource constraints and limited generalizability of traditional summarization approaches recently large language models have shown promise in this task without the need for training however they rely excessively on prompt engineering and face token limits and hallucination challenges especially with in context learning to address these challenges in this paper we propose a novel framework for aspect based summarization self aspect retrieval enhanced summary generation rather than relying solely on in context learning given an aspect we employ an embedding driven retrieval mechanism to identify its relevant text segments this approach extracts the pertinent content while avoiding unnecessary details thereby mitigating the challenge of token limits moreover our framework optimizes token usage by deleting unrelated parts of the text and ensuring that the model generates output strictly based on the given aspect with extensive experiments on benchmark datasets we demonstrate that our framework not only achieves superior performance but also effectively mitigates the token limitation problem,"['aspect', 'based', 'summarization', 'with', 'self', 'aspect', 'retrieval', 'enhanced', 'generation']","['aspect', 'based', 'summarization', 'aims', 'to', 'generate', 'summaries', 'tailored', 'to', 'specific', 'aspects', 'addressing', 'the', 'resource', 'constraints', 'and', 'limited', 'generalizability', 'of', 'traditional', 'summarization', 'approaches', 'recently', 'large', 'language', 'models', 'have', 'shown', 'promise', 'in', 'this', 'task', 'without', 'the', 'need', 'for', 'training', 'however', 'they', 'rely', 'excessively', 'on', 'prompt', 'engineering', 'and', 'face', 'token', 'limits', 'and', 'hallucination', 'challenges', 'especially', 'with', 'in', 'context', 'learning', 'to', 'address', 'these', 'challenges', 'in', 'this', 'paper', 'we', 'propose', 'a', 'novel', 'framework', 'for', 'aspect', 'based', 'summarization', 'self', 'aspect', 'retrieval', 'enhanced', 'summary', 'generation', 'rather', 'than', 'relying', 'solely', 'on', 'in', 'context', 'learning', 'given', 'an', 'aspect', 'we', 'employ', 'an', 'embedding', 'driven', 'retrieval', 'mechanism', 'to', 'identify', 'its', 'relevant', 'text', 'segments', 'this', 'approach', 'extracts', 'the', 'pertinent', 'content', 'while', 'avoiding', 'unnecessary', 'details', 'thereby', 'mitigating', 'the', 'challenge', 'of', 'token', 'limits', 'moreover', 'our', 'framework', 'optimizes', 'token', 'usage', 'by', 'deleting', 'unrelated', 'parts', 'of', 'the', 'text', 'and', 'ensuring', 'that', 'the', 'model', 'generates', 'output', 'strictly', 'based', 'on', 'the', 'given', 'aspect', 'with', 'extensive', 'experiments', 'on', 'benchmark', 'datasets', 'we', 'demonstrate', 'that', 'our', 'framework', 'not', 'only', 'achieves', 'superior', 'performance', 'but', 'also', 'effectively', 'mitigates', 'the', 'token', 'limitation', 'problem']",9,169,"['Aspect', 'Recently', 'Rather', 'However', 'Summary', 'Self', 'Retrieval', 'Generation', 'Moreover', 'Enhanced']"
2504.13048v1,Design Topological Materials by Reinforcement Fine-Tuned Generative   Model,"Topological insulators (TIs) and topological crystalline insulators (TCIs) are materials with unconventional electronic properties, making their discovery highly valuable for practical applications. However, such materials, particularly those with a full band gap, remain scarce. Given the limitations of traditional approaches that scan known materials for candidates, we focus on the generation of new topological materials through a generative model. Specifically, we apply reinforcement fine-tuning (ReFT) to a pre-trained generative model, thereby aligning the model's objectives with our material design goals. We demonstrate that ReFT is effective in enhancing the model's ability to generate TIs and TCIs, with minimal compromise on the stability of the generated materials. Using the fine-tuned model, we successfully identify a large number of new topological materials, with Ge$_2$Bi$_2$O$_6$ serving as a representative example--a TI with a full band gap of 0.26 eV, ranking among the largest known in this category.","Haosheng Xu, Dongheng Qian, Zhixuan Liu, Yadong Jiang, Jing Wang","cond-mat.mtrl-sci, cs.AI",2025-04-17T16:05:24Z,http://arxiv.org/abs/2504.13048v1,design topological materials by reinforcement fine tuned generative model,topological insulators tis and topological crystalline insulators tcis are materials with unconventional electronic properties making their discovery highly valuable for practical applications however such materials particularly those with a full band gap remain scarce given the limitations of traditional approaches that scan known materials for candidates we focus on the generation of new topological materials through a generative model specifically we apply reinforcement fine tuning reft to a pre trained generative model thereby aligning the model s objectives with our material design goals we demonstrate that reft is effective in enhancing the model s ability to generate tis and tcis with minimal compromise on the stability of the generated materials using the fine tuned model we successfully identify a large number of new topological materials with ge _ bi _ o _ serving as a representative example a ti with a full band gap of ev ranking among the largest known in this category,"['design', 'topological', 'materials', 'by', 'reinforcement', 'fine', 'tuned', 'generative', 'model']","['topological', 'insulators', 'tis', 'and', 'topological', 'crystalline', 'insulators', 'tcis', 'are', 'materials', 'with', 'unconventional', 'electronic', 'properties', 'making', 'their', 'discovery', 'highly', 'valuable', 'for', 'practical', 'applications', 'however', 'such', 'materials', 'particularly', 'those', 'with', 'a', 'full', 'band', 'gap', 'remain', 'scarce', 'given', 'the', 'limitations', 'of', 'traditional', 'approaches', 'that', 'scan', 'known', 'materials', 'for', 'candidates', 'we', 'focus', 'on', 'the', 'generation', 'of', 'new', 'topological', 'materials', 'through', 'a', 'generative', 'model', 'specifically', 'we', 'apply', 'reinforcement', 'fine', 'tuning', 'reft', 'to', 'a', 'pre', 'trained', 'generative', 'model', 'thereby', 'aligning', 'the', 'model', 's', 'objectives', 'with', 'our', 'material', 'design', 'goals', 'we', 'demonstrate', 'that', 'reft', 'is', 'effective', 'in', 'enhancing', 'the', 'model', 's', 'ability', 'to', 'generate', 'tis', 'and', 'tcis', 'with', 'minimal', 'compromise', 'on', 'the', 'stability', 'of', 'the', 'generated', 'materials', 'using', 'the', 'fine', 'tuned', 'model', 'we', 'successfully', 'identify', 'a', 'large', 'number', 'of', 'new', 'topological', 'materials', 'with', 'ge', '_', 'bi', '_', 'o', '_', 'serving', 'as', 'a', 'representative', 'example', 'a', 'ti', 'with', 'a', 'full', 'band', 'gap', 'of', 'ev', 'ranking', 'among', 'the', 'largest', 'known', 'in', 'this', 'category']",9,154,"['Specifically', 'TCIs', 'However', 'Given', 'TIs', 'ReFT', 'Topological']"
2504.13042v1,Event-Enhanced Blurry Video Super-Resolution,"In this paper, we tackle the task of blurry video super-resolution (BVSR), aiming to generate high-resolution (HR) videos from low-resolution (LR) and blurry inputs. Current BVSR methods often fail to restore sharp details at high resolutions, resulting in noticeable artifacts and jitter due to insufficient motion information for deconvolution and the lack of high-frequency details in LR frames. To address these challenges, we introduce event signals into BVSR and propose a novel event-enhanced network, Ev-DeblurVSR. To effectively fuse information from frames and events for feature deblurring, we introduce a reciprocal feature deblurring module that leverages motion information from intra-frame events to deblur frame features while reciprocally using global scene context from the frames to enhance event features. Furthermore, to enhance temporal consistency, we propose a hybrid deformable alignment module that fully exploits the complementary motion information from inter-frame events and optical flow to improve motion estimation in the deformable alignment process. Extensive evaluations demonstrate that Ev-DeblurVSR establishes a new state-of-the-art performance on both synthetic and real-world datasets. Notably, on real data, our method is +2.59 dB more accurate and 7.28$\times$ faster than the recent best BVSR baseline FMA-Net. Code: https://github.com/DachunKai/Ev-DeblurVSR.","Dachun Kai, Yueyi Zhang, Jin Wang, Zeyu Xiao, Zhiwei Xiong, Xiaoyan Sun","cs.CV, cs.AI",2025-04-17T15:55:41Z,http://arxiv.org/abs/2504.13042v1,event enhanced blurry video super resolution,in this paper we tackle the task of blurry video super resolution bvsr aiming to generate high resolution hr videos from low resolution lr and blurry inputs current bvsr methods often fail to restore sharp details at high resolutions resulting in noticeable artifacts and jitter due to insufficient motion information for deconvolution and the lack of high frequency details in lr frames to address these challenges we introduce event signals into bvsr and propose a novel event enhanced network ev deblurvsr to effectively fuse information from frames and events for feature deblurring we introduce a reciprocal feature deblurring module that leverages motion information from intra frame events to deblur frame features while reciprocally using global scene context from the frames to enhance event features furthermore to enhance temporal consistency we propose a hybrid deformable alignment module that fully exploits the complementary motion information from inter frame events and optical flow to improve motion estimation in the deformable alignment process extensive evaluations demonstrate that ev deblurvsr establishes a new state of the art performance on both synthetic and real world datasets notably on real data our method is db more accurate and faster than the recent best bvsr baseline fma net code,"['event', 'enhanced', 'blurry', 'video', 'super', 'resolution']","['in', 'this', 'paper', 'we', 'tackle', 'the', 'task', 'of', 'blurry', 'video', 'super', 'resolution', 'bvsr', 'aiming', 'to', 'generate', 'high', 'resolution', 'hr', 'videos', 'from', 'low', 'resolution', 'lr', 'and', 'blurry', 'inputs', 'current', 'bvsr', 'methods', 'often', 'fail', 'to', 'restore', 'sharp', 'details', 'at', 'high', 'resolutions', 'resulting', 'in', 'noticeable', 'artifacts', 'and', 'jitter', 'due', 'to', 'insufficient', 'motion', 'information', 'for', 'deconvolution', 'and', 'the', 'lack', 'of', 'high', 'frequency', 'details', 'in', 'lr', 'frames', 'to', 'address', 'these', 'challenges', 'we', 'introduce', 'event', 'signals', 'into', 'bvsr', 'and', 'propose', 'a', 'novel', 'event', 'enhanced', 'network', 'ev', 'deblurvsr', 'to', 'effectively', 'fuse', 'information', 'from', 'frames', 'and', 'events', 'for', 'feature', 'deblurring', 'we', 'introduce', 'a', 'reciprocal', 'feature', 'deblurring', 'module', 'that', 'leverages', 'motion', 'information', 'from', 'intra', 'frame', 'events', 'to', 'deblur', 'frame', 'features', 'while', 'reciprocally', 'using', 'global', 'scene', 'context', 'from', 'the', 'frames', 'to', 'enhance', 'event', 'features', 'furthermore', 'to', 'enhance', 'temporal', 'consistency', 'we', 'propose', 'a', 'hybrid', 'deformable', 'alignment', 'module', 'that', 'fully', 'exploits', 'the', 'complementary', 'motion', 'information', 'from', 'inter', 'frame', 'events', 'and', 'optical', 'flow', 'to', 'improve', 'motion', 'estimation', 'in', 'the', 'deformable', 'alignment', 'process', 'extensive', 'evaluations', 'demonstrate', 'that', 'ev', 'deblurvsr', 'establishes', 'a', 'new', 'state', 'of', 'the', 'art', 'performance', 'on', 'both', 'synthetic', 'and', 'real', 'world', 'datasets', 'notably', 'on', 'real', 'data', 'our', 'method', 'is', 'db', 'more', 'accurate', 'and', 'faster', 'than', 'the', 'recent', 'best', 'bvsr', 'baseline', 'fma', 'net', 'code']",6,201,"['Extensive', 'DeblurVSR', 'FMA-Net', 'Code', 'Furthermore', 'BVSR', 'Notably', 'Current', 'DachunKai']"
2504.13032v1,InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction   Graphs for LLM-Based Task Planning,"Recent advancements in large language models (LLMs) have enabled their use as agents for planning complex tasks. Existing methods typically rely on a thought-action-observation (TAO) process to enhance LLM performance, but these approaches are often constrained by the LLMs' limited knowledge of complex tasks. Retrieval-augmented generation (RAG) offers new opportunities by leveraging external databases to ground generation in retrieved information. In this paper, we identify two key challenges (enlargability and transferability) in applying RAG to task planning. We propose InstructRAG, a novel solution within a multi-agent meta-reinforcement learning framework, to address these challenges. InstructRAG includes a graph to organize past instruction paths (sequences of correct actions), an RL-Agent with Reinforcement Learning to expand graph coverage for enlargability, and an ML-Agent with Meta-Learning to improve task generalization for transferability. The two agents are trained end-to-end to optimize overall planning performance. Our experiments on four widely used task planning datasets demonstrate that InstructRAG significantly enhances performance and adapts efficiently to new tasks, achieving up to a 19.2% improvement over the best existing approach.","Zheng Wang, Shu Xian Teo, Jun Jie Chew, Wei Shi","cs.AI, cs.IR",2025-04-17T15:41:39Z,http://arxiv.org/abs/2504.13032v1,instructrag leveraging retrieval augmented generation on instruction graphs for llm based task planning,recent advancements in large language models llms have enabled their use as agents for planning complex tasks existing methods typically rely on a thought action observation tao process to enhance llm performance but these approaches are often constrained by the llms limited knowledge of complex tasks retrieval augmented generation rag offers new opportunities by leveraging external databases to ground generation in retrieved information in this paper we identify two key challenges enlargability and transferability in applying rag to task planning we propose instructrag a novel solution within a multi agent meta reinforcement learning framework to address these challenges instructrag includes a graph to organize past instruction paths sequences of correct actions an rl agent with reinforcement learning to expand graph coverage for enlargability and an ml agent with meta learning to improve task generalization for transferability the two agents are trained end to end to optimize overall planning performance our experiments on four widely used task planning datasets demonstrate that instructrag significantly enhances performance and adapts efficiently to new tasks achieving up to a improvement over the best existing approach,"['instructrag', 'leveraging', 'retrieval', 'augmented', 'generation', 'on', 'instruction', 'graphs', 'for', 'llm', 'based', 'task', 'planning']","['recent', 'advancements', 'in', 'large', 'language', 'models', 'llms', 'have', 'enabled', 'their', 'use', 'as', 'agents', 'for', 'planning', 'complex', 'tasks', 'existing', 'methods', 'typically', 'rely', 'on', 'a', 'thought', 'action', 'observation', 'tao', 'process', 'to', 'enhance', 'llm', 'performance', 'but', 'these', 'approaches', 'are', 'often', 'constrained', 'by', 'the', 'llms', 'limited', 'knowledge', 'of', 'complex', 'tasks', 'retrieval', 'augmented', 'generation', 'rag', 'offers', 'new', 'opportunities', 'by', 'leveraging', 'external', 'databases', 'to', 'ground', 'generation', 'in', 'retrieved', 'information', 'in', 'this', 'paper', 'we', 'identify', 'two', 'key', 'challenges', 'enlargability', 'and', 'transferability', 'in', 'applying', 'rag', 'to', 'task', 'planning', 'we', 'propose', 'instructrag', 'a', 'novel', 'solution', 'within', 'a', 'multi', 'agent', 'meta', 'reinforcement', 'learning', 'framework', 'to', 'address', 'these', 'challenges', 'instructrag', 'includes', 'a', 'graph', 'to', 'organize', 'past', 'instruction', 'paths', 'sequences', 'of', 'correct', 'actions', 'an', 'rl', 'agent', 'with', 'reinforcement', 'learning', 'to', 'expand', 'graph', 'coverage', 'for', 'enlargability', 'and', 'an', 'ml', 'agent', 'with', 'meta', 'learning', 'to', 'improve', 'task', 'generalization', 'for', 'transferability', 'the', 'two', 'agents', 'are', 'trained', 'end', 'to', 'end', 'to', 'optimize', 'overall', 'planning', 'performance', 'our', 'experiments', 'on', 'four', 'widely', 'used', 'task', 'planning', 'datasets', 'demonstrate', 'that', 'instructrag', 'significantly', 'enhances', 'performance', 'and', 'adapts', 'efficiently', 'to', 'new', 'tasks', 'achieving', 'up', 'to', 'a', 'improvement', 'over', 'the', 'best', 'existing', 'approach']",13,180,"['Recent', 'TAO', 'Existing', 'RAG', 'LLMs', 'ML-Agent', 'Meta', 'RL-Agent', 'Learning', 'Retrieval', 'Our', 'InstructRAG', 'LLM', 'Reinforcement']"
2504.13021v1,Pose and Facial Expression Transfer by using StyleGAN,"We propose a method to transfer pose and expression between face images. Given a source and target face portrait, the model produces an output image in which the pose and expression of the source face image are transferred onto the target identity. The architecture consists of two encoders and a mapping network that projects the two inputs into the latent space of StyleGAN2, which finally generates the output. The training is self-supervised from video sequences of many individuals. Manual labeling is not required. Our model enables the synthesis of random identities with controllable pose and expression. Close-to-real-time performance is achieved.","Petr Jahoda, Jan Cech","cs.CV, cs.AI",2025-04-17T15:29:41Z,http://arxiv.org/abs/2504.13021v1,pose and facial expression transfer by using stylegan,we propose a method to transfer pose and expression between face images given a source and target face portrait the model produces an output image in which the pose and expression of the source face image are transferred onto the target identity the architecture consists of two encoders and a mapping network that projects the two inputs into the latent space of stylegan which finally generates the output the training is self supervised from video sequences of many individuals manual labeling is not required our model enables the synthesis of random identities with controllable pose and expression close to real time performance is achieved,"['pose', 'and', 'facial', 'expression', 'transfer', 'by', 'using', 'stylegan']","['we', 'propose', 'a', 'method', 'to', 'transfer', 'pose', 'and', 'expression', 'between', 'face', 'images', 'given', 'a', 'source', 'and', 'target', 'face', 'portrait', 'the', 'model', 'produces', 'an', 'output', 'image', 'in', 'which', 'the', 'pose', 'and', 'expression', 'of', 'the', 'source', 'face', 'image', 'are', 'transferred', 'onto', 'the', 'target', 'identity', 'the', 'architecture', 'consists', 'of', 'two', 'encoders', 'and', 'a', 'mapping', 'network', 'that', 'projects', 'the', 'two', 'inputs', 'into', 'the', 'latent', 'space', 'of', 'stylegan', 'which', 'finally', 'generates', 'the', 'output', 'the', 'training', 'is', 'self', 'supervised', 'from', 'video', 'sequences', 'of', 'many', 'individuals', 'manual', 'labeling', 'is', 'not', 'required', 'our', 'model', 'enables', 'the', 'synthesis', 'of', 'random', 'identities', 'with', 'controllable', 'pose', 'and', 'expression', 'close', 'to', 'real', 'time', 'performance', 'is', 'achieved']",8,104,"['Close', 'Manual', 'Given', 'Our', 'StyleGAN2']"
2504.12984v1,A Virtual Machine for Arbitrary Low-Precision GPGPU Computation in LLM   Serving,"Serving Large Language Models (LLMs) is critical for AI-powered applications but demands substantial computational resources, particularly in memory bandwidth and computational throughput. Low-precision computation has emerged as a key technique to improve efficiency while reducing resource consumption. Existing approaches for generating low-precision kernels are limited to weight bit widths that are powers of two and suffer from suboptimal performance due to high-level GPU programming abstractions. These abstractions restrict critical optimizations, such as fine-grained register management and optimized memory access patterns, which are essential for efficient low-precision computations. In this paper, we introduce a virtual machine (VM) designed for General-Purpose GPU (GPGPU) computing, enabling support for low-precision data types with arbitrary bit widths while maintaining GPU programmability. The proposed VM features a thread-block-level programming model, a hierarchical memory space, a novel algebraic layout system, and extensive support for diverse low-precision data types. VM programs are compiled into highly efficient GPU programs with automatic vectorization and instruction selection. Extensive experiments demonstrate that our VM efficiently supports a full spectrum of low-precision data types, and outperforms state-of-the-art low-precision kernels on their supported types. Compared to existing compilers like Triton and Ladder, as well as hand-optimized kernels such as QuantLLM and Marlin, our VM achieves performance improvements of 1.75x, 2.61x, 1.29x and 1.03x, respectively.","Yaoyao Ding, Bohan Hou, Xiao Zhang, Allan Lin, Tianqi Chen, Cody Yu Hao, Yida Wang, Gennady Pekhimenko","cs.LG, cs.AI, cs.PL",2025-04-17T14:45:03Z,http://arxiv.org/abs/2504.12984v1,a virtual machine for arbitrary low precision gpgpu computation in llm serving,serving large language models llms is critical for ai powered applications but demands substantial computational resources particularly in memory bandwidth and computational throughput low precision computation has emerged as a key technique to improve efficiency while reducing resource consumption existing approaches for generating low precision kernels are limited to weight bit widths that are powers of two and suffer from suboptimal performance due to high level gpu programming abstractions these abstractions restrict critical optimizations such as fine grained register management and optimized memory access patterns which are essential for efficient low precision computations in this paper we introduce a virtual machine vm designed for general purpose gpu gpgpu computing enabling support for low precision data types with arbitrary bit widths while maintaining gpu programmability the proposed vm features a thread block level programming model a hierarchical memory space a novel algebraic layout system and extensive support for diverse low precision data types vm programs are compiled into highly efficient gpu programs with automatic vectorization and instruction selection extensive experiments demonstrate that our vm efficiently supports a full spectrum of low precision data types and outperforms state of the art low precision kernels on their supported types compared to existing compilers like triton and ladder as well as hand optimized kernels such as quantllm and marlin our vm achieves performance improvements of x x x and x respectively,"['a', 'virtual', 'machine', 'for', 'arbitrary', 'low', 'precision', 'gpgpu', 'computation', 'in', 'llm', 'serving']","['serving', 'large', 'language', 'models', 'llms', 'is', 'critical', 'for', 'ai', 'powered', 'applications', 'but', 'demands', 'substantial', 'computational', 'resources', 'particularly', 'in', 'memory', 'bandwidth', 'and', 'computational', 'throughput', 'low', 'precision', 'computation', 'has', 'emerged', 'as', 'a', 'key', 'technique', 'to', 'improve', 'efficiency', 'while', 'reducing', 'resource', 'consumption', 'existing', 'approaches', 'for', 'generating', 'low', 'precision', 'kernels', 'are', 'limited', 'to', 'weight', 'bit', 'widths', 'that', 'are', 'powers', 'of', 'two', 'and', 'suffer', 'from', 'suboptimal', 'performance', 'due', 'to', 'high', 'level', 'gpu', 'programming', 'abstractions', 'these', 'abstractions', 'restrict', 'critical', 'optimizations', 'such', 'as', 'fine', 'grained', 'register', 'management', 'and', 'optimized', 'memory', 'access', 'patterns', 'which', 'are', 'essential', 'for', 'efficient', 'low', 'precision', 'computations', 'in', 'this', 'paper', 'we', 'introduce', 'a', 'virtual', 'machine', 'vm', 'designed', 'for', 'general', 'purpose', 'gpu', 'gpgpu', 'computing', 'enabling', 'support', 'for', 'low', 'precision', 'data', 'types', 'with', 'arbitrary', 'bit', 'widths', 'while', 'maintaining', 'gpu', 'programmability', 'the', 'proposed', 'vm', 'features', 'a', 'thread', 'block', 'level', 'programming', 'model', 'a', 'hierarchical', 'memory', 'space', 'a', 'novel', 'algebraic', 'layout', 'system', 'and', 'extensive', 'support', 'for', 'diverse', 'low', 'precision', 'data', 'types', 'vm', 'programs', 'are', 'compiled', 'into', 'highly', 'efficient', 'gpu', 'programs', 'with', 'automatic', 'vectorization', 'and', 'instruction', 'selection', 'extensive', 'experiments', 'demonstrate', 'that', 'our', 'vm', 'efficiently', 'supports', 'a', 'full', 'spectrum', 'of', 'low', 'precision', 'data', 'types', 'and', 'outperforms', 'state', 'of', 'the', 'art', 'low', 'precision', 'kernels', 'on', 'their', 'supported', 'types', 'compared', 'to', 'existing', 'compilers', 'like', 'triton', 'and', 'ladder', 'as', 'well', 'as', 'hand', 'optimized', 'kernels', 'such', 'as', 'quantllm', 'and', 'marlin', 'our', 'vm', 'achieves', 'performance', 'improvements', 'of', 'x', 'x', 'x', 'and', 'x', 'respectively']",12,227,"['75x', '03x', 'Language', 'Marlin', 'GPU', 'Compared', 'Purpose', 'LLMs', 'Serving', 'Large', 'AI-powered', 'GPGPU', 'Triton', 'Low', 'General', 'Extensive', 'Existing', 'These', 'QuantLLM', '29x', 'Models', 'Ladder', '61x']"
2504.12982v1,Accommodate Knowledge Conflicts in Retrieval-augmented LLMs: Towards   Reliable Response Generation in the Wild,"The proliferation of large language models (LLMs) has significantly advanced information retrieval systems, particularly in response generation (RG). Unfortunately, LLMs often face knowledge conflicts between internal memory and retrievaled external information, arising from misinformation, biases, or outdated knowledge. These conflicts undermine response reliability and introduce uncertainty in decision-making. In this work, we analyze how LLMs navigate knowledge conflicts from an information-theoretic perspective and reveal that when conflicting and supplementary information exhibit significant differences, LLMs confidently resolve their preferences. However, when the distinction is ambiguous, LLMs experience heightened uncertainty. Based on this insight, we propose Swin-VIB, a novel framework that integrates a pipeline of variational information bottleneck models into adaptive augmentation of retrieved information and guiding LLM preference in response generation. Extensive experiments on single-choice, open-ended question-answering (QA), and retrieval augmented generation (RAG) validate our theoretical findings and demonstrate the efficacy of Swin-VIB. Notably, our method improves single-choice task accuracy by at least 7.54\% over competitive baselines.","Jiatai Wang, Zhiwei Xu, Di Jin, Xuewen Yang, Tao Li","cs.CL, cs.AI",2025-04-17T14:40:31Z,http://arxiv.org/abs/2504.12982v1,accommodate knowledge conflicts in retrieval augmented llms towards reliable response generation in the wild,the proliferation of large language models llms has significantly advanced information retrieval systems particularly in response generation rg unfortunately llms often face knowledge conflicts between internal memory and retrievaled external information arising from misinformation biases or outdated knowledge these conflicts undermine response reliability and introduce uncertainty in decision making in this work we analyze how llms navigate knowledge conflicts from an information theoretic perspective and reveal that when conflicting and supplementary information exhibit significant differences llms confidently resolve their preferences however when the distinction is ambiguous llms experience heightened uncertainty based on this insight we propose swin vib a novel framework that integrates a pipeline of variational information bottleneck models into adaptive augmentation of retrieved information and guiding llm preference in response generation extensive experiments on single choice open ended question answering qa and retrieval augmented generation rag validate our theoretical findings and demonstrate the efficacy of swin vib notably our method improves single choice task accuracy by at least over competitive baselines,"['accommodate', 'knowledge', 'conflicts', 'in', 'retrieval', 'augmented', 'llms', 'towards', 'reliable', 'response', 'generation', 'in', 'the', 'wild']","['the', 'proliferation', 'of', 'large', 'language', 'models', 'llms', 'has', 'significantly', 'advanced', 'information', 'retrieval', 'systems', 'particularly', 'in', 'response', 'generation', 'rg', 'unfortunately', 'llms', 'often', 'face', 'knowledge', 'conflicts', 'between', 'internal', 'memory', 'and', 'retrievaled', 'external', 'information', 'arising', 'from', 'misinformation', 'biases', 'or', 'outdated', 'knowledge', 'these', 'conflicts', 'undermine', 'response', 'reliability', 'and', 'introduce', 'uncertainty', 'in', 'decision', 'making', 'in', 'this', 'work', 'we', 'analyze', 'how', 'llms', 'navigate', 'knowledge', 'conflicts', 'from', 'an', 'information', 'theoretic', 'perspective', 'and', 'reveal', 'that', 'when', 'conflicting', 'and', 'supplementary', 'information', 'exhibit', 'significant', 'differences', 'llms', 'confidently', 'resolve', 'their', 'preferences', 'however', 'when', 'the', 'distinction', 'is', 'ambiguous', 'llms', 'experience', 'heightened', 'uncertainty', 'based', 'on', 'this', 'insight', 'we', 'propose', 'swin', 'vib', 'a', 'novel', 'framework', 'that', 'integrates', 'a', 'pipeline', 'of', 'variational', 'information', 'bottleneck', 'models', 'into', 'adaptive', 'augmentation', 'of', 'retrieved', 'information', 'and', 'guiding', 'llm', 'preference', 'in', 'response', 'generation', 'extensive', 'experiments', 'on', 'single', 'choice', 'open', 'ended', 'question', 'answering', 'qa', 'and', 'retrieval', 'augmented', 'generation', 'rag', 'validate', 'our', 'theoretical', 'findings', 'and', 'demonstrate', 'the', 'efficacy', 'of', 'swin', 'vib', 'notably', 'our', 'method', 'improves', 'single', 'choice', 'task', 'accuracy', 'by', 'at', 'least', 'over', 'competitive', 'baselines']",14,163,"['Extensive', 'Based', 'Unfortunately', 'RAG', 'LLMs', 'These', 'However', 'VIB', 'Notably', 'Swin', 'LLM']"
2504.12961v1,QLLM: Do We Really Need a Mixing Network for Credit Assignment in   Multi-Agent Reinforcement Learning?,"Credit assignment has remained a fundamental challenge in multi-agent reinforcement learning (MARL). Previous studies have primarily addressed this issue through value decomposition methods under the centralized training with decentralized execution paradigm, where neural networks are utilized to approximate the nonlinear relationship between individual Q-values and the global Q-value. Although these approaches have achieved considerable success in various benchmark tasks, they still suffer from several limitations, including imprecise attribution of contributions, limited interpretability, and poor scalability in high-dimensional state spaces. To address these challenges, we propose a novel algorithm, \textbf{QLLM}, which facilitates the automatic construction of credit assignment functions using large language models (LLMs). Specifically, the concept of \textbf{TFCAF} is introduced, wherein the credit allocation process is represented as a direct and expressive nonlinear functional formulation. A custom-designed \textit{coder-evaluator} framework is further employed to guide the generation, verification, and refinement of executable code by LLMs, significantly mitigating issues such as hallucination and shallow reasoning during inference. Extensive experiments conducted on several standard MARL benchmarks demonstrate that the proposed method consistently outperforms existing state-of-the-art baselines. Moreover, QLLM exhibits strong generalization capability and maintains compatibility with a wide range of MARL algorithms that utilize mixing networks, positioning it as a promising and versatile solution for complex multi-agent scenarios.","Zhouyang Jiang, Bin Zhang, Airong Wei, Zhiwei Xu","cs.MA, cs.AI",2025-04-17T14:07:11Z,http://arxiv.org/abs/2504.12961v1,qllm do we really need a mixing network for credit assignment in multi agent reinforcement learning,credit assignment has remained a fundamental challenge in multi agent reinforcement learning marl previous studies have primarily addressed this issue through value decomposition methods under the centralized training with decentralized execution paradigm where neural networks are utilized to approximate the nonlinear relationship between individual q values and the global q value although these approaches have achieved considerable success in various benchmark tasks they still suffer from several limitations including imprecise attribution of contributions limited interpretability and poor scalability in high dimensional state spaces to address these challenges we propose a novel algorithm qllm which facilitates the automatic construction of credit assignment functions using large language models llms specifically the concept of tfcaf is introduced wherein the credit allocation process is represented as a direct and expressive nonlinear functional formulation a custom designed coder evaluator framework is further employed to guide the generation verification and refinement of executable code by llms significantly mitigating issues such as hallucination and shallow reasoning during inference extensive experiments conducted on several standard marl benchmarks demonstrate that the proposed method consistently outperforms existing state of the art baselines moreover qllm exhibits strong generalization capability and maintains compatibility with a wide range of marl algorithms that utilize mixing networks positioning it as a promising and versatile solution for complex multi agent scenarios,"['qllm', 'do', 'we', 'really', 'need', 'a', 'mixing', 'network', 'for', 'credit', 'assignment', 'in', 'multi', 'agent', 'reinforcement', 'learning']","['credit', 'assignment', 'has', 'remained', 'a', 'fundamental', 'challenge', 'in', 'multi', 'agent', 'reinforcement', 'learning', 'marl', 'previous', 'studies', 'have', 'primarily', 'addressed', 'this', 'issue', 'through', 'value', 'decomposition', 'methods', 'under', 'the', 'centralized', 'training', 'with', 'decentralized', 'execution', 'paradigm', 'where', 'neural', 'networks', 'are', 'utilized', 'to', 'approximate', 'the', 'nonlinear', 'relationship', 'between', 'individual', 'q', 'values', 'and', 'the', 'global', 'q', 'value', 'although', 'these', 'approaches', 'have', 'achieved', 'considerable', 'success', 'in', 'various', 'benchmark', 'tasks', 'they', 'still', 'suffer', 'from', 'several', 'limitations', 'including', 'imprecise', 'attribution', 'of', 'contributions', 'limited', 'interpretability', 'and', 'poor', 'scalability', 'in', 'high', 'dimensional', 'state', 'spaces', 'to', 'address', 'these', 'challenges', 'we', 'propose', 'a', 'novel', 'algorithm', 'qllm', 'which', 'facilitates', 'the', 'automatic', 'construction', 'of', 'credit', 'assignment', 'functions', 'using', 'large', 'language', 'models', 'llms', 'specifically', 'the', 'concept', 'of', 'tfcaf', 'is', 'introduced', 'wherein', 'the', 'credit', 'allocation', 'process', 'is', 'represented', 'as', 'a', 'direct', 'and', 'expressive', 'nonlinear', 'functional', 'formulation', 'a', 'custom', 'designed', 'coder', 'evaluator', 'framework', 'is', 'further', 'employed', 'to', 'guide', 'the', 'generation', 'verification', 'and', 'refinement', 'of', 'executable', 'code', 'by', 'llms', 'significantly', 'mitigating', 'issues', 'such', 'as', 'hallucination', 'and', 'shallow', 'reasoning', 'during', 'inference', 'extensive', 'experiments', 'conducted', 'on', 'several', 'standard', 'marl', 'benchmarks', 'demonstrate', 'that', 'the', 'proposed', 'method', 'consistently', 'outperforms', 'existing', 'state', 'of', 'the', 'art', 'baselines', 'moreover', 'qllm', 'exhibits', 'strong', 'generalization', 'capability', 'and', 'maintains', 'compatibility', 'with', 'a', 'wide', 'range', 'of', 'marl', 'algorithms', 'that', 'utilize', 'mixing', 'networks', 'positioning', 'it', 'as', 'a', 'promising', 'and', 'versatile', 'solution', 'for', 'complex', 'multi', 'agent', 'scenarios']",16,215,"['QLLM', 'Extensive', 'TFCAF', 'Credit', 'Specifically', 'LLMs', 'MARL', 'Moreover', 'Although', 'Q-value', 'Q-values', 'Previous']"
2504.12951v1,Are Retrials All You Need? Enhancing Large Language Model Reasoning   Without Verbalized Feedback,"Recent advancements in large language models (LLMs) have catalyzed the development of general-purpose autonomous agents, demonstrating remarkable performance in complex reasoning tasks across various domains. This surge has spurred the evolution of a plethora of prompt-based reasoning frameworks. A recent focus has been on iterative reasoning strategies that refine outputs through self-evaluation and verbalized feedback. However, these strategies require additional computational complexity to enable models to recognize and correct their mistakes, leading to a significant increase in their cost. In this work, we introduce the concept of ``retrials without feedback'', an embarrassingly simple yet powerful mechanism for enhancing reasoning frameworks by allowing LLMs to retry problem-solving attempts upon identifying incorrect answers. Unlike conventional iterative refinement methods, our method does not require explicit self-reflection or verbalized feedback, simplifying the refinement process. Our findings indicate that simpler retrial-based approaches often outperform more sophisticated reasoning frameworks, suggesting that the benefits of complex methods may not always justify their computational costs. By challenging the prevailing assumption that more intricate reasoning strategies inherently lead to better performance, our work offers new insights into how simpler, more efficient approaches can achieve optimal results. So, are retrials all you need?","Nearchos Potamitis, Akhil Arora","cs.CL, cs.AI, cs.LG",2025-04-17T13:52:48Z,http://arxiv.org/abs/2504.12951v1,are retrials all you need enhancing large language model reasoning without verbalized feedback,recent advancements in large language models llms have catalyzed the development of general purpose autonomous agents demonstrating remarkable performance in complex reasoning tasks across various domains this surge has spurred the evolution of a plethora of prompt based reasoning frameworks a recent focus has been on iterative reasoning strategies that refine outputs through self evaluation and verbalized feedback however these strategies require additional computational complexity to enable models to recognize and correct their mistakes leading to a significant increase in their cost in this work we introduce the concept of retrials without feedback an embarrassingly simple yet powerful mechanism for enhancing reasoning frameworks by allowing llms to retry problem solving attempts upon identifying incorrect answers unlike conventional iterative refinement methods our method does not require explicit self reflection or verbalized feedback simplifying the refinement process our findings indicate that simpler retrial based approaches often outperform more sophisticated reasoning frameworks suggesting that the benefits of complex methods may not always justify their computational costs by challenging the prevailing assumption that more intricate reasoning strategies inherently lead to better performance our work offers new insights into how simpler more efficient approaches can achieve optimal results so are retrials all you need,"['are', 'retrials', 'all', 'you', 'need', 'enhancing', 'large', 'language', 'model', 'reasoning', 'without', 'verbalized', 'feedback']","['recent', 'advancements', 'in', 'large', 'language', 'models', 'llms', 'have', 'catalyzed', 'the', 'development', 'of', 'general', 'purpose', 'autonomous', 'agents', 'demonstrating', 'remarkable', 'performance', 'in', 'complex', 'reasoning', 'tasks', 'across', 'various', 'domains', 'this', 'surge', 'has', 'spurred', 'the', 'evolution', 'of', 'a', 'plethora', 'of', 'prompt', 'based', 'reasoning', 'frameworks', 'a', 'recent', 'focus', 'has', 'been', 'on', 'iterative', 'reasoning', 'strategies', 'that', 'refine', 'outputs', 'through', 'self', 'evaluation', 'and', 'verbalized', 'feedback', 'however', 'these', 'strategies', 'require', 'additional', 'computational', 'complexity', 'to', 'enable', 'models', 'to', 'recognize', 'and', 'correct', 'their', 'mistakes', 'leading', 'to', 'a', 'significant', 'increase', 'in', 'their', 'cost', 'in', 'this', 'work', 'we', 'introduce', 'the', 'concept', 'of', 'retrials', 'without', 'feedback', 'an', 'embarrassingly', 'simple', 'yet', 'powerful', 'mechanism', 'for', 'enhancing', 'reasoning', 'frameworks', 'by', 'allowing', 'llms', 'to', 'retry', 'problem', 'solving', 'attempts', 'upon', 'identifying', 'incorrect', 'answers', 'unlike', 'conventional', 'iterative', 'refinement', 'methods', 'our', 'method', 'does', 'not', 'require', 'explicit', 'self', 'reflection', 'or', 'verbalized', 'feedback', 'simplifying', 'the', 'refinement', 'process', 'our', 'findings', 'indicate', 'that', 'simpler', 'retrial', 'based', 'approaches', 'often', 'outperform', 'more', 'sophisticated', 'reasoning', 'frameworks', 'suggesting', 'that', 'the', 'benefits', 'of', 'complex', 'methods', 'may', 'not', 'always', 'justify', 'their', 'computational', 'costs', 'by', 'challenging', 'the', 'prevailing', 'assumption', 'that', 'more', 'intricate', 'reasoning', 'strategies', 'inherently', 'lead', 'to', 'better', 'performance', 'our', 'work', 'offers', 'new', 'insights', 'into', 'how', 'simpler', 'more', 'efficient', 'approaches', 'can', 'achieve', 'optimal', 'results', 'so', 'are', 'retrials', 'all', 'you', 'need']",13,199,"['Unlike', 'Recent', 'LLMs', 'However', 'Our']"
2504.12911v1,Benchmarking Multi-National Value Alignment for Large Language Models,"Do Large Language Models (LLMs) hold positions that conflict with your country's values? Occasionally they do! However, existing works primarily focus on ethical reviews, failing to capture the diversity of national values, which encompass broader policy, legal, and moral considerations. Furthermore, current benchmarks that rely on spectrum tests using manually designed questionnaires are not easily scalable.   To address these limitations, we introduce NaVAB, a comprehensive benchmark to evaluate the alignment of LLMs with the values of five major nations: China, the United States, the United Kingdom, France, and Germany. NaVAB implements a national value extraction pipeline to efficiently construct value assessment datasets. Specifically, we propose a modeling procedure with instruction tagging to process raw data sources, a screening process to filter value-related topics and a generation process with a Conflict Reduction mechanism to filter non-conflicting values.We conduct extensive experiments on various LLMs across countries, and the results provide insights into assisting in the identification of misaligned scenarios. Moreover, we demonstrate that NaVAB can be combined with alignment techniques to effectively reduce value concerns by aligning LLMs' values with the target country.","Chengyi Ju, Weijie Shi, Chengzhong Liu, Jiaming Ji, Jipeng Zhang, Ruiyuan Zhang, Jia Zhu, Jiajie Xu, Yaodong Yang, Sirui Han, Yike Guo","cs.CL, cs.AI",2025-04-17T13:01:38Z,http://arxiv.org/abs/2504.12911v1,benchmarking multi national value alignment for large language models,do large language models llms hold positions that conflict with your country s values occasionally they do however existing works primarily focus on ethical reviews failing to capture the diversity of national values which encompass broader policy legal and moral considerations furthermore current benchmarks that rely on spectrum tests using manually designed questionnaires are not easily scalable to address these limitations we introduce navab a comprehensive benchmark to evaluate the alignment of llms with the values of five major nations china the united states the united kingdom france and germany navab implements a national value extraction pipeline to efficiently construct value assessment datasets specifically we propose a modeling procedure with instruction tagging to process raw data sources a screening process to filter value related topics and a generation process with a conflict reduction mechanism to filter non conflicting values we conduct extensive experiments on various llms across countries and the results provide insights into assisting in the identification of misaligned scenarios moreover we demonstrate that navab can be combined with alignment techniques to effectively reduce value concerns by aligning llms values with the target country,"['benchmarking', 'multi', 'national', 'value', 'alignment', 'for', 'large', 'language', 'models']","['do', 'large', 'language', 'models', 'llms', 'hold', 'positions', 'that', 'conflict', 'with', 'your', 'country', 's', 'values', 'occasionally', 'they', 'do', 'however', 'existing', 'works', 'primarily', 'focus', 'on', 'ethical', 'reviews', 'failing', 'to', 'capture', 'the', 'diversity', 'of', 'national', 'values', 'which', 'encompass', 'broader', 'policy', 'legal', 'and', 'moral', 'considerations', 'furthermore', 'current', 'benchmarks', 'that', 'rely', 'on', 'spectrum', 'tests', 'using', 'manually', 'designed', 'questionnaires', 'are', 'not', 'easily', 'scalable', 'to', 'address', 'these', 'limitations', 'we', 'introduce', 'navab', 'a', 'comprehensive', 'benchmark', 'to', 'evaluate', 'the', 'alignment', 'of', 'llms', 'with', 'the', 'values', 'of', 'five', 'major', 'nations', 'china', 'the', 'united', 'states', 'the', 'united', 'kingdom', 'france', 'and', 'germany', 'navab', 'implements', 'a', 'national', 'value', 'extraction', 'pipeline', 'to', 'efficiently', 'construct', 'value', 'assessment', 'datasets', 'specifically', 'we', 'propose', 'a', 'modeling', 'procedure', 'with', 'instruction', 'tagging', 'to', 'process', 'raw', 'data', 'sources', 'a', 'screening', 'process', 'to', 'filter', 'value', 'related', 'topics', 'and', 'a', 'generation', 'process', 'with', 'a', 'conflict', 'reduction', 'mechanism', 'to', 'filter', 'non', 'conflicting', 'values', 'we', 'conduct', 'extensive', 'experiments', 'on', 'various', 'llms', 'across', 'countries', 'and', 'the', 'results', 'provide', 'insights', 'into', 'assisting', 'in', 'the', 'identification', 'of', 'misaligned', 'scenarios', 'moreover', 'we', 'demonstrate', 'that', 'navab', 'can', 'be', 'combined', 'with', 'alignment', 'techniques', 'to', 'effectively', 'reduce', 'value', 'concerns', 'by', 'aligning', 'llms', 'values', 'with', 'the', 'target', 'country']",9,185,"['France', 'Specifically', 'Conflict', 'LLMs', 'However', 'Kingdom', 'Models', 'Language', 'China', 'Furthermore', 'States', 'Germany', 'Occasionally', 'Reduction', 'Large', 'United', 'Moreover', 'NaVAB']"
2504.12867v1,EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text   Prompting,"Human speech goes beyond the mere transfer of information; it is a profound exchange of emotions and a connection between individuals. While Text-to-Speech (TTS) models have made huge progress, they still face challenges in controlling the emotional expression in the generated speech. In this work, we propose EmoVoice, a novel emotion-controllable TTS model that exploits large language models (LLMs) to enable fine-grained freestyle natural language emotion control, and a phoneme boost variant design that makes the model output phoneme tokens and audio tokens in parallel to enhance content consistency, inspired by chain-of-thought (CoT) and modality-of-thought (CoM) techniques. Besides, we introduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring expressive speech and fine-grained emotion labels with natural language descriptions. EmoVoice achieves state-of-the-art performance on the English EmoVoice-DB test set using only synthetic training data, and on the Chinese Secap test set using our in-house data. We further investigate the reliability of existing emotion evaluation metrics and their alignment with human perceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and Gemini to assess emotional speech. Demo samples are available at https://anonymous.4open.science/r/EmoVoice-DF55. Dataset, code, and checkpoints will be released.","Guanrou Yang, Chen Yang, Qian Chen, Ziyang Ma, Wenxi Chen, Wen Wang, Tianrui Wang, Yifan Yang, Zhikang Niu, Wenrui Liu, Fan Yu, Zhihao Du, Zhifu Gao, ShiLiang Zhang, Xie Chen","eess.AS, cs.AI, cs.CL",2025-04-17T11:50:04Z,http://arxiv.org/abs/2504.12867v1,emovoice llm based emotional text to speech model with freestyle text prompting,human speech goes beyond the mere transfer of information it is a profound exchange of emotions and a connection between individuals while text to speech tts models have made huge progress they still face challenges in controlling the emotional expression in the generated speech in this work we propose emovoice a novel emotion controllable tts model that exploits large language models llms to enable fine grained freestyle natural language emotion control and a phoneme boost variant design that makes the model output phoneme tokens and audio tokens in parallel to enhance content consistency inspired by chain of thought cot and modality of thought com techniques besides we introduce emovoice db a high quality hour english emotion dataset featuring expressive speech and fine grained emotion labels with natural language descriptions emovoice achieves state of the art performance on the english emovoice db test set using only synthetic training data and on the chinese secap test set using our in house data we further investigate the reliability of existing emotion evaluation metrics and their alignment with human perceptual preferences and explore using sota multimodal llms gpt o audio and gemini to assess emotional speech demo samples are available at dataset code and checkpoints will be released,"['emovoice', 'llm', 'based', 'emotional', 'text', 'to', 'speech', 'model', 'with', 'freestyle', 'text', 'prompting']","['human', 'speech', 'goes', 'beyond', 'the', 'mere', 'transfer', 'of', 'information', 'it', 'is', 'a', 'profound', 'exchange', 'of', 'emotions', 'and', 'a', 'connection', 'between', 'individuals', 'while', 'text', 'to', 'speech', 'tts', 'models', 'have', 'made', 'huge', 'progress', 'they', 'still', 'face', 'challenges', 'in', 'controlling', 'the', 'emotional', 'expression', 'in', 'the', 'generated', 'speech', 'in', 'this', 'work', 'we', 'propose', 'emovoice', 'a', 'novel', 'emotion', 'controllable', 'tts', 'model', 'that', 'exploits', 'large', 'language', 'models', 'llms', 'to', 'enable', 'fine', 'grained', 'freestyle', 'natural', 'language', 'emotion', 'control', 'and', 'a', 'phoneme', 'boost', 'variant', 'design', 'that', 'makes', 'the', 'model', 'output', 'phoneme', 'tokens', 'and', 'audio', 'tokens', 'in', 'parallel', 'to', 'enhance', 'content', 'consistency', 'inspired', 'by', 'chain', 'of', 'thought', 'cot', 'and', 'modality', 'of', 'thought', 'com', 'techniques', 'besides', 'we', 'introduce', 'emovoice', 'db', 'a', 'high', 'quality', 'hour', 'english', 'emotion', 'dataset', 'featuring', 'expressive', 'speech', 'and', 'fine', 'grained', 'emotion', 'labels', 'with', 'natural', 'language', 'descriptions', 'emovoice', 'achieves', 'state', 'of', 'the', 'art', 'performance', 'on', 'the', 'english', 'emovoice', 'db', 'test', 'set', 'using', 'only', 'synthetic', 'training', 'data', 'and', 'on', 'the', 'chinese', 'secap', 'test', 'set', 'using', 'our', 'in', 'house', 'data', 'we', 'further', 'investigate', 'the', 'reliability', 'of', 'existing', 'emotion', 'evaluation', 'metrics', 'and', 'their', 'alignment', 'with', 'human', 'perceptual', 'preferences', 'and', 'explore', 'using', 'sota', 'multimodal', 'llms', 'gpt', 'o', 'audio', 'and', 'gemini', 'to', 'assess', 'emotional', 'speech', 'demo', 'samples', 'are', 'available', 'at', 'dataset', 'code', 'and', 'checkpoints', 'will', 'be', 'released']",12,204,"['40-hour', 'CoT', 'TTS', 'GPT-4o', 'LLMs', 'While', 'Gemini', 'CoM', 'DF55', 'Besides', 'Secap', 'Demo', 'English', 'Human', 'Text', 'Speech', 'Dataset', 'SOTA', '4open', 'EmoVoice', 'Chinese']"
2504.12856v1,3D-PNAS: 3D Industrial Surface Anomaly Synthesis with Perlin Noise,"Large pretrained vision foundation models have shown significant potential in various vision tasks. However, for industrial anomaly detection, the scarcity of real defect samples poses a critical challenge in leveraging these models. While 2D anomaly generation has significantly advanced with established generative models, the adoption of 3D sensors in industrial manufacturing has made leveraging 3D data for surface quality inspection an emerging trend. In contrast to 2D techniques, 3D anomaly generation remains largely unexplored, limiting the potential of 3D data in industrial quality inspection. To address this gap, we propose a novel yet simple 3D anomaly generation method, 3D-PNAS, based on Perlin noise and surface parameterization. Our method generates realistic 3D surface anomalies by projecting the point cloud onto a 2D plane, sampling multi-scale noise values from a Perlin noise field, and perturbing the point cloud along its normal direction. Through comprehensive visualization experiments, we demonstrate how key parameters - including noise scale, perturbation strength, and octaves, provide fine-grained control over the generated anomalies, enabling the creation of diverse defect patterns from pronounced deformations to subtle surface variations. Additionally, our cross-category experiments show that the method produces consistent yet geometrically plausible anomalies across different object types, adapting to their specific surface characteristics. We also provide a comprehensive codebase and visualization toolkit to facilitate future research.","Yifeng Cheng, Juan Du","cs.GR, cs.AI, cs.CV, cs.LG, cs.RO, I.5.4",2025-04-17T11:23:17Z,http://arxiv.org/abs/2504.12856v1,d pnas d industrial surface anomaly synthesis with perlin noise,large pretrained vision foundation models have shown significant potential in various vision tasks however for industrial anomaly detection the scarcity of real defect samples poses a critical challenge in leveraging these models while d anomaly generation has significantly advanced with established generative models the adoption of d sensors in industrial manufacturing has made leveraging d data for surface quality inspection an emerging trend in contrast to d techniques d anomaly generation remains largely unexplored limiting the potential of d data in industrial quality inspection to address this gap we propose a novel yet simple d anomaly generation method d pnas based on perlin noise and surface parameterization our method generates realistic d surface anomalies by projecting the point cloud onto a d plane sampling multi scale noise values from a perlin noise field and perturbing the point cloud along its normal direction through comprehensive visualization experiments we demonstrate how key parameters including noise scale perturbation strength and octaves provide fine grained control over the generated anomalies enabling the creation of diverse defect patterns from pronounced deformations to subtle surface variations additionally our cross category experiments show that the method produces consistent yet geometrically plausible anomalies across different object types adapting to their specific surface characteristics we also provide a comprehensive codebase and visualization toolkit to facilitate future research,"['d', 'pnas', 'd', 'industrial', 'surface', 'anomaly', 'synthesis', 'with', 'perlin', 'noise']","['large', 'pretrained', 'vision', 'foundation', 'models', 'have', 'shown', 'significant', 'potential', 'in', 'various', 'vision', 'tasks', 'however', 'for', 'industrial', 'anomaly', 'detection', 'the', 'scarcity', 'of', 'real', 'defect', 'samples', 'poses', 'a', 'critical', 'challenge', 'in', 'leveraging', 'these', 'models', 'while', 'd', 'anomaly', 'generation', 'has', 'significantly', 'advanced', 'with', 'established', 'generative', 'models', 'the', 'adoption', 'of', 'd', 'sensors', 'in', 'industrial', 'manufacturing', 'has', 'made', 'leveraging', 'd', 'data', 'for', 'surface', 'quality', 'inspection', 'an', 'emerging', 'trend', 'in', 'contrast', 'to', 'd', 'techniques', 'd', 'anomaly', 'generation', 'remains', 'largely', 'unexplored', 'limiting', 'the', 'potential', 'of', 'd', 'data', 'in', 'industrial', 'quality', 'inspection', 'to', 'address', 'this', 'gap', 'we', 'propose', 'a', 'novel', 'yet', 'simple', 'd', 'anomaly', 'generation', 'method', 'd', 'pnas', 'based', 'on', 'perlin', 'noise', 'and', 'surface', 'parameterization', 'our', 'method', 'generates', 'realistic', 'd', 'surface', 'anomalies', 'by', 'projecting', 'the', 'point', 'cloud', 'onto', 'a', 'd', 'plane', 'sampling', 'multi', 'scale', 'noise', 'values', 'from', 'a', 'perlin', 'noise', 'field', 'and', 'perturbing', 'the', 'point', 'cloud', 'along', 'its', 'normal', 'direction', 'through', 'comprehensive', 'visualization', 'experiments', 'we', 'demonstrate', 'how', 'key', 'parameters', 'including', 'noise', 'scale', 'perturbation', 'strength', 'and', 'octaves', 'provide', 'fine', 'grained', 'control', 'over', 'the', 'generated', 'anomalies', 'enabling', 'the', 'creation', 'of', 'diverse', 'defect', 'patterns', 'from', 'pronounced', 'deformations', 'to', 'subtle', 'surface', 'variations', 'additionally', 'our', 'cross', 'category', 'experiments', 'show', 'that', 'the', 'method', 'produces', 'consistent', 'yet', 'geometrically', 'plausible', 'anomalies', 'across', 'different', 'object', 'types', 'adapting', 'to', 'their', 'specific', 'surface', 'characteristics', 'we', 'also', 'provide', 'a', 'comprehensive', 'codebase', 'and', 'visualization', 'toolkit', 'to', 'facilitate', 'future', 'research']",10,218,"['3D-PNAS', 'While', 'However', 'Perlin', 'Additionally', 'Our', 'Large', 'Through']"
2504.12782v1,Set You Straight: Auto-Steering Denoising Trajectories to Sidestep   Unwanted Concepts,"Ensuring the ethical deployment of text-to-image models requires effective techniques to prevent the generation of harmful or inappropriate content. While concept erasure methods offer a promising solution, existing finetuning-based approaches suffer from notable limitations. Anchor-free methods risk disrupting sampling trajectories, leading to visual artifacts, while anchor-based methods rely on the heuristic selection of anchor concepts. To overcome these shortcomings, we introduce a finetuning framework, dubbed ANT, which Automatically guides deNoising Trajectories to avoid unwanted concepts. ANT is built on a key insight: reversing the condition direction of classifier-free guidance during mid-to-late denoising stages enables precise content modification without sacrificing early-stage structural integrity. This inspires a trajectory-aware objective that preserves the integrity of the early-stage score function field, which steers samples toward the natural image manifold, without relying on heuristic anchor concept selection. For single-concept erasure, we propose an augmentation-enhanced weight saliency map to precisely identify the critical parameters that most significantly contribute to the unwanted concept, enabling more thorough and efficient erasure. For multi-concept erasure, our objective function offers a versatile plug-and-play solution that significantly boosts performance. Extensive experiments demonstrate that ANT achieves state-of-the-art results in both single and multi-concept erasure, delivering high-quality, safe outputs without compromising the generative fidelity. Code is available at https://github.com/lileyang1210/ANT","Leyang Li, Shilin Lu, Yan Ren, Adams Wai-Kin Kong","cs.CV, cs.AI, cs.CR, cs.LG",2025-04-17T09:29:30Z,http://arxiv.org/abs/2504.12782v1,set you straight auto steering denoising trajectories to sidestep unwanted concepts,ensuring the ethical deployment of text to image models requires effective techniques to prevent the generation of harmful or inappropriate content while concept erasure methods offer a promising solution existing finetuning based approaches suffer from notable limitations anchor free methods risk disrupting sampling trajectories leading to visual artifacts while anchor based methods rely on the heuristic selection of anchor concepts to overcome these shortcomings we introduce a finetuning framework dubbed ant which automatically guides denoising trajectories to avoid unwanted concepts ant is built on a key insight reversing the condition direction of classifier free guidance during mid to late denoising stages enables precise content modification without sacrificing early stage structural integrity this inspires a trajectory aware objective that preserves the integrity of the early stage score function field which steers samples toward the natural image manifold without relying on heuristic anchor concept selection for single concept erasure we propose an augmentation enhanced weight saliency map to precisely identify the critical parameters that most significantly contribute to the unwanted concept enabling more thorough and efficient erasure for multi concept erasure our objective function offers a versatile plug and play solution that significantly boosts performance extensive experiments demonstrate that ant achieves state of the art results in both single and multi concept erasure delivering high quality safe outputs without compromising the generative fidelity code is available at,"['set', 'you', 'straight', 'auto', 'steering', 'denoising', 'trajectories', 'to', 'sidestep', 'unwanted', 'concepts']","['ensuring', 'the', 'ethical', 'deployment', 'of', 'text', 'to', 'image', 'models', 'requires', 'effective', 'techniques', 'to', 'prevent', 'the', 'generation', 'of', 'harmful', 'or', 'inappropriate', 'content', 'while', 'concept', 'erasure', 'methods', 'offer', 'a', 'promising', 'solution', 'existing', 'finetuning', 'based', 'approaches', 'suffer', 'from', 'notable', 'limitations', 'anchor', 'free', 'methods', 'risk', 'disrupting', 'sampling', 'trajectories', 'leading', 'to', 'visual', 'artifacts', 'while', 'anchor', 'based', 'methods', 'rely', 'on', 'the', 'heuristic', 'selection', 'of', 'anchor', 'concepts', 'to', 'overcome', 'these', 'shortcomings', 'we', 'introduce', 'a', 'finetuning', 'framework', 'dubbed', 'ant', 'which', 'automatically', 'guides', 'denoising', 'trajectories', 'to', 'avoid', 'unwanted', 'concepts', 'ant', 'is', 'built', 'on', 'a', 'key', 'insight', 'reversing', 'the', 'condition', 'direction', 'of', 'classifier', 'free', 'guidance', 'during', 'mid', 'to', 'late', 'denoising', 'stages', 'enables', 'precise', 'content', 'modification', 'without', 'sacrificing', 'early', 'stage', 'structural', 'integrity', 'this', 'inspires', 'a', 'trajectory', 'aware', 'objective', 'that', 'preserves', 'the', 'integrity', 'of', 'the', 'early', 'stage', 'score', 'function', 'field', 'which', 'steers', 'samples', 'toward', 'the', 'natural', 'image', 'manifold', 'without', 'relying', 'on', 'heuristic', 'anchor', 'concept', 'selection', 'for', 'single', 'concept', 'erasure', 'we', 'propose', 'an', 'augmentation', 'enhanced', 'weight', 'saliency', 'map', 'to', 'precisely', 'identify', 'the', 'critical', 'parameters', 'that', 'most', 'significantly', 'contribute', 'to', 'the', 'unwanted', 'concept', 'enabling', 'more', 'thorough', 'and', 'efficient', 'erasure', 'for', 'multi', 'concept', 'erasure', 'our', 'objective', 'function', 'offers', 'a', 'versatile', 'plug', 'and', 'play', 'solution', 'that', 'significantly', 'boosts', 'performance', 'extensive', 'experiments', 'demonstrate', 'that', 'ant', 'achieves', 'state', 'of', 'the', 'art', 'results', 'in', 'both', 'single', 'and', 'multi', 'concept', 'erasure', 'delivering', 'high', 'quality', 'safe', 'outputs', 'without', 'compromising', 'the', 'generative', 'fidelity', 'code', 'is', 'available', 'at']",11,225,"['Extensive', 'While', 'ANT', 'Code', 'Anchor', 'Automatically', 'Trajectories', 'Ensuring']"
2504.12773v1,Enhancing the Geometric Problem-Solving Ability of Multimodal LLMs via   Symbolic-Neural Integration,"Recent advances in Multimodal Large Language Models (MLLMs) have achieved remarkable progress in general domains and demonstrated promise in multimodal mathematical reasoning. However, applying MLLMs to geometry problem solving (GPS) remains challenging due to lack of accurate step-by-step solution data and severe hallucinations during reasoning. In this paper, we propose GeoGen, a pipeline that can automatically generates step-wise reasoning paths for geometry diagrams. By leveraging the precise symbolic reasoning, \textbf{GeoGen} produces large-scale, high-quality question-answer pairs. To further enhance the logical reasoning ability of MLLMs, we train \textbf{GeoLogic}, a Large Language Model (LLM) using synthetic data generated by GeoGen. Serving as a bridge between natural language and symbolic systems, GeoLogic enables symbolic tools to help verifying MLLM outputs, making the reasoning process more rigorous and alleviating hallucinations. Experimental results show that our approach consistently improves the performance of MLLMs, achieving remarkable results on benchmarks for geometric reasoning tasks. This improvement stems from our integration of the strengths of LLMs and symbolic systems, which enables a more reliable and interpretable approach for the GPS task. Codes are available at https://github.com/ycpNotFound/GeoGen.","Yicheng Pan, Zhenrong Zhang, Pengfei Hu, Jiefeng Ma, Jun Du, Jianshu Zhang, Quan Liu, Jianqing Gao, Feng Ma","cs.CL, cs.AI",2025-04-17T09:13:46Z,http://arxiv.org/abs/2504.12773v1,enhancing the geometric problem solving ability of multimodal llms via symbolic neural integration,recent advances in multimodal large language models mllms have achieved remarkable progress in general domains and demonstrated promise in multimodal mathematical reasoning however applying mllms to geometry problem solving gps remains challenging due to lack of accurate step by step solution data and severe hallucinations during reasoning in this paper we propose geogen a pipeline that can automatically generates step wise reasoning paths for geometry diagrams by leveraging the precise symbolic reasoning geogen produces large scale high quality question answer pairs to further enhance the logical reasoning ability of mllms we train geologic a large language model llm using synthetic data generated by geogen serving as a bridge between natural language and symbolic systems geologic enables symbolic tools to help verifying mllm outputs making the reasoning process more rigorous and alleviating hallucinations experimental results show that our approach consistently improves the performance of mllms achieving remarkable results on benchmarks for geometric reasoning tasks this improvement stems from our integration of the strengths of llms and symbolic systems which enables a more reliable and interpretable approach for the gps task codes are available at,"['enhancing', 'the', 'geometric', 'problem', 'solving', 'ability', 'of', 'multimodal', 'llms', 'via', 'symbolic', 'neural', 'integration']","['recent', 'advances', 'in', 'multimodal', 'large', 'language', 'models', 'mllms', 'have', 'achieved', 'remarkable', 'progress', 'in', 'general', 'domains', 'and', 'demonstrated', 'promise', 'in', 'multimodal', 'mathematical', 'reasoning', 'however', 'applying', 'mllms', 'to', 'geometry', 'problem', 'solving', 'gps', 'remains', 'challenging', 'due', 'to', 'lack', 'of', 'accurate', 'step', 'by', 'step', 'solution', 'data', 'and', 'severe', 'hallucinations', 'during', 'reasoning', 'in', 'this', 'paper', 'we', 'propose', 'geogen', 'a', 'pipeline', 'that', 'can', 'automatically', 'generates', 'step', 'wise', 'reasoning', 'paths', 'for', 'geometry', 'diagrams', 'by', 'leveraging', 'the', 'precise', 'symbolic', 'reasoning', 'geogen', 'produces', 'large', 'scale', 'high', 'quality', 'question', 'answer', 'pairs', 'to', 'further', 'enhance', 'the', 'logical', 'reasoning', 'ability', 'of', 'mllms', 'we', 'train', 'geologic', 'a', 'large', 'language', 'model', 'llm', 'using', 'synthetic', 'data', 'generated', 'by', 'geogen', 'serving', 'as', 'a', 'bridge', 'between', 'natural', 'language', 'and', 'symbolic', 'systems', 'geologic', 'enables', 'symbolic', 'tools', 'to', 'help', 'verifying', 'mllm', 'outputs', 'making', 'the', 'reasoning', 'process', 'more', 'rigorous', 'and', 'alleviating', 'hallucinations', 'experimental', 'results', 'show', 'that', 'our', 'approach', 'consistently', 'improves', 'the', 'performance', 'of', 'mllms', 'achieving', 'remarkable', 'results', 'on', 'benchmarks', 'for', 'geometric', 'reasoning', 'tasks', 'this', 'improvement', 'stems', 'from', 'our', 'integration', 'of', 'the', 'strengths', 'of', 'llms', 'and', 'symbolic', 'systems', 'which', 'enables', 'a', 'more', 'reliable', 'and', 'interpretable', 'approach', 'for', 'the', 'gps', 'task', 'codes', 'are', 'available', 'at']",13,183,"['GeoGen', 'Codes', 'GeoLogic', 'Recent', 'Multimodal', 'Experimental', 'GPS', 'Model', 'MLLM', 'Serving', 'MLLMs', 'However', 'LLMs', 'Models', 'Language', 'Large', 'LLM']"
2504.12755v1,Trajectory Adaptation using Large Language Models,"Adapting robot trajectories based on human instructions as per new situations is essential for achieving more intuitive and scalable human-robot interactions. This work proposes a flexible language-based framework to adapt generic robotic trajectories produced by off-the-shelf motion planners like RRT, A-star, etc, or learned from human demonstrations. We utilize pre-trained LLMs to adapt trajectory waypoints by generating code as a policy for dense robot manipulation, enabling more complex and flexible instructions than current methods. This approach allows us to incorporate a broader range of commands, including numerical inputs. Compared to state-of-the-art feature-based sequence-to-sequence models which require training, our method does not require task-specific training and offers greater interpretability and more effective feedback mechanisms. We validate our approach through simulation experiments on the robotic manipulator, aerial vehicle, and ground robot in the Pybullet and Gazebo simulation environments, demonstrating that LLMs can successfully adapt trajectories to complex human instructions.","Anurag Maurya, Tashmoy Ghosh, Ravi Prakash","cs.RO, cs.AI",2025-04-17T08:48:23Z,http://arxiv.org/abs/2504.12755v1,trajectory adaptation using large language models,adapting robot trajectories based on human instructions as per new situations is essential for achieving more intuitive and scalable human robot interactions this work proposes a flexible language based framework to adapt generic robotic trajectories produced by off the shelf motion planners like rrt a star etc or learned from human demonstrations we utilize pre trained llms to adapt trajectory waypoints by generating code as a policy for dense robot manipulation enabling more complex and flexible instructions than current methods this approach allows us to incorporate a broader range of commands including numerical inputs compared to state of the art feature based sequence to sequence models which require training our method does not require task specific training and offers greater interpretability and more effective feedback mechanisms we validate our approach through simulation experiments on the robotic manipulator aerial vehicle and ground robot in the pybullet and gazebo simulation environments demonstrating that llms can successfully adapt trajectories to complex human instructions,"['trajectory', 'adaptation', 'using', 'large', 'language', 'models']","['adapting', 'robot', 'trajectories', 'based', 'on', 'human', 'instructions', 'as', 'per', 'new', 'situations', 'is', 'essential', 'for', 'achieving', 'more', 'intuitive', 'and', 'scalable', 'human', 'robot', 'interactions', 'this', 'work', 'proposes', 'a', 'flexible', 'language', 'based', 'framework', 'to', 'adapt', 'generic', 'robotic', 'trajectories', 'produced', 'by', 'off', 'the', 'shelf', 'motion', 'planners', 'like', 'rrt', 'a', 'star', 'etc', 'or', 'learned', 'from', 'human', 'demonstrations', 'we', 'utilize', 'pre', 'trained', 'llms', 'to', 'adapt', 'trajectory', 'waypoints', 'by', 'generating', 'code', 'as', 'a', 'policy', 'for', 'dense', 'robot', 'manipulation', 'enabling', 'more', 'complex', 'and', 'flexible', 'instructions', 'than', 'current', 'methods', 'this', 'approach', 'allows', 'us', 'to', 'incorporate', 'a', 'broader', 'range', 'of', 'commands', 'including', 'numerical', 'inputs', 'compared', 'to', 'state', 'of', 'the', 'art', 'feature', 'based', 'sequence', 'to', 'sequence', 'models', 'which', 'require', 'training', 'our', 'method', 'does', 'not', 'require', 'task', 'specific', 'training', 'and', 'offers', 'greater', 'interpretability', 'and', 'more', 'effective', 'feedback', 'mechanisms', 'we', 'validate', 'our', 'approach', 'through', 'simulation', 'experiments', 'on', 'the', 'robotic', 'manipulator', 'aerial', 'vehicle', 'and', 'ground', 'robot', 'in', 'the', 'pybullet', 'and', 'gazebo', 'simulation', 'environments', 'demonstrating', 'that', 'llms', 'can', 'successfully', 'adapt', 'trajectories', 'to', 'complex', 'human', 'instructions']",6,160,"['Gazebo', 'Compared', 'Adapting', 'A-star', 'LLMs', 'RRT', 'Pybullet']"
2504.12734v1,Pandora: A Code-Driven Large Language Model Agent for Unified Reasoning   Across Diverse Structured Knowledge,"Unified Structured Knowledge Reasoning (USKR) aims to answer natural language questions (NLQs) by using structured sources such as tables, databases, and knowledge graphs in a unified way. Existing USKR methods either rely on employing task-specific strategies or custom-defined representations, which struggle to leverage the knowledge transfer between different SKR tasks or align with the prior of LLMs, thereby limiting their performance. This paper proposes a novel USKR framework named \textsc{Pandora}, which takes advantage of \textsc{Python}'s \textsc{Pandas} API to construct a unified knowledge representation for alignment with LLM pre-training. It employs an LLM to generate textual reasoning steps and executable Python code for each question. Demonstrations are drawn from a memory of training examples that cover various SKR tasks, facilitating knowledge transfer. Extensive experiments on four benchmarks involving three SKR tasks demonstrate that \textsc{Pandora} outperforms existing unified frameworks and competes effectively with task-specific methods.","Yongrui Chen, Junhao He, Linbo Fu, Shenyu Zhang, Rihui Jin, Xinbang Dai, Jiaqi Li, Dehai Min, Nan Hu, Yuxin Zhang, Guilin Qi, Yi Huang, Tongtong Wu","cs.CL, cs.AI",2025-04-17T08:18:09Z,http://arxiv.org/abs/2504.12734v1,pandora a code driven large language model agent for unified reasoning across diverse structured knowledge,unified structured knowledge reasoning uskr aims to answer natural language questions nlqs by using structured sources such as tables databases and knowledge graphs in a unified way existing uskr methods either rely on employing task specific strategies or custom defined representations which struggle to leverage the knowledge transfer between different skr tasks or align with the prior of llms thereby limiting their performance this paper proposes a novel uskr framework named pandora which takes advantage of python s pandas api to construct a unified knowledge representation for alignment with llm pre training it employs an llm to generate textual reasoning steps and executable python code for each question demonstrations are drawn from a memory of training examples that cover various skr tasks facilitating knowledge transfer extensive experiments on four benchmarks involving three skr tasks demonstrate that pandora outperforms existing unified frameworks and competes effectively with task specific methods,"['pandora', 'a', 'code', 'driven', 'large', 'language', 'model', 'agent', 'for', 'unified', 'reasoning', 'across', 'diverse', 'structured', 'knowledge']","['unified', 'structured', 'knowledge', 'reasoning', 'uskr', 'aims', 'to', 'answer', 'natural', 'language', 'questions', 'nlqs', 'by', 'using', 'structured', 'sources', 'such', 'as', 'tables', 'databases', 'and', 'knowledge', 'graphs', 'in', 'a', 'unified', 'way', 'existing', 'uskr', 'methods', 'either', 'rely', 'on', 'employing', 'task', 'specific', 'strategies', 'or', 'custom', 'defined', 'representations', 'which', 'struggle', 'to', 'leverage', 'the', 'knowledge', 'transfer', 'between', 'different', 'skr', 'tasks', 'or', 'align', 'with', 'the', 'prior', 'of', 'llms', 'thereby', 'limiting', 'their', 'performance', 'this', 'paper', 'proposes', 'a', 'novel', 'uskr', 'framework', 'named', 'pandora', 'which', 'takes', 'advantage', 'of', 'python', 's', 'pandas', 'api', 'to', 'construct', 'a', 'unified', 'knowledge', 'representation', 'for', 'alignment', 'with', 'llm', 'pre', 'training', 'it', 'employs', 'an', 'llm', 'to', 'generate', 'textual', 'reasoning', 'steps', 'and', 'executable', 'python', 'code', 'for', 'each', 'question', 'demonstrations', 'are', 'drawn', 'from', 'a', 'memory', 'of', 'training', 'examples', 'that', 'cover', 'various', 'skr', 'tasks', 'facilitating', 'knowledge', 'transfer', 'extensive', 'experiments', 'on', 'four', 'benchmarks', 'involving', 'three', 'skr', 'tasks', 'demonstrate', 'that', 'pandora', 'outperforms', 'existing', 'unified', 'frameworks', 'and', 'competes', 'effectively', 'with', 'task', 'specific', 'methods']",15,148,"['Reasoning', 'Extensive', 'NLQs', 'API', 'Existing', 'Demonstrations', 'LLMs', 'Structured', 'Python', 'Pandas', 'USKR', 'Pandora', 'Knowledge', 'LLM', 'Unified', 'SKR']"
2504.12721v1,TimeCapsule: Solving the Jigsaw Puzzle of Long-Term Time Series   Forecasting with Compressed Predictive Representations,"Recent deep learning models for Long-term Time Series Forecasting (LTSF) often emphasize complex, handcrafted designs, while simpler architectures like linear models or MLPs have often outperformed these intricate solutions. In this paper, we revisit and organize the core ideas behind several key techniques, such as redundancy reduction and multi-scale modeling, which are frequently employed in advanced LTSF models. Our goal is to streamline these ideas for more efficient deep learning utilization. To this end, we introduce TimeCapsule, a model built around the principle of high-dimensional information compression that unifies these techniques in a generalized yet simplified framework. Specifically, we model time series as a 3D tensor, incorporating temporal, variate, and level dimensions, and leverage mode production to capture multi-mode dependencies while achieving dimensionality compression. We propose an internal forecast within the compressed representation domain, supported by the Joint-Embedding Predictive Architecture (JEPA), to monitor the learning of predictive representations. Extensive experiments on challenging benchmarks demonstrate the versatility of our method, showing that TimeCapsule can achieve state-of-the-art performance.","Yihang Lu, Yangyang Xu, Qitao Qing, Xianwei Meng","cs.LG, cs.AI, eess.SP",2025-04-17T07:54:26Z,http://arxiv.org/abs/2504.12721v1,timecapsule solving the jigsaw puzzle of long term time series forecasting with compressed predictive representations,recent deep learning models for long term time series forecasting ltsf often emphasize complex handcrafted designs while simpler architectures like linear models or mlps have often outperformed these intricate solutions in this paper we revisit and organize the core ideas behind several key techniques such as redundancy reduction and multi scale modeling which are frequently employed in advanced ltsf models our goal is to streamline these ideas for more efficient deep learning utilization to this end we introduce timecapsule a model built around the principle of high dimensional information compression that unifies these techniques in a generalized yet simplified framework specifically we model time series as a d tensor incorporating temporal variate and level dimensions and leverage mode production to capture multi mode dependencies while achieving dimensionality compression we propose an internal forecast within the compressed representation domain supported by the joint embedding predictive architecture jepa to monitor the learning of predictive representations extensive experiments on challenging benchmarks demonstrate the versatility of our method showing that timecapsule can achieve state of the art performance,"['timecapsule', 'solving', 'the', 'jigsaw', 'puzzle', 'of', 'long', 'term', 'time', 'series', 'forecasting', 'with', 'compressed', 'predictive', 'representations']","['recent', 'deep', 'learning', 'models', 'for', 'long', 'term', 'time', 'series', 'forecasting', 'ltsf', 'often', 'emphasize', 'complex', 'handcrafted', 'designs', 'while', 'simpler', 'architectures', 'like', 'linear', 'models', 'or', 'mlps', 'have', 'often', 'outperformed', 'these', 'intricate', 'solutions', 'in', 'this', 'paper', 'we', 'revisit', 'and', 'organize', 'the', 'core', 'ideas', 'behind', 'several', 'key', 'techniques', 'such', 'as', 'redundancy', 'reduction', 'and', 'multi', 'scale', 'modeling', 'which', 'are', 'frequently', 'employed', 'in', 'advanced', 'ltsf', 'models', 'our', 'goal', 'is', 'to', 'streamline', 'these', 'ideas', 'for', 'more', 'efficient', 'deep', 'learning', 'utilization', 'to', 'this', 'end', 'we', 'introduce', 'timecapsule', 'a', 'model', 'built', 'around', 'the', 'principle', 'of', 'high', 'dimensional', 'information', 'compression', 'that', 'unifies', 'these', 'techniques', 'in', 'a', 'generalized', 'yet', 'simplified', 'framework', 'specifically', 'we', 'model', 'time', 'series', 'as', 'a', 'd', 'tensor', 'incorporating', 'temporal', 'variate', 'and', 'level', 'dimensions', 'and', 'leverage', 'mode', 'production', 'to', 'capture', 'multi', 'mode', 'dependencies', 'while', 'achieving', 'dimensionality', 'compression', 'we', 'propose', 'an', 'internal', 'forecast', 'within', 'the', 'compressed', 'representation', 'domain', 'supported', 'by', 'the', 'joint', 'embedding', 'predictive', 'architecture', 'jepa', 'to', 'monitor', 'the', 'learning', 'of', 'predictive', 'representations', 'extensive', 'experiments', 'on', 'challenging', 'benchmarks', 'demonstrate', 'the', 'versatility', 'of', 'our', 'method', 'showing', 'that', 'timecapsule', 'can', 'achieve', 'state', 'of', 'the', 'art', 'performance']",15,174,"['Series', 'Extensive', 'Recent', 'Predictive', 'Long', 'Embedding', 'Forecasting', 'LTSF', 'Joint', 'Specifically', 'Our', 'JEPA', 'Architecture', 'TimeCapsule', 'MLPs', 'Time']"
2504.12717v1,Post-pre-training for Modality Alignment in Vision-Language Foundation   Models,"Contrastive language image pre-training (CLIP) is an essential component of building modern vision-language foundation models. While CLIP demonstrates remarkable zero-shot performance on downstream tasks, the multi-modal feature spaces still suffer from a modality gap, which is a gap between image and text feature clusters and limits downstream task performance. Although existing works attempt to address the modality gap by modifying pre-training or fine-tuning, they struggle with heavy training costs with large datasets or degradations of zero-shot performance. This paper presents CLIP-Refine, a post-pre-training method for CLIP models at a phase between pre-training and fine-tuning. CLIP-Refine aims to align the feature space with 1 epoch training on small image-text datasets without zero-shot performance degradations. To this end, we introduce two techniques: random feature alignment (RaFA) and hybrid contrastive-distillation (HyCD). RaFA aligns the image and text features to follow a shared prior distribution by minimizing the distance to random reference vectors sampled from the prior. HyCD updates the model with hybrid soft labels generated by combining ground-truth image-text pair labels and outputs from the pre-trained CLIP model. This contributes to achieving both maintaining the past knowledge and learning new knowledge to align features. Our extensive experiments with multiple classification and retrieval tasks show that CLIP-Refine succeeds in mitigating the modality gap and improving the zero-shot performance.","Shin'ya Yamaguchi, Dewei Feng, Sekitoshi Kanai, Kazuki Adachi, Daiki Chijiwa","cs.CV, cs.AI, cs.LG",2025-04-17T07:46:19Z,http://arxiv.org/abs/2504.12717v1,post pre training for modality alignment in vision language foundation models,contrastive language image pre training clip is an essential component of building modern vision language foundation models while clip demonstrates remarkable zero shot performance on downstream tasks the multi modal feature spaces still suffer from a modality gap which is a gap between image and text feature clusters and limits downstream task performance although existing works attempt to address the modality gap by modifying pre training or fine tuning they struggle with heavy training costs with large datasets or degradations of zero shot performance this paper presents clip refine a post pre training method for clip models at a phase between pre training and fine tuning clip refine aims to align the feature space with epoch training on small image text datasets without zero shot performance degradations to this end we introduce two techniques random feature alignment rafa and hybrid contrastive distillation hycd rafa aligns the image and text features to follow a shared prior distribution by minimizing the distance to random reference vectors sampled from the prior hycd updates the model with hybrid soft labels generated by combining ground truth image text pair labels and outputs from the pre trained clip model this contributes to achieving both maintaining the past knowledge and learning new knowledge to align features our extensive experiments with multiple classification and retrieval tasks show that clip refine succeeds in mitigating the modality gap and improving the zero shot performance,"['post', 'pre', 'training', 'for', 'modality', 'alignment', 'in', 'vision', 'language', 'foundation', 'models']","['contrastive', 'language', 'image', 'pre', 'training', 'clip', 'is', 'an', 'essential', 'component', 'of', 'building', 'modern', 'vision', 'language', 'foundation', 'models', 'while', 'clip', 'demonstrates', 'remarkable', 'zero', 'shot', 'performance', 'on', 'downstream', 'tasks', 'the', 'multi', 'modal', 'feature', 'spaces', 'still', 'suffer', 'from', 'a', 'modality', 'gap', 'which', 'is', 'a', 'gap', 'between', 'image', 'and', 'text', 'feature', 'clusters', 'and', 'limits', 'downstream', 'task', 'performance', 'although', 'existing', 'works', 'attempt', 'to', 'address', 'the', 'modality', 'gap', 'by', 'modifying', 'pre', 'training', 'or', 'fine', 'tuning', 'they', 'struggle', 'with', 'heavy', 'training', 'costs', 'with', 'large', 'datasets', 'or', 'degradations', 'of', 'zero', 'shot', 'performance', 'this', 'paper', 'presents', 'clip', 'refine', 'a', 'post', 'pre', 'training', 'method', 'for', 'clip', 'models', 'at', 'a', 'phase', 'between', 'pre', 'training', 'and', 'fine', 'tuning', 'clip', 'refine', 'aims', 'to', 'align', 'the', 'feature', 'space', 'with', 'epoch', 'training', 'on', 'small', 'image', 'text', 'datasets', 'without', 'zero', 'shot', 'performance', 'degradations', 'to', 'this', 'end', 'we', 'introduce', 'two', 'techniques', 'random', 'feature', 'alignment', 'rafa', 'and', 'hybrid', 'contrastive', 'distillation', 'hycd', 'rafa', 'aligns', 'the', 'image', 'and', 'text', 'features', 'to', 'follow', 'a', 'shared', 'prior', 'distribution', 'by', 'minimizing', 'the', 'distance', 'to', 'random', 'reference', 'vectors', 'sampled', 'from', 'the', 'prior', 'hycd', 'updates', 'the', 'model', 'with', 'hybrid', 'soft', 'labels', 'generated', 'by', 'combining', 'ground', 'truth', 'image', 'text', 'pair', 'labels', 'and', 'outputs', 'from', 'the', 'pre', 'trained', 'clip', 'model', 'this', 'contributes', 'to', 'achieving', 'both', 'maintaining', 'the', 'past', 'knowledge', 'and', 'learning', 'new', 'knowledge', 'to', 'align', 'features', 'our', 'extensive', 'experiments', 'with', 'multiple', 'classification', 'and', 'retrieval', 'tasks', 'show', 'that', 'clip', 'refine', 'succeeds', 'in', 'mitigating', 'the', 'modality', 'gap', 'and', 'improving', 'the', 'zero', 'shot', 'performance']",11,234,"['CLIP-Refine', 'HyCD', 'While', 'RaFA', 'Although', 'Our', 'Contrastive', 'CLIP']"
2504.12714v1,Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination,"Zero-shot coordination (ZSC), the ability to adapt to a new partner in a cooperative task, is a critical component of human-compatible AI. While prior work has focused on training agents to cooperate on a single task, these specialized models do not generalize to new tasks, even if they are highly similar. Here, we study how reinforcement learning on a distribution of environments with a single partner enables learning general cooperative skills that support ZSC with many new partners on many new problems. We introduce two Jax-based, procedural generators that create billions of solvable coordination challenges. We develop a new paradigm called Cross-Environment Cooperation (CEC), and show that it outperforms competitive baselines quantitatively and qualitatively when collaborating with real people. Our findings suggest that learning to collaborate across many unique scenarios encourages agents to develop general norms, which prove effective for collaboration with different partners. Together, our results suggest a new route toward designing generalist cooperative agents capable of interacting with humans without requiring human data.","Kunal Jha, Wilka Carvalho, Yancheng Liang, Simon S. Du, Max Kleiman-Weiner, Natasha Jaques","cs.MA, cs.AI, cs.LG",2025-04-17T07:41:25Z,http://arxiv.org/abs/2504.12714v1,cross environment cooperation enables zero shot multi agent coordination,zero shot coordination zsc the ability to adapt to a new partner in a cooperative task is a critical component of human compatible ai while prior work has focused on training agents to cooperate on a single task these specialized models do not generalize to new tasks even if they are highly similar here we study how reinforcement learning on a distribution of environments with a single partner enables learning general cooperative skills that support zsc with many new partners on many new problems we introduce two jax based procedural generators that create billions of solvable coordination challenges we develop a new paradigm called cross environment cooperation cec and show that it outperforms competitive baselines quantitatively and qualitatively when collaborating with real people our findings suggest that learning to collaborate across many unique scenarios encourages agents to develop general norms which prove effective for collaboration with different partners together our results suggest a new route toward designing generalist cooperative agents capable of interacting with humans without requiring human data,"['cross', 'environment', 'cooperation', 'enables', 'zero', 'shot', 'multi', 'agent', 'coordination']","['zero', 'shot', 'coordination', 'zsc', 'the', 'ability', 'to', 'adapt', 'to', 'a', 'new', 'partner', 'in', 'a', 'cooperative', 'task', 'is', 'a', 'critical', 'component', 'of', 'human', 'compatible', 'ai', 'while', 'prior', 'work', 'has', 'focused', 'on', 'training', 'agents', 'to', 'cooperate', 'on', 'a', 'single', 'task', 'these', 'specialized', 'models', 'do', 'not', 'generalize', 'to', 'new', 'tasks', 'even', 'if', 'they', 'are', 'highly', 'similar', 'here', 'we', 'study', 'how', 'reinforcement', 'learning', 'on', 'a', 'distribution', 'of', 'environments', 'with', 'a', 'single', 'partner', 'enables', 'learning', 'general', 'cooperative', 'skills', 'that', 'support', 'zsc', 'with', 'many', 'new', 'partners', 'on', 'many', 'new', 'problems', 'we', 'introduce', 'two', 'jax', 'based', 'procedural', 'generators', 'that', 'create', 'billions', 'of', 'solvable', 'coordination', 'challenges', 'we', 'develop', 'a', 'new', 'paradigm', 'called', 'cross', 'environment', 'cooperation', 'cec', 'and', 'show', 'that', 'it', 'outperforms', 'competitive', 'baselines', 'quantitatively', 'and', 'qualitatively', 'when', 'collaborating', 'with', 'real', 'people', 'our', 'findings', 'suggest', 'that', 'learning', 'to', 'collaborate', 'across', 'many', 'unique', 'scenarios', 'encourages', 'agents', 'to', 'develop', 'general', 'norms', 'which', 'prove', 'effective', 'for', 'collaboration', 'with', 'different', 'partners', 'together', 'our', 'results', 'suggest', 'a', 'new', 'route', 'toward', 'designing', 'generalist', 'cooperative', 'agents', 'capable', 'of', 'interacting', 'with', 'humans', 'without', 'requiring', 'human', 'data']",9,169,"['Together', 'ZSC', 'Here', 'CEC', 'Cross', 'While', 'Zero', 'Jax', 'Cooperation', 'Our', 'Environment']"
2504.12680v1,Embodied-R: Collaborative Framework for Activating Embodied Spatial   Reasoning in Foundation Models via Reinforcement Learning,"Humans can perceive and reason about spatial relationships from sequential visual observations, such as egocentric video streams. However, how pretrained models acquire such abilities, especially high-level reasoning, remains unclear. This paper introduces Embodied-R, a collaborative framework combining large-scale Vision-Language Models (VLMs) for perception and small-scale Language Models (LMs) for reasoning. Using Reinforcement Learning (RL) with a novel reward system considering think-answer logical consistency, the model achieves slow-thinking capabilities with limited computational resources. After training on only 5k embodied video samples, Embodied-R with a 3B LM matches state-of-the-art multimodal reasoning models (OpenAI-o1, Gemini-2.5-pro) on both in-distribution and out-of-distribution embodied spatial reasoning tasks. Embodied-R also exhibits emergent thinking patterns such as systematic analysis and contextual integration. We further explore research questions including response length, training on VLM, strategies for reward design, and differences in model generalization after SFT (Supervised Fine-Tuning) and RL training.","Baining Zhao, Ziyou Wang, Jianjie Fang, Chen Gao, Fanhang Man, Jinqiang Cui, Xin Wang, Xinlei Chen, Yong Li, Wenwu Zhu","cs.AI, cs.CV",2025-04-17T06:16:11Z,http://arxiv.org/abs/2504.12680v1,embodied r collaborative framework for activating embodied spatial reasoning in foundation models via reinforcement learning,humans can perceive and reason about spatial relationships from sequential visual observations such as egocentric video streams however how pretrained models acquire such abilities especially high level reasoning remains unclear this paper introduces embodied r a collaborative framework combining large scale vision language models vlms for perception and small scale language models lms for reasoning using reinforcement learning rl with a novel reward system considering think answer logical consistency the model achieves slow thinking capabilities with limited computational resources after training on only k embodied video samples embodied r with a b lm matches state of the art multimodal reasoning models openai o gemini pro on both in distribution and out of distribution embodied spatial reasoning tasks embodied r also exhibits emergent thinking patterns such as systematic analysis and contextual integration we further explore research questions including response length training on vlm strategies for reward design and differences in model generalization after sft supervised fine tuning and rl training,"['embodied', 'r', 'collaborative', 'framework', 'for', 'activating', 'embodied', 'spatial', 'reasoning', 'in', 'foundation', 'models', 'via', 'reinforcement', 'learning']","['humans', 'can', 'perceive', 'and', 'reason', 'about', 'spatial', 'relationships', 'from', 'sequential', 'visual', 'observations', 'such', 'as', 'egocentric', 'video', 'streams', 'however', 'how', 'pretrained', 'models', 'acquire', 'such', 'abilities', 'especially', 'high', 'level', 'reasoning', 'remains', 'unclear', 'this', 'paper', 'introduces', 'embodied', 'r', 'a', 'collaborative', 'framework', 'combining', 'large', 'scale', 'vision', 'language', 'models', 'vlms', 'for', 'perception', 'and', 'small', 'scale', 'language', 'models', 'lms', 'for', 'reasoning', 'using', 'reinforcement', 'learning', 'rl', 'with', 'a', 'novel', 'reward', 'system', 'considering', 'think', 'answer', 'logical', 'consistency', 'the', 'model', 'achieves', 'slow', 'thinking', 'capabilities', 'with', 'limited', 'computational', 'resources', 'after', 'training', 'on', 'only', 'k', 'embodied', 'video', 'samples', 'embodied', 'r', 'with', 'a', 'b', 'lm', 'matches', 'state', 'of', 'the', 'art', 'multimodal', 'reasoning', 'models', 'openai', 'o', 'gemini', 'pro', 'on', 'both', 'in', 'distribution', 'and', 'out', 'of', 'distribution', 'embodied', 'spatial', 'reasoning', 'tasks', 'embodied', 'r', 'also', 'exhibits', 'emergent', 'thinking', 'patterns', 'such', 'as', 'systematic', 'analysis', 'and', 'contextual', 'integration', 'we', 'further', 'explore', 'research', 'questions', 'including', 'response', 'length', 'training', 'on', 'vlm', 'strategies', 'for', 'reward', 'design', 'and', 'differences', 'in', 'model', 'generalization', 'after', 'sft', 'supervised', 'fine', 'tuning', 'and', 'rl', 'training']",15,159,"['Fine', 'After', 'Learning', 'Language', 'Reinforcement', '5-pro', 'However', 'Embodied', 'VLMs', 'Gemini-2', 'SFT', 'OpenAI', 'VLM', 'Humans', 'LMs', 'Models', 'Vision', 'Supervised', 'Tuning']"
2504.12673v1,ACoRN: Noise-Robust Abstractive Compression in Retrieval-Augmented   Language Models,"Abstractive compression utilizes smaller langauge models to condense query-relevant context, reducing computational costs in retrieval-augmented generation (RAG). However,retrieved documents often include information that is either irrelevant to answering the query or misleading due to factual incorrect content, despite having high relevance scores. This behavior indicates that abstractive compressors are more likely to omit important information essential for the correct answer, especially in long contexts where attention dispersion occurs. To address this issue, we categorize retrieved documents in a more fine-grained manner and propose Abstractive Compression Robust against Noise (ACoRN), which introduces two novel training steps. First, we use offline data augmentation on the training dataset to enhance compressor robustness against two distinct types of retrieval noise. Second, since the language modelbased compressor cannot fully utilize information from multiple retrieved documents and exhibits positional bias, we perform finetuning to generate summaries centered around key information that directly supports the correct answer. Our experiments demonstrate that T5-large, trained with ACoRN as a compressor, improves EM and F1 scores while preserving the answer string, which could serve as direct evidence. ACoRN excels on datasets with many accuracy-reducing documents, making it highly useful in real-world scenarios.","Singon Kim, Gunho Jung, Seong-Whan Lee","cs.CL, cs.AI",2025-04-17T06:05:35Z,http://arxiv.org/abs/2504.12673v1,acorn noise robust abstractive compression in retrieval augmented language models,abstractive compression utilizes smaller langauge models to condense query relevant context reducing computational costs in retrieval augmented generation rag however retrieved documents often include information that is either irrelevant to answering the query or misleading due to factual incorrect content despite having high relevance scores this behavior indicates that abstractive compressors are more likely to omit important information essential for the correct answer especially in long contexts where attention dispersion occurs to address this issue we categorize retrieved documents in a more fine grained manner and propose abstractive compression robust against noise acorn which introduces two novel training steps first we use offline data augmentation on the training dataset to enhance compressor robustness against two distinct types of retrieval noise second since the language modelbased compressor cannot fully utilize information from multiple retrieved documents and exhibits positional bias we perform finetuning to generate summaries centered around key information that directly supports the correct answer our experiments demonstrate that t large trained with acorn as a compressor improves em and f scores while preserving the answer string which could serve as direct evidence acorn excels on datasets with many accuracy reducing documents making it highly useful in real world scenarios,"['acorn', 'noise', 'robust', 'abstractive', 'compression', 'in', 'retrieval', 'augmented', 'language', 'models']","['abstractive', 'compression', 'utilizes', 'smaller', 'langauge', 'models', 'to', 'condense', 'query', 'relevant', 'context', 'reducing', 'computational', 'costs', 'in', 'retrieval', 'augmented', 'generation', 'rag', 'however', 'retrieved', 'documents', 'often', 'include', 'information', 'that', 'is', 'either', 'irrelevant', 'to', 'answering', 'the', 'query', 'or', 'misleading', 'due', 'to', 'factual', 'incorrect', 'content', 'despite', 'having', 'high', 'relevance', 'scores', 'this', 'behavior', 'indicates', 'that', 'abstractive', 'compressors', 'are', 'more', 'likely', 'to', 'omit', 'important', 'information', 'essential', 'for', 'the', 'correct', 'answer', 'especially', 'in', 'long', 'contexts', 'where', 'attention', 'dispersion', 'occurs', 'to', 'address', 'this', 'issue', 'we', 'categorize', 'retrieved', 'documents', 'in', 'a', 'more', 'fine', 'grained', 'manner', 'and', 'propose', 'abstractive', 'compression', 'robust', 'against', 'noise', 'acorn', 'which', 'introduces', 'two', 'novel', 'training', 'steps', 'first', 'we', 'use', 'offline', 'data', 'augmentation', 'on', 'the', 'training', 'dataset', 'to', 'enhance', 'compressor', 'robustness', 'against', 'two', 'distinct', 'types', 'of', 'retrieval', 'noise', 'second', 'since', 'the', 'language', 'modelbased', 'compressor', 'can', 'not', 'fully', 'utilize', 'information', 'from', 'multiple', 'retrieved', 'documents', 'and', 'exhibits', 'positional', 'bias', 'we', 'perform', 'finetuning', 'to', 'generate', 'summaries', 'centered', 'around', 'key', 'information', 'that', 'directly', 'supports', 'the', 'correct', 'answer', 'our', 'experiments', 'demonstrate', 'that', 't', 'large', 'trained', 'with', 'acorn', 'as', 'a', 'compressor', 'improves', 'em', 'and', 'f', 'scores', 'while', 'preserving', 'the', 'answer', 'string', 'which', 'could', 'serve', 'as', 'direct', 'evidence', 'acorn', 'excels', 'on', 'datasets', 'with', 'many', 'accuracy', 'reducing', 'documents', 'making', 'it', 'highly', 'useful', 'in', 'real', 'world', 'scenarios']",10,200,"['ACoRN', 'RAG', 'However', 'T5-large', 'Second', 'Compression', 'First', 'Robust', 'Noise', 'Our', 'Abstractive']"
2504.12663v1,Persona-judge: Personalized Alignment of Large Language Models via   Token-level Self-judgment,"Aligning language models with human preferences presents significant challenges, particularly in achieving personalization without incurring excessive computational costs. Existing methods rely on reward signals and additional annotated data, limiting their scalability and adaptability to diverse human values. To address these challenges, we introduce Persona-judge, a novel discriminative paradigm that enables training-free personalized alignment with unseen preferences. Instead of optimizing policy parameters through external reward feedback, Persona-judge leverages the intrinsic preference judgment capabilities of the model. Specifically, a draft model generates candidate tokens conditioned on a given preference, while a judge model, embodying another preference, cross-validates the predicted tokens whether to be accepted. Experimental results demonstrate that Persona-judge, using the inherent preference evaluation mechanisms of the model, offers a scalable and computationally efficient solution to personalized alignment, paving the way for more adaptive customized alignment.","Xiaotian Zhang, Ruizhe Chen, Yang Feng, Zuozhu Liu","cs.CL, cs.AI",2025-04-17T05:50:13Z,http://arxiv.org/abs/2504.12663v1,persona judge personalized alignment of large language models via token level self judgment,aligning language models with human preferences presents significant challenges particularly in achieving personalization without incurring excessive computational costs existing methods rely on reward signals and additional annotated data limiting their scalability and adaptability to diverse human values to address these challenges we introduce persona judge a novel discriminative paradigm that enables training free personalized alignment with unseen preferences instead of optimizing policy parameters through external reward feedback persona judge leverages the intrinsic preference judgment capabilities of the model specifically a draft model generates candidate tokens conditioned on a given preference while a judge model embodying another preference cross validates the predicted tokens whether to be accepted experimental results demonstrate that persona judge using the inherent preference evaluation mechanisms of the model offers a scalable and computationally efficient solution to personalized alignment paving the way for more adaptive customized alignment,"['persona', 'judge', 'personalized', 'alignment', 'of', 'large', 'language', 'models', 'via', 'token', 'level', 'self', 'judgment']","['aligning', 'language', 'models', 'with', 'human', 'preferences', 'presents', 'significant', 'challenges', 'particularly', 'in', 'achieving', 'personalization', 'without', 'incurring', 'excessive', 'computational', 'costs', 'existing', 'methods', 'rely', 'on', 'reward', 'signals', 'and', 'additional', 'annotated', 'data', 'limiting', 'their', 'scalability', 'and', 'adaptability', 'to', 'diverse', 'human', 'values', 'to', 'address', 'these', 'challenges', 'we', 'introduce', 'persona', 'judge', 'a', 'novel', 'discriminative', 'paradigm', 'that', 'enables', 'training', 'free', 'personalized', 'alignment', 'with', 'unseen', 'preferences', 'instead', 'of', 'optimizing', 'policy', 'parameters', 'through', 'external', 'reward', 'feedback', 'persona', 'judge', 'leverages', 'the', 'intrinsic', 'preference', 'judgment', 'capabilities', 'of', 'the', 'model', 'specifically', 'a', 'draft', 'model', 'generates', 'candidate', 'tokens', 'conditioned', 'on', 'a', 'given', 'preference', 'while', 'a', 'judge', 'model', 'embodying', 'another', 'preference', 'cross', 'validates', 'the', 'predicted', 'tokens', 'whether', 'to', 'be', 'accepted', 'experimental', 'results', 'demonstrate', 'that', 'persona', 'judge', 'using', 'the', 'inherent', 'preference', 'evaluation', 'mechanisms', 'of', 'the', 'model', 'offers', 'a', 'scalable', 'and', 'computationally', 'efficient', 'solution', 'to', 'personalized', 'alignment', 'paving', 'the', 'way', 'for', 'more', 'adaptive', 'customized', 'alignment']",13,139,"['Experimental', 'Instead', 'Existing', 'Aligning', 'Persona', 'Specifically']"
2504.12637v1,Scaling Instruction-Tuned LLMs to Million-Token Contexts via   Hierarchical Synthetic Data Generation,"Large Language Models (LLMs) struggle with long-context reasoning, not only due to the quadratic scaling of computational complexity with sequence length but also because of the scarcity and expense of annotating long-context data. There has been barely any open-source work that systematically ablates long-context data, nor is there any openly available instruction tuning dataset with contexts surpassing 100K tokens. To bridge this gap, we introduce a novel post-training synthetic data generation strategy designed to efficiently extend the context window of LLMs while preserving their general task performance. Our approach scalably extends to arbitrarily long context lengths, unconstrained by the length of available real-world data, which effectively addresses the scarcity of raw long-context data. Through a step-by-step rotary position embedding (RoPE) scaling training strategy, we demonstrate that our model, with a context length of up to 1M tokens, performs well on the RULER benchmark and InfiniteBench and maintains robust performance on general language tasks.","Linda He, Jue Wang, Maurice Weber, Shang Zhu, Ben Athiwaratkun, Ce Zhang","cs.CL, cs.AI",2025-04-17T04:46:57Z,http://arxiv.org/abs/2504.12637v1,scaling instruction tuned llms to million token contexts via hierarchical synthetic data generation,large language models llms struggle with long context reasoning not only due to the quadratic scaling of computational complexity with sequence length but also because of the scarcity and expense of annotating long context data there has been barely any open source work that systematically ablates long context data nor is there any openly available instruction tuning dataset with contexts surpassing k tokens to bridge this gap we introduce a novel post training synthetic data generation strategy designed to efficiently extend the context window of llms while preserving their general task performance our approach scalably extends to arbitrarily long context lengths unconstrained by the length of available real world data which effectively addresses the scarcity of raw long context data through a step by step rotary position embedding rope scaling training strategy we demonstrate that our model with a context length of up to m tokens performs well on the ruler benchmark and infinitebench and maintains robust performance on general language tasks,"['scaling', 'instruction', 'tuned', 'llms', 'to', 'million', 'token', 'contexts', 'via', 'hierarchical', 'synthetic', 'data', 'generation']","['large', 'language', 'models', 'llms', 'struggle', 'with', 'long', 'context', 'reasoning', 'not', 'only', 'due', 'to', 'the', 'quadratic', 'scaling', 'of', 'computational', 'complexity', 'with', 'sequence', 'length', 'but', 'also', 'because', 'of', 'the', 'scarcity', 'and', 'expense', 'of', 'annotating', 'long', 'context', 'data', 'there', 'has', 'been', 'barely', 'any', 'open', 'source', 'work', 'that', 'systematically', 'ablates', 'long', 'context', 'data', 'nor', 'is', 'there', 'any', 'openly', 'available', 'instruction', 'tuning', 'dataset', 'with', 'contexts', 'surpassing', 'k', 'tokens', 'to', 'bridge', 'this', 'gap', 'we', 'introduce', 'a', 'novel', 'post', 'training', 'synthetic', 'data', 'generation', 'strategy', 'designed', 'to', 'efficiently', 'extend', 'the', 'context', 'window', 'of', 'llms', 'while', 'preserving', 'their', 'general', 'task', 'performance', 'our', 'approach', 'scalably', 'extends', 'to', 'arbitrarily', 'long', 'context', 'lengths', 'unconstrained', 'by', 'the', 'length', 'of', 'available', 'real', 'world', 'data', 'which', 'effectively', 'addresses', 'the', 'scarcity', 'of', 'raw', 'long', 'context', 'data', 'through', 'a', 'step', 'by', 'step', 'rotary', 'position', 'embedding', 'rope', 'scaling', 'training', 'strategy', 'we', 'demonstrate', 'that', 'our', 'model', 'with', 'a', 'context', 'length', 'of', 'up', 'to', 'm', 'tokens', 'performs', 'well', 'on', 'the', 'ruler', 'benchmark', 'and', 'infinitebench', 'and', 'maintains', 'robust', 'performance', 'on', 'general', 'language', 'tasks']",13,162,"['100K', 'LLMs', 'Models', 'RULER', 'InfiniteBench', 'Language', 'Our', 'Large', 'There', 'RoPE', 'Through']"
2504.12612v1,The Chronicles of Foundation AI for Forensics of Multi-Agent Provenance,"Provenance is the chronology of things, resonating with the fundamental pursuit to uncover origins, trace connections, and situate entities within the flow of space and time. As artificial intelligence advances towards autonomous agents capable of interactive collaboration on complex tasks, the provenance of generated content becomes entangled in the interplay of collective creation, where contributions are continuously revised, extended or overwritten. In a multi-agent generative chain, content undergoes successive transformations, often leaving little, if any, trace of prior contributions. In this study, we investigates the problem of tracking multi-agent provenance across the temporal dimension of generation. We propose a chronological system for post hoc attribution of generative history from content alone, without reliance on internal memory states or external meta-information. At its core lies the notion of symbolic chronicles, representing signed and time-stamped records, in a form analogous to the chain of custody in forensic science. The system operates through a feedback loop, whereby each generative timestep updates the chronicle of prior interactions and synchronises it with the synthetic content in the very act of generation. This research seeks to develop an accountable form of collaborative artificial intelligence within evolving cyber ecosystems.","Ching-Chun Chang, Isao Echizen","cs.AI, cs.CR, cs.MA",2025-04-17T03:23:17Z,http://arxiv.org/abs/2504.12612v1,the chronicles of foundation ai for forensics of multi agent provenance,provenance is the chronology of things resonating with the fundamental pursuit to uncover origins trace connections and situate entities within the flow of space and time as artificial intelligence advances towards autonomous agents capable of interactive collaboration on complex tasks the provenance of generated content becomes entangled in the interplay of collective creation where contributions are continuously revised extended or overwritten in a multi agent generative chain content undergoes successive transformations often leaving little if any trace of prior contributions in this study we investigates the problem of tracking multi agent provenance across the temporal dimension of generation we propose a chronological system for post hoc attribution of generative history from content alone without reliance on internal memory states or external meta information at its core lies the notion of symbolic chronicles representing signed and time stamped records in a form analogous to the chain of custody in forensic science the system operates through a feedback loop whereby each generative timestep updates the chronicle of prior interactions and synchronises it with the synthetic content in the very act of generation this research seeks to develop an accountable form of collaborative artificial intelligence within evolving cyber ecosystems,"['the', 'chronicles', 'of', 'foundation', 'ai', 'for', 'forensics', 'of', 'multi', 'agent', 'provenance']","['provenance', 'is', 'the', 'chronology', 'of', 'things', 'resonating', 'with', 'the', 'fundamental', 'pursuit', 'to', 'uncover', 'origins', 'trace', 'connections', 'and', 'situate', 'entities', 'within', 'the', 'flow', 'of', 'space', 'and', 'time', 'as', 'artificial', 'intelligence', 'advances', 'towards', 'autonomous', 'agents', 'capable', 'of', 'interactive', 'collaboration', 'on', 'complex', 'tasks', 'the', 'provenance', 'of', 'generated', 'content', 'becomes', 'entangled', 'in', 'the', 'interplay', 'of', 'collective', 'creation', 'where', 'contributions', 'are', 'continuously', 'revised', 'extended', 'or', 'overwritten', 'in', 'a', 'multi', 'agent', 'generative', 'chain', 'content', 'undergoes', 'successive', 'transformations', 'often', 'leaving', 'little', 'if', 'any', 'trace', 'of', 'prior', 'contributions', 'in', 'this', 'study', 'we', 'investigates', 'the', 'problem', 'of', 'tracking', 'multi', 'agent', 'provenance', 'across', 'the', 'temporal', 'dimension', 'of', 'generation', 'we', 'propose', 'a', 'chronological', 'system', 'for', 'post', 'hoc', 'attribution', 'of', 'generative', 'history', 'from', 'content', 'alone', 'without', 'reliance', 'on', 'internal', 'memory', 'states', 'or', 'external', 'meta', 'information', 'at', 'its', 'core', 'lies', 'the', 'notion', 'of', 'symbolic', 'chronicles', 'representing', 'signed', 'and', 'time', 'stamped', 'records', 'in', 'a', 'form', 'analogous', 'to', 'the', 'chain', 'of', 'custody', 'in', 'forensic', 'science', 'the', 'system', 'operates', 'through', 'a', 'feedback', 'loop', 'whereby', 'each', 'generative', 'timestep', 'updates', 'the', 'chronicle', 'of', 'prior', 'interactions', 'and', 'synchronises', 'it', 'with', 'the', 'synthetic', 'content', 'in', 'the', 'very', 'act', 'of', 'generation', 'this', 'research', 'seeks', 'to', 'develop', 'an', 'accountable', 'form', 'of', 'collaborative', 'artificial', 'intelligence', 'within', 'evolving', 'cyber', 'ecosystems']",11,196,['Provenance']
2504.12608v1,Code Copycat Conundrum: Demystifying Repetition in LLM-based Code   Generation,"Despite recent advances in Large Language Models (LLMs) for code generation, the quality of LLM-generated code still faces significant challenges. One significant issue is code repetition, which refers to the model's tendency to generate structurally redundant code, resulting in inefficiencies and reduced readability. To address this, we conduct the first empirical study to investigate the prevalence and nature of repetition across 19 state-of-the-art code LLMs using three widely-used benchmarks. Our study includes both quantitative and qualitative analyses, revealing that repetition is pervasive and manifests at various granularities and extents, including character, statement, and block levels. We further summarize a taxonomy of 20 repetition patterns. Building on our findings, we propose DeRep, a rule-based technique designed to detect and mitigate repetition in generated code. We evaluate DeRep using both open-source benchmarks and in an industrial setting. Our results demonstrate that DeRep significantly outperforms baselines in reducing repetition (with an average improvements of 91.3%, 93.5%, and 79.9% in rep-3, rep-line, and sim-line metrics) and enhancing code quality (with a Pass@1 increase of 208.3% over greedy search). Furthermore, integrating DeRep improves the performance of existing repetition mitigation methods, with Pass@1 improvements ranging from 53.7% to 215.7%.","Mingwei Liu, Juntao Li, Ying Wang, Xueying Du, Zuoyu Ou, Qiuyuan Chen, Bingxu An, Zhao Wei, Yong Xu, Fangming Zou, Xin Peng, Yiling Lou","cs.SE, cs.AI",2025-04-17T03:13:39Z,http://arxiv.org/abs/2504.12608v1,code copycat conundrum demystifying repetition in llm based code generation,despite recent advances in large language models llms for code generation the quality of llm generated code still faces significant challenges one significant issue is code repetition which refers to the model s tendency to generate structurally redundant code resulting in inefficiencies and reduced readability to address this we conduct the first empirical study to investigate the prevalence and nature of repetition across state of the art code llms using three widely used benchmarks our study includes both quantitative and qualitative analyses revealing that repetition is pervasive and manifests at various granularities and extents including character statement and block levels we further summarize a taxonomy of repetition patterns building on our findings we propose derep a rule based technique designed to detect and mitigate repetition in generated code we evaluate derep using both open source benchmarks and in an industrial setting our results demonstrate that derep significantly outperforms baselines in reducing repetition with an average improvements of and in rep rep line and sim line metrics and enhancing code quality with a pass increase of over greedy search furthermore integrating derep improves the performance of existing repetition mitigation methods with pass improvements ranging from to,"['code', 'copycat', 'conundrum', 'demystifying', 'repetition', 'in', 'llm', 'based', 'code', 'generation']","['despite', 'recent', 'advances', 'in', 'large', 'language', 'models', 'llms', 'for', 'code', 'generation', 'the', 'quality', 'of', 'llm', 'generated', 'code', 'still', 'faces', 'significant', 'challenges', 'one', 'significant', 'issue', 'is', 'code', 'repetition', 'which', 'refers', 'to', 'the', 'model', 's', 'tendency', 'to', 'generate', 'structurally', 'redundant', 'code', 'resulting', 'in', 'inefficiencies', 'and', 'reduced', 'readability', 'to', 'address', 'this', 'we', 'conduct', 'the', 'first', 'empirical', 'study', 'to', 'investigate', 'the', 'prevalence', 'and', 'nature', 'of', 'repetition', 'across', 'state', 'of', 'the', 'art', 'code', 'llms', 'using', 'three', 'widely', 'used', 'benchmarks', 'our', 'study', 'includes', 'both', 'quantitative', 'and', 'qualitative', 'analyses', 'revealing', 'that', 'repetition', 'is', 'pervasive', 'and', 'manifests', 'at', 'various', 'granularities', 'and', 'extents', 'including', 'character', 'statement', 'and', 'block', 'levels', 'we', 'further', 'summarize', 'a', 'taxonomy', 'of', 'repetition', 'patterns', 'building', 'on', 'our', 'findings', 'we', 'propose', 'derep', 'a', 'rule', 'based', 'technique', 'designed', 'to', 'detect', 'and', 'mitigate', 'repetition', 'in', 'generated', 'code', 'we', 'evaluate', 'derep', 'using', 'both', 'open', 'source', 'benchmarks', 'and', 'in', 'an', 'industrial', 'setting', 'our', 'results', 'demonstrate', 'that', 'derep', 'significantly', 'outperforms', 'baselines', 'in', 'reducing', 'repetition', 'with', 'an', 'average', 'improvements', 'of', 'and', 'in', 'rep', 'rep', 'line', 'and', 'sim', 'line', 'metrics', 'and', 'enhancing', 'code', 'quality', 'with', 'a', 'pass', 'increase', 'of', 'over', 'greedy', 'search', 'furthermore', 'integrating', 'derep', 'improves', 'the', 'performance', 'of', 'existing', 'repetition', 'mitigation', 'methods', 'with', 'pass', 'improvements', 'ranging', 'from', 'to']",10,195,"['LLM-generated', 'Despite', 'LLMs', 'DeRep', '208', 'Models', 'One', 'Pass', 'Furthermore', '215', 'Language', 'Our', 'Building', 'Large']"
2504.12606v1,Robo-SGG: Exploiting Layout-Oriented Normalization and Restitution for   Robust Scene Graph Generation,"In this paper, we introduce a novel method named Robo-SGG, i.e., Layout-Oriented Normalization and Restitution for Robust Scene Graph Generation. Compared to the existing SGG setting, the robust scene graph generation aims to perform inference on a diverse range of corrupted images, with the core challenge being the domain shift between the clean and corrupted images. Existing SGG methods suffer from degraded performance due to compromised visual features e.g., corruption interference or occlusions. To obtain robust visual features, we exploit the layout information, which is domain-invariant, to enhance the efficacy of existing SGG methods on corrupted images. Specifically, we employ Instance Normalization(IN) to filter out the domain-specific feature and recover the unchangeable structural features, i.e., the positional and semantic relationships among objects by the proposed Layout-Oriented Restitution. Additionally, we propose a Layout-Embedded Encoder (LEE) that augments the existing object and predicate encoders within the SGG framework, enriching the robust positional and semantic features of objects and predicates. Note that our proposed Robo-SGG module is designed as a plug-and-play component, which can be easily integrated into any baseline SGG model. Extensive experiments demonstrate that by integrating the state-of-the-art method into our proposed Robo-SGG, we achieve relative improvements of 5.6%, 8.0%, and 6.5% in mR@50 for PredCls, SGCls, and SGDet tasks on the VG-C dataset, respectively, and achieve new state-of-the-art performance in corruption scene graph generation benchmark (VG-C and GQA-C). We will release our source code and model.","Changsheng Lv, Mengshi Qi, Zijian Fu, Huadong Ma","cs.CV, cs.AI",2025-04-17T03:09:22Z,http://arxiv.org/abs/2504.12606v1,robo sgg exploiting layout oriented normalization and restitution for robust scene graph generation,in this paper we introduce a novel method named robo sgg i e layout oriented normalization and restitution for robust scene graph generation compared to the existing sgg setting the robust scene graph generation aims to perform inference on a diverse range of corrupted images with the core challenge being the domain shift between the clean and corrupted images existing sgg methods suffer from degraded performance due to compromised visual features e g corruption interference or occlusions to obtain robust visual features we exploit the layout information which is domain invariant to enhance the efficacy of existing sgg methods on corrupted images specifically we employ instance normalization in to filter out the domain specific feature and recover the unchangeable structural features i e the positional and semantic relationships among objects by the proposed layout oriented restitution additionally we propose a layout embedded encoder lee that augments the existing object and predicate encoders within the sgg framework enriching the robust positional and semantic features of objects and predicates note that our proposed robo sgg module is designed as a plug and play component which can be easily integrated into any baseline sgg model extensive experiments demonstrate that by integrating the state of the art method into our proposed robo sgg we achieve relative improvements of and in mr for predcls sgcls and sgdet tasks on the vg c dataset respectively and achieve new state of the art performance in corruption scene graph generation benchmark vg c and gqa c we will release our source code and model,"['robo', 'sgg', 'exploiting', 'layout', 'oriented', 'normalization', 'and', 'restitution', 'for', 'robust', 'scene', 'graph', 'generation']","['in', 'this', 'paper', 'we', 'introduce', 'a', 'novel', 'method', 'named', 'robo', 'sgg', 'i', 'e', 'layout', 'oriented', 'normalization', 'and', 'restitution', 'for', 'robust', 'scene', 'graph', 'generation', 'compared', 'to', 'the', 'existing', 'sgg', 'setting', 'the', 'robust', 'scene', 'graph', 'generation', 'aims', 'to', 'perform', 'inference', 'on', 'a', 'diverse', 'range', 'of', 'corrupted', 'images', 'with', 'the', 'core', 'challenge', 'being', 'the', 'domain', 'shift', 'between', 'the', 'clean', 'and', 'corrupted', 'images', 'existing', 'sgg', 'methods', 'suffer', 'from', 'degraded', 'performance', 'due', 'to', 'compromised', 'visual', 'features', 'e', 'g', 'corruption', 'interference', 'or', 'occlusions', 'to', 'obtain', 'robust', 'visual', 'features', 'we', 'exploit', 'the', 'layout', 'information', 'which', 'is', 'domain', 'invariant', 'to', 'enhance', 'the', 'efficacy', 'of', 'existing', 'sgg', 'methods', 'on', 'corrupted', 'images', 'specifically', 'we', 'employ', 'instance', 'normalization', 'in', 'to', 'filter', 'out', 'the', 'domain', 'specific', 'feature', 'and', 'recover', 'the', 'unchangeable', 'structural', 'features', 'i', 'e', 'the', 'positional', 'and', 'semantic', 'relationships', 'among', 'objects', 'by', 'the', 'proposed', 'layout', 'oriented', 'restitution', 'additionally', 'we', 'propose', 'a', 'layout', 'embedded', 'encoder', 'lee', 'that', 'augments', 'the', 'existing', 'object', 'and', 'predicate', 'encoders', 'within', 'the', 'sgg', 'framework', 'enriching', 'the', 'robust', 'positional', 'and', 'semantic', 'features', 'of', 'objects', 'and', 'predicates', 'note', 'that', 'our', 'proposed', 'robo', 'sgg', 'module', 'is', 'designed', 'as', 'a', 'plug', 'and', 'play', 'component', 'which', 'can', 'be', 'easily', 'integrated', 'into', 'any', 'baseline', 'sgg', 'model', 'extensive', 'experiments', 'demonstrate', 'that', 'by', 'integrating', 'the', 'state', 'of', 'the', 'art', 'method', 'into', 'our', 'proposed', 'robo', 'sgg', 'we', 'achieve', 'relative', 'improvements', 'of', 'and', 'in', 'mr', 'for', 'predcls', 'sgcls', 'and', 'sgdet', 'tasks', 'on', 'the', 'vg', 'c', 'dataset', 'respectively', 'and', 'achieve', 'new', 'state', 'of', 'the', 'art', 'performance', 'in', 'corruption', 'scene', 'graph', 'generation', 'benchmark', 'vg', 'c', 'and', 'gqa', 'c', 'we', 'will', 'release', 'our', 'source', 'code', 'and', 'model']",13,256,"['Restitution', 'GQA-C', 'Encoder', 'Robo', 'Embedded', 'Specifically', 'SGCls', 'Compared', 'SGG', 'Layout', 'Normalization', 'Generation', 'Scene', 'PredCls', 'Graph', 'Additionally', 'Instance', 'LEE', 'Extensive', 'Existing', 'Oriented', 'SGDet', 'Robust', 'VG-C', 'Note']"
2504.12563v1,MetaSynth: Meta-Prompting-Driven Agentic Scaffolds for Diverse Synthetic   Data Generation,"Recent smaller language models such Phi-3.5 and Phi-4 rely on synthetic data generated using larger Language models. Questions remain about leveraging synthetic data for other use cases, such as adapting LLMs to specific domains. A key limitation of synthetic data is low diversity, which negatively impacts its downstream applicability for improving other models. To address this, we propose MetaSynth, a method for generating synthetic data that enhances diversity through meta-prompting, where a language model orchestrates multiple ""expert"" LLM agents to collaboratively generate data. Using only 25 million tokens of synthetic data generated with MetaSynth, we successfully adapt a well-trained LLM (Mistral-7B-v0.3) to two specialized domains-Finance and Biomedicine-without compromising the capabilities of the resulting model in general tasks. In addition, we evaluate the diversity of our synthetic data using seven automated metrics, and find that it approaches the diversity of LLM pre-training corpora.   Continually pre-training Mistral-7B-v0.3 with MetaSynth notably outperforms the base LLM, showing improvements of up to 4.08% in Finance and 13.75% in Biomedicine. The same model shows degraded performance when trained on data generated using a template prompt, even when the template includes prior generations and varying In-Context exemplars of real data. Our findings suggest that a few million tokens of diverse synthetic data without mixing any real data, is sufficient for effective domain adaptation when using MetaSynth.","Haris Riaz, Sourav Bhabesh, Vinayak Arannil, Miguel Ballesteros, Graham Horwood","cs.CL, cs.AI, cs.LG",2025-04-17T01:25:15Z,http://arxiv.org/abs/2504.12563v1,metasynth meta prompting driven agentic scaffolds for diverse synthetic data generation,recent smaller language models such phi and phi rely on synthetic data generated using larger language models questions remain about leveraging synthetic data for other use cases such as adapting llms to specific domains a key limitation of synthetic data is low diversity which negatively impacts its downstream applicability for improving other models to address this we propose metasynth a method for generating synthetic data that enhances diversity through meta prompting where a language model orchestrates multiple expert llm agents to collaboratively generate data using only million tokens of synthetic data generated with metasynth we successfully adapt a well trained llm mistral b v to two specialized domains finance and biomedicine without compromising the capabilities of the resulting model in general tasks in addition we evaluate the diversity of our synthetic data using seven automated metrics and find that it approaches the diversity of llm pre training corpora continually pre training mistral b v with metasynth notably outperforms the base llm showing improvements of up to in finance and in biomedicine the same model shows degraded performance when trained on data generated using a template prompt even when the template includes prior generations and varying in context exemplars of real data our findings suggest that a few million tokens of diverse synthetic data without mixing any real data is sufficient for effective domain adaptation when using metasynth,"['metasynth', 'meta', 'prompting', 'driven', 'agentic', 'scaffolds', 'for', 'diverse', 'synthetic', 'data', 'generation']","['recent', 'smaller', 'language', 'models', 'such', 'phi', 'and', 'phi', 'rely', 'on', 'synthetic', 'data', 'generated', 'using', 'larger', 'language', 'models', 'questions', 'remain', 'about', 'leveraging', 'synthetic', 'data', 'for', 'other', 'use', 'cases', 'such', 'as', 'adapting', 'llms', 'to', 'specific', 'domains', 'a', 'key', 'limitation', 'of', 'synthetic', 'data', 'is', 'low', 'diversity', 'which', 'negatively', 'impacts', 'its', 'downstream', 'applicability', 'for', 'improving', 'other', 'models', 'to', 'address', 'this', 'we', 'propose', 'metasynth', 'a', 'method', 'for', 'generating', 'synthetic', 'data', 'that', 'enhances', 'diversity', 'through', 'meta', 'prompting', 'where', 'a', 'language', 'model', 'orchestrates', 'multiple', 'expert', 'llm', 'agents', 'to', 'collaboratively', 'generate', 'data', 'using', 'only', 'million', 'tokens', 'of', 'synthetic', 'data', 'generated', 'with', 'metasynth', 'we', 'successfully', 'adapt', 'a', 'well', 'trained', 'llm', 'mistral', 'b', 'v', 'to', 'two', 'specialized', 'domains', 'finance', 'and', 'biomedicine', 'without', 'compromising', 'the', 'capabilities', 'of', 'the', 'resulting', 'model', 'in', 'general', 'tasks', 'in', 'addition', 'we', 'evaluate', 'the', 'diversity', 'of', 'our', 'synthetic', 'data', 'using', 'seven', 'automated', 'metrics', 'and', 'find', 'that', 'it', 'approaches', 'the', 'diversity', 'of', 'llm', 'pre', 'training', 'corpora', 'continually', 'pre', 'training', 'mistral', 'b', 'v', 'with', 'metasynth', 'notably', 'outperforms', 'the', 'base', 'llm', 'showing', 'improvements', 'of', 'up', 'to', 'in', 'finance', 'and', 'in', 'biomedicine', 'the', 'same', 'model', 'shows', 'degraded', 'performance', 'when', 'trained', 'on', 'data', 'generated', 'using', 'a', 'template', 'prompt', 'even', 'when', 'the', 'template', 'includes', 'prior', 'generations', 'and', 'varying', 'in', 'context', 'exemplars', 'of', 'real', 'data', 'our', 'findings', 'suggest', 'that', 'a', 'few', 'million', 'tokens', 'of', 'diverse', 'synthetic', 'data', 'without', 'mixing', 'any', 'real', 'data', 'is', 'sufficient', 'for', 'effective', 'domain', 'adaptation', 'when', 'using', 'metasynth']",11,227,"['MetaSynth', 'Recent', 'Our', 'Context', 'LLMs', 'Finance', 'Biomedicine', 'Continually', 'Phi-4', 'Mistral', 'Language', '7B-v0', 'Phi-3', 'LLM', 'Questions']"
2504.12562v1,ZeroSumEval: Scaling LLM Evaluation with Inter-Model Competition,"Evaluating the capabilities of Large Language Models (LLMs) has traditionally relied on static benchmark datasets, human assessments, or model-based evaluations - methods that often suffer from overfitting, high costs, and biases. ZeroSumEval is a novel competition-based evaluation protocol that leverages zero-sum games to assess LLMs with dynamic benchmarks that resist saturation. ZeroSumEval encompasses a diverse suite of games, including security challenges (PyJail), classic games (Chess, Liar's Dice, Poker), knowledge tests (MathQuiz), and persuasion challenges (Gandalf, Debate). These games are designed to evaluate a range of AI capabilities such as strategic reasoning, planning, knowledge application, and creativity. Building upon recent studies that highlight the effectiveness of game-based evaluations for LLMs, ZeroSumEval enhances these approaches by providing a standardized and extensible framework. To demonstrate this, we conduct extensive experiments with >7000 simulations across 7 games and 13 models. Our results show that while frontier models from the GPT and Claude families can play common games and answer questions, they struggle to play games that require creating novel and challenging questions. We also observe that models cannot reliably jailbreak each other and fail generally at tasks requiring creativity. We release our code at https://github.com/facebookresearch/ZeroSumEval.","Haidar Khan, Hisham A. Alyahya, Yazeed Alnumay, M Saiful Bari, B√ºlent Yener","cs.AI, cs.CL",2025-04-17T01:23:50Z,http://arxiv.org/abs/2504.12562v1,zerosumeval scaling llm evaluation with inter model competition,evaluating the capabilities of large language models llms has traditionally relied on static benchmark datasets human assessments or model based evaluations methods that often suffer from overfitting high costs and biases zerosumeval is a novel competition based evaluation protocol that leverages zero sum games to assess llms with dynamic benchmarks that resist saturation zerosumeval encompasses a diverse suite of games including security challenges pyjail classic games chess liar s dice poker knowledge tests mathquiz and persuasion challenges gandalf debate these games are designed to evaluate a range of ai capabilities such as strategic reasoning planning knowledge application and creativity building upon recent studies that highlight the effectiveness of game based evaluations for llms zerosumeval enhances these approaches by providing a standardized and extensible framework to demonstrate this we conduct extensive experiments with simulations across games and models our results show that while frontier models from the gpt and claude families can play common games and answer questions they struggle to play games that require creating novel and challenging questions we also observe that models cannot reliably jailbreak each other and fail generally at tasks requiring creativity we release our code at,"['zerosumeval', 'scaling', 'llm', 'evaluation', 'with', 'inter', 'model', 'competition']","['evaluating', 'the', 'capabilities', 'of', 'large', 'language', 'models', 'llms', 'has', 'traditionally', 'relied', 'on', 'static', 'benchmark', 'datasets', 'human', 'assessments', 'or', 'model', 'based', 'evaluations', 'methods', 'that', 'often', 'suffer', 'from', 'overfitting', 'high', 'costs', 'and', 'biases', 'zerosumeval', 'is', 'a', 'novel', 'competition', 'based', 'evaluation', 'protocol', 'that', 'leverages', 'zero', 'sum', 'games', 'to', 'assess', 'llms', 'with', 'dynamic', 'benchmarks', 'that', 'resist', 'saturation', 'zerosumeval', 'encompasses', 'a', 'diverse', 'suite', 'of', 'games', 'including', 'security', 'challenges', 'pyjail', 'classic', 'games', 'chess', 'liar', 's', 'dice', 'poker', 'knowledge', 'tests', 'mathquiz', 'and', 'persuasion', 'challenges', 'gandalf', 'debate', 'these', 'games', 'are', 'designed', 'to', 'evaluate', 'a', 'range', 'of', 'ai', 'capabilities', 'such', 'as', 'strategic', 'reasoning', 'planning', 'knowledge', 'application', 'and', 'creativity', 'building', 'upon', 'recent', 'studies', 'that', 'highlight', 'the', 'effectiveness', 'of', 'game', 'based', 'evaluations', 'for', 'llms', 'zerosumeval', 'enhances', 'these', 'approaches', 'by', 'providing', 'a', 'standardized', 'and', 'extensible', 'framework', 'to', 'demonstrate', 'this', 'we', 'conduct', 'extensive', 'experiments', 'with', 'simulations', 'across', 'games', 'and', 'models', 'our', 'results', 'show', 'that', 'while', 'frontier', 'models', 'from', 'the', 'gpt', 'and', 'claude', 'families', 'can', 'play', 'common', 'games', 'and', 'answer', 'questions', 'they', 'struggle', 'to', 'play', 'games', 'that', 'require', 'creating', 'novel', 'and', 'challenging', 'questions', 'we', 'also', 'observe', 'that', 'models', 'can', 'not', 'reliably', 'jailbreak', 'each', 'other', 'and', 'fail', 'generally', 'at', 'tasks', 'requiring', 'creativity', 'we', 'release', 'our', 'code', 'at']",8,192,"['7000', 'Poker', 'Chess', 'ZeroSumEval', 'Debate', 'Language', 'Our', 'Dice', 'LLMs', 'Evaluating', 'GPT', 'Claude', 'Building', 'Large', 'Gandalf', 'PyJail', 'MathQuiz', 'Liar', 'These', 'Models']"
2504.12557v1,TraCeS: Trajectory Based Credit Assignment From Sparse Safety Feedback,"In safe reinforcement learning (RL), auxiliary safety costs are used to align the agent to safe decision making. In practice, safety constraints, including cost functions and budgets, are unknown or hard to specify, as it requires anticipation of all possible unsafe behaviors. We therefore address a general setting where the true safety definition is unknown, and has to be learned from sparsely labeled data. Our key contributions are: first, we design a safety model that performs credit assignment to estimate each decision step's impact on the overall safety using a dataset of diverse trajectories and their corresponding binary safety labels (i.e., whether the corresponding trajectory is safe/unsafe). Second, we illustrate the architecture of our safety model to demonstrate its ability to learn a separate safety score for each timestep. Third, we reformulate the safe RL problem using the proposed safety model and derive an effective algorithm to optimize a safe yet rewarding policy. Finally, our empirical results corroborate our findings and show that this approach is effective in satisfying unknown safety definition, and scalable to various continuous control tasks.","Siow Meng Low, Akshat Kumar","cs.LG, cs.AI",2025-04-17T01:11:08Z,http://arxiv.org/abs/2504.12557v1,traces trajectory based credit assignment from sparse safety feedback,in safe reinforcement learning rl auxiliary safety costs are used to align the agent to safe decision making in practice safety constraints including cost functions and budgets are unknown or hard to specify as it requires anticipation of all possible unsafe behaviors we therefore address a general setting where the true safety definition is unknown and has to be learned from sparsely labeled data our key contributions are first we design a safety model that performs credit assignment to estimate each decision step s impact on the overall safety using a dataset of diverse trajectories and their corresponding binary safety labels i e whether the corresponding trajectory is safe unsafe second we illustrate the architecture of our safety model to demonstrate its ability to learn a separate safety score for each timestep third we reformulate the safe rl problem using the proposed safety model and derive an effective algorithm to optimize a safe yet rewarding policy finally our empirical results corroborate our findings and show that this approach is effective in satisfying unknown safety definition and scalable to various continuous control tasks,"['traces', 'trajectory', 'based', 'credit', 'assignment', 'from', 'sparse', 'safety', 'feedback']","['in', 'safe', 'reinforcement', 'learning', 'rl', 'auxiliary', 'safety', 'costs', 'are', 'used', 'to', 'align', 'the', 'agent', 'to', 'safe', 'decision', 'making', 'in', 'practice', 'safety', 'constraints', 'including', 'cost', 'functions', 'and', 'budgets', 'are', 'unknown', 'or', 'hard', 'to', 'specify', 'as', 'it', 'requires', 'anticipation', 'of', 'all', 'possible', 'unsafe', 'behaviors', 'we', 'therefore', 'address', 'a', 'general', 'setting', 'where', 'the', 'true', 'safety', 'definition', 'is', 'unknown', 'and', 'has', 'to', 'be', 'learned', 'from', 'sparsely', 'labeled', 'data', 'our', 'key', 'contributions', 'are', 'first', 'we', 'design', 'a', 'safety', 'model', 'that', 'performs', 'credit', 'assignment', 'to', 'estimate', 'each', 'decision', 'step', 's', 'impact', 'on', 'the', 'overall', 'safety', 'using', 'a', 'dataset', 'of', 'diverse', 'trajectories', 'and', 'their', 'corresponding', 'binary', 'safety', 'labels', 'i', 'e', 'whether', 'the', 'corresponding', 'trajectory', 'is', 'safe', 'unsafe', 'second', 'we', 'illustrate', 'the', 'architecture', 'of', 'our', 'safety', 'model', 'to', 'demonstrate', 'its', 'ability', 'to', 'learn', 'a', 'separate', 'safety', 'score', 'for', 'each', 'timestep', 'third', 'we', 'reformulate', 'the', 'safe', 'rl', 'problem', 'using', 'the', 'proposed', 'safety', 'model', 'and', 'derive', 'an', 'effective', 'algorithm', 'to', 'optimize', 'a', 'safe', 'yet', 'rewarding', 'policy', 'finally', 'our', 'empirical', 'results', 'corroborate', 'our', 'findings', 'and', 'show', 'that', 'this', 'approach', 'is', 'effective', 'in', 'satisfying', 'unknown', 'safety', 'definition', 'and', 'scalable', 'to', 'various', 'continuous', 'control', 'tasks']",9,182,"['Our', 'Second', 'Finally', 'Third']"
2504.12552v1,Privacy-Preserving Operating Room Workflow Analysis using Digital Twins,"Purpose: The operating room (OR) is a complex environment where optimizing workflows is critical to reduce costs and improve patient outcomes. The use of computer vision approaches for the automatic recognition of perioperative events enables identification of bottlenecks for OR optimization. However, privacy concerns limit the use of computer vision for automated event detection from OR videos, which makes privacy-preserving approaches needed for OR workflow analysis. Methods: We propose a two-stage pipeline for privacy-preserving OR video analysis and event detection. In the first stage, we leverage vision foundation models for depth estimation and semantic segmentation to generate de-identified Digital Twins (DT) of the OR from conventional RGB videos. In the second stage, we employ the SafeOR model, a fused two-stream approach that processes segmentation masks and depth maps for OR event detection. We evaluate this method on an internal dataset of 38 simulated surgical trials with five event classes. Results: Our results indicate that this DT-based approach to the OR event detection model achieves performance on par and sometimes even better than raw RGB video-based models on detecting OR events. Conclusion: DTs enable privacy-preserving OR workflow analysis, facilitating the sharing of de-identified data across institutions and they can potentially enhance model generalizability by mitigating domain-specific appearance differences.","Alejandra Perez, Han Zhang, Yu-Chun Ku, Lalithkumar Seenivasan, Roger Soberanis, Jose L. Porras, Richard Day, Jeff Jopling, Peter Najjar, Mathias Unberath","cs.CV, cs.AI, cs.LG",2025-04-17T00:46:06Z,http://arxiv.org/abs/2504.12552v1,privacy preserving operating room workflow analysis using digital twins,purpose the operating room or is a complex environment where optimizing workflows is critical to reduce costs and improve patient outcomes the use of computer vision approaches for the automatic recognition of perioperative events enables identification of bottlenecks for or optimization however privacy concerns limit the use of computer vision for automated event detection from or videos which makes privacy preserving approaches needed for or workflow analysis methods we propose a two stage pipeline for privacy preserving or video analysis and event detection in the first stage we leverage vision foundation models for depth estimation and semantic segmentation to generate de identified digital twins dt of the or from conventional rgb videos in the second stage we employ the safeor model a fused two stream approach that processes segmentation masks and depth maps for or event detection we evaluate this method on an internal dataset of simulated surgical trials with five event classes results our results indicate that this dt based approach to the or event detection model achieves performance on par and sometimes even better than raw rgb video based models on detecting or events conclusion dts enable privacy preserving or workflow analysis facilitating the sharing of de identified data across institutions and they can potentially enhance model generalizability by mitigating domain specific appearance differences,"['privacy', 'preserving', 'operating', 'room', 'workflow', 'analysis', 'using', 'digital', 'twins']","['purpose', 'the', 'operating', 'room', 'or', 'is', 'a', 'complex', 'environment', 'where', 'optimizing', 'workflows', 'is', 'critical', 'to', 'reduce', 'costs', 'and', 'improve', 'patient', 'outcomes', 'the', 'use', 'of', 'computer', 'vision', 'approaches', 'for', 'the', 'automatic', 'recognition', 'of', 'perioperative', 'events', 'enables', 'identification', 'of', 'bottlenecks', 'for', 'or', 'optimization', 'however', 'privacy', 'concerns', 'limit', 'the', 'use', 'of', 'computer', 'vision', 'for', 'automated', 'event', 'detection', 'from', 'or', 'videos', 'which', 'makes', 'privacy', 'preserving', 'approaches', 'needed', 'for', 'or', 'workflow', 'analysis', 'methods', 'we', 'propose', 'a', 'two', 'stage', 'pipeline', 'for', 'privacy', 'preserving', 'or', 'video', 'analysis', 'and', 'event', 'detection', 'in', 'the', 'first', 'stage', 'we', 'leverage', 'vision', 'foundation', 'models', 'for', 'depth', 'estimation', 'and', 'semantic', 'segmentation', 'to', 'generate', 'de', 'identified', 'digital', 'twins', 'dt', 'of', 'the', 'or', 'from', 'conventional', 'rgb', 'videos', 'in', 'the', 'second', 'stage', 'we', 'employ', 'the', 'safeor', 'model', 'a', 'fused', 'two', 'stream', 'approach', 'that', 'processes', 'segmentation', 'masks', 'and', 'depth', 'maps', 'for', 'or', 'event', 'detection', 'we', 'evaluate', 'this', 'method', 'on', 'an', 'internal', 'dataset', 'of', 'simulated', 'surgical', 'trials', 'with', 'five', 'event', 'classes', 'results', 'our', 'results', 'indicate', 'that', 'this', 'dt', 'based', 'approach', 'to', 'the', 'or', 'event', 'detection', 'model', 'achieves', 'performance', 'on', 'par', 'and', 'sometimes', 'even', 'better', 'than', 'raw', 'rgb', 'video', 'based', 'models', 'on', 'detecting', 'or', 'events', 'conclusion', 'dts', 'enable', 'privacy', 'preserving', 'or', 'workflow', 'analysis', 'facilitating', 'the', 'sharing', 'of', 'de', 'identified', 'data', 'across', 'institutions', 'and', 'they', 'can', 'potentially', 'enhance', 'model', 'generalizability', 'by', 'mitigating', 'domain', 'specific', 'appearance', 'differences']",9,216,"['SafeOR', 'RGB', 'Purpose', 'However', 'Digital', 'Methods', 'DT-based', 'DTs', 'Our', 'Twins', 'Conclusion', 'Results']"
2504.12545v1,Knowledge Acquisition on Mass-shooting Events via LLMs for AI-Driven   Justice,"Mass-shooting events pose a significant challenge to public safety, generating large volumes of unstructured textual data that hinder effective investigations and the formulation of public policy. Despite the urgency, few prior studies have effectively automated the extraction of key information from these events to support legal and investigative efforts. This paper presented the first dataset designed for knowledge acquisition on mass-shooting events through the application of named entity recognition (NER) techniques. It focuses on identifying key entities such as offenders, victims, locations, and criminal instruments, that are vital for legal and investigative purposes. The NER process is powered by Large Language Models (LLMs) using few-shot prompting, facilitating the efficient extraction and organization of critical information from diverse sources, including news articles, police reports, and social media. Experimental results on real-world mass-shooting corpora demonstrate that GPT-4o is the most effective model for mass-shooting NER, achieving the highest Micro Precision, Micro Recall, and Micro F1-scores. Meanwhile, o1-mini delivers competitive performance, making it a resource-efficient alternative for less complex NER tasks. It is also observed that increasing the shot count enhances the performance of all models, but the gains are more substantial for GPT-4o and o1-mini, highlighting their superior adaptability to few-shot learning scenarios.","Benign John Ihugba, Afsana Nasrin, Ling Wu, Lin Li, Lijun Qian, Xishuang Dong","cs.CY, cs.AI, cs.CL",2025-04-17T00:13:04Z,http://arxiv.org/abs/2504.12545v1,knowledge acquisition on mass shooting events via llms for ai driven justice,mass shooting events pose a significant challenge to public safety generating large volumes of unstructured textual data that hinder effective investigations and the formulation of public policy despite the urgency few prior studies have effectively automated the extraction of key information from these events to support legal and investigative efforts this paper presented the first dataset designed for knowledge acquisition on mass shooting events through the application of named entity recognition ner techniques it focuses on identifying key entities such as offenders victims locations and criminal instruments that are vital for legal and investigative purposes the ner process is powered by large language models llms using few shot prompting facilitating the efficient extraction and organization of critical information from diverse sources including news articles police reports and social media experimental results on real world mass shooting corpora demonstrate that gpt o is the most effective model for mass shooting ner achieving the highest micro precision micro recall and micro f scores meanwhile o mini delivers competitive performance making it a resource efficient alternative for less complex ner tasks it is also observed that increasing the shot count enhances the performance of all models but the gains are more substantial for gpt o and o mini highlighting their superior adaptability to few shot learning scenarios,"['knowledge', 'acquisition', 'on', 'mass', 'shooting', 'events', 'via', 'llms', 'for', 'ai', 'driven', 'justice']","['mass', 'shooting', 'events', 'pose', 'a', 'significant', 'challenge', 'to', 'public', 'safety', 'generating', 'large', 'volumes', 'of', 'unstructured', 'textual', 'data', 'that', 'hinder', 'effective', 'investigations', 'and', 'the', 'formulation', 'of', 'public', 'policy', 'despite', 'the', 'urgency', 'few', 'prior', 'studies', 'have', 'effectively', 'automated', 'the', 'extraction', 'of', 'key', 'information', 'from', 'these', 'events', 'to', 'support', 'legal', 'and', 'investigative', 'efforts', 'this', 'paper', 'presented', 'the', 'first', 'dataset', 'designed', 'for', 'knowledge', 'acquisition', 'on', 'mass', 'shooting', 'events', 'through', 'the', 'application', 'of', 'named', 'entity', 'recognition', 'ner', 'techniques', 'it', 'focuses', 'on', 'identifying', 'key', 'entities', 'such', 'as', 'offenders', 'victims', 'locations', 'and', 'criminal', 'instruments', 'that', 'are', 'vital', 'for', 'legal', 'and', 'investigative', 'purposes', 'the', 'ner', 'process', 'is', 'powered', 'by', 'large', 'language', 'models', 'llms', 'using', 'few', 'shot', 'prompting', 'facilitating', 'the', 'efficient', 'extraction', 'and', 'organization', 'of', 'critical', 'information', 'from', 'diverse', 'sources', 'including', 'news', 'articles', 'police', 'reports', 'and', 'social', 'media', 'experimental', 'results', 'on', 'real', 'world', 'mass', 'shooting', 'corpora', 'demonstrate', 'that', 'gpt', 'o', 'is', 'the', 'most', 'effective', 'model', 'for', 'mass', 'shooting', 'ner', 'achieving', 'the', 'highest', 'micro', 'precision', 'micro', 'recall', 'and', 'micro', 'f', 'scores', 'meanwhile', 'o', 'mini', 'delivers', 'competitive', 'performance', 'making', 'it', 'a', 'resource', 'efficient', 'alternative', 'for', 'less', 'complex', 'ner', 'tasks', 'it', 'is', 'also', 'observed', 'that', 'increasing', 'the', 'shot', 'count', 'enhances', 'the', 'performance', 'of', 'all', 'models', 'but', 'the', 'gains', 'are', 'more', 'substantial', 'for', 'gpt', 'o', 'and', 'o', 'mini', 'highlighting', 'their', 'superior', 'adaptability', 'to', 'few', 'shot', 'learning', 'scenarios']",12,214,"['Experimental', 'Despite', 'LLMs', 'Micro', 'NER', 'Recall', 'Models', 'F1-scores', 'Meanwhile', 'Mass', 'Precision', 'Language', 'Large', 'GPT-4o']"
2504.12535v1,Decision-based AI Visual Navigation for Cardiac Ultrasounds,"Ultrasound imaging of the heart (echocardiography) is widely used to diagnose cardiac diseases. However, obtaining an echocardiogram requires an expert sonographer and a high-quality ultrasound imaging device, which are generally only available in hospitals. Recently, AI-based navigation models and algorithms have been used to aid novice sonographers in acquiring the standardized cardiac views necessary to visualize potential disease pathologies. These navigation systems typically rely on directional guidance to predict the necessary rotation of the ultrasound probe. This paper demonstrates a novel AI navigation system that builds on a decision model for identifying the inferior vena cava (IVC) of the heart. The decision model is trained offline using cardiac ultrasound videos and employs binary classification to determine whether the IVC is present in a given ultrasound video. The underlying model integrates a novel localization algorithm that leverages the learned feature representations to annotate the spatial location of the IVC in real-time. Our model demonstrates strong localization performance on traditional high-quality hospital ultrasound videos, as well as impressive zero-shot performance on lower-quality ultrasound videos from a more affordable Butterfly iQ handheld ultrasound machine. This capability facilitates the expansion of ultrasound diagnostics beyond hospital settings. Currently, the guidance system is undergoing clinical trials and is available on the Butterfly iQ app.","Andy Dimnaku, Dominic Yurk, Zhiyuan Gao, Arun Padmanabhan, Mandar Aras, Yaser Abu-Mostafa","cs.CV, cs.AI",2025-04-16T23:54:46Z,http://arxiv.org/abs/2504.12535v1,decision based ai visual navigation for cardiac ultrasounds,ultrasound imaging of the heart echocardiography is widely used to diagnose cardiac diseases however obtaining an echocardiogram requires an expert sonographer and a high quality ultrasound imaging device which are generally only available in hospitals recently ai based navigation models and algorithms have been used to aid novice sonographers in acquiring the standardized cardiac views necessary to visualize potential disease pathologies these navigation systems typically rely on directional guidance to predict the necessary rotation of the ultrasound probe this paper demonstrates a novel ai navigation system that builds on a decision model for identifying the inferior vena cava ivc of the heart the decision model is trained offline using cardiac ultrasound videos and employs binary classification to determine whether the ivc is present in a given ultrasound video the underlying model integrates a novel localization algorithm that leverages the learned feature representations to annotate the spatial location of the ivc in real time our model demonstrates strong localization performance on traditional high quality hospital ultrasound videos as well as impressive zero shot performance on lower quality ultrasound videos from a more affordable butterfly iq handheld ultrasound machine this capability facilitates the expansion of ultrasound diagnostics beyond hospital settings currently the guidance system is undergoing clinical trials and is available on the butterfly iq app,"['decision', 'based', 'ai', 'visual', 'navigation', 'for', 'cardiac', 'ultrasounds']","['ultrasound', 'imaging', 'of', 'the', 'heart', 'echocardiography', 'is', 'widely', 'used', 'to', 'diagnose', 'cardiac', 'diseases', 'however', 'obtaining', 'an', 'echocardiogram', 'requires', 'an', 'expert', 'sonographer', 'and', 'a', 'high', 'quality', 'ultrasound', 'imaging', 'device', 'which', 'are', 'generally', 'only', 'available', 'in', 'hospitals', 'recently', 'ai', 'based', 'navigation', 'models', 'and', 'algorithms', 'have', 'been', 'used', 'to', 'aid', 'novice', 'sonographers', 'in', 'acquiring', 'the', 'standardized', 'cardiac', 'views', 'necessary', 'to', 'visualize', 'potential', 'disease', 'pathologies', 'these', 'navigation', 'systems', 'typically', 'rely', 'on', 'directional', 'guidance', 'to', 'predict', 'the', 'necessary', 'rotation', 'of', 'the', 'ultrasound', 'probe', 'this', 'paper', 'demonstrates', 'a', 'novel', 'ai', 'navigation', 'system', 'that', 'builds', 'on', 'a', 'decision', 'model', 'for', 'identifying', 'the', 'inferior', 'vena', 'cava', 'ivc', 'of', 'the', 'heart', 'the', 'decision', 'model', 'is', 'trained', 'offline', 'using', 'cardiac', 'ultrasound', 'videos', 'and', 'employs', 'binary', 'classification', 'to', 'determine', 'whether', 'the', 'ivc', 'is', 'present', 'in', 'a', 'given', 'ultrasound', 'video', 'the', 'underlying', 'model', 'integrates', 'a', 'novel', 'localization', 'algorithm', 'that', 'leverages', 'the', 'learned', 'feature', 'representations', 'to', 'annotate', 'the', 'spatial', 'location', 'of', 'the', 'ivc', 'in', 'real', 'time', 'our', 'model', 'demonstrates', 'strong', 'localization', 'performance', 'on', 'traditional', 'high', 'quality', 'hospital', 'ultrasound', 'videos', 'as', 'well', 'as', 'impressive', 'zero', 'shot', 'performance', 'on', 'lower', 'quality', 'ultrasound', 'videos', 'from', 'a', 'more', 'affordable', 'butterfly', 'iq', 'handheld', 'ultrasound', 'machine', 'this', 'capability', 'facilitates', 'the', 'expansion', 'of', 'ultrasound', 'diagnostics', 'beyond', 'hospital', 'settings', 'currently', 'the', 'guidance', 'system', 'is', 'undergoing', 'clinical', 'trials', 'and', 'is', 'available', 'on', 'the', 'butterfly', 'iq', 'app']",8,214,"['IVC', 'Recently', 'These', 'However', 'AI-based', 'Ultrasound', 'Butterfly', 'Our', 'Currently']"
2504.12532v1,Generalization through variance: how noise shapes inductive biases in   diffusion models,"How diffusion models generalize beyond their training set is not known, and is somewhat mysterious given two facts: the optimum of the denoising score matching (DSM) objective usually used to train diffusion models is the score function of the training distribution; and the networks usually used to learn the score function are expressive enough to learn this score to high accuracy. We claim that a certain feature of the DSM objective -- the fact that its target is not the training distribution's score, but a noisy quantity only equal to it in expectation -- strongly impacts whether and to what extent diffusion models generalize. In this paper, we develop a mathematical theory that partly explains this 'generalization through variance' phenomenon. Our theoretical analysis exploits a physics-inspired path integral approach to compute the distributions typically learned by a few paradigmatic under- and overparameterized diffusion models. We find that the distributions diffusion models effectively learn to sample from resemble their training distributions, but with 'gaps' filled in, and that this inductive bias is due to the covariance structure of the noisy target used during training. We also characterize how this inductive bias interacts with feature-related inductive biases.",John J. Vastola,"cs.LG, cond-mat.dis-nn, cs.AI",2025-04-16T23:41:10Z,http://arxiv.org/abs/2504.12532v1,generalization through variance how noise shapes inductive biases in diffusion models,how diffusion models generalize beyond their training set is not known and is somewhat mysterious given two facts the optimum of the denoising score matching dsm objective usually used to train diffusion models is the score function of the training distribution and the networks usually used to learn the score function are expressive enough to learn this score to high accuracy we claim that a certain feature of the dsm objective the fact that its target is not the training distribution s score but a noisy quantity only equal to it in expectation strongly impacts whether and to what extent diffusion models generalize in this paper we develop a mathematical theory that partly explains this generalization through variance phenomenon our theoretical analysis exploits a physics inspired path integral approach to compute the distributions typically learned by a few paradigmatic under and overparameterized diffusion models we find that the distributions diffusion models effectively learn to sample from resemble their training distributions but with gaps filled in and that this inductive bias is due to the covariance structure of the noisy target used during training we also characterize how this inductive bias interacts with feature related inductive biases,"['generalization', 'through', 'variance', 'how', 'noise', 'shapes', 'inductive', 'biases', 'in', 'diffusion', 'models']","['how', 'diffusion', 'models', 'generalize', 'beyond', 'their', 'training', 'set', 'is', 'not', 'known', 'and', 'is', 'somewhat', 'mysterious', 'given', 'two', 'facts', 'the', 'optimum', 'of', 'the', 'denoising', 'score', 'matching', 'dsm', 'objective', 'usually', 'used', 'to', 'train', 'diffusion', 'models', 'is', 'the', 'score', 'function', 'of', 'the', 'training', 'distribution', 'and', 'the', 'networks', 'usually', 'used', 'to', 'learn', 'the', 'score', 'function', 'are', 'expressive', 'enough', 'to', 'learn', 'this', 'score', 'to', 'high', 'accuracy', 'we', 'claim', 'that', 'a', 'certain', 'feature', 'of', 'the', 'dsm', 'objective', 'the', 'fact', 'that', 'its', 'target', 'is', 'not', 'the', 'training', 'distribution', 's', 'score', 'but', 'a', 'noisy', 'quantity', 'only', 'equal', 'to', 'it', 'in', 'expectation', 'strongly', 'impacts', 'whether', 'and', 'to', 'what', 'extent', 'diffusion', 'models', 'generalize', 'in', 'this', 'paper', 'we', 'develop', 'a', 'mathematical', 'theory', 'that', 'partly', 'explains', 'this', 'generalization', 'through', 'variance', 'phenomenon', 'our', 'theoretical', 'analysis', 'exploits', 'a', 'physics', 'inspired', 'path', 'integral', 'approach', 'to', 'compute', 'the', 'distributions', 'typically', 'learned', 'by', 'a', 'few', 'paradigmatic', 'under', 'and', 'overparameterized', 'diffusion', 'models', 'we', 'find', 'that', 'the', 'distributions', 'diffusion', 'models', 'effectively', 'learn', 'to', 'sample', 'from', 'resemble', 'their', 'training', 'distributions', 'but', 'with', 'gaps', 'filled', 'in', 'and', 'that', 'this', 'inductive', 'bias', 'is', 'due', 'to', 'the', 'covariance', 'structure', 'of', 'the', 'noisy', 'target', 'used', 'during', 'training', 'we', 'also', 'characterize', 'how', 'this', 'inductive', 'bias', 'interacts', 'with', 'feature', 'related', 'inductive', 'biases']",11,196,"['Our', 'How', 'DSM']"
2504.12523v1,Memorization vs. Reasoning: Updating LLMs with New Knowledge,"Large language models (LLMs) encode vast amounts of pre-trained knowledge in their parameters, but updating them as real-world information evolves remains a challenge. Existing methodologies and benchmarks primarily target entity substitutions, failing to capture the full breadth of complex real-world dynamics. In this paper, we introduce Knowledge Update Playground (KUP), an automatic pipeline for simulating realistic knowledge updates reflected in an evidence corpora. KUP's evaluation framework includes direct and indirect probes to both test memorization of updated facts and reasoning over them, for any update learning methods. Next, we present a lightweight method called memory conditioned training (MCT), which conditions tokens in the update corpus on self-generated ""memory"" tokens during training. Our strategy encourages LLMs to surface and reason over newly memorized knowledge at inference. Our results on two strong LLMs show that (1) KUP benchmark is highly challenging, with the best CPT models achieving $<2\%$ in indirect probing setting (reasoning) and (2) MCT training significantly outperforms prior continued pre-training (CPT) baselines, improving direct probing (memorization) results by up to $25.4\%$.","Aochong Oliver Li, Tanya Goyal","cs.CL, cs.AI, cs.LG",2025-04-16T23:03:40Z,http://arxiv.org/abs/2504.12523v1,memorization vs reasoning updating llms with new knowledge,large language models llms encode vast amounts of pre trained knowledge in their parameters but updating them as real world information evolves remains a challenge existing methodologies and benchmarks primarily target entity substitutions failing to capture the full breadth of complex real world dynamics in this paper we introduce knowledge update playground kup an automatic pipeline for simulating realistic knowledge updates reflected in an evidence corpora kup s evaluation framework includes direct and indirect probes to both test memorization of updated facts and reasoning over them for any update learning methods next we present a lightweight method called memory conditioned training mct which conditions tokens in the update corpus on self generated memory tokens during training our strategy encourages llms to surface and reason over newly memorized knowledge at inference our results on two strong llms show that kup benchmark is highly challenging with the best cpt models achieving in indirect probing setting reasoning and mct training significantly outperforms prior continued pre training cpt baselines improving direct probing memorization results by up to,"['memorization', 'vs', 'reasoning', 'updating', 'llms', 'with', 'new', 'knowledge']","['large', 'language', 'models', 'llms', 'encode', 'vast', 'amounts', 'of', 'pre', 'trained', 'knowledge', 'in', 'their', 'parameters', 'but', 'updating', 'them', 'as', 'real', 'world', 'information', 'evolves', 'remains', 'a', 'challenge', 'existing', 'methodologies', 'and', 'benchmarks', 'primarily', 'target', 'entity', 'substitutions', 'failing', 'to', 'capture', 'the', 'full', 'breadth', 'of', 'complex', 'real', 'world', 'dynamics', 'in', 'this', 'paper', 'we', 'introduce', 'knowledge', 'update', 'playground', 'kup', 'an', 'automatic', 'pipeline', 'for', 'simulating', 'realistic', 'knowledge', 'updates', 'reflected', 'in', 'an', 'evidence', 'corpora', 'kup', 's', 'evaluation', 'framework', 'includes', 'direct', 'and', 'indirect', 'probes', 'to', 'both', 'test', 'memorization', 'of', 'updated', 'facts', 'and', 'reasoning', 'over', 'them', 'for', 'any', 'update', 'learning', 'methods', 'next', 'we', 'present', 'a', 'lightweight', 'method', 'called', 'memory', 'conditioned', 'training', 'mct', 'which', 'conditions', 'tokens', 'in', 'the', 'update', 'corpus', 'on', 'self', 'generated', 'memory', 'tokens', 'during', 'training', 'our', 'strategy', 'encourages', 'llms', 'to', 'surface', 'and', 'reason', 'over', 'newly', 'memorized', 'knowledge', 'at', 'inference', 'our', 'results', 'on', 'two', 'strong', 'llms', 'show', 'that', 'kup', 'benchmark', 'is', 'highly', 'challenging', 'with', 'the', 'best', 'cpt', 'models', 'achieving', 'in', 'indirect', 'probing', 'setting', 'reasoning', 'and', 'mct', 'training', 'significantly', 'outperforms', 'prior', 'continued', 'pre', 'training', 'cpt', 'baselines', 'improving', 'direct', 'probing', 'memorization', 'results', 'by', 'up', 'to']",8,173,"['Our', 'Existing', 'KUP', 'LLMs', 'Playground', 'Next', 'MCT', 'CPT', 'Update', 'Knowledge', 'Large']"
2504.12522v1,Evaluating the Diversity and Quality of LLM Generated Content,"Recent work suggests that preference-tuning techniques--including Reinforcement Learning from Human Preferences (RLHF) methods like PPO and GRPO, as well as alternatives like DPO--reduce diversity, creating a dilemma given that such models are widely deployed in applications requiring diverse outputs. To address this, we introduce a framework for measuring effective semantic diversity--diversity among outputs that meet quality thresholds--which better reflects the practical utility of large language models (LLMs). Using open-ended tasks that require no human intervention, we find counterintuitive results: although preference-tuned models--especially those trained via RL--exhibit reduced lexical and syntactic diversity, they produce greater effective semantic diversity than SFT or base models, not from increasing diversity among high-quality outputs, but from generating more high-quality outputs overall. We discover that preference tuning reduces syntactic diversity while preserving semantic diversity--revealing a distinction between diversity in form and diversity in content that traditional metrics often overlook. Our analysis further shows that smaller models are consistently more parameter-efficient at generating unique content within a fixed sampling budget, offering insights into the relationship between model scaling and diversity. These findings have important implications for applications that require diverse yet high-quality outputs, from creative assistance to synthetic data generation.","Alexander Shypula, Shuo Li, Botong Zhang, Vishakh Padmakumar, Kayo Yin, Osbert Bastani","cs.CL, cs.AI",2025-04-16T23:02:23Z,http://arxiv.org/abs/2504.12522v1,evaluating the diversity and quality of llm generated content,recent work suggests that preference tuning techniques including reinforcement learning from human preferences rlhf methods like ppo and grpo as well as alternatives like dpo reduce diversity creating a dilemma given that such models are widely deployed in applications requiring diverse outputs to address this we introduce a framework for measuring effective semantic diversity diversity among outputs that meet quality thresholds which better reflects the practical utility of large language models llms using open ended tasks that require no human intervention we find counterintuitive results although preference tuned models especially those trained via rl exhibit reduced lexical and syntactic diversity they produce greater effective semantic diversity than sft or base models not from increasing diversity among high quality outputs but from generating more high quality outputs overall we discover that preference tuning reduces syntactic diversity while preserving semantic diversity revealing a distinction between diversity in form and diversity in content that traditional metrics often overlook our analysis further shows that smaller models are consistently more parameter efficient at generating unique content within a fixed sampling budget offering insights into the relationship between model scaling and diversity these findings have important implications for applications that require diverse yet high quality outputs from creative assistance to synthetic data generation,"['evaluating', 'the', 'diversity', 'and', 'quality', 'of', 'llm', 'generated', 'content']","['recent', 'work', 'suggests', 'that', 'preference', 'tuning', 'techniques', 'including', 'reinforcement', 'learning', 'from', 'human', 'preferences', 'rlhf', 'methods', 'like', 'ppo', 'and', 'grpo', 'as', 'well', 'as', 'alternatives', 'like', 'dpo', 'reduce', 'diversity', 'creating', 'a', 'dilemma', 'given', 'that', 'such', 'models', 'are', 'widely', 'deployed', 'in', 'applications', 'requiring', 'diverse', 'outputs', 'to', 'address', 'this', 'we', 'introduce', 'a', 'framework', 'for', 'measuring', 'effective', 'semantic', 'diversity', 'diversity', 'among', 'outputs', 'that', 'meet', 'quality', 'thresholds', 'which', 'better', 'reflects', 'the', 'practical', 'utility', 'of', 'large', 'language', 'models', 'llms', 'using', 'open', 'ended', 'tasks', 'that', 'require', 'no', 'human', 'intervention', 'we', 'find', 'counterintuitive', 'results', 'although', 'preference', 'tuned', 'models', 'especially', 'those', 'trained', 'via', 'rl', 'exhibit', 'reduced', 'lexical', 'and', 'syntactic', 'diversity', 'they', 'produce', 'greater', 'effective', 'semantic', 'diversity', 'than', 'sft', 'or', 'base', 'models', 'not', 'from', 'increasing', 'diversity', 'among', 'high', 'quality', 'outputs', 'but', 'from', 'generating', 'more', 'high', 'quality', 'outputs', 'overall', 'we', 'discover', 'that', 'preference', 'tuning', 'reduces', 'syntactic', 'diversity', 'while', 'preserving', 'semantic', 'diversity', 'revealing', 'a', 'distinction', 'between', 'diversity', 'in', 'form', 'and', 'diversity', 'in', 'content', 'that', 'traditional', 'metrics', 'often', 'overlook', 'our', 'analysis', 'further', 'shows', 'that', 'smaller', 'models', 'are', 'consistently', 'more', 'parameter', 'efficient', 'at', 'generating', 'unique', 'content', 'within', 'a', 'fixed', 'sampling', 'budget', 'offering', 'insights', 'into', 'the', 'relationship', 'between', 'model', 'scaling', 'and', 'diversity', 'these', 'findings', 'have', 'important', 'implications', 'for', 'applications', 'that', 'require', 'diverse', 'yet', 'high', 'quality', 'outputs', 'from', 'creative', 'assistance', 'to', 'synthetic', 'data', 'generation']",9,207,"['Preferences', 'PPO', 'Recent', 'RLHF', 'GRPO', 'DPO', 'SFT', 'LLMs', 'These', 'Learning', 'Human', 'Our', 'Reinforcement']"
2504.12503v1,Continual Learning Strategies for 3D Engineering Regression Problems: A   Benchmarking Study,"Engineering problems that apply machine learning often involve computationally intensive methods but rely on limited datasets. As engineering data evolves with new designs and constraints, models must incorporate new knowledge over time. However, high computational costs make retraining models from scratch infeasible. Continual learning (CL) offers a promising solution by enabling models to learn from sequential data while mitigating catastrophic forgetting, where a model forgets previously learned mappings. This work introduces CL to engineering design by benchmarking several CL methods on representative regression tasks. We apply these strategies to five engineering datasets and construct nine new engineering CL benchmarks to evaluate their ability to address forgetting and improve generalization. Preliminary results show that applying existing CL methods to these tasks improves performance over naive baselines. In particular, the Replay strategy achieved performance comparable to retraining in several benchmarks while reducing training time by nearly half, demonstrating its potential for real-world engineering workflows. The code and datasets used in this work will be available at: https://github.com/kmsamuel/cl-for-engineering-release.","Kaira M. Samuel, Faez Ahmed","cs.LG, cs.AI, cs.CE",2025-04-16T21:40:03Z,http://arxiv.org/abs/2504.12503v1,continual learning strategies for d engineering regression problems a benchmarking study,engineering problems that apply machine learning often involve computationally intensive methods but rely on limited datasets as engineering data evolves with new designs and constraints models must incorporate new knowledge over time however high computational costs make retraining models from scratch infeasible continual learning cl offers a promising solution by enabling models to learn from sequential data while mitigating catastrophic forgetting where a model forgets previously learned mappings this work introduces cl to engineering design by benchmarking several cl methods on representative regression tasks we apply these strategies to five engineering datasets and construct nine new engineering cl benchmarks to evaluate their ability to address forgetting and improve generalization preliminary results show that applying existing cl methods to these tasks improves performance over naive baselines in particular the replay strategy achieved performance comparable to retraining in several benchmarks while reducing training time by nearly half demonstrating its potential for real world engineering workflows the code and datasets used in this work will be available at,"['continual', 'learning', 'strategies', 'for', 'd', 'engineering', 'regression', 'problems', 'a', 'benchmarking', 'study']","['engineering', 'problems', 'that', 'apply', 'machine', 'learning', 'often', 'involve', 'computationally', 'intensive', 'methods', 'but', 'rely', 'on', 'limited', 'datasets', 'as', 'engineering', 'data', 'evolves', 'with', 'new', 'designs', 'and', 'constraints', 'models', 'must', 'incorporate', 'new', 'knowledge', 'over', 'time', 'however', 'high', 'computational', 'costs', 'make', 'retraining', 'models', 'from', 'scratch', 'infeasible', 'continual', 'learning', 'cl', 'offers', 'a', 'promising', 'solution', 'by', 'enabling', 'models', 'to', 'learn', 'from', 'sequential', 'data', 'while', 'mitigating', 'catastrophic', 'forgetting', 'where', 'a', 'model', 'forgets', 'previously', 'learned', 'mappings', 'this', 'work', 'introduces', 'cl', 'to', 'engineering', 'design', 'by', 'benchmarking', 'several', 'cl', 'methods', 'on', 'representative', 'regression', 'tasks', 'we', 'apply', 'these', 'strategies', 'to', 'five', 'engineering', 'datasets', 'and', 'construct', 'nine', 'new', 'engineering', 'cl', 'benchmarks', 'to', 'evaluate', 'their', 'ability', 'to', 'address', 'forgetting', 'and', 'improve', 'generalization', 'preliminary', 'results', 'show', 'that', 'applying', 'existing', 'cl', 'methods', 'to', 'these', 'tasks', 'improves', 'performance', 'over', 'naive', 'baselines', 'in', 'particular', 'the', 'replay', 'strategy', 'achieved', 'performance', 'comparable', 'to', 'retraining', 'in', 'several', 'benchmarks', 'while', 'reducing', 'training', 'time', 'by', 'nearly', 'half', 'demonstrating', 'its', 'potential', 'for', 'real', 'world', 'engineering', 'workflows', 'the', 'code', 'and', 'datasets', 'used', 'in', 'this', 'work', 'will', 'be', 'available', 'at']",11,165,"['Engineering', 'However', 'Preliminary', 'Replay', 'Continual']"
2504.12497v1,Heuristic Recognition and Rapid Response to Unfamiliar Events Outside of   Agent Design Scope,"Regardless of past learning, an agent in an open world will face unfamiliar situations and events outside of prior experience, existing models, or policies. Further, the agent will sometimes lack relevant knowledge and/or sufficient time to assess the situation, generate and evaluate options, and pursue a robustly considered course of action. How can an agent respond reasonably to situations that are outside of its original design scope? How can it recognize such situations sufficiently quickly and reliably to determine reasonable, adaptive courses of action? We identify key characteristics needed for solutions, evaluate the state-of-the-art by these requirements, and outline a proposed, novel approach that combines domain-general meta-knowledge (in the form of appraisals inspired by human cognition) and metareasoning. It has the potential to provide fast, adaptive responses to unfamiliar situations, more fully meeting the performance characteristics required for open-world, general agents.","Robert E. Wray, Steven J. Jones, John E. Laird","cs.AI, I.2.8",2025-04-16T21:26:12Z,http://arxiv.org/abs/2504.12497v1,heuristic recognition and rapid response to unfamiliar events outside of agent design scope,regardless of past learning an agent in an open world will face unfamiliar situations and events outside of prior experience existing models or policies further the agent will sometimes lack relevant knowledge and or sufficient time to assess the situation generate and evaluate options and pursue a robustly considered course of action how can an agent respond reasonably to situations that are outside of its original design scope how can it recognize such situations sufficiently quickly and reliably to determine reasonable adaptive courses of action we identify key characteristics needed for solutions evaluate the state of the art by these requirements and outline a proposed novel approach that combines domain general meta knowledge in the form of appraisals inspired by human cognition and metareasoning it has the potential to provide fast adaptive responses to unfamiliar situations more fully meeting the performance characteristics required for open world general agents,"['heuristic', 'recognition', 'and', 'rapid', 'response', 'to', 'unfamiliar', 'events', 'outside', 'of', 'agent', 'design', 'scope']","['regardless', 'of', 'past', 'learning', 'an', 'agent', 'in', 'an', 'open', 'world', 'will', 'face', 'unfamiliar', 'situations', 'and', 'events', 'outside', 'of', 'prior', 'experience', 'existing', 'models', 'or', 'policies', 'further', 'the', 'agent', 'will', 'sometimes', 'lack', 'relevant', 'knowledge', 'and', 'or', 'sufficient', 'time', 'to', 'assess', 'the', 'situation', 'generate', 'and', 'evaluate', 'options', 'and', 'pursue', 'a', 'robustly', 'considered', 'course', 'of', 'action', 'how', 'can', 'an', 'agent', 'respond', 'reasonably', 'to', 'situations', 'that', 'are', 'outside', 'of', 'its', 'original', 'design', 'scope', 'how', 'can', 'it', 'recognize', 'such', 'situations', 'sufficiently', 'quickly', 'and', 'reliably', 'to', 'determine', 'reasonable', 'adaptive', 'courses', 'of', 'action', 'we', 'identify', 'key', 'characteristics', 'needed', 'for', 'solutions', 'evaluate', 'the', 'state', 'of', 'the', 'art', 'by', 'these', 'requirements', 'and', 'outline', 'a', 'proposed', 'novel', 'approach', 'that', 'combines', 'domain', 'general', 'meta', 'knowledge', 'in', 'the', 'form', 'of', 'appraisals', 'inspired', 'by', 'human', 'cognition', 'and', 'metareasoning', 'it', 'has', 'the', 'potential', 'to', 'provide', 'fast', 'adaptive', 'responses', 'to', 'unfamiliar', 'situations', 'more', 'fully', 'meeting', 'the', 'performance', 'characteristics', 'required', 'for', 'open', 'world', 'general', 'agents']",13,148,"['How', 'Regardless', 'Further']"
2504.12488v1,"Co-Writing with AI, on Human Terms: Aligning Research with User Demands   Across the Writing Process","As generative AI tools like ChatGPT become integral to everyday writing, critical questions arise about how to preserve writers' sense of agency and ownership when using these tools. Yet, a systematic understanding of how AI assistance affects different aspects of the writing process - and how this shapes writers' agency - remains underexplored. To address this gap, we conducted a systematic review of 109 HCI papers using the PRISMA approach. From this literature, we identify four overarching design strategies for AI writing support: structured guidance, guided exploration, active co-writing, and critical feedback - mapped across the four key cognitive processes in writing: planning, translating, reviewing, and monitoring. We complement this analysis with interviews of 15 writers across diverse domains. Our findings reveal that writers' desired levels of AI intervention vary across the writing process: content-focused writers (e.g., academics) prioritize ownership during planning, while form-focused writers (e.g., creatives) value control over translating and reviewing. Writers' preferences are also shaped by contextual goals, values, and notions of originality and authorship. By examining when ownership matters, what writers want to own, and how AI interactions shape agency, we surface both alignment and gaps between research and user needs. Our findings offer actionable design guidance for developing human-centered writing tools for co-writing with AI, on human terms.","Mohi Reza, Jeb Thomas-Mitchell, Peter Dushniku, Nathan Laundry, Joseph Jay Williams, Anastasia Kuzminykh","cs.HC, cs.AI, H.5.2; I.2.7; I.2.6; I.7.2",2025-04-16T21:05:46Z,http://arxiv.org/abs/2504.12488v1,co writing with ai on human terms aligning research with user demands across the writing process,as generative ai tools like chatgpt become integral to everyday writing critical questions arise about how to preserve writers sense of agency and ownership when using these tools yet a systematic understanding of how ai assistance affects different aspects of the writing process and how this shapes writers agency remains underexplored to address this gap we conducted a systematic review of hci papers using the prisma approach from this literature we identify four overarching design strategies for ai writing support structured guidance guided exploration active co writing and critical feedback mapped across the four key cognitive processes in writing planning translating reviewing and monitoring we complement this analysis with interviews of writers across diverse domains our findings reveal that writers desired levels of ai intervention vary across the writing process content focused writers e g academics prioritize ownership during planning while form focused writers e g creatives value control over translating and reviewing writers preferences are also shaped by contextual goals values and notions of originality and authorship by examining when ownership matters what writers want to own and how ai interactions shape agency we surface both alignment and gaps between research and user needs our findings offer actionable design guidance for developing human centered writing tools for co writing with ai on human terms,"['co', 'writing', 'with', 'ai', 'on', 'human', 'terms', 'aligning', 'research', 'with', 'user', 'demands', 'across', 'the', 'writing', 'process']","['as', 'generative', 'ai', 'tools', 'like', 'chatgpt', 'become', 'integral', 'to', 'everyday', 'writing', 'critical', 'questions', 'arise', 'about', 'how', 'to', 'preserve', 'writers', 'sense', 'of', 'agency', 'and', 'ownership', 'when', 'using', 'these', 'tools', 'yet', 'a', 'systematic', 'understanding', 'of', 'how', 'ai', 'assistance', 'affects', 'different', 'aspects', 'of', 'the', 'writing', 'process', 'and', 'how', 'this', 'shapes', 'writers', 'agency', 'remains', 'underexplored', 'to', 'address', 'this', 'gap', 'we', 'conducted', 'a', 'systematic', 'review', 'of', 'hci', 'papers', 'using', 'the', 'prisma', 'approach', 'from', 'this', 'literature', 'we', 'identify', 'four', 'overarching', 'design', 'strategies', 'for', 'ai', 'writing', 'support', 'structured', 'guidance', 'guided', 'exploration', 'active', 'co', 'writing', 'and', 'critical', 'feedback', 'mapped', 'across', 'the', 'four', 'key', 'cognitive', 'processes', 'in', 'writing', 'planning', 'translating', 'reviewing', 'and', 'monitoring', 'we', 'complement', 'this', 'analysis', 'with', 'interviews', 'of', 'writers', 'across', 'diverse', 'domains', 'our', 'findings', 'reveal', 'that', 'writers', 'desired', 'levels', 'of', 'ai', 'intervention', 'vary', 'across', 'the', 'writing', 'process', 'content', 'focused', 'writers', 'e', 'g', 'academics', 'prioritize', 'ownership', 'during', 'planning', 'while', 'form', 'focused', 'writers', 'e', 'g', 'creatives', 'value', 'control', 'over', 'translating', 'and', 'reviewing', 'writers', 'preferences', 'are', 'also', 'shaped', 'by', 'contextual', 'goals', 'values', 'and', 'notions', 'of', 'originality', 'and', 'authorship', 'by', 'examining', 'when', 'ownership', 'matters', 'what', 'writers', 'want', 'to', 'own', 'and', 'how', 'ai', 'interactions', 'shape', 'agency', 'we', 'surface', 'both', 'alignment', 'and', 'gaps', 'between', 'research', 'and', 'user', 'needs', 'our', 'findings', 'offer', 'actionable', 'design', 'guidance', 'for', 'developing', 'human', 'centered', 'writing', 'tools', 'for', 'co', 'writing', 'with', 'ai', 'on', 'human', 'terms']",16,215,"['Yet', 'HCI', 'From', 'ChatGPT', 'Writers', '109', 'Our', 'PRISMA']"
2504.12477v1,Towards Conversational AI for Human-Machine Collaborative MLOps,"This paper presents a Large Language Model (LLM) based conversational agent system designed to enhance human-machine collaboration in Machine Learning Operations (MLOps). We introduce the Swarm Agent, an extensible architecture that integrates specialized agents to create and manage ML workflows through natural language interactions. The system leverages a hierarchical, modular design incorporating a KubeFlow Pipelines (KFP) Agent for ML pipeline orchestration, a MinIO Agent for data management, and a Retrieval-Augmented Generation (RAG) Agent for domain-specific knowledge integration. Through iterative reasoning loops and context-aware processing, the system enables users with varying technical backgrounds to discover, execute, and monitor ML pipelines; manage datasets and artifacts; and access relevant documentation, all via intuitive conversational interfaces. Our approach addresses the accessibility gap in complex MLOps platforms like Kubeflow, making advanced ML tools broadly accessible while maintaining the flexibility to extend to other platforms. The paper describes the architecture, implementation details, and demonstrates how this conversational MLOps assistant reduces complexity and lowers barriers to entry for users across diverse technical skill levels.","George Fatouros, Georgios Makridis, George Kousiouris, John Soldatos, Anargyros Tsadimas, Dimosthenis Kyriazis","cs.AI, cs.CL, cs.HC, 68T50, 68T99, 68U35, 68N19, I.2.1; H.5.2; D.2.11; I.2.7",2025-04-16T20:28:50Z,http://arxiv.org/abs/2504.12477v1,towards conversational ai for human machine collaborative mlops,this paper presents a large language model llm based conversational agent system designed to enhance human machine collaboration in machine learning operations mlops we introduce the swarm agent an extensible architecture that integrates specialized agents to create and manage ml workflows through natural language interactions the system leverages a hierarchical modular design incorporating a kubeflow pipelines kfp agent for ml pipeline orchestration a minio agent for data management and a retrieval augmented generation rag agent for domain specific knowledge integration through iterative reasoning loops and context aware processing the system enables users with varying technical backgrounds to discover execute and monitor ml pipelines manage datasets and artifacts and access relevant documentation all via intuitive conversational interfaces our approach addresses the accessibility gap in complex mlops platforms like kubeflow making advanced ml tools broadly accessible while maintaining the flexibility to extend to other platforms the paper describes the architecture implementation details and demonstrates how this conversational mlops assistant reduces complexity and lowers barriers to entry for users across diverse technical skill levels,"['towards', 'conversational', 'ai', 'for', 'human', 'machine', 'collaborative', 'mlops']","['this', 'paper', 'presents', 'a', 'large', 'language', 'model', 'llm', 'based', 'conversational', 'agent', 'system', 'designed', 'to', 'enhance', 'human', 'machine', 'collaboration', 'in', 'machine', 'learning', 'operations', 'mlops', 'we', 'introduce', 'the', 'swarm', 'agent', 'an', 'extensible', 'architecture', 'that', 'integrates', 'specialized', 'agents', 'to', 'create', 'and', 'manage', 'ml', 'workflows', 'through', 'natural', 'language', 'interactions', 'the', 'system', 'leverages', 'a', 'hierarchical', 'modular', 'design', 'incorporating', 'a', 'kubeflow', 'pipelines', 'kfp', 'agent', 'for', 'ml', 'pipeline', 'orchestration', 'a', 'minio', 'agent', 'for', 'data', 'management', 'and', 'a', 'retrieval', 'augmented', 'generation', 'rag', 'agent', 'for', 'domain', 'specific', 'knowledge', 'integration', 'through', 'iterative', 'reasoning', 'loops', 'and', 'context', 'aware', 'processing', 'the', 'system', 'enables', 'users', 'with', 'varying', 'technical', 'backgrounds', 'to', 'discover', 'execute', 'and', 'monitor', 'ml', 'pipelines', 'manage', 'datasets', 'and', 'artifacts', 'and', 'access', 'relevant', 'documentation', 'all', 'via', 'intuitive', 'conversational', 'interfaces', 'our', 'approach', 'addresses', 'the', 'accessibility', 'gap', 'in', 'complex', 'mlops', 'platforms', 'like', 'kubeflow', 'making', 'advanced', 'ml', 'tools', 'broadly', 'accessible', 'while', 'maintaining', 'the', 'flexibility', 'to', 'extend', 'to', 'other', 'platforms', 'the', 'paper', 'describes', 'the', 'architecture', 'implementation', 'details', 'and', 'demonstrates', 'how', 'this', 'conversational', 'mlops', 'assistant', 'reduces', 'complexity', 'and', 'lowers', 'barriers', 'to', 'entry', 'for', 'users', 'across', 'diverse', 'technical', 'skill', 'levels']",8,171,"['Model', 'Learning', 'Language', 'Retrieval', 'Our', 'Operations', 'Through', 'KFP', 'Agent', 'Pipelines', 'Augmented', 'MLOps', 'Generation', 'Large', 'RAG', 'MinIO', 'Swarm', 'LLM', 'KubeFlow', 'Kubeflow', 'Machine']"
2504.12476v1,What do people expect from Artificial Intelligence? Public opinion on   alignment in AI moderation from Germany and the United States,"Recent advances in generative Artificial Intelligence have raised public awareness, shaping expectations and concerns about their societal implications. Central to these debates is the question of AI alignment -- how well AI systems meet public expectations regarding safety, fairness, and social values. However, little is known about what people expect from AI-enabled systems and how these expectations differ across national contexts. We present evidence from two surveys of public preferences for key functional features of AI-enabled systems in Germany (n = 1800) and the United States (n = 1756). We examine support for four types of alignment in AI moderation: accuracy and reliability, safety, bias mitigation, and the promotion of aspirational imaginaries. U.S. respondents report significantly higher AI use and consistently greater support for all alignment features, reflecting broader technological openness and higher societal involvement with AI. In both countries, accuracy and safety enjoy the strongest support, while more normatively charged goals -- like fairness and aspirational imaginaries -- receive more cautious backing, particularly in Germany. We also explore how individual experience with AI, attitudes toward free speech, political ideology, partisan affiliation, and gender shape these preferences. AI use and free speech support explain more variation in Germany. In contrast, U.S. responses show greater attitudinal uniformity, suggesting that higher exposure to AI may consolidate public expectations. These findings contribute to debates on AI governance and cross-national variation in public preferences. More broadly, our study demonstrates the value of empirically grounding AI alignment debates in public attitudes and of explicitly developing normatively grounded expectations into theoretical and policy discussions on the governance of AI-generated content.","Andreas Jungherr, Adrian Rauchfleisch","cs.CY, cs.AI",2025-04-16T20:27:03Z,http://arxiv.org/abs/2504.12476v1,what do people expect from artificial intelligence public opinion on alignment in ai moderation from germany and the united states,recent advances in generative artificial intelligence have raised public awareness shaping expectations and concerns about their societal implications central to these debates is the question of ai alignment how well ai systems meet public expectations regarding safety fairness and social values however little is known about what people expect from ai enabled systems and how these expectations differ across national contexts we present evidence from two surveys of public preferences for key functional features of ai enabled systems in germany n and the united states n we examine support for four types of alignment in ai moderation accuracy and reliability safety bias mitigation and the promotion of aspirational imaginaries u s respondents report significantly higher ai use and consistently greater support for all alignment features reflecting broader technological openness and higher societal involvement with ai in both countries accuracy and safety enjoy the strongest support while more normatively charged goals like fairness and aspirational imaginaries receive more cautious backing particularly in germany we also explore how individual experience with ai attitudes toward free speech political ideology partisan affiliation and gender shape these preferences ai use and free speech support explain more variation in germany in contrast u s responses show greater attitudinal uniformity suggesting that higher exposure to ai may consolidate public expectations these findings contribute to debates on ai governance and cross national variation in public preferences more broadly our study demonstrates the value of empirically grounding ai alignment debates in public attitudes and of explicitly developing normatively grounded expectations into theoretical and policy discussions on the governance of ai generated content,"['what', 'do', 'people', 'expect', 'from', 'artificial', 'intelligence', 'public', 'opinion', 'on', 'alignment', 'in', 'ai', 'moderation', 'from', 'germany', 'and', 'the', 'united', 'states']","['recent', 'advances', 'in', 'generative', 'artificial', 'intelligence', 'have', 'raised', 'public', 'awareness', 'shaping', 'expectations', 'and', 'concerns', 'about', 'their', 'societal', 'implications', 'central', 'to', 'these', 'debates', 'is', 'the', 'question', 'of', 'ai', 'alignment', 'how', 'well', 'ai', 'systems', 'meet', 'public', 'expectations', 'regarding', 'safety', 'fairness', 'and', 'social', 'values', 'however', 'little', 'is', 'known', 'about', 'what', 'people', 'expect', 'from', 'ai', 'enabled', 'systems', 'and', 'how', 'these', 'expectations', 'differ', 'across', 'national', 'contexts', 'we', 'present', 'evidence', 'from', 'two', 'surveys', 'of', 'public', 'preferences', 'for', 'key', 'functional', 'features', 'of', 'ai', 'enabled', 'systems', 'in', 'germany', 'n', 'and', 'the', 'united', 'states', 'n', 'we', 'examine', 'support', 'for', 'four', 'types', 'of', 'alignment', 'in', 'ai', 'moderation', 'accuracy', 'and', 'reliability', 'safety', 'bias', 'mitigation', 'and', 'the', 'promotion', 'of', 'aspirational', 'imaginaries', 'u', 's', 'respondents', 'report', 'significantly', 'higher', 'ai', 'use', 'and', 'consistently', 'greater', 'support', 'for', 'all', 'alignment', 'features', 'reflecting', 'broader', 'technological', 'openness', 'and', 'higher', 'societal', 'involvement', 'with', 'ai', 'in', 'both', 'countries', 'accuracy', 'and', 'safety', 'enjoy', 'the', 'strongest', 'support', 'while', 'more', 'normatively', 'charged', 'goals', 'like', 'fairness', 'and', 'aspirational', 'imaginaries', 'receive', 'more', 'cautious', 'backing', 'particularly', 'in', 'germany', 'we', 'also', 'explore', 'how', 'individual', 'experience', 'with', 'ai', 'attitudes', 'toward', 'free', 'speech', 'political', 'ideology', 'partisan', 'affiliation', 'and', 'gender', 'shape', 'these', 'preferences', 'ai', 'use', 'and', 'free', 'speech', 'support', 'explain', 'more', 'variation', 'in', 'germany', 'in', 'contrast', 'u', 's', 'responses', 'show', 'greater', 'attitudinal', 'uniformity', 'suggesting', 'that', 'higher', 'exposure', 'to', 'ai', 'may', 'consolidate', 'public', 'expectations', 'these', 'findings', 'contribute', 'to', 'debates', 'on', 'ai', 'governance', 'and', 'cross', 'national', 'variation', 'in', 'public', 'preferences', 'more', 'broadly', 'our', 'study', 'demonstrates', 'the', 'value', 'of', 'empirically', 'grounding', 'ai', 'alignment', 'debates', 'in', 'public', 'attitudes', 'and', 'of', 'explicitly', 'developing', 'normatively', 'grounded', 'expectations', 'into', 'theoretical', 'and', 'policy', 'discussions', 'on', 'the', 'governance', 'of', 'ai', 'generated', 'content']",20,263,"['More', 'Intelligence', 'AI-enabled', 'Recent', '1800', '1756', 'However', 'Artificial', 'These', 'Germany', 'States', 'Central', 'AI-generated', 'United']"
2504.12474v1,Integrating Structural and Semantic Signals in Text-Attributed Graphs   with BiGTex,"Text-attributed graphs (TAGs) present unique challenges in representation learning by requiring models to capture both the semantic richness of node-associated texts and the structural dependencies of the graph. While graph neural networks (GNNs) excel at modeling topological information, they lack the capacity to process unstructured text. Conversely, large language models (LLMs) are proficient in text understanding but are typically unaware of graph structure. In this work, we propose BiGTex (Bidirectional Graph Text), a novel architecture that tightly integrates GNNs and LLMs through stacked Graph-Text Fusion Units. Each unit allows for mutual attention between textual and structural representations, enabling information to flow in both directions, text influencing structure and structure guiding textual interpretation. The proposed architecture is trained using parameter-efficient fine-tuning (LoRA), keeping the LLM frozen while adapting to task-specific signals. Extensive experiments on five benchmark datasets demonstrate that BiGTex achieves state-of-the-art performance in node classification and generalizes effectively to link prediction. An ablation study further highlights the importance of soft prompting and bi-directional attention in the model's success.","Azadeh Beiranvand, Seyed Mehdi Vahidipour","cs.CL, cs.AI",2025-04-16T20:25:11Z,http://arxiv.org/abs/2504.12474v1,integrating structural and semantic signals in text attributed graphs with bigtex,text attributed graphs tags present unique challenges in representation learning by requiring models to capture both the semantic richness of node associated texts and the structural dependencies of the graph while graph neural networks gnns excel at modeling topological information they lack the capacity to process unstructured text conversely large language models llms are proficient in text understanding but are typically unaware of graph structure in this work we propose bigtex bidirectional graph text a novel architecture that tightly integrates gnns and llms through stacked graph text fusion units each unit allows for mutual attention between textual and structural representations enabling information to flow in both directions text influencing structure and structure guiding textual interpretation the proposed architecture is trained using parameter efficient fine tuning lora keeping the llm frozen while adapting to task specific signals extensive experiments on five benchmark datasets demonstrate that bigtex achieves state of the art performance in node classification and generalizes effectively to link prediction an ablation study further highlights the importance of soft prompting and bi directional attention in the model s success,"['integrating', 'structural', 'and', 'semantic', 'signals', 'in', 'text', 'attributed', 'graphs', 'with', 'bigtex']","['text', 'attributed', 'graphs', 'tags', 'present', 'unique', 'challenges', 'in', 'representation', 'learning', 'by', 'requiring', 'models', 'to', 'capture', 'both', 'the', 'semantic', 'richness', 'of', 'node', 'associated', 'texts', 'and', 'the', 'structural', 'dependencies', 'of', 'the', 'graph', 'while', 'graph', 'neural', 'networks', 'gnns', 'excel', 'at', 'modeling', 'topological', 'information', 'they', 'lack', 'the', 'capacity', 'to', 'process', 'unstructured', 'text', 'conversely', 'large', 'language', 'models', 'llms', 'are', 'proficient', 'in', 'text', 'understanding', 'but', 'are', 'typically', 'unaware', 'of', 'graph', 'structure', 'in', 'this', 'work', 'we', 'propose', 'bigtex', 'bidirectional', 'graph', 'text', 'a', 'novel', 'architecture', 'that', 'tightly', 'integrates', 'gnns', 'and', 'llms', 'through', 'stacked', 'graph', 'text', 'fusion', 'units', 'each', 'unit', 'allows', 'for', 'mutual', 'attention', 'between', 'textual', 'and', 'structural', 'representations', 'enabling', 'information', 'to', 'flow', 'in', 'both', 'directions', 'text', 'influencing', 'structure', 'and', 'structure', 'guiding', 'textual', 'interpretation', 'the', 'proposed', 'architecture', 'is', 'trained', 'using', 'parameter', 'efficient', 'fine', 'tuning', 'lora', 'keeping', 'the', 'llm', 'frozen', 'while', 'adapting', 'to', 'task', 'specific', 'signals', 'extensive', 'experiments', 'on', 'five', 'benchmark', 'datasets', 'demonstrate', 'that', 'bigtex', 'achieves', 'state', 'of', 'the', 'art', 'performance', 'in', 'node', 'classification', 'and', 'generalizes', 'effectively', 'to', 'link', 'prediction', 'an', 'ablation', 'study', 'further', 'highlights', 'the', 'importance', 'of', 'soft', 'prompting', 'and', 'bi', 'directional', 'attention', 'in', 'the', 'model', 's', 'success']",11,179,"['Conversely', 'Extensive', 'LLMs', 'While', 'LLM', 'Graph', 'BiGTex', 'Fusion', 'LoRA', 'Units', 'Bidirectional', 'Each', 'Text', 'TAGs', 'GNNs']"
2504.12436v1,Sparsity Outperforms Low-Rank Projections in Few-Shot Adaptation,"Adapting Vision-Language Models (VLMs) to new domains with few labeled samples remains a significant challenge due to severe overfitting and computational constraints. State-of-the-art solutions, such as low-rank reparameterization, mitigate these issues but often struggle with generalization and require extensive hyperparameter tuning. In this paper, a novel Sparse Optimization (SO) framework is proposed. Unlike low-rank approaches that typically constrain updates to a fixed subspace, our SO method leverages high sparsity to dynamically adjust very few parameters. We introduce two key paradigms. First, we advocate for \textit{local sparsity and global density}, which updates a minimal subset of parameters per iteration while maintaining overall model expressiveness. As a second paradigm, we advocate for \textit{local randomness and global importance}, which sparsifies the gradient using random selection while pruning the first moment based on importance. This combination significantly mitigates overfitting and ensures stable adaptation in low-data regimes. Extensive experiments on 11 diverse datasets show that SO achieves state-of-the-art few-shot adaptation performance while reducing memory overhead.","Nairouz Mrabah, Nicolas Richet, Ismail Ben Ayed, √âric Granger","cs.CV, cs.AI, I.4.8; I.5.1; G.1.6",2025-04-16T19:10:34Z,http://arxiv.org/abs/2504.12436v1,sparsity outperforms low rank projections in few shot adaptation,adapting vision language models vlms to new domains with few labeled samples remains a significant challenge due to severe overfitting and computational constraints state of the art solutions such as low rank reparameterization mitigate these issues but often struggle with generalization and require extensive hyperparameter tuning in this paper a novel sparse optimization so framework is proposed unlike low rank approaches that typically constrain updates to a fixed subspace our so method leverages high sparsity to dynamically adjust very few parameters we introduce two key paradigms first we advocate for local sparsity and global density which updates a minimal subset of parameters per iteration while maintaining overall model expressiveness as a second paradigm we advocate for local randomness and global importance which sparsifies the gradient using random selection while pruning the first moment based on importance this combination significantly mitigates overfitting and ensures stable adaptation in low data regimes extensive experiments on diverse datasets show that so achieves state of the art few shot adaptation performance while reducing memory overhead,"['sparsity', 'outperforms', 'low', 'rank', 'projections', 'in', 'few', 'shot', 'adaptation']","['adapting', 'vision', 'language', 'models', 'vlms', 'to', 'new', 'domains', 'with', 'few', 'labeled', 'samples', 'remains', 'a', 'significant', 'challenge', 'due', 'to', 'severe', 'overfitting', 'and', 'computational', 'constraints', 'state', 'of', 'the', 'art', 'solutions', 'such', 'as', 'low', 'rank', 'reparameterization', 'mitigate', 'these', 'issues', 'but', 'often', 'struggle', 'with', 'generalization', 'and', 'require', 'extensive', 'hyperparameter', 'tuning', 'in', 'this', 'paper', 'a', 'novel', 'sparse', 'optimization', 'so', 'framework', 'is', 'proposed', 'unlike', 'low', 'rank', 'approaches', 'that', 'typically', 'constrain', 'updates', 'to', 'a', 'fixed', 'subspace', 'our', 'so', 'method', 'leverages', 'high', 'sparsity', 'to', 'dynamically', 'adjust', 'very', 'few', 'parameters', 'we', 'introduce', 'two', 'key', 'paradigms', 'first', 'we', 'advocate', 'for', 'local', 'sparsity', 'and', 'global', 'density', 'which', 'updates', 'a', 'minimal', 'subset', 'of', 'parameters', 'per', 'iteration', 'while', 'maintaining', 'overall', 'model', 'expressiveness', 'as', 'a', 'second', 'paradigm', 'we', 'advocate', 'for', 'local', 'randomness', 'and', 'global', 'importance', 'which', 'sparsifies', 'the', 'gradient', 'using', 'random', 'selection', 'while', 'pruning', 'the', 'first', 'moment', 'based', 'on', 'importance', 'this', 'combination', 'significantly', 'mitigates', 'overfitting', 'and', 'ensures', 'stable', 'adaptation', 'in', 'low', 'data', 'regimes', 'extensive', 'experiments', 'on', 'diverse', 'datasets', 'show', 'that', 'so', 'achieves', 'state', 'of', 'the', 'art', 'few', 'shot', 'adaptation', 'performance', 'while', 'reducing', 'memory', 'overhead']",9,170,"['Extensive', 'Adapting', 'Unlike', 'Optimization', 'Models', 'First', 'Vision', 'State', 'Language', 'Sparse', 'VLMs']"
2504.12424v1,"Don't Just Translate, Agitate: Using Large Language Models as Devil's   Advocates for AI Explanations","This position paper highlights a growing trend in Explainable AI (XAI) research where Large Language Models (LLMs) are used to translate outputs from explainability techniques, like feature-attribution weights, into a natural language explanation. While this approach may improve accessibility or readability for users, recent findings suggest that translating into human-like explanations does not necessarily enhance user understanding and may instead lead to overreliance on AI systems. When LLMs summarize XAI outputs without surfacing model limitations, uncertainties, or inconsistencies, they risk reinforcing the illusion of interpretability rather than fostering meaningful transparency. We argue that - instead of merely translating XAI outputs - LLMs should serve as constructive agitators, or devil's advocates, whose role is to actively interrogate AI explanations by presenting alternative interpretations, potential biases, training data limitations, and cases where the model's reasoning may break down. In this role, LLMs can facilitate users in engaging critically with AI systems and generated explanations, with the potential to reduce overreliance caused by misinterpreted or specious explanations.","Ashley Suh, Kenneth Alperin, Harry Li, Steven R Gomez","cs.HC, cs.AI",2025-04-16T18:45:18Z,http://arxiv.org/abs/2504.12424v1,don t just translate agitate using large language models as devil s advocates for ai explanations,this position paper highlights a growing trend in explainable ai xai research where large language models llms are used to translate outputs from explainability techniques like feature attribution weights into a natural language explanation while this approach may improve accessibility or readability for users recent findings suggest that translating into human like explanations does not necessarily enhance user understanding and may instead lead to overreliance on ai systems when llms summarize xai outputs without surfacing model limitations uncertainties or inconsistencies they risk reinforcing the illusion of interpretability rather than fostering meaningful transparency we argue that instead of merely translating xai outputs llms should serve as constructive agitators or devil s advocates whose role is to actively interrogate ai explanations by presenting alternative interpretations potential biases training data limitations and cases where the model s reasoning may break down in this role llms can facilitate users in engaging critically with ai systems and generated explanations with the potential to reduce overreliance caused by misinterpreted or specious explanations,"['don', 't', 'just', 'translate', 'agitate', 'using', 'large', 'language', 'models', 'as', 'devil', 's', 'advocates', 'for', 'ai', 'explanations']","['this', 'position', 'paper', 'highlights', 'a', 'growing', 'trend', 'in', 'explainable', 'ai', 'xai', 'research', 'where', 'large', 'language', 'models', 'llms', 'are', 'used', 'to', 'translate', 'outputs', 'from', 'explainability', 'techniques', 'like', 'feature', 'attribution', 'weights', 'into', 'a', 'natural', 'language', 'explanation', 'while', 'this', 'approach', 'may', 'improve', 'accessibility', 'or', 'readability', 'for', 'users', 'recent', 'findings', 'suggest', 'that', 'translating', 'into', 'human', 'like', 'explanations', 'does', 'not', 'necessarily', 'enhance', 'user', 'understanding', 'and', 'may', 'instead', 'lead', 'to', 'overreliance', 'on', 'ai', 'systems', 'when', 'llms', 'summarize', 'xai', 'outputs', 'without', 'surfacing', 'model', 'limitations', 'uncertainties', 'or', 'inconsistencies', 'they', 'risk', 'reinforcing', 'the', 'illusion', 'of', 'interpretability', 'rather', 'than', 'fostering', 'meaningful', 'transparency', 'we', 'argue', 'that', 'instead', 'of', 'merely', 'translating', 'xai', 'outputs', 'llms', 'should', 'serve', 'as', 'constructive', 'agitators', 'or', 'devil', 's', 'advocates', 'whose', 'role', 'is', 'to', 'actively', 'interrogate', 'ai', 'explanations', 'by', 'presenting', 'alternative', 'interpretations', 'potential', 'biases', 'training', 'data', 'limitations', 'and', 'cases', 'where', 'the', 'model', 's', 'reasoning', 'may', 'break', 'down', 'in', 'this', 'role', 'llms', 'can', 'facilitate', 'users', 'in', 'engaging', 'critically', 'with', 'ai', 'systems', 'and', 'generated', 'explanations', 'with', 'the', 'potential', 'to', 'reduce', 'overreliance', 'caused', 'by', 'misinterpreted', 'or', 'specious', 'explanations']",16,166,"['XAI', 'LLMs', 'While', 'Explainable', 'Models', 'When', 'Language', 'Large']"
2504.12397v1,Activated LoRA: Fine-tuned LLMs for Intrinsics,"Low-Rank Adaptation (LoRA) has emerged as a highly efficient framework for finetuning the weights of large foundation models, and has become the go-to method for data-driven customization of LLMs. Despite the promise of highly customized behaviors and capabilities, switching between relevant LoRAs in a multiturn setting is highly inefficient, as the key-value (KV) cache of the entire turn history must be recomputed with the LoRA weights before generation can begin. To address this problem, we propose Activated LoRA (aLoRA), which modifies the LoRA framework to only adapt weights for the tokens in the sequence \emph{after} the aLoRA is invoked. This change crucially allows aLoRA to accept the base model's KV cache of the input string, meaning that aLoRA can be instantly activated whenever needed in a chain without recomputing the cache. This enables building what we call \emph{intrinsics}, i.e. highly specialized models invoked to perform well-defined operations on portions of an input chain or conversation that otherwise uses the base model by default. We use aLoRA to train a set of intrinsics models, demonstrating competitive accuracy with standard LoRA while achieving significant inference benefits.","Kristjan Greenewald, Luis Lastras, Thomas Parnell, Vraj Shah, Lucian Popa, Giulio Zizzo, Chulaka Gunasekara, Ambrish Rawat, David Cox","cs.LG, cs.AI",2025-04-16T18:03:21Z,http://arxiv.org/abs/2504.12397v1,activated lora fine tuned llms for intrinsics,low rank adaptation lora has emerged as a highly efficient framework for finetuning the weights of large foundation models and has become the go to method for data driven customization of llms despite the promise of highly customized behaviors and capabilities switching between relevant loras in a multiturn setting is highly inefficient as the key value kv cache of the entire turn history must be recomputed with the lora weights before generation can begin to address this problem we propose activated lora alora which modifies the lora framework to only adapt weights for the tokens in the sequence after the alora is invoked this change crucially allows alora to accept the base model s kv cache of the input string meaning that alora can be instantly activated whenever needed in a chain without recomputing the cache this enables building what we call intrinsics i e highly specialized models invoked to perform well defined operations on portions of an input chain or conversation that otherwise uses the base model by default we use alora to train a set of intrinsics models demonstrating competitive accuracy with standard lora while achieving significant inference benefits,"['activated', 'lora', 'fine', 'tuned', 'llms', 'for', 'intrinsics']","['low', 'rank', 'adaptation', 'lora', 'has', 'emerged', 'as', 'a', 'highly', 'efficient', 'framework', 'for', 'finetuning', 'the', 'weights', 'of', 'large', 'foundation', 'models', 'and', 'has', 'become', 'the', 'go', 'to', 'method', 'for', 'data', 'driven', 'customization', 'of', 'llms', 'despite', 'the', 'promise', 'of', 'highly', 'customized', 'behaviors', 'and', 'capabilities', 'switching', 'between', 'relevant', 'loras', 'in', 'a', 'multiturn', 'setting', 'is', 'highly', 'inefficient', 'as', 'the', 'key', 'value', 'kv', 'cache', 'of', 'the', 'entire', 'turn', 'history', 'must', 'be', 'recomputed', 'with', 'the', 'lora', 'weights', 'before', 'generation', 'can', 'begin', 'to', 'address', 'this', 'problem', 'we', 'propose', 'activated', 'lora', 'alora', 'which', 'modifies', 'the', 'lora', 'framework', 'to', 'only', 'adapt', 'weights', 'for', 'the', 'tokens', 'in', 'the', 'sequence', 'after', 'the', 'alora', 'is', 'invoked', 'this', 'change', 'crucially', 'allows', 'alora', 'to', 'accept', 'the', 'base', 'model', 's', 'kv', 'cache', 'of', 'the', 'input', 'string', 'meaning', 'that', 'alora', 'can', 'be', 'instantly', 'activated', 'whenever', 'needed', 'in', 'a', 'chain', 'without', 'recomputing', 'the', 'cache', 'this', 'enables', 'building', 'what', 'we', 'call', 'intrinsics', 'i', 'e', 'highly', 'specialized', 'models', 'invoked', 'to', 'perform', 'well', 'defined', 'operations', 'on', 'portions', 'of', 'an', 'input', 'chain', 'or', 'conversation', 'that', 'otherwise', 'uses', 'the', 'base', 'model', 'by', 'default', 'we', 'use', 'alora', 'to', 'train', 'a', 'set', 'of', 'intrinsics', 'models', 'demonstrating', 'competitive', 'accuracy', 'with', 'standard', 'lora', 'while', 'achieving', 'significant', 'inference', 'benefits']",7,191,"['LoRAs', 'Despite', 'LLMs', 'LoRA', 'Rank', 'Adaptation', 'Activated', 'Low']"
2504.12284v1,How Do I Do That? Synthesizing 3D Hand Motion and Contacts for Everyday   Interactions,"We tackle the novel problem of predicting 3D hand motion and contact maps (or Interaction Trajectories) given a single RGB view, action text, and a 3D contact point on the object as input. Our approach consists of (1) Interaction Codebook: a VQVAE model to learn a latent codebook of hand poses and contact points, effectively tokenizing interaction trajectories, (2) Interaction Predictor: a transformer-decoder module to predict the interaction trajectory from test time inputs by using an indexer module to retrieve a latent affordance from the learned codebook. To train our model, we develop a data engine that extracts 3D hand poses and contact trajectories from the diverse HoloAssist dataset. We evaluate our model on a benchmark that is 2.5-10X larger than existing works, in terms of diversity of objects and interactions observed, and test for generalization of the model across object categories, action categories, tasks, and scenes. Experimental results show the effectiveness of our approach over transformer & diffusion baselines across all settings.","Aditya Prakash, Benjamin Lundell, Dmitry Andreychuk, David Forsyth, Saurabh Gupta, Harpreet Sawhney","cs.CV, cs.AI, cs.LG",2025-04-16T17:48:12Z,http://arxiv.org/abs/2504.12284v1,how do i do that synthesizing d hand motion and contacts for everyday interactions,we tackle the novel problem of predicting d hand motion and contact maps or interaction trajectories given a single rgb view action text and a d contact point on the object as input our approach consists of interaction codebook a vqvae model to learn a latent codebook of hand poses and contact points effectively tokenizing interaction trajectories interaction predictor a transformer decoder module to predict the interaction trajectory from test time inputs by using an indexer module to retrieve a latent affordance from the learned codebook to train our model we develop a data engine that extracts d hand poses and contact trajectories from the diverse holoassist dataset we evaluate our model on a benchmark that is x larger than existing works in terms of diversity of objects and interactions observed and test for generalization of the model across object categories action categories tasks and scenes experimental results show the effectiveness of our approach over transformer diffusion baselines across all settings,"['how', 'do', 'i', 'do', 'that', 'synthesizing', 'd', 'hand', 'motion', 'and', 'contacts', 'for', 'everyday', 'interactions']","['we', 'tackle', 'the', 'novel', 'problem', 'of', 'predicting', 'd', 'hand', 'motion', 'and', 'contact', 'maps', 'or', 'interaction', 'trajectories', 'given', 'a', 'single', 'rgb', 'view', 'action', 'text', 'and', 'a', 'd', 'contact', 'point', 'on', 'the', 'object', 'as', 'input', 'our', 'approach', 'consists', 'of', 'interaction', 'codebook', 'a', 'vqvae', 'model', 'to', 'learn', 'a', 'latent', 'codebook', 'of', 'hand', 'poses', 'and', 'contact', 'points', 'effectively', 'tokenizing', 'interaction', 'trajectories', 'interaction', 'predictor', 'a', 'transformer', 'decoder', 'module', 'to', 'predict', 'the', 'interaction', 'trajectory', 'from', 'test', 'time', 'inputs', 'by', 'using', 'an', 'indexer', 'module', 'to', 'retrieve', 'a', 'latent', 'affordance', 'from', 'the', 'learned', 'codebook', 'to', 'train', 'our', 'model', 'we', 'develop', 'a', 'data', 'engine', 'that', 'extracts', 'd', 'hand', 'poses', 'and', 'contact', 'trajectories', 'from', 'the', 'diverse', 'holoassist', 'dataset', 'we', 'evaluate', 'our', 'model', 'on', 'a', 'benchmark', 'that', 'is', 'x', 'larger', 'than', 'existing', 'works', 'in', 'terms', 'of', 'diversity', 'of', 'objects', 'and', 'interactions', 'observed', 'and', 'test', 'for', 'generalization', 'of', 'the', 'model', 'across', 'object', 'categories', 'action', 'categories', 'tasks', 'and', 'scenes', 'experimental', 'results', 'show', 'the', 'effectiveness', 'of', 'our', 'approach', 'over', 'transformer', 'diffusion', 'baselines', 'across', 'all', 'settings']",14,161,"['HoloAssist', 'RGB', 'Experimental', 'Interaction', 'Predictor', 'Codebook', '5-10X', 'VQVAE', 'Our', 'Trajectories']"
2504.12268v1,HLS-Eval: A Benchmark and Framework for Evaluating LLMs on High-Level   Synthesis Design Tasks,"The rapid scaling of large language model (LLM) training and inference has driven their adoption in semiconductor design across academia and industry. While most prior work evaluates LLMs on hardware description language (HDL) tasks, particularly Verilog, designers are increasingly using high-level synthesis (HLS) to build domain-specific accelerators and complex hardware systems. However, benchmarks and tooling to comprehensively evaluate LLMs for HLS design tasks remain scarce.   To address this, we introduce HLS-Eval, the first complete benchmark and evaluation framework for LLM-driven HLS design. HLS-Eval targets two core tasks: (1) generating HLS code from natural language descriptions, and (2) performing HLS-specific code edits to optimize performance and hardware efficiency. The benchmark includes 94 unique designs drawn from standard HLS benchmarks and novel sources. Each case is prepared via a semi-automated flow that produces a natural language description and a paired testbench for C-simulation and synthesis validation, ensuring each task is ""LLM-ready.""   Beyond the benchmark, HLS-Eval offers a modular Python framework for automated, parallel evaluation of both local and hosted LLMs. It includes a parallel evaluation engine, direct HLS tool integration, and abstractions for to support different LLM interaction paradigms, enabling rapid prototyping of new benchmarks, tasks, and LLM methods.   We demonstrate HLS-Eval through baseline evaluations of open-source LLMs on Vitis HLS, measuring outputs across four key metrics - parseability, compilability, runnability, and synthesizability - reflecting the iterative HLS design cycle. We also report pass@k metrics, establishing clear baselines and reusable infrastructure for the broader LLM-for-hardware community.   All benchmarks, framework code, and results are open-sourced at https://github.com/stefanpie/hls-eval.","Stefan Abi-Karam, Cong Hao","cs.AR, cs.AI",2025-04-16T17:30:36Z,http://arxiv.org/abs/2504.12268v1,hls eval a benchmark and framework for evaluating llms on high level synthesis design tasks,the rapid scaling of large language model llm training and inference has driven their adoption in semiconductor design across academia and industry while most prior work evaluates llms on hardware description language hdl tasks particularly verilog designers are increasingly using high level synthesis hls to build domain specific accelerators and complex hardware systems however benchmarks and tooling to comprehensively evaluate llms for hls design tasks remain scarce to address this we introduce hls eval the first complete benchmark and evaluation framework for llm driven hls design hls eval targets two core tasks generating hls code from natural language descriptions and performing hls specific code edits to optimize performance and hardware efficiency the benchmark includes unique designs drawn from standard hls benchmarks and novel sources each case is prepared via a semi automated flow that produces a natural language description and a paired testbench for c simulation and synthesis validation ensuring each task is llm ready beyond the benchmark hls eval offers a modular python framework for automated parallel evaluation of both local and hosted llms it includes a parallel evaluation engine direct hls tool integration and abstractions for to support different llm interaction paradigms enabling rapid prototyping of new benchmarks tasks and llm methods we demonstrate hls eval through baseline evaluations of open source llms on vitis hls measuring outputs across four key metrics parseability compilability runnability and synthesizability reflecting the iterative hls design cycle we also report pass k metrics establishing clear baselines and reusable infrastructure for the broader llm for hardware community all benchmarks framework code and results are open sourced at,"['hls', 'eval', 'a', 'benchmark', 'and', 'framework', 'for', 'evaluating', 'llms', 'on', 'high', 'level', 'synthesis', 'design', 'tasks']","['the', 'rapid', 'scaling', 'of', 'large', 'language', 'model', 'llm', 'training', 'and', 'inference', 'has', 'driven', 'their', 'adoption', 'in', 'semiconductor', 'design', 'across', 'academia', 'and', 'industry', 'while', 'most', 'prior', 'work', 'evaluates', 'llms', 'on', 'hardware', 'description', 'language', 'hdl', 'tasks', 'particularly', 'verilog', 'designers', 'are', 'increasingly', 'using', 'high', 'level', 'synthesis', 'hls', 'to', 'build', 'domain', 'specific', 'accelerators', 'and', 'complex', 'hardware', 'systems', 'however', 'benchmarks', 'and', 'tooling', 'to', 'comprehensively', 'evaluate', 'llms', 'for', 'hls', 'design', 'tasks', 'remain', 'scarce', 'to', 'address', 'this', 'we', 'introduce', 'hls', 'eval', 'the', 'first', 'complete', 'benchmark', 'and', 'evaluation', 'framework', 'for', 'llm', 'driven', 'hls', 'design', 'hls', 'eval', 'targets', 'two', 'core', 'tasks', 'generating', 'hls', 'code', 'from', 'natural', 'language', 'descriptions', 'and', 'performing', 'hls', 'specific', 'code', 'edits', 'to', 'optimize', 'performance', 'and', 'hardware', 'efficiency', 'the', 'benchmark', 'includes', 'unique', 'designs', 'drawn', 'from', 'standard', 'hls', 'benchmarks', 'and', 'novel', 'sources', 'each', 'case', 'is', 'prepared', 'via', 'a', 'semi', 'automated', 'flow', 'that', 'produces', 'a', 'natural', 'language', 'description', 'and', 'a', 'paired', 'testbench', 'for', 'c', 'simulation', 'and', 'synthesis', 'validation', 'ensuring', 'each', 'task', 'is', 'llm', 'ready', 'beyond', 'the', 'benchmark', 'hls', 'eval', 'offers', 'a', 'modular', 'python', 'framework', 'for', 'automated', 'parallel', 'evaluation', 'of', 'both', 'local', 'and', 'hosted', 'llms', 'it', 'includes', 'a', 'parallel', 'evaluation', 'engine', 'direct', 'hls', 'tool', 'integration', 'and', 'abstractions', 'for', 'to', 'support', 'different', 'llm', 'interaction', 'paradigms', 'enabling', 'rapid', 'prototyping', 'of', 'new', 'benchmarks', 'tasks', 'and', 'llm', 'methods', 'we', 'demonstrate', 'hls', 'eval', 'through', 'baseline', 'evaluations', 'of', 'open', 'source', 'llms', 'on', 'vitis', 'hls', 'measuring', 'outputs', 'across', 'four', 'key', 'metrics', 'parseability', 'compilability', 'runnability', 'and', 'synthesizability', 'reflecting', 'the', 'iterative', 'hls', 'design', 'cycle', 'we', 'also', 'report', 'pass', 'k', 'metrics', 'establishing', 'clear', 'baselines', 'and', 'reusable', 'infrastructure', 'for', 'the', 'broader', 'llm', 'for', 'hardware', 'community', 'all', 'benchmarks', 'framework', 'code', 'and', 'results', 'are', 'open', 'sourced', 'at']",15,264,"['Beyond', 'Verilog', 'All', 'HLS', 'LLMs', 'While', 'However', 'HDL', 'Python', 'HLS-Eval', 'C-simulation', 'Each', 'LLM-for', 'LLM-driven', 'HLS-specific', 'Vitis', 'LLM', 'LLM-ready']"
2504.12262v1,SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via   Scalable Conditioned Neural Fields,"Spatiotemporal learning is challenging due to the intricate interplay between spatial and temporal dependencies, the high dimensionality of the data, and scalability constraints. These challenges are further amplified in scientific domains, where data is often irregularly distributed (e.g., missing values from sensor failures) and high-volume (e.g., high-fidelity simulations), posing additional computational and modeling difficulties. In this paper, we present SCENT, a novel framework for scalable and continuity-informed spatiotemporal representation learning. SCENT unifies interpolation, reconstruction, and forecasting within a single architecture. Built on a transformer-based encoder-processor-decoder backbone, SCENT introduces learnable queries to enhance generalization and a query-wise cross-attention mechanism to effectively capture multi-scale dependencies. To ensure scalability in both data size and model complexity, we incorporate a sparse attention mechanism, enabling flexible output representations and efficient evaluation at arbitrary resolutions. We validate SCENT through extensive simulations and real-world experiments, demonstrating state-of-the-art performance across multiple challenging tasks while achieving superior scalability.","David Keetae Park, Xihaier Luo, Guang Zhao, Seungjun Lee, Miruna Oprescu, Shinjae Yoo","cs.LG, cs.AI",2025-04-16T17:17:31Z,http://arxiv.org/abs/2504.12262v1,scent robust spatiotemporal learning for continuous scientific data via scalable conditioned neural fields,spatiotemporal learning is challenging due to the intricate interplay between spatial and temporal dependencies the high dimensionality of the data and scalability constraints these challenges are further amplified in scientific domains where data is often irregularly distributed e g missing values from sensor failures and high volume e g high fidelity simulations posing additional computational and modeling difficulties in this paper we present scent a novel framework for scalable and continuity informed spatiotemporal representation learning scent unifies interpolation reconstruction and forecasting within a single architecture built on a transformer based encoder processor decoder backbone scent introduces learnable queries to enhance generalization and a query wise cross attention mechanism to effectively capture multi scale dependencies to ensure scalability in both data size and model complexity we incorporate a sparse attention mechanism enabling flexible output representations and efficient evaluation at arbitrary resolutions we validate scent through extensive simulations and real world experiments demonstrating state of the art performance across multiple challenging tasks while achieving superior scalability,"['scent', 'robust', 'spatiotemporal', 'learning', 'for', 'continuous', 'scientific', 'data', 'via', 'scalable', 'conditioned', 'neural', 'fields']","['spatiotemporal', 'learning', 'is', 'challenging', 'due', 'to', 'the', 'intricate', 'interplay', 'between', 'spatial', 'and', 'temporal', 'dependencies', 'the', 'high', 'dimensionality', 'of', 'the', 'data', 'and', 'scalability', 'constraints', 'these', 'challenges', 'are', 'further', 'amplified', 'in', 'scientific', 'domains', 'where', 'data', 'is', 'often', 'irregularly', 'distributed', 'e', 'g', 'missing', 'values', 'from', 'sensor', 'failures', 'and', 'high', 'volume', 'e', 'g', 'high', 'fidelity', 'simulations', 'posing', 'additional', 'computational', 'and', 'modeling', 'difficulties', 'in', 'this', 'paper', 'we', 'present', 'scent', 'a', 'novel', 'framework', 'for', 'scalable', 'and', 'continuity', 'informed', 'spatiotemporal', 'representation', 'learning', 'scent', 'unifies', 'interpolation', 'reconstruction', 'and', 'forecasting', 'within', 'a', 'single', 'architecture', 'built', 'on', 'a', 'transformer', 'based', 'encoder', 'processor', 'decoder', 'backbone', 'scent', 'introduces', 'learnable', 'queries', 'to', 'enhance', 'generalization', 'and', 'a', 'query', 'wise', 'cross', 'attention', 'mechanism', 'to', 'effectively', 'capture', 'multi', 'scale', 'dependencies', 'to', 'ensure', 'scalability', 'in', 'both', 'data', 'size', 'and', 'model', 'complexity', 'we', 'incorporate', 'a', 'sparse', 'attention', 'mechanism', 'enabling', 'flexible', 'output', 'representations', 'and', 'efficient', 'evaluation', 'at', 'arbitrary', 'resolutions', 'we', 'validate', 'scent', 'through', 'extensive', 'simulations', 'and', 'real', 'world', 'experiments', 'demonstrating', 'state', 'of', 'the', 'art', 'performance', 'across', 'multiple', 'challenging', 'tasks', 'while', 'achieving', 'superior', 'scalability']",13,164,"['Spatiotemporal', 'Built', 'These', 'SCENT']"
2504.12256v1,FLIP Reasoning Challenge,"Over the past years, advances in artificial intelligence (AI) have demonstrated how AI can solve many perception and generation tasks, such as image classification and text writing, yet reasoning remains a challenge. This paper introduces the FLIP dataset, a benchmark for evaluating AI reasoning capabilities based on human verification tasks on the Idena blockchain. FLIP challenges present users with two orderings of 4 images, requiring them to identify the logically coherent one. By emphasizing sequential reasoning, visual storytelling, and common sense, FLIP provides a unique testbed for multimodal AI systems. Our experiments evaluate state-of-the-art models, leveraging both vision-language models (VLMs) and large language models (LLMs). Results reveal that even the best open-sourced and closed-sourced models achieve maximum accuracies of 75.5% and 77.9%, respectively, in zero-shot settings, compared to human performance of 95.3%. Captioning models aid reasoning models by providing text descriptions of images, yielding better results than when using the raw images directly, 69.6% vs. 75.2% for Gemini 1.5 Pro. Combining the predictions from 15 models in an ensemble increases the accuracy to 85.2%. These findings highlight the limitations of existing reasoning models and the need for robust multimodal benchmarks like FLIP. The full codebase and dataset will be available at https://github.com/aplesner/FLIP-Reasoning-Challenge.","Andreas Plesner, Turlan Kuzhagaliyev, Roger Wattenhofer","cs.CV, cs.AI, cs.LG",2025-04-16T17:07:16Z,http://arxiv.org/abs/2504.12256v1,flip reasoning challenge,over the past years advances in artificial intelligence ai have demonstrated how ai can solve many perception and generation tasks such as image classification and text writing yet reasoning remains a challenge this paper introduces the flip dataset a benchmark for evaluating ai reasoning capabilities based on human verification tasks on the idena blockchain flip challenges present users with two orderings of images requiring them to identify the logically coherent one by emphasizing sequential reasoning visual storytelling and common sense flip provides a unique testbed for multimodal ai systems our experiments evaluate state of the art models leveraging both vision language models vlms and large language models llms results reveal that even the best open sourced and closed sourced models achieve maximum accuracies of and respectively in zero shot settings compared to human performance of captioning models aid reasoning models by providing text descriptions of images yielding better results than when using the raw images directly vs for gemini pro combining the predictions from models in an ensemble increases the accuracy to these findings highlight the limitations of existing reasoning models and the need for robust multimodal benchmarks like flip the full codebase and dataset will be available at,"['flip', 'reasoning', 'challenge']","['over', 'the', 'past', 'years', 'advances', 'in', 'artificial', 'intelligence', 'ai', 'have', 'demonstrated', 'how', 'ai', 'can', 'solve', 'many', 'perception', 'and', 'generation', 'tasks', 'such', 'as', 'image', 'classification', 'and', 'text', 'writing', 'yet', 'reasoning', 'remains', 'a', 'challenge', 'this', 'paper', 'introduces', 'the', 'flip', 'dataset', 'a', 'benchmark', 'for', 'evaluating', 'ai', 'reasoning', 'capabilities', 'based', 'on', 'human', 'verification', 'tasks', 'on', 'the', 'idena', 'blockchain', 'flip', 'challenges', 'present', 'users', 'with', 'two', 'orderings', 'of', 'images', 'requiring', 'them', 'to', 'identify', 'the', 'logically', 'coherent', 'one', 'by', 'emphasizing', 'sequential', 'reasoning', 'visual', 'storytelling', 'and', 'common', 'sense', 'flip', 'provides', 'a', 'unique', 'testbed', 'for', 'multimodal', 'ai', 'systems', 'our', 'experiments', 'evaluate', 'state', 'of', 'the', 'art', 'models', 'leveraging', 'both', 'vision', 'language', 'models', 'vlms', 'and', 'large', 'language', 'models', 'llms', 'results', 'reveal', 'that', 'even', 'the', 'best', 'open', 'sourced', 'and', 'closed', 'sourced', 'models', 'achieve', 'maximum', 'accuracies', 'of', 'and', 'respectively', 'in', 'zero', 'shot', 'settings', 'compared', 'to', 'human', 'performance', 'of', 'captioning', 'models', 'aid', 'reasoning', 'models', 'by', 'providing', 'text', 'descriptions', 'of', 'images', 'yielding', 'better', 'results', 'than', 'when', 'using', 'the', 'raw', 'images', 'directly', 'vs', 'for', 'gemini', 'pro', 'combining', 'the', 'predictions', 'from', 'models', 'in', 'an', 'ensemble', 'increases', 'the', 'accuracy', 'to', 'these', 'findings', 'highlight', 'the', 'limitations', 'of', 'existing', 'reasoning', 'models', 'and', 'the', 'need', 'for', 'robust', 'multimodal', 'benchmarks', 'like', 'flip', 'the', 'full', 'codebase', 'and', 'dataset', 'will', 'be', 'available', 'at']",3,199,"['Challenge', 'Our', 'LLMs', 'Captioning', 'Results', 'These', 'FLIP-Reasoning', 'Gemini', 'Pro', 'Combining', 'Over', 'Idena', 'FLIP', 'VLMs']"
2504.12215v1,Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware   Post-Processing,"Reliable tumor segmentation in thoracic computed tomography (CT) remains challenging due to boundary ambiguity, class imbalance, and anatomical variability. We propose an uncertainty-guided, coarse-to-fine segmentation framework that combines full-volume tumor localization with refined region-of-interest (ROI) segmentation, enhanced by anatomically aware post-processing. The first-stage model generates a coarse prediction, followed by anatomically informed filtering based on lung overlap, proximity to lung surfaces, and component size. The resulting ROIs are segmented by a second-stage model trained with uncertainty-aware loss functions to improve accuracy and boundary calibration in ambiguous regions. Experiments on private and public datasets demonstrate improvements in Dice and Hausdorff scores, with fewer false positives and enhanced spatial interpretability. These results highlight the value of combining uncertainty modeling and anatomical priors in cascaded segmentation pipelines for robust and clinically meaningful tumor delineation. On the Orlando dataset, our framework improved Swin UNETR Dice from 0.4690 to 0.6447. Reduction in spurious components was strongly correlated with segmentation gains, underscoring the value of anatomically informed post-processing.","Ilkin Sevgi Isler, David Mohaisen, Curtis Lisle, Damla Turgut, Ulas Bagci","cs.CV, cs.AI",2025-04-16T16:08:38Z,http://arxiv.org/abs/2504.12215v1,uncertainty guided coarse to fine tumor segmentation with anatomy aware post processing,reliable tumor segmentation in thoracic computed tomography ct remains challenging due to boundary ambiguity class imbalance and anatomical variability we propose an uncertainty guided coarse to fine segmentation framework that combines full volume tumor localization with refined region of interest roi segmentation enhanced by anatomically aware post processing the first stage model generates a coarse prediction followed by anatomically informed filtering based on lung overlap proximity to lung surfaces and component size the resulting rois are segmented by a second stage model trained with uncertainty aware loss functions to improve accuracy and boundary calibration in ambiguous regions experiments on private and public datasets demonstrate improvements in dice and hausdorff scores with fewer false positives and enhanced spatial interpretability these results highlight the value of combining uncertainty modeling and anatomical priors in cascaded segmentation pipelines for robust and clinically meaningful tumor delineation on the orlando dataset our framework improved swin unetr dice from to reduction in spurious components was strongly correlated with segmentation gains underscoring the value of anatomically informed post processing,"['uncertainty', 'guided', 'coarse', 'to', 'fine', 'tumor', 'segmentation', 'with', 'anatomy', 'aware', 'post', 'processing']","['reliable', 'tumor', 'segmentation', 'in', 'thoracic', 'computed', 'tomography', 'ct', 'remains', 'challenging', 'due', 'to', 'boundary', 'ambiguity', 'class', 'imbalance', 'and', 'anatomical', 'variability', 'we', 'propose', 'an', 'uncertainty', 'guided', 'coarse', 'to', 'fine', 'segmentation', 'framework', 'that', 'combines', 'full', 'volume', 'tumor', 'localization', 'with', 'refined', 'region', 'of', 'interest', 'roi', 'segmentation', 'enhanced', 'by', 'anatomically', 'aware', 'post', 'processing', 'the', 'first', 'stage', 'model', 'generates', 'a', 'coarse', 'prediction', 'followed', 'by', 'anatomically', 'informed', 'filtering', 'based', 'on', 'lung', 'overlap', 'proximity', 'to', 'lung', 'surfaces', 'and', 'component', 'size', 'the', 'resulting', 'rois', 'are', 'segmented', 'by', 'a', 'second', 'stage', 'model', 'trained', 'with', 'uncertainty', 'aware', 'loss', 'functions', 'to', 'improve', 'accuracy', 'and', 'boundary', 'calibration', 'in', 'ambiguous', 'regions', 'experiments', 'on', 'private', 'and', 'public', 'datasets', 'demonstrate', 'improvements', 'in', 'dice', 'and', 'hausdorff', 'scores', 'with', 'fewer', 'false', 'positives', 'and', 'enhanced', 'spatial', 'interpretability', 'these', 'results', 'highlight', 'the', 'value', 'of', 'combining', 'uncertainty', 'modeling', 'and', 'anatomical', 'priors', 'in', 'cascaded', 'segmentation', 'pipelines', 'for', 'robust', 'and', 'clinically', 'meaningful', 'tumor', 'delineation', 'on', 'the', 'orlando', 'dataset', 'our', 'framework', 'improved', 'swin', 'unetr', 'dice', 'from', 'to', 'reduction', 'in', 'spurious', 'components', 'was', 'strongly', 'correlated', 'with', 'segmentation', 'gains', 'underscoring', 'the', 'value', 'of', 'anatomically', 'informed', 'post', 'processing']",12,171,"['UNETR', 'Dice', 'Reliable', 'Orlando', '4690', 'ROIs', '6447', 'These', 'ROI', 'Swin', 'Reduction', 'Experiments', 'Hausdorff']"
2504.12365v1,Themisto: Jupyter-Based Runtime Benchmark,"In this work, we present a benchmark that consists of Jupyter notebooks development trajectories and allows measuring how large language models (LLMs) can leverage runtime information for predicting code output and code generation. We demonstrate that the current generation of LLMs performs poorly on these tasks and argue that there exists a significantly understudied domain in the development of code-based models, which involves incorporating the runtime context.","Konstantin Grotov, Sergey Titov","cs.SE, cs.AI, cs.LG",2025-04-16T16:07:18Z,http://arxiv.org/abs/2504.12365v1,themisto jupyter based runtime benchmark,in this work we present a benchmark that consists of jupyter notebooks development trajectories and allows measuring how large language models llms can leverage runtime information for predicting code output and code generation we demonstrate that the current generation of llms performs poorly on these tasks and argue that there exists a significantly understudied domain in the development of code based models which involves incorporating the runtime context,"['themisto', 'jupyter', 'based', 'runtime', 'benchmark']","['in', 'this', 'work', 'we', 'present', 'a', 'benchmark', 'that', 'consists', 'of', 'jupyter', 'notebooks', 'development', 'trajectories', 'and', 'allows', 'measuring', 'how', 'large', 'language', 'models', 'llms', 'can', 'leverage', 'runtime', 'information', 'for', 'predicting', 'code', 'output', 'and', 'code', 'generation', 'we', 'demonstrate', 'that', 'the', 'current', 'generation', 'of', 'llms', 'performs', 'poorly', 'on', 'these', 'tasks', 'and', 'argue', 'that', 'there', 'exists', 'a', 'significantly', 'understudied', 'domain', 'in', 'the', 'development', 'of', 'code', 'based', 'models', 'which', 'involves', 'incorporating', 'the', 'runtime', 'context']",5,68,"['Jupyter', 'LLMs']"
2504.12192v1,From Requirements to Architecture: Semi-Automatically Generating   Software Architectures,"To support junior and senior architects, I propose developing a new architecture creation method that leverages LLMs' evolving capabilities to support the architect. This method involves the architect's close collaboration with LLM-fueled tooling over the whole process. The architect is guided through Domain Model creation, Use Case specification, architectural decisions, and architecture evaluation. While the architect can take complete control of the process and the results, and use the tooling as a building set, they can follow the intended process for maximum tooling support. The preliminary results suggest the feasibility of this process and indicate major time savings for the architect.",Tobias Eisenreich,"cs.SE, cs.AI, D.2.2",2025-04-16T15:46:56Z,http://arxiv.org/abs/2504.12192v1,from requirements to architecture semi automatically generating software architectures,to support junior and senior architects i propose developing a new architecture creation method that leverages llms evolving capabilities to support the architect this method involves the architect s close collaboration with llm fueled tooling over the whole process the architect is guided through domain model creation use case specification architectural decisions and architecture evaluation while the architect can take complete control of the process and the results and use the tooling as a building set they can follow the intended process for maximum tooling support the preliminary results suggest the feasibility of this process and indicate major time savings for the architect,"['from', 'requirements', 'to', 'architecture', 'semi', 'automatically', 'generating', 'software', 'architectures']","['to', 'support', 'junior', 'and', 'senior', 'architects', 'i', 'propose', 'developing', 'a', 'new', 'architecture', 'creation', 'method', 'that', 'leverages', 'llms', 'evolving', 'capabilities', 'to', 'support', 'the', 'architect', 'this', 'method', 'involves', 'the', 'architect', 's', 'close', 'collaboration', 'with', 'llm', 'fueled', 'tooling', 'over', 'the', 'whole', 'process', 'the', 'architect', 'is', 'guided', 'through', 'domain', 'model', 'creation', 'use', 'case', 'specification', 'architectural', 'decisions', 'and', 'architecture', 'evaluation', 'while', 'the', 'architect', 'can', 'take', 'complete', 'control', 'of', 'the', 'process', 'and', 'the', 'results', 'and', 'use', 'the', 'tooling', 'as', 'a', 'building', 'set', 'they', 'can', 'follow', 'the', 'intended', 'process', 'for', 'maximum', 'tooling', 'support', 'the', 'preliminary', 'results', 'suggest', 'the', 'feasibility', 'of', 'this', 'process', 'and', 'indicate', 'major', 'time', 'savings', 'for', 'the', 'architect']",9,103,"['Domain', 'Model', 'Use', 'LLMs', 'While', 'Case', 'LLM-fueled']"
2504.12185v1,SALAD: Improving Robustness and Generalization through Contrastive   Learning with Structure-Aware and LLM-Driven Augmented Data,"In various natural language processing (NLP) tasks, fine-tuning Pre-trained Language Models (PLMs) often leads to the issue of spurious correlations, which negatively impacts performance, particularly when dealing with out-of-distribution data. To address this problem, we propose SALAD}(Structure Aware and LLM-driven Augmented Data), a novel approach designed to enhance model robustness and generalization by generating structure-aware and counterfactually augmented data for contrastive learning. Our method leverages a tagging-based approach to generate structure-aware positive samples and utilizes large language models (LLMs) to generate counterfactual negative samples with diverse sentence patterns. By applying contrastive learning, SALAD enables the model to focus on learning the structural relationships between key sentence components while minimizing reliance on spurious correlations. We validate our approach through experiments on three tasks: Sentiment Classification, Sexism Detection, and Natural Language Inference. The results demonstrate that SALAD not only improves model robustness and performance across different environments but also enhances generalization to out-of-distribution datasets and cross-domain scenarios.","Suyoung Bae, Hyojun Kim, YunSeok Choi, Jee-Hyong Lee","cs.CL, cs.AI",2025-04-16T15:40:10Z,http://arxiv.org/abs/2504.12185v1,salad improving robustness and generalization through contrastive learning with structure aware and llm driven augmented data,in various natural language processing nlp tasks fine tuning pre trained language models plms often leads to the issue of spurious correlations which negatively impacts performance particularly when dealing with out of distribution data to address this problem we propose salad structure aware and llm driven augmented data a novel approach designed to enhance model robustness and generalization by generating structure aware and counterfactually augmented data for contrastive learning our method leverages a tagging based approach to generate structure aware positive samples and utilizes large language models llms to generate counterfactual negative samples with diverse sentence patterns by applying contrastive learning salad enables the model to focus on learning the structural relationships between key sentence components while minimizing reliance on spurious correlations we validate our approach through experiments on three tasks sentiment classification sexism detection and natural language inference the results demonstrate that salad not only improves model robustness and performance across different environments but also enhances generalization to out of distribution datasets and cross domain scenarios,"['salad', 'improving', 'robustness', 'and', 'generalization', 'through', 'contrastive', 'learning', 'with', 'structure', 'aware', 'and', 'llm', 'driven', 'augmented', 'data']","['in', 'various', 'natural', 'language', 'processing', 'nlp', 'tasks', 'fine', 'tuning', 'pre', 'trained', 'language', 'models', 'plms', 'often', 'leads', 'to', 'the', 'issue', 'of', 'spurious', 'correlations', 'which', 'negatively', 'impacts', 'performance', 'particularly', 'when', 'dealing', 'with', 'out', 'of', 'distribution', 'data', 'to', 'address', 'this', 'problem', 'we', 'propose', 'salad', 'structure', 'aware', 'and', 'llm', 'driven', 'augmented', 'data', 'a', 'novel', 'approach', 'designed', 'to', 'enhance', 'model', 'robustness', 'and', 'generalization', 'by', 'generating', 'structure', 'aware', 'and', 'counterfactually', 'augmented', 'data', 'for', 'contrastive', 'learning', 'our', 'method', 'leverages', 'a', 'tagging', 'based', 'approach', 'to', 'generate', 'structure', 'aware', 'positive', 'samples', 'and', 'utilizes', 'large', 'language', 'models', 'llms', 'to', 'generate', 'counterfactual', 'negative', 'samples', 'with', 'diverse', 'sentence', 'patterns', 'by', 'applying', 'contrastive', 'learning', 'salad', 'enables', 'the', 'model', 'to', 'focus', 'on', 'learning', 'the', 'structural', 'relationships', 'between', 'key', 'sentence', 'components', 'while', 'minimizing', 'reliance', 'on', 'spurious', 'correlations', 'we', 'validate', 'our', 'approach', 'through', 'experiments', 'on', 'three', 'tasks', 'sentiment', 'classification', 'sexism', 'detection', 'and', 'natural', 'language', 'inference', 'the', 'results', 'demonstrate', 'that', 'salad', 'not', 'only', 'improves', 'model', 'robustness', 'and', 'performance', 'across', 'different', 'environments', 'but', 'also', 'enhances', 'generalization', 'to', 'out', 'of', 'distribution', 'datasets', 'and', 'cross', 'domain', 'scenarios']",16,167,"['SALAD', 'Sentiment', 'NLP', 'Aware', 'Language', 'Our', 'PLMs', 'Data', 'LLMs', 'Augmented', 'Classification', 'Sexism', 'Inference', 'Natural', 'Structure', 'Models', 'Detection', 'LLM-driven', 'Pre']"
2504.12180v1,Trusting CHATGPT: how minor tweaks in the prompts lead to major   differences in sentiment classification,"One fundamental question for the social sciences today is: how much can we trust highly complex predictive models like ChatGPT? This study tests the hypothesis that subtle changes in the structure of prompts do not produce significant variations in the classification results of sentiment polarity analysis generated by the Large Language Model GPT-4o mini. Using a dataset of 100.000 comments in Spanish on four Latin American presidents, the model classified the comments as positive, negative, or neutral on 10 occasions, varying the prompts slightly each time. The experimental methodology included exploratory and confirmatory analyses to identify significant discrepancies among classifications.   The results reveal that even minor modifications to prompts such as lexical, syntactic, or modal changes, or even their lack of structure impact the classifications. In certain cases, the model produced inconsistent responses, such as mixing categories, providing unsolicited explanations, or using languages other than Spanish. Statistical analysis using Chi-square tests confirmed significant differences in most comparisons between prompts, except in one case where linguistic structures were highly similar.   These findings challenge the robustness and trust of Large Language Models for classification tasks, highlighting their vulnerability to variations in instructions. Moreover, it was evident that the lack of structured grammar in prompts increases the frequency of hallucinations. The discussion underscores that trust in Large Language Models is based not only on technical performance but also on the social and institutional relationships underpinning their use.","Jaime E. Cuellar, Oscar Moreno-Martinez, Paula Sofia Torres-Rodriguez, Jaime Andres Pavlich-Mariscal, Andres Felipe Mican-Castiblanco, Juan Guillermo Torres-Hurtado","cs.CL, cs.AI",2025-04-16T15:37:09Z,http://arxiv.org/abs/2504.12180v1,trusting chatgpt how minor tweaks in the prompts lead to major differences in sentiment classification,one fundamental question for the social sciences today is how much can we trust highly complex predictive models like chatgpt this study tests the hypothesis that subtle changes in the structure of prompts do not produce significant variations in the classification results of sentiment polarity analysis generated by the large language model gpt o mini using a dataset of comments in spanish on four latin american presidents the model classified the comments as positive negative or neutral on occasions varying the prompts slightly each time the experimental methodology included exploratory and confirmatory analyses to identify significant discrepancies among classifications the results reveal that even minor modifications to prompts such as lexical syntactic or modal changes or even their lack of structure impact the classifications in certain cases the model produced inconsistent responses such as mixing categories providing unsolicited explanations or using languages other than spanish statistical analysis using chi square tests confirmed significant differences in most comparisons between prompts except in one case where linguistic structures were highly similar these findings challenge the robustness and trust of large language models for classification tasks highlighting their vulnerability to variations in instructions moreover it was evident that the lack of structured grammar in prompts increases the frequency of hallucinations the discussion underscores that trust in large language models is based not only on technical performance but also on the social and institutional relationships underpinning their use,"['trusting', 'chatgpt', 'how', 'minor', 'tweaks', 'in', 'the', 'prompts', 'lead', 'to', 'major', 'differences', 'in', 'sentiment', 'classification']","['one', 'fundamental', 'question', 'for', 'the', 'social', 'sciences', 'today', 'is', 'how', 'much', 'can', 'we', 'trust', 'highly', 'complex', 'predictive', 'models', 'like', 'chatgpt', 'this', 'study', 'tests', 'the', 'hypothesis', 'that', 'subtle', 'changes', 'in', 'the', 'structure', 'of', 'prompts', 'do', 'not', 'produce', 'significant', 'variations', 'in', 'the', 'classification', 'results', 'of', 'sentiment', 'polarity', 'analysis', 'generated', 'by', 'the', 'large', 'language', 'model', 'gpt', 'o', 'mini', 'using', 'a', 'dataset', 'of', 'comments', 'in', 'spanish', 'on', 'four', 'latin', 'american', 'presidents', 'the', 'model', 'classified', 'the', 'comments', 'as', 'positive', 'negative', 'or', 'neutral', 'on', 'occasions', 'varying', 'the', 'prompts', 'slightly', 'each', 'time', 'the', 'experimental', 'methodology', 'included', 'exploratory', 'and', 'confirmatory', 'analyses', 'to', 'identify', 'significant', 'discrepancies', 'among', 'classifications', 'the', 'results', 'reveal', 'that', 'even', 'minor', 'modifications', 'to', 'prompts', 'such', 'as', 'lexical', 'syntactic', 'or', 'modal', 'changes', 'or', 'even', 'their', 'lack', 'of', 'structure', 'impact', 'the', 'classifications', 'in', 'certain', 'cases', 'the', 'model', 'produced', 'inconsistent', 'responses', 'such', 'as', 'mixing', 'categories', 'providing', 'unsolicited', 'explanations', 'or', 'using', 'languages', 'other', 'than', 'spanish', 'statistical', 'analysis', 'using', 'chi', 'square', 'tests', 'confirmed', 'significant', 'differences', 'in', 'most', 'comparisons', 'between', 'prompts', 'except', 'in', 'one', 'case', 'where', 'linguistic', 'structures', 'were', 'highly', 'similar', 'these', 'findings', 'challenge', 'the', 'robustness', 'and', 'trust', 'of', 'large', 'language', 'models', 'for', 'classification', 'tasks', 'highlighting', 'their', 'vulnerability', 'to', 'variations', 'in', 'instructions', 'moreover', 'it', 'was', 'evident', 'that', 'the', 'lack', 'of', 'structured', 'grammar', 'in', 'prompts', 'increases', 'the', 'frequency', 'of', 'hallucinations', 'the', 'discussion', 'underscores', 'that', 'trust', 'in', 'large', 'language', 'models', 'is', 'based', 'not', 'only', 'on', 'technical', 'performance', 'but', 'also', 'on', 'the', 'social', 'and', 'institutional', 'relationships', 'underpinning', 'their', 'use']",15,234,"['000', 'Model', 'American', 'Latin', '100', 'These', 'ChatGPT', 'One', 'Models', 'Statistical', 'Language', 'Spanish', 'Chi', 'Large', 'Moreover', 'GPT-4o']"
2504.12172v1,Poem Meter Classification of Recited Arabic Poetry: Integrating   High-Resource Systems for a Low-Resource Task,"Arabic poetry is an essential and integral part of Arabic language and culture. It has been used by the Arabs to spot lights on their major events such as depicting brutal battles and conflicts. They also used it, as in many other languages, for various purposes such as romance, pride, lamentation, etc. Arabic poetry has received major attention from linguistics over the decades. One of the main characteristics of Arabic poetry is its special rhythmic structure as opposed to prose. This structure is referred to as a meter. Meters, along with other poetic characteristics, are intensively studied in an Arabic linguistic field called ""\textit{Aroud}"". Identifying these meters for a verse is a lengthy and complicated process. It also requires technical knowledge in \textit{Aruod}. For recited poetry, it adds an extra layer of processing. Developing systems for automatic identification of poem meters for recited poems need large amounts of labelled data. In this study, we propose a state-of-the-art framework to identify the poem meters of recited Arabic poetry, where we integrate two separate high-resource systems to perform the low-resource task. To ensure generalization of our proposed architecture, we publish a benchmark for this task for future research.","Maged S. Al-Shaibani, Zaid Alyafeai, Irfan Ahmad","cs.CL, cs.AI",2025-04-16T15:25:45Z,http://arxiv.org/abs/2504.12172v1,poem meter classification of recited arabic poetry integrating high resource systems for a low resource task,arabic poetry is an essential and integral part of arabic language and culture it has been used by the arabs to spot lights on their major events such as depicting brutal battles and conflicts they also used it as in many other languages for various purposes such as romance pride lamentation etc arabic poetry has received major attention from linguistics over the decades one of the main characteristics of arabic poetry is its special rhythmic structure as opposed to prose this structure is referred to as a meter meters along with other poetic characteristics are intensively studied in an arabic linguistic field called aroud identifying these meters for a verse is a lengthy and complicated process it also requires technical knowledge in aruod for recited poetry it adds an extra layer of processing developing systems for automatic identification of poem meters for recited poems need large amounts of labelled data in this study we propose a state of the art framework to identify the poem meters of recited arabic poetry where we integrate two separate high resource systems to perform the low resource task to ensure generalization of our proposed architecture we publish a benchmark for this task for future research,"['poem', 'meter', 'classification', 'of', 'recited', 'arabic', 'poetry', 'integrating', 'high', 'resource', 'systems', 'for', 'a', 'low', 'resource', 'task']","['arabic', 'poetry', 'is', 'an', 'essential', 'and', 'integral', 'part', 'of', 'arabic', 'language', 'and', 'culture', 'it', 'has', 'been', 'used', 'by', 'the', 'arabs', 'to', 'spot', 'lights', 'on', 'their', 'major', 'events', 'such', 'as', 'depicting', 'brutal', 'battles', 'and', 'conflicts', 'they', 'also', 'used', 'it', 'as', 'in', 'many', 'other', 'languages', 'for', 'various', 'purposes', 'such', 'as', 'romance', 'pride', 'lamentation', 'etc', 'arabic', 'poetry', 'has', 'received', 'major', 'attention', 'from', 'linguistics', 'over', 'the', 'decades', 'one', 'of', 'the', 'main', 'characteristics', 'of', 'arabic', 'poetry', 'is', 'its', 'special', 'rhythmic', 'structure', 'as', 'opposed', 'to', 'prose', 'this', 'structure', 'is', 'referred', 'to', 'as', 'a', 'meter', 'meters', 'along', 'with', 'other', 'poetic', 'characteristics', 'are', 'intensively', 'studied', 'in', 'an', 'arabic', 'linguistic', 'field', 'called', 'aroud', 'identifying', 'these', 'meters', 'for', 'a', 'verse', 'is', 'a', 'lengthy', 'and', 'complicated', 'process', 'it', 'also', 'requires', 'technical', 'knowledge', 'in', 'aruod', 'for', 'recited', 'poetry', 'it', 'adds', 'an', 'extra', 'layer', 'of', 'processing', 'developing', 'systems', 'for', 'automatic', 'identification', 'of', 'poem', 'meters', 'for', 'recited', 'poems', 'need', 'large', 'amounts', 'of', 'labelled', 'data', 'in', 'this', 'study', 'we', 'propose', 'a', 'state', 'of', 'the', 'art', 'framework', 'to', 'identify', 'the', 'poem', 'meters', 'of', 'recited', 'arabic', 'poetry', 'where', 'we', 'integrate', 'two', 'separate', 'high', 'resource', 'systems', 'to', 'perform', 'the', 'low', 'resource', 'task', 'to', 'ensure', 'generalization', 'of', 'our', 'proposed', 'architecture', 'we', 'publish', 'a', 'benchmark', 'for', 'this', 'task', 'for', 'future', 'research']",16,201,"['Identifying', 'Developing', 'One', 'Aruod', 'Meters', 'Arabic', 'Arabs', 'Aroud']"
2504.12143v1,ARCeR: an Agentic RAG for the Automated Definition of Cyber Ranges,"The growing and evolving landscape of cybersecurity threats necessitates the development of supporting tools and platforms that allow for the creation of realistic IT environments operating within virtual, controlled settings as Cyber Ranges (CRs). CRs can be exploited for analyzing vulnerabilities and experimenting with the effectiveness of devised countermeasures, as well as serving as training environments for building cyber security skills and abilities for IT operators. This paper proposes ARCeR as an innovative solution for the automatic generation and deployment of CRs, starting from user-provided descriptions in a natural language. ARCeR relies on the Agentic RAG paradigm, which allows it to fully exploit state-of-art AI technologies. Experimental results show that ARCeR is able to successfully process prompts even in cases that LLMs or basic RAG systems are not able to cope with. Furthermore, ARCeR is able to target any CR framework provided that specific knowledge is made available to it.","Matteo Lupinacci, Francesco Blefari, Francesco Romeo, Francesco Aurelio Pironti, Angelo Furfaro","cs.CR, cs.AI",2025-04-16T14:53:28Z,http://arxiv.org/abs/2504.12143v1,arcer an agentic rag for the automated definition of cyber ranges,the growing and evolving landscape of cybersecurity threats necessitates the development of supporting tools and platforms that allow for the creation of realistic it environments operating within virtual controlled settings as cyber ranges crs crs can be exploited for analyzing vulnerabilities and experimenting with the effectiveness of devised countermeasures as well as serving as training environments for building cyber security skills and abilities for it operators this paper proposes arcer as an innovative solution for the automatic generation and deployment of crs starting from user provided descriptions in a natural language arcer relies on the agentic rag paradigm which allows it to fully exploit state of art ai technologies experimental results show that arcer is able to successfully process prompts even in cases that llms or basic rag systems are not able to cope with furthermore arcer is able to target any cr framework provided that specific knowledge is made available to it,"['arcer', 'an', 'agentic', 'rag', 'for', 'the', 'automated', 'definition', 'of', 'cyber', 'ranges']","['the', 'growing', 'and', 'evolving', 'landscape', 'of', 'cybersecurity', 'threats', 'necessitates', 'the', 'development', 'of', 'supporting', 'tools', 'and', 'platforms', 'that', 'allow', 'for', 'the', 'creation', 'of', 'realistic', 'it', 'environments', 'operating', 'within', 'virtual', 'controlled', 'settings', 'as', 'cyber', 'ranges', 'crs', 'crs', 'can', 'be', 'exploited', 'for', 'analyzing', 'vulnerabilities', 'and', 'experimenting', 'with', 'the', 'effectiveness', 'of', 'devised', 'countermeasures', 'as', 'well', 'as', 'serving', 'as', 'training', 'environments', 'for', 'building', 'cyber', 'security', 'skills', 'and', 'abilities', 'for', 'it', 'operators', 'this', 'paper', 'proposes', 'arcer', 'as', 'an', 'innovative', 'solution', 'for', 'the', 'automatic', 'generation', 'and', 'deployment', 'of', 'crs', 'starting', 'from', 'user', 'provided', 'descriptions', 'in', 'a', 'natural', 'language', 'arcer', 'relies', 'on', 'the', 'agentic', 'rag', 'paradigm', 'which', 'allows', 'it', 'to', 'fully', 'exploit', 'state', 'of', 'art', 'ai', 'technologies', 'experimental', 'results', 'show', 'that', 'arcer', 'is', 'able', 'to', 'successfully', 'process', 'prompts', 'even', 'in', 'cases', 'that', 'llms', 'or', 'basic', 'rag', 'systems', 'are', 'not', 'able', 'to', 'cope', 'with', 'furthermore', 'arcer', 'is', 'able', 'to', 'target', 'any', 'cr', 'framework', 'provided', 'that', 'specific', 'knowledge', 'is', 'made', 'available', 'to', 'it']",11,153,"['Experimental', 'RAG', 'LLMs', 'Agentic', 'Ranges', 'Furthermore', 'Cyber', 'CRs', 'ARCeR']"
2504.12137v1,Efficient Contrastive Decoding with Probabilistic Hallucination   Detection - Mitigating Hallucinations in Large Vision Language Models -,"Despite recent advances in Large Vision Language Models (LVLMs), these models still suffer from generating hallucinatory responses that do not align with the visual input provided. To mitigate such hallucinations, we introduce Efficient Contrastive Decoding (ECD), a simple method that leverages probabilistic hallucination detection to shift the output distribution towards contextually accurate answers at inference time. By contrasting token probabilities and hallucination scores, ECD subtracts hallucinated concepts from the original distribution, effectively suppressing hallucinations. Notably, our proposed method can be applied to any open-source LVLM and does not require additional LVLM training. We evaluate our method on several benchmark datasets and across different LVLMs. Our experiments show that ECD effectively mitigates hallucinations, outperforming state-of-the-art methods with respect to performance on LVLM benchmarks and computation time.","Laura Fieback, Nishilkumar Balar, Jakob Spiegelberg, Hanno Gottschalk","cs.CV, cs.AI, cs.CL, cs.LG",2025-04-16T14:50:25Z,http://arxiv.org/abs/2504.12137v1,efficient contrastive decoding with probabilistic hallucination detection mitigating hallucinations in large vision language models,despite recent advances in large vision language models lvlms these models still suffer from generating hallucinatory responses that do not align with the visual input provided to mitigate such hallucinations we introduce efficient contrastive decoding ecd a simple method that leverages probabilistic hallucination detection to shift the output distribution towards contextually accurate answers at inference time by contrasting token probabilities and hallucination scores ecd subtracts hallucinated concepts from the original distribution effectively suppressing hallucinations notably our proposed method can be applied to any open source lvlm and does not require additional lvlm training we evaluate our method on several benchmark datasets and across different lvlms our experiments show that ecd effectively mitigates hallucinations outperforming state of the art methods with respect to performance on lvlm benchmarks and computation time,"['efficient', 'contrastive', 'decoding', 'with', 'probabilistic', 'hallucination', 'detection', 'mitigating', 'hallucinations', 'in', 'large', 'vision', 'language', 'models']","['despite', 'recent', 'advances', 'in', 'large', 'vision', 'language', 'models', 'lvlms', 'these', 'models', 'still', 'suffer', 'from', 'generating', 'hallucinatory', 'responses', 'that', 'do', 'not', 'align', 'with', 'the', 'visual', 'input', 'provided', 'to', 'mitigate', 'such', 'hallucinations', 'we', 'introduce', 'efficient', 'contrastive', 'decoding', 'ecd', 'a', 'simple', 'method', 'that', 'leverages', 'probabilistic', 'hallucination', 'detection', 'to', 'shift', 'the', 'output', 'distribution', 'towards', 'contextually', 'accurate', 'answers', 'at', 'inference', 'time', 'by', 'contrasting', 'token', 'probabilities', 'and', 'hallucination', 'scores', 'ecd', 'subtracts', 'hallucinated', 'concepts', 'from', 'the', 'original', 'distribution', 'effectively', 'suppressing', 'hallucinations', 'notably', 'our', 'proposed', 'method', 'can', 'be', 'applied', 'to', 'any', 'open', 'source', 'lvlm', 'and', 'does', 'not', 'require', 'additional', 'lvlm', 'training', 'we', 'evaluate', 'our', 'method', 'on', 'several', 'benchmark', 'datasets', 'and', 'across', 'different', 'lvlms', 'our', 'experiments', 'show', 'that', 'ecd', 'effectively', 'mitigates', 'hallucinations', 'outperforming', 'state', 'of', 'the', 'art', 'methods', 'with', 'respect', 'to', 'performance', 'on', 'lvlm', 'benchmarks', 'and', 'computation', 'time']",14,129,"['Efficient', 'Despite', 'ECD', 'LVLMs', 'LVLM', 'Models', 'Vision', 'Notably', 'Language', 'Our', 'Contrastive', 'Large', 'Decoding']"
2504.12090v1,"Reasoning-Based AI for Startup Evaluation (R.A.I.S.E.): A   Memory-Augmented, Multi-Step Decision Framework","We present a novel framework that bridges the gap between the interpretability of decision trees and the advanced reasoning capabilities of large language models (LLMs) to predict startup success. Our approach leverages chain-of-thought prompting to generate detailed reasoning logs, which are subsequently distilled into structured, human-understandable logical rules. The pipeline integrates multiple enhancements - efficient data ingestion, a two-step refinement process, ensemble candidate sampling, simulated reinforcement learning scoring, and persistent memory - to ensure both stable decision-making and transparent output. Experimental evaluations on curated startup datasets demonstrate that our combined pipeline improves precision by 54% from 0.225 to 0.346 and accuracy by 50% from 0.46 to 0.70 compared to a standalone OpenAI o3 model. Notably, our model achieves over 2x the precision of a random classifier (16%). By combining state-of-the-art AI reasoning with explicit rule-based explanations, our method not only augments traditional decision-making processes but also facilitates expert intervention and continuous policy refinement. This work lays the foundation for the implementation of interpretable LLM-powered decision frameworks in high-stakes investment environments and other domains that require transparent and data-driven insights.","Jack Preuveneers, Joseph Ternasky, Fuat Alican, Yigit Ihlamur","cs.AI, I.2.7",2025-04-16T13:53:42Z,http://arxiv.org/abs/2504.12090v1,reasoning based ai for startup evaluation r a i s e a memory augmented multi step decision framework,we present a novel framework that bridges the gap between the interpretability of decision trees and the advanced reasoning capabilities of large language models llms to predict startup success our approach leverages chain of thought prompting to generate detailed reasoning logs which are subsequently distilled into structured human understandable logical rules the pipeline integrates multiple enhancements efficient data ingestion a two step refinement process ensemble candidate sampling simulated reinforcement learning scoring and persistent memory to ensure both stable decision making and transparent output experimental evaluations on curated startup datasets demonstrate that our combined pipeline improves precision by from to and accuracy by from to compared to a standalone openai o model notably our model achieves over x the precision of a random classifier by combining state of the art ai reasoning with explicit rule based explanations our method not only augments traditional decision making processes but also facilitates expert intervention and continuous policy refinement this work lays the foundation for the implementation of interpretable llm powered decision frameworks in high stakes investment environments and other domains that require transparent and data driven insights,"['reasoning', 'based', 'ai', 'for', 'startup', 'evaluation', 'r', 'a', 'i', 's', 'e', 'a', 'memory', 'augmented', 'multi', 'step', 'decision', 'framework']","['we', 'present', 'a', 'novel', 'framework', 'that', 'bridges', 'the', 'gap', 'between', 'the', 'interpretability', 'of', 'decision', 'trees', 'and', 'the', 'advanced', 'reasoning', 'capabilities', 'of', 'large', 'language', 'models', 'llms', 'to', 'predict', 'startup', 'success', 'our', 'approach', 'leverages', 'chain', 'of', 'thought', 'prompting', 'to', 'generate', 'detailed', 'reasoning', 'logs', 'which', 'are', 'subsequently', 'distilled', 'into', 'structured', 'human', 'understandable', 'logical', 'rules', 'the', 'pipeline', 'integrates', 'multiple', 'enhancements', 'efficient', 'data', 'ingestion', 'a', 'two', 'step', 'refinement', 'process', 'ensemble', 'candidate', 'sampling', 'simulated', 'reinforcement', 'learning', 'scoring', 'and', 'persistent', 'memory', 'to', 'ensure', 'both', 'stable', 'decision', 'making', 'and', 'transparent', 'output', 'experimental', 'evaluations', 'on', 'curated', 'startup', 'datasets', 'demonstrate', 'that', 'our', 'combined', 'pipeline', 'improves', 'precision', 'by', 'from', 'to', 'and', 'accuracy', 'by', 'from', 'to', 'compared', 'to', 'a', 'standalone', 'openai', 'o', 'model', 'notably', 'our', 'model', 'achieves', 'over', 'x', 'the', 'precision', 'of', 'a', 'random', 'classifier', 'by', 'combining', 'state', 'of', 'the', 'art', 'ai', 'reasoning', 'with', 'explicit', 'rule', 'based', 'explanations', 'our', 'method', 'not', 'only', 'augments', 'traditional', 'decision', 'making', 'processes', 'but', 'also', 'facilitates', 'expert', 'intervention', 'and', 'continuous', 'policy', 'refinement', 'this', 'work', 'lays', 'the', 'foundation', 'for', 'the', 'implementation', 'of', 'interpretable', 'llm', 'powered', 'decision', 'frameworks', 'in', 'high', 'stakes', 'investment', 'environments', 'and', 'other', 'domains', 'that', 'require', 'transparent', 'and', 'data', 'driven', 'insights']",18,183,"['225', 'Experimental', '346', 'LLMs', 'LLM-powered', 'OpenAI', 'Notably', 'Our']"
2504.12063v1,Optimizing Compound Retrieval Systems,"Modern retrieval systems do not rely on a single ranking model to construct their rankings. Instead, they generally take a cascading approach where a sequence of ranking models are applied in multiple re-ranking stages. Thereby, they balance the quality of the top-K ranking with computational costs by limiting the number of documents each model re-ranks. However, the cascading approach is not the only way models can interact to form a retrieval system.   We propose the concept of compound retrieval systems as a broader class of retrieval systems that apply multiple prediction models. This encapsulates cascading models but also allows other types of interactions than top-K re-ranking. In particular, we enable interactions with large language models (LLMs) which can provide relative relevance comparisons. We focus on the optimization of compound retrieval system design which uniquely involves learning where to apply the component models and how to aggregate their predictions into a final ranking. This work shows how our compound approach can combine the classic BM25 retrieval model with state-of-the-art (pairwise) LLM relevance predictions, while optimizing a given ranking metric and efficiency target. Our experimental results show optimized compound retrieval systems provide better trade-offs between effectiveness and efficiency than cascading approaches, even when applied in a self-supervised manner.   With the introduction of compound retrieval systems, we hope to inspire the information retrieval field to more out-of-the-box thinking on how prediction models can interact to form rankings.","Harrie Oosterhuis, Rolf Jagerman, Zhen Qin, Xuanhui Wang","cs.IR, cs.AI, cs.LG",2025-04-16T13:18:16Z,http://arxiv.org/abs/2504.12063v1,optimizing compound retrieval systems,modern retrieval systems do not rely on a single ranking model to construct their rankings instead they generally take a cascading approach where a sequence of ranking models are applied in multiple re ranking stages thereby they balance the quality of the top k ranking with computational costs by limiting the number of documents each model re ranks however the cascading approach is not the only way models can interact to form a retrieval system we propose the concept of compound retrieval systems as a broader class of retrieval systems that apply multiple prediction models this encapsulates cascading models but also allows other types of interactions than top k re ranking in particular we enable interactions with large language models llms which can provide relative relevance comparisons we focus on the optimization of compound retrieval system design which uniquely involves learning where to apply the component models and how to aggregate their predictions into a final ranking this work shows how our compound approach can combine the classic bm retrieval model with state of the art pairwise llm relevance predictions while optimizing a given ranking metric and efficiency target our experimental results show optimized compound retrieval systems provide better trade offs between effectiveness and efficiency than cascading approaches even when applied in a self supervised manner with the introduction of compound retrieval systems we hope to inspire the information retrieval field to more out of the box thinking on how prediction models can interact to form rankings,"['optimizing', 'compound', 'retrieval', 'systems']","['modern', 'retrieval', 'systems', 'do', 'not', 'rely', 'on', 'a', 'single', 'ranking', 'model', 'to', 'construct', 'their', 'rankings', 'instead', 'they', 'generally', 'take', 'a', 'cascading', 'approach', 'where', 'a', 'sequence', 'of', 'ranking', 'models', 'are', 'applied', 'in', 'multiple', 're', 'ranking', 'stages', 'thereby', 'they', 'balance', 'the', 'quality', 'of', 'the', 'top', 'k', 'ranking', 'with', 'computational', 'costs', 'by', 'limiting', 'the', 'number', 'of', 'documents', 'each', 'model', 're', 'ranks', 'however', 'the', 'cascading', 'approach', 'is', 'not', 'the', 'only', 'way', 'models', 'can', 'interact', 'to', 'form', 'a', 'retrieval', 'system', 'we', 'propose', 'the', 'concept', 'of', 'compound', 'retrieval', 'systems', 'as', 'a', 'broader', 'class', 'of', 'retrieval', 'systems', 'that', 'apply', 'multiple', 'prediction', 'models', 'this', 'encapsulates', 'cascading', 'models', 'but', 'also', 'allows', 'other', 'types', 'of', 'interactions', 'than', 'top', 'k', 're', 'ranking', 'in', 'particular', 'we', 'enable', 'interactions', 'with', 'large', 'language', 'models', 'llms', 'which', 'can', 'provide', 'relative', 'relevance', 'comparisons', 'we', 'focus', 'on', 'the', 'optimization', 'of', 'compound', 'retrieval', 'system', 'design', 'which', 'uniquely', 'involves', 'learning', 'where', 'to', 'apply', 'the', 'component', 'models', 'and', 'how', 'to', 'aggregate', 'their', 'predictions', 'into', 'a', 'final', 'ranking', 'this', 'work', 'shows', 'how', 'our', 'compound', 'approach', 'can', 'combine', 'the', 'classic', 'bm', 'retrieval', 'model', 'with', 'state', 'of', 'the', 'art', 'pairwise', 'llm', 'relevance', 'predictions', 'while', 'optimizing', 'a', 'given', 'ranking', 'metric', 'and', 'efficiency', 'target', 'our', 'experimental', 'results', 'show', 'optimized', 'compound', 'retrieval', 'systems', 'provide', 'better', 'trade', 'offs', 'between', 'effectiveness', 'and', 'efficiency', 'than', 'cascading', 'approaches', 'even', 'when', 'applied', 'in', 'a', 'self', 'supervised', 'manner', 'with', 'the', 'introduction', 'of', 'compound', 'retrieval', 'systems', 'we', 'hope', 'to', 'inspire', 'the', 'information', 'retrieval', 'field', 'to', 'more', 'out', 'of', 'the', 'box', 'thinking', 'on', 'how', 'prediction', 'models', 'can', 'interact', 'to', 'form', 'rankings']",4,247,"['Thereby', 'Instead', 'LLMs', 'BM25', 'LLM', 'However', 'Our', 'Modern']"
2504.12007v1,Generative Recommendation with Continuous-Token Diffusion,"In recent years, there has been a significant trend toward using large language model (LLM)-based recommender systems (RecSys). Current research primarily focuses on representing complex user-item interactions within a discrete space to align with the inherent discrete nature of language models. However, this approach faces limitations due to its discrete nature: (i) information is often compressed during discretization; (ii) the tokenization and generation for the vast number of users and items in real-world scenarios are constrained by a limited vocabulary. Embracing continuous data presents a promising alternative to enhance expressive capabilities, though this approach is still in its early stages. To address this gap, we propose a novel framework, DeftRec, which incorporates \textbf{de}noising di\textbf{f}fusion models to enable LLM-based RecSys to seamlessly support continuous \textbf{t}oken as input and target. First, we introduce a robust tokenizer with a masking operation and an additive K-way architecture to index users and items, capturing their complex collaborative relationships into continuous tokens. Crucially, we develop a denoising diffusion model to process user preferences within continuous domains by conditioning on reasoning content from pre-trained large language model. During the denoising process, we reformulate the objective to include negative interactions, building a comprehensive understanding of user preferences for effective and accurate recommendation generation. Finally, given a continuous token as output, recommendations can be easily generated through score-based retrieval. Extensive experiments demonstrate the effectiveness of the proposed methods, showing that DeftRec surpasses competitive benchmarks, including both traditional and emerging LLM-based RecSys.","Haohao Qu, Wenqi Fan, Shanru Lin","cs.IR, cs.AI",2025-04-16T12:01:03Z,http://arxiv.org/abs/2504.12007v1,generative recommendation with continuous token diffusion,in recent years there has been a significant trend toward using large language model llm based recommender systems recsys current research primarily focuses on representing complex user item interactions within a discrete space to align with the inherent discrete nature of language models however this approach faces limitations due to its discrete nature i information is often compressed during discretization ii the tokenization and generation for the vast number of users and items in real world scenarios are constrained by a limited vocabulary embracing continuous data presents a promising alternative to enhance expressive capabilities though this approach is still in its early stages to address this gap we propose a novel framework deftrec which incorporates de noising di f fusion models to enable llm based recsys to seamlessly support continuous t oken as input and target first we introduce a robust tokenizer with a masking operation and an additive k way architecture to index users and items capturing their complex collaborative relationships into continuous tokens crucially we develop a denoising diffusion model to process user preferences within continuous domains by conditioning on reasoning content from pre trained large language model during the denoising process we reformulate the objective to include negative interactions building a comprehensive understanding of user preferences for effective and accurate recommendation generation finally given a continuous token as output recommendations can be easily generated through score based retrieval extensive experiments demonstrate the effectiveness of the proposed methods showing that deftrec surpasses competitive benchmarks including both traditional and emerging llm based recsys,"['generative', 'recommendation', 'with', 'continuous', 'token', 'diffusion']","['in', 'recent', 'years', 'there', 'has', 'been', 'a', 'significant', 'trend', 'toward', 'using', 'large', 'language', 'model', 'llm', 'based', 'recommender', 'systems', 'recsys', 'current', 'research', 'primarily', 'focuses', 'on', 'representing', 'complex', 'user', 'item', 'interactions', 'within', 'a', 'discrete', 'space', 'to', 'align', 'with', 'the', 'inherent', 'discrete', 'nature', 'of', 'language', 'models', 'however', 'this', 'approach', 'faces', 'limitations', 'due', 'to', 'its', 'discrete', 'nature', 'i', 'information', 'is', 'often', 'compressed', 'during', 'discretization', 'ii', 'the', 'tokenization', 'and', 'generation', 'for', 'the', 'vast', 'number', 'of', 'users', 'and', 'items', 'in', 'real', 'world', 'scenarios', 'are', 'constrained', 'by', 'a', 'limited', 'vocabulary', 'embracing', 'continuous', 'data', 'presents', 'a', 'promising', 'alternative', 'to', 'enhance', 'expressive', 'capabilities', 'though', 'this', 'approach', 'is', 'still', 'in', 'its', 'early', 'stages', 'to', 'address', 'this', 'gap', 'we', 'propose', 'a', 'novel', 'framework', 'deftrec', 'which', 'incorporates', 'de', 'noising', 'di', 'f', 'fusion', 'models', 'to', 'enable', 'llm', 'based', 'recsys', 'to', 'seamlessly', 'support', 'continuous', 't', 'oken', 'as', 'input', 'and', 'target', 'first', 'we', 'introduce', 'a', 'robust', 'tokenizer', 'with', 'a', 'masking', 'operation', 'and', 'an', 'additive', 'k', 'way', 'architecture', 'to', 'index', 'users', 'and', 'items', 'capturing', 'their', 'complex', 'collaborative', 'relationships', 'into', 'continuous', 'tokens', 'crucially', 'we', 'develop', 'a', 'denoising', 'diffusion', 'model', 'to', 'process', 'user', 'preferences', 'within', 'continuous', 'domains', 'by', 'conditioning', 'on', 'reasoning', 'content', 'from', 'pre', 'trained', 'large', 'language', 'model', 'during', 'the', 'denoising', 'process', 'we', 'reformulate', 'the', 'objective', 'to', 'include', 'negative', 'interactions', 'building', 'a', 'comprehensive', 'understanding', 'of', 'user', 'preferences', 'for', 'effective', 'and', 'accurate', 'recommendation', 'generation', 'finally', 'given', 'a', 'continuous', 'token', 'as', 'output', 'recommendations', 'can', 'be', 'easily', 'generated', 'through', 'score', 'based', 'retrieval', 'extensive', 'experiments', 'demonstrate', 'the', 'effectiveness', 'of', 'the', 'proposed', 'methods', 'showing', 'that', 'deftrec', 'surpasses', 'competitive', 'benchmarks', 'including', 'both', 'traditional', 'and', 'emerging', 'llm', 'based', 'recsys']",6,254,"['Extensive', 'Finally', 'K-way', 'DeftRec', 'However', 'Crucially', 'During', 'RecSys', 'LLM-based', 'First', 'Current', 'LLM', 'Embracing']"
2504.11986v1,"Language Models as Quasi-Crystalline Thought: Structure, Constraint, and   Emergence in Generative Systems","This essay proposes an analogy between large language models (LLMs) and quasicrystals: systems that exhibit global coherence without periodic repetition and that are generated through local constraints. While LLMs are often evaluated in terms of predictive accuracy, factuality, or alignment, this structural perspective suggests that their most characteristic behavior is the production of internally resonant linguistic patterns. Just as quasicrystals forced a redefinition of order in physical systems, viewing LLMs as generators of quasi-structured language opens new paths for evaluation and design: privileging propagation of constraint over token-level accuracy, and coherence of form over fixed meaning. LLM outputs should be read not only for what they say, but for the patterns of constraint and coherence that organize them. This shift reframes generative language as a space of emergent patterning: LLMs are neither fully random nor strictly rule-based, but defined by a logic of constraint, resonance, and structural depth.",Jose Manuel Guevara-Vela,"cs.CL, cs.AI",2025-04-16T11:27:47Z,http://arxiv.org/abs/2504.11986v1,language models as quasi crystalline thought structure constraint and emergence in generative systems,this essay proposes an analogy between large language models llms and quasicrystals systems that exhibit global coherence without periodic repetition and that are generated through local constraints while llms are often evaluated in terms of predictive accuracy factuality or alignment this structural perspective suggests that their most characteristic behavior is the production of internally resonant linguistic patterns just as quasicrystals forced a redefinition of order in physical systems viewing llms as generators of quasi structured language opens new paths for evaluation and design privileging propagation of constraint over token level accuracy and coherence of form over fixed meaning llm outputs should be read not only for what they say but for the patterns of constraint and coherence that organize them this shift reframes generative language as a space of emergent patterning llms are neither fully random nor strictly rule based but defined by a logic of constraint resonance and structural depth,"['language', 'models', 'as', 'quasi', 'crystalline', 'thought', 'structure', 'constraint', 'and', 'emergence', 'in', 'generative', 'systems']","['this', 'essay', 'proposes', 'an', 'analogy', 'between', 'large', 'language', 'models', 'llms', 'and', 'quasicrystals', 'systems', 'that', 'exhibit', 'global', 'coherence', 'without', 'periodic', 'repetition', 'and', 'that', 'are', 'generated', 'through', 'local', 'constraints', 'while', 'llms', 'are', 'often', 'evaluated', 'in', 'terms', 'of', 'predictive', 'accuracy', 'factuality', 'or', 'alignment', 'this', 'structural', 'perspective', 'suggests', 'that', 'their', 'most', 'characteristic', 'behavior', 'is', 'the', 'production', 'of', 'internally', 'resonant', 'linguistic', 'patterns', 'just', 'as', 'quasicrystals', 'forced', 'a', 'redefinition', 'of', 'order', 'in', 'physical', 'systems', 'viewing', 'llms', 'as', 'generators', 'of', 'quasi', 'structured', 'language', 'opens', 'new', 'paths', 'for', 'evaluation', 'and', 'design', 'privileging', 'propagation', 'of', 'constraint', 'over', 'token', 'level', 'accuracy', 'and', 'coherence', 'of', 'form', 'over', 'fixed', 'meaning', 'llm', 'outputs', 'should', 'be', 'read', 'not', 'only', 'for', 'what', 'they', 'say', 'but', 'for', 'the', 'patterns', 'of', 'constraint', 'and', 'coherence', 'that', 'organize', 'them', 'this', 'shift', 'reframes', 'generative', 'language', 'as', 'a', 'space', 'of', 'emergent', 'patterning', 'llms', 'are', 'neither', 'fully', 'random', 'nor', 'strictly', 'rule', 'based', 'but', 'defined', 'by', 'a', 'logic', 'of', 'constraint', 'resonance', 'and', 'structural', 'depth']",13,151,"['LLMs', 'While', 'Just', 'LLM']"
2504.11967v2,"Securing the Skies: A Comprehensive Survey on Anti-UAV Methods,   Benchmarking, and Future Directions","Unmanned Aerial Vehicles (UAVs) are indispensable for infrastructure inspection, surveillance, and related tasks, yet they also introduce critical security challenges. This survey provides a wide-ranging examination of the anti-UAV domain, centering on three core objectives-classification, detection, and tracking-while detailing emerging methodologies such as diffusion-based data synthesis, multi-modal fusion, vision-language modeling, self-supervised learning, and reinforcement learning. We systematically evaluate state-of-the-art solutions across both single-modality and multi-sensor pipelines (spanning RGB, infrared, audio, radar, and RF) and discuss large-scale as well as adversarially oriented benchmarks. Our analysis reveals persistent gaps in real-time performance, stealth detection, and swarm-based scenarios, underscoring pressing needs for robust, adaptive anti-UAV systems. By highlighting open research directions, we aim to foster innovation and guide the development of next-generation defense strategies in an era marked by the extensive use of UAVs.","Yifei Dong, Fengyi Wu, Sanjian Zhang, Guangyu Chen, Yuzhi Hu, Masumi Yano, Jingdong Sun, Siyu Huang, Feng Liu, Qi Dai, Zhi-Qi Cheng","cs.CV, cs.AI, cs.RO",2025-04-16T10:58:33Z,http://arxiv.org/abs/2504.11967v2,securing the skies a comprehensive survey on anti uav methods benchmarking and future directions,unmanned aerial vehicles uavs are indispensable for infrastructure inspection surveillance and related tasks yet they also introduce critical security challenges this survey provides a wide ranging examination of the anti uav domain centering on three core objectives classification detection and tracking while detailing emerging methodologies such as diffusion based data synthesis multi modal fusion vision language modeling self supervised learning and reinforcement learning we systematically evaluate state of the art solutions across both single modality and multi sensor pipelines spanning rgb infrared audio radar and rf and discuss large scale as well as adversarially oriented benchmarks our analysis reveals persistent gaps in real time performance stealth detection and swarm based scenarios underscoring pressing needs for robust adaptive anti uav systems by highlighting open research directions we aim to foster innovation and guide the development of next generation defense strategies in an era marked by the extensive use of uavs,"['securing', 'the', 'skies', 'a', 'comprehensive', 'survey', 'on', 'anti', 'uav', 'methods', 'benchmarking', 'and', 'future', 'directions']","['unmanned', 'aerial', 'vehicles', 'uavs', 'are', 'indispensable', 'for', 'infrastructure', 'inspection', 'surveillance', 'and', 'related', 'tasks', 'yet', 'they', 'also', 'introduce', 'critical', 'security', 'challenges', 'this', 'survey', 'provides', 'a', 'wide', 'ranging', 'examination', 'of', 'the', 'anti', 'uav', 'domain', 'centering', 'on', 'three', 'core', 'objectives', 'classification', 'detection', 'and', 'tracking', 'while', 'detailing', 'emerging', 'methodologies', 'such', 'as', 'diffusion', 'based', 'data', 'synthesis', 'multi', 'modal', 'fusion', 'vision', 'language', 'modeling', 'self', 'supervised', 'learning', 'and', 'reinforcement', 'learning', 'we', 'systematically', 'evaluate', 'state', 'of', 'the', 'art', 'solutions', 'across', 'both', 'single', 'modality', 'and', 'multi', 'sensor', 'pipelines', 'spanning', 'rgb', 'infrared', 'audio', 'radar', 'and', 'rf', 'and', 'discuss', 'large', 'scale', 'as', 'well', 'as', 'adversarially', 'oriented', 'benchmarks', 'our', 'analysis', 'reveals', 'persistent', 'gaps', 'in', 'real', 'time', 'performance', 'stealth', 'detection', 'and', 'swarm', 'based', 'scenarios', 'underscoring', 'pressing', 'needs', 'for', 'robust', 'adaptive', 'anti', 'uav', 'systems', 'by', 'highlighting', 'open', 'research', 'directions', 'we', 'aim', 'to', 'foster', 'innovation', 'and', 'guide', 'the', 'development', 'of', 'next', 'generation', 'defense', 'strategies', 'in', 'an', 'era', 'marked', 'by', 'the', 'extensive', 'use', 'of', 'uavs']",14,149,"['Unmanned', 'RGB', 'Our', 'UAVs', 'UAV', 'Vehicles', 'Aerial']"
2504.11952v1,Robust and Fine-Grained Detection of AI Generated Texts,"An ideal detection system for machine generated content is supposed to work well on any generator as many more advanced LLMs come into existence day by day. Existing systems often struggle with accurately identifying AI-generated content over shorter texts. Further, not all texts might be entirely authored by a human or LLM, hence we focused more over partial cases i.e human-LLM co-authored texts. Our paper introduces a set of models built for the task of token classification which are trained on an extensive collection of human-machine co-authored texts, which performed well over texts of unseen domains, unseen generators, texts by non-native speakers and those with adversarial inputs. We also introduce a new dataset of over 2.4M such texts mostly co-authored by several popular proprietary LLMs over 23 languages. We also present findings of our models' performance over each texts of each domain and generator. Additional findings include comparison of performance against each adversarial method, length of input texts and characteristics of generated texts compared to the original human authored texts.","Ram Mohan Rao Kadiyala, Siddartha Pullakhandam, Kanwal Mehreen, Drishti Sharma, Siddhant Gupta, Jebish Purbey, Ashay Srivastava, Subhasya TippaReddy, Arvind Reddy Bobbili, Suraj Telugara Chandrashekhar, Modabbir Adeeb, Srinadh Vura, Hamza Farooq","cs.CL, cs.AI, cs.LG",2025-04-16T10:29:30Z,http://arxiv.org/abs/2504.11952v1,robust and fine grained detection of ai generated texts,an ideal detection system for machine generated content is supposed to work well on any generator as many more advanced llms come into existence day by day existing systems often struggle with accurately identifying ai generated content over shorter texts further not all texts might be entirely authored by a human or llm hence we focused more over partial cases i e human llm co authored texts our paper introduces a set of models built for the task of token classification which are trained on an extensive collection of human machine co authored texts which performed well over texts of unseen domains unseen generators texts by non native speakers and those with adversarial inputs we also introduce a new dataset of over m such texts mostly co authored by several popular proprietary llms over languages we also present findings of our models performance over each texts of each domain and generator additional findings include comparison of performance against each adversarial method length of input texts and characteristics of generated texts compared to the original human authored texts,"['robust', 'and', 'fine', 'grained', 'detection', 'of', 'ai', 'generated', 'texts']","['an', 'ideal', 'detection', 'system', 'for', 'machine', 'generated', 'content', 'is', 'supposed', 'to', 'work', 'well', 'on', 'any', 'generator', 'as', 'many', 'more', 'advanced', 'llms', 'come', 'into', 'existence', 'day', 'by', 'day', 'existing', 'systems', 'often', 'struggle', 'with', 'accurately', 'identifying', 'ai', 'generated', 'content', 'over', 'shorter', 'texts', 'further', 'not', 'all', 'texts', 'might', 'be', 'entirely', 'authored', 'by', 'a', 'human', 'or', 'llm', 'hence', 'we', 'focused', 'more', 'over', 'partial', 'cases', 'i', 'e', 'human', 'llm', 'co', 'authored', 'texts', 'our', 'paper', 'introduces', 'a', 'set', 'of', 'models', 'built', 'for', 'the', 'task', 'of', 'token', 'classification', 'which', 'are', 'trained', 'on', 'an', 'extensive', 'collection', 'of', 'human', 'machine', 'co', 'authored', 'texts', 'which', 'performed', 'well', 'over', 'texts', 'of', 'unseen', 'domains', 'unseen', 'generators', 'texts', 'by', 'non', 'native', 'speakers', 'and', 'those', 'with', 'adversarial', 'inputs', 'we', 'also', 'introduce', 'a', 'new', 'dataset', 'of', 'over', 'm', 'such', 'texts', 'mostly', 'co', 'authored', 'by', 'several', 'popular', 'proprietary', 'llms', 'over', 'languages', 'we', 'also', 'present', 'findings', 'of', 'our', 'models', 'performance', 'over', 'each', 'texts', 'of', 'each', 'domain', 'and', 'generator', 'additional', 'findings', 'include', 'comparison', 'of', 'performance', 'against', 'each', 'adversarial', 'method', 'length', 'of', 'input', 'texts', 'and', 'characteristics', 'of', 'generated', 'texts', 'compared', 'to', 'the', 'original', 'human', 'authored', 'texts']",9,177,"['Existing', 'LLMs', 'Further', 'Our', 'Additional', 'AI-generated', 'LLM']"
2504.11944v1,VIPO: Value Function Inconsistency Penalized Offline Reinforcement   Learning,"Offline reinforcement learning (RL) learns effective policies from pre-collected datasets, offering a practical solution for applications where online interactions are risky or costly. Model-based approaches are particularly advantageous for offline RL, owing to their data efficiency and generalizability. However, due to inherent model errors, model-based methods often artificially introduce conservatism guided by heuristic uncertainty estimation, which can be unreliable. In this paper, we introduce VIPO, a novel model-based offline RL algorithm that incorporates self-supervised feedback from value estimation to enhance model training. Specifically, the model is learned by additionally minimizing the inconsistency between the value learned directly from the offline data and the one estimated from the model. We perform comprehensive evaluations from multiple perspectives to show that VIPO can learn a highly accurate model efficiently and consistently outperform existing methods. It offers a general framework that can be readily integrated into existing model-based offline RL algorithms to systematically enhance model accuracy. As a result, VIPO achieves state-of-the-art performance on almost all tasks in both D4RL and NeoRL benchmarks.","Xuyang Chen, Guojian Wang, Keyu Yan, Lin Zhao","cs.LG, cs.AI",2025-04-16T10:23:44Z,http://arxiv.org/abs/2504.11944v1,vipo value function inconsistency penalized offline reinforcement learning,offline reinforcement learning rl learns effective policies from pre collected datasets offering a practical solution for applications where online interactions are risky or costly model based approaches are particularly advantageous for offline rl owing to their data efficiency and generalizability however due to inherent model errors model based methods often artificially introduce conservatism guided by heuristic uncertainty estimation which can be unreliable in this paper we introduce vipo a novel model based offline rl algorithm that incorporates self supervised feedback from value estimation to enhance model training specifically the model is learned by additionally minimizing the inconsistency between the value learned directly from the offline data and the one estimated from the model we perform comprehensive evaluations from multiple perspectives to show that vipo can learn a highly accurate model efficiently and consistently outperform existing methods it offers a general framework that can be readily integrated into existing model based offline rl algorithms to systematically enhance model accuracy as a result vipo achieves state of the art performance on almost all tasks in both d rl and neorl benchmarks,"['vipo', 'value', 'function', 'inconsistency', 'penalized', 'offline', 'reinforcement', 'learning']","['offline', 'reinforcement', 'learning', 'rl', 'learns', 'effective', 'policies', 'from', 'pre', 'collected', 'datasets', 'offering', 'a', 'practical', 'solution', 'for', 'applications', 'where', 'online', 'interactions', 'are', 'risky', 'or', 'costly', 'model', 'based', 'approaches', 'are', 'particularly', 'advantageous', 'for', 'offline', 'rl', 'owing', 'to', 'their', 'data', 'efficiency', 'and', 'generalizability', 'however', 'due', 'to', 'inherent', 'model', 'errors', 'model', 'based', 'methods', 'often', 'artificially', 'introduce', 'conservatism', 'guided', 'by', 'heuristic', 'uncertainty', 'estimation', 'which', 'can', 'be', 'unreliable', 'in', 'this', 'paper', 'we', 'introduce', 'vipo', 'a', 'novel', 'model', 'based', 'offline', 'rl', 'algorithm', 'that', 'incorporates', 'self', 'supervised', 'feedback', 'from', 'value', 'estimation', 'to', 'enhance', 'model', 'training', 'specifically', 'the', 'model', 'is', 'learned', 'by', 'additionally', 'minimizing', 'the', 'inconsistency', 'between', 'the', 'value', 'learned', 'directly', 'from', 'the', 'offline', 'data', 'and', 'the', 'one', 'estimated', 'from', 'the', 'model', 'we', 'perform', 'comprehensive', 'evaluations', 'from', 'multiple', 'perspectives', 'to', 'show', 'that', 'vipo', 'can', 'learn', 'a', 'highly', 'accurate', 'model', 'efficiently', 'and', 'consistently', 'outperform', 'existing', 'methods', 'it', 'offers', 'a', 'general', 'framework', 'that', 'can', 'be', 'readily', 'integrated', 'into', 'existing', 'model', 'based', 'offline', 'rl', 'algorithms', 'to', 'systematically', 'enhance', 'model', 'accuracy', 'as', 'a', 'result', 'vipo', 'achieves', 'state', 'of', 'the', 'art', 'performance', 'on', 'almost', 'all', 'tasks', 'in', 'both', 'd', 'rl', 'and', 'neorl', 'benchmarks']",8,179,"['Offline', 'D4RL', 'Model', 'However', 'NeoRL', 'VIPO', 'Specifically']"
2504.11919v1,Rethinking the Generation of High-Quality CoT Data from the Perspective   of LLM-Adaptive Question Difficulty Grading,"Recently, DeepSeek-R1 (671B) (DeepSeek-AIet al., 2025) has demonstrated its excellent reasoning ability in complex tasks and has publiclyshared its methodology. This provides potentially high-quality chain-of-thought (CoT) data for stimulating the reasoning abilities of small-sized large language models (LLMs). To generate high-quality CoT data for different LLMs, we seek an efficient method for generating high-quality CoT data with LLM-Adaptive questiondifficulty levels. First, we grade the difficulty of the questions according to the reasoning ability of the LLMs themselves and construct a LLM-Adaptive question database. Second, we sample the problem database based on a distribution of difficulty levels of the questions and then use DeepSeek-R1 (671B) (DeepSeek-AI et al., 2025) to generate the corresponding high-quality CoT data with correct answers. Thanks to the construction of CoT data with LLM-Adaptive difficulty levels, we have significantly reduced the cost of data generation and enhanced the efficiency of model supervised fine-tuning (SFT). Finally, we have validated the effectiveness and generalizability of the proposed method in the fields of complex mathematical competitions and code generation tasks. Notably, with only 2k high-quality mathematical CoT data, our ZMath-32B surpasses DeepSeek-Distill-32B in math reasoning task. Similarly, with only 2k high-quality code CoT data, our ZCode-32B surpasses DeepSeek-Distill-32B in code reasoning tasks.","Qianjin Yu, Keyu Wu, Zihan Chen, Chushu Zhang, Manlin Mei, Lingjun Huang, Fang Tan, Yongsheng Du, Kunlin Liu, Yurui Zhu",cs.AI,2025-04-16T09:55:34Z,http://arxiv.org/abs/2504.11919v1,rethinking the generation of high quality cot data from the perspective of llm adaptive question difficulty grading,recently deepseek r b deepseek aiet al has demonstrated its excellent reasoning ability in complex tasks and has publiclyshared its methodology this provides potentially high quality chain of thought cot data for stimulating the reasoning abilities of small sized large language models llms to generate high quality cot data for different llms we seek an efficient method for generating high quality cot data with llm adaptive questiondifficulty levels first we grade the difficulty of the questions according to the reasoning ability of the llms themselves and construct a llm adaptive question database second we sample the problem database based on a distribution of difficulty levels of the questions and then use deepseek r b deepseek ai et al to generate the corresponding high quality cot data with correct answers thanks to the construction of cot data with llm adaptive difficulty levels we have significantly reduced the cost of data generation and enhanced the efficiency of model supervised fine tuning sft finally we have validated the effectiveness and generalizability of the proposed method in the fields of complex mathematical competitions and code generation tasks notably with only k high quality mathematical cot data our zmath b surpasses deepseek distill b in math reasoning task similarly with only k high quality code cot data our zcode b surpasses deepseek distill b in code reasoning tasks,"['rethinking', 'the', 'generation', 'of', 'high', 'quality', 'cot', 'data', 'from', 'the', 'perspective', 'of', 'llm', 'adaptive', 'question', 'difficulty', 'grading']","['recently', 'deepseek', 'r', 'b', 'deepseek', 'aiet', 'al', 'has', 'demonstrated', 'its', 'excellent', 'reasoning', 'ability', 'in', 'complex', 'tasks', 'and', 'has', 'publiclyshared', 'its', 'methodology', 'this', 'provides', 'potentially', 'high', 'quality', 'chain', 'of', 'thought', 'cot', 'data', 'for', 'stimulating', 'the', 'reasoning', 'abilities', 'of', 'small', 'sized', 'large', 'language', 'models', 'llms', 'to', 'generate', 'high', 'quality', 'cot', 'data', 'for', 'different', 'llms', 'we', 'seek', 'an', 'efficient', 'method', 'for', 'generating', 'high', 'quality', 'cot', 'data', 'with', 'llm', 'adaptive', 'questiondifficulty', 'levels', 'first', 'we', 'grade', 'the', 'difficulty', 'of', 'the', 'questions', 'according', 'to', 'the', 'reasoning', 'ability', 'of', 'the', 'llms', 'themselves', 'and', 'construct', 'a', 'llm', 'adaptive', 'question', 'database', 'second', 'we', 'sample', 'the', 'problem', 'database', 'based', 'on', 'a', 'distribution', 'of', 'difficulty', 'levels', 'of', 'the', 'questions', 'and', 'then', 'use', 'deepseek', 'r', 'b', 'deepseek', 'ai', 'et', 'al', 'to', 'generate', 'the', 'corresponding', 'high', 'quality', 'cot', 'data', 'with', 'correct', 'answers', 'thanks', 'to', 'the', 'construction', 'of', 'cot', 'data', 'with', 'llm', 'adaptive', 'difficulty', 'levels', 'we', 'have', 'significantly', 'reduced', 'the', 'cost', 'of', 'data', 'generation', 'and', 'enhanced', 'the', 'efficiency', 'of', 'model', 'supervised', 'fine', 'tuning', 'sft', 'finally', 'we', 'have', 'validated', 'the', 'effectiveness', 'and', 'generalizability', 'of', 'the', 'proposed', 'method', 'in', 'the', 'fields', 'of', 'complex', 'mathematical', 'competitions', 'and', 'code', 'generation', 'tasks', 'notably', 'with', 'only', 'k', 'high', 'quality', 'mathematical', 'cot', 'data', 'our', 'zmath', 'b', 'surpasses', 'deepseek', 'distill', 'b', 'in', 'math', 'reasoning', 'task', 'similarly', 'with', 'only', 'k', 'high', 'quality', 'code', 'cot', 'data', 'our', 'zcode', 'b', 'surpasses', 'deepseek', 'distill', 'b', 'in', 'code', 'reasoning', 'tasks']",17,223,"['DeepSeek', 'LLM-Adaptive', 'CoT', 'Recently', 'Notably', 'Similarly', '2025', 'Thanks', 'LLMs', '671B', 'Distill', 'Finally', 'SFT', 'ZCode', 'First', '32B', 'AIet', 'ZMath', 'Second']"
2504.11901v2,Causality-enhanced Decision-Making for Autonomous Mobile Robots in   Dynamic Environments,"The growing integration of robots in shared environments -- such as warehouses, shopping centres, and hospitals -- demands a deep understanding of the underlying dynamics and human behaviours, including how, when, and where individuals engage in various activities and interactions. This knowledge goes beyond simple correlation studies and requires a more comprehensive causal analysis. By leveraging causal inference to model cause-and-effect relationships, we can better anticipate critical environmental factors and enable autonomous robots to plan and execute tasks more effectively. To this end, we propose a novel causality-based decision-making framework that reasons over a learned causal model to predict battery usage and human obstructions, understanding how these factors could influence robot task execution. Such reasoning framework assists the robot in deciding when and how to complete a given task. To achieve this, we developed also PeopleFlow, a new Gazebo-based simulator designed to model context-sensitive human-robot spatial interactions in shared workspaces. PeopleFlow features realistic human and robot trajectories influenced by contextual factors such as time, environment layout, and robot state, and can simulate a large number of agents. While the simulator is general-purpose, in this paper we focus on a warehouse-like environment as a case study, where we conduct an extensive evaluation benchmarking our causal approach against a non-causal baseline. Our findings demonstrate the efficacy of the proposed solutions, highlighting how causal reasoning enables autonomous robots to operate more efficiently and safely in dynamic environments shared with humans.","Luca Castri, Gloria Beraldo, Nicola Bellotto","cs.RO, cs.AI",2025-04-16T09:26:04Z,http://arxiv.org/abs/2504.11901v2,causality enhanced decision making for autonomous mobile robots in dynamic environments,the growing integration of robots in shared environments such as warehouses shopping centres and hospitals demands a deep understanding of the underlying dynamics and human behaviours including how when and where individuals engage in various activities and interactions this knowledge goes beyond simple correlation studies and requires a more comprehensive causal analysis by leveraging causal inference to model cause and effect relationships we can better anticipate critical environmental factors and enable autonomous robots to plan and execute tasks more effectively to this end we propose a novel causality based decision making framework that reasons over a learned causal model to predict battery usage and human obstructions understanding how these factors could influence robot task execution such reasoning framework assists the robot in deciding when and how to complete a given task to achieve this we developed also peopleflow a new gazebo based simulator designed to model context sensitive human robot spatial interactions in shared workspaces peopleflow features realistic human and robot trajectories influenced by contextual factors such as time environment layout and robot state and can simulate a large number of agents while the simulator is general purpose in this paper we focus on a warehouse like environment as a case study where we conduct an extensive evaluation benchmarking our causal approach against a non causal baseline our findings demonstrate the efficacy of the proposed solutions highlighting how causal reasoning enables autonomous robots to operate more efficiently and safely in dynamic environments shared with humans,"['causality', 'enhanced', 'decision', 'making', 'for', 'autonomous', 'mobile', 'robots', 'in', 'dynamic', 'environments']","['the', 'growing', 'integration', 'of', 'robots', 'in', 'shared', 'environments', 'such', 'as', 'warehouses', 'shopping', 'centres', 'and', 'hospitals', 'demands', 'a', 'deep', 'understanding', 'of', 'the', 'underlying', 'dynamics', 'and', 'human', 'behaviours', 'including', 'how', 'when', 'and', 'where', 'individuals', 'engage', 'in', 'various', 'activities', 'and', 'interactions', 'this', 'knowledge', 'goes', 'beyond', 'simple', 'correlation', 'studies', 'and', 'requires', 'a', 'more', 'comprehensive', 'causal', 'analysis', 'by', 'leveraging', 'causal', 'inference', 'to', 'model', 'cause', 'and', 'effect', 'relationships', 'we', 'can', 'better', 'anticipate', 'critical', 'environmental', 'factors', 'and', 'enable', 'autonomous', 'robots', 'to', 'plan', 'and', 'execute', 'tasks', 'more', 'effectively', 'to', 'this', 'end', 'we', 'propose', 'a', 'novel', 'causality', 'based', 'decision', 'making', 'framework', 'that', 'reasons', 'over', 'a', 'learned', 'causal', 'model', 'to', 'predict', 'battery', 'usage', 'and', 'human', 'obstructions', 'understanding', 'how', 'these', 'factors', 'could', 'influence', 'robot', 'task', 'execution', 'such', 'reasoning', 'framework', 'assists', 'the', 'robot', 'in', 'deciding', 'when', 'and', 'how', 'to', 'complete', 'a', 'given', 'task', 'to', 'achieve', 'this', 'we', 'developed', 'also', 'peopleflow', 'a', 'new', 'gazebo', 'based', 'simulator', 'designed', 'to', 'model', 'context', 'sensitive', 'human', 'robot', 'spatial', 'interactions', 'in', 'shared', 'workspaces', 'peopleflow', 'features', 'realistic', 'human', 'and', 'robot', 'trajectories', 'influenced', 'by', 'contextual', 'factors', 'such', 'as', 'time', 'environment', 'layout', 'and', 'robot', 'state', 'and', 'can', 'simulate', 'a', 'large', 'number', 'of', 'agents', 'while', 'the', 'simulator', 'is', 'general', 'purpose', 'in', 'this', 'paper', 'we', 'focus', 'on', 'a', 'warehouse', 'like', 'environment', 'as', 'a', 'case', 'study', 'where', 'we', 'conduct', 'an', 'extensive', 'evaluation', 'benchmarking', 'our', 'causal', 'approach', 'against', 'a', 'non', 'causal', 'baseline', 'our', 'findings', 'demonstrate', 'the', 'efficacy', 'of', 'the', 'proposed', 'solutions', 'highlighting', 'how', 'causal', 'reasoning', 'enables', 'autonomous', 'robots', 'to', 'operate', 'more', 'efficiently', 'and', 'safely', 'in', 'dynamic', 'environments', 'shared', 'with', 'humans']",11,245,"['PeopleFlow', 'Gazebo', 'Such', 'While', 'Our']"
2504.11864v1,Moving between high-quality optima using multi-satisfiability   characteristics in hard-to-solve Max3Sat instances,"Gray-box optimization proposes effective and efficient optimizers of general use. To this end, it leverages information about variable dependencies and the subfunction-based problem representation. These approaches were already shown effective by enabling \textit{tunnelling} between local optima even if these moves require the modification of many dependent variables. Tunnelling is useful in solving the maximum satisfiability problem (MaxSat), which can be reformulated to Max3Sat. Since many real-world problems can be brought to solving the MaxSat/Max3Sat instances, it is important to solve them effectively and efficiently. Therefore, we focus on Max3Sat instances for which tunnelling fails to introduce improving moves between locally optimal high-quality solutions and the region of globally optimal solutions. We analyze the features of such instances on the ground of phase transitions. Based on these observations, we propose manipulating clause-satisfiability characteristics that allow connecting high-quality solutions distant in the solution space. We utilize multi-satisfiability characteristics in the optimizer built from typical gray-box mechanisms. The experimental study shows that the proposed optimizer can solve those Max3Sat instances that are out of the grasp of state-of-the-art gray-box optimizers. At the same time, it remains effective for instances that have already been successfully solved by gray-box.","J. Piatek, M. W. Przewozniczek, F. Chicano, R. Tin√≥s",cs.AI,2025-04-16T08:38:08Z,http://arxiv.org/abs/2504.11864v1,moving between high quality optima using multi satisfiability characteristics in hard to solve max sat instances,gray box optimization proposes effective and efficient optimizers of general use to this end it leverages information about variable dependencies and the subfunction based problem representation these approaches were already shown effective by enabling tunnelling between local optima even if these moves require the modification of many dependent variables tunnelling is useful in solving the maximum satisfiability problem maxsat which can be reformulated to max sat since many real world problems can be brought to solving the maxsat max sat instances it is important to solve them effectively and efficiently therefore we focus on max sat instances for which tunnelling fails to introduce improving moves between locally optimal high quality solutions and the region of globally optimal solutions we analyze the features of such instances on the ground of phase transitions based on these observations we propose manipulating clause satisfiability characteristics that allow connecting high quality solutions distant in the solution space we utilize multi satisfiability characteristics in the optimizer built from typical gray box mechanisms the experimental study shows that the proposed optimizer can solve those max sat instances that are out of the grasp of state of the art gray box optimizers at the same time it remains effective for instances that have already been successfully solved by gray box,"['moving', 'between', 'high', 'quality', 'optima', 'using', 'multi', 'satisfiability', 'characteristics', 'in', 'hard', 'to', 'solve', 'max', 'sat', 'instances']","['gray', 'box', 'optimization', 'proposes', 'effective', 'and', 'efficient', 'optimizers', 'of', 'general', 'use', 'to', 'this', 'end', 'it', 'leverages', 'information', 'about', 'variable', 'dependencies', 'and', 'the', 'subfunction', 'based', 'problem', 'representation', 'these', 'approaches', 'were', 'already', 'shown', 'effective', 'by', 'enabling', 'tunnelling', 'between', 'local', 'optima', 'even', 'if', 'these', 'moves', 'require', 'the', 'modification', 'of', 'many', 'dependent', 'variables', 'tunnelling', 'is', 'useful', 'in', 'solving', 'the', 'maximum', 'satisfiability', 'problem', 'maxsat', 'which', 'can', 'be', 'reformulated', 'to', 'max', 'sat', 'since', 'many', 'real', 'world', 'problems', 'can', 'be', 'brought', 'to', 'solving', 'the', 'maxsat', 'max', 'sat', 'instances', 'it', 'is', 'important', 'to', 'solve', 'them', 'effectively', 'and', 'efficiently', 'therefore', 'we', 'focus', 'on', 'max', 'sat', 'instances', 'for', 'which', 'tunnelling', 'fails', 'to', 'introduce', 'improving', 'moves', 'between', 'locally', 'optimal', 'high', 'quality', 'solutions', 'and', 'the', 'region', 'of', 'globally', 'optimal', 'solutions', 'we', 'analyze', 'the', 'features', 'of', 'such', 'instances', 'on', 'the', 'ground', 'of', 'phase', 'transitions', 'based', 'on', 'these', 'observations', 'we', 'propose', 'manipulating', 'clause', 'satisfiability', 'characteristics', 'that', 'allow', 'connecting', 'high', 'quality', 'solutions', 'distant', 'in', 'the', 'solution', 'space', 'we', 'utilize', 'multi', 'satisfiability', 'characteristics', 'in', 'the', 'optimizer', 'built', 'from', 'typical', 'gray', 'box', 'mechanisms', 'the', 'experimental', 'study', 'shows', 'that', 'the', 'proposed', 'optimizer', 'can', 'solve', 'those', 'max', 'sat', 'instances', 'that', 'are', 'out', 'of', 'the', 'grasp', 'of', 'state', 'of', 'the', 'art', 'gray', 'box', 'optimizers', 'at', 'the', 'same', 'time', 'it', 'remains', 'effective', 'for', 'instances', 'that', 'have', 'already', 'been', 'successfully', 'solved', 'by', 'gray', 'box']",16,212,"['Gray', 'Max3Sat', 'Based', 'These', 'Since', 'MaxSat', 'Tunnelling', 'Therefore']"
2504.11829v1,D√©j√† Vu: Multilingual LLM Evaluation through the Lens of Machine   Translation Evaluation,"Generation capabilities and language coverage of multilingual large language models (mLLMs) are advancing rapidly. However, evaluation practices for generative abilities of mLLMs are still lacking comprehensiveness, scientific rigor, and consistent adoption across research labs, which undermines their potential to meaningfully guide mLLM development. We draw parallels with machine translation (MT) evaluation, a field that faced similar challenges and has, over decades, developed transparent reporting standards and reliable evaluations for multilingual generative models. Through targeted experiments across key stages of the generative evaluation pipeline, we demonstrate how best practices from MT evaluation can deepen the understanding of quality differences between models. Additionally, we identify essential components for robust meta-evaluation of mLLMs, ensuring the evaluation methods themselves are rigorously assessed. We distill these insights into a checklist of actionable recommendations for mLLM research and development.","Julia Kreutzer, Eleftheria Briakou, Sweta Agrawal, Marzieh Fadaee, Kocmi Tom","cs.CL, cs.AI",2025-04-16T07:38:19Z,http://arxiv.org/abs/2504.11829v1,d√©j√† vu multilingual llm evaluation through the lens of machine translation evaluation,generation capabilities and language coverage of multilingual large language models mllms are advancing rapidly however evaluation practices for generative abilities of mllms are still lacking comprehensiveness scientific rigor and consistent adoption across research labs which undermines their potential to meaningfully guide mllm development we draw parallels with machine translation mt evaluation a field that faced similar challenges and has over decades developed transparent reporting standards and reliable evaluations for multilingual generative models through targeted experiments across key stages of the generative evaluation pipeline we demonstrate how best practices from mt evaluation can deepen the understanding of quality differences between models additionally we identify essential components for robust meta evaluation of mllms ensuring the evaluation methods themselves are rigorously assessed we distill these insights into a checklist of actionable recommendations for mllm research and development,"['d√©j√†', 'vu', 'multilingual', 'llm', 'evaluation', 'through', 'the', 'lens', 'of', 'machine', 'translation', 'evaluation']","['generation', 'capabilities', 'and', 'language', 'coverage', 'of', 'multilingual', 'large', 'language', 'models', 'mllms', 'are', 'advancing', 'rapidly', 'however', 'evaluation', 'practices', 'for', 'generative', 'abilities', 'of', 'mllms', 'are', 'still', 'lacking', 'comprehensiveness', 'scientific', 'rigor', 'and', 'consistent', 'adoption', 'across', 'research', 'labs', 'which', 'undermines', 'their', 'potential', 'to', 'meaningfully', 'guide', 'mllm', 'development', 'we', 'draw', 'parallels', 'with', 'machine', 'translation', 'mt', 'evaluation', 'a', 'field', 'that', 'faced', 'similar', 'challenges', 'and', 'has', 'over', 'decades', 'developed', 'transparent', 'reporting', 'standards', 'and', 'reliable', 'evaluations', 'for', 'multilingual', 'generative', 'models', 'through', 'targeted', 'experiments', 'across', 'key', 'stages', 'of', 'the', 'generative', 'evaluation', 'pipeline', 'we', 'demonstrate', 'how', 'best', 'practices', 'from', 'mt', 'evaluation', 'can', 'deepen', 'the', 'understanding', 'of', 'quality', 'differences', 'between', 'models', 'additionally', 'we', 'identify', 'essential', 'components', 'for', 'robust', 'meta', 'evaluation', 'of', 'mllms', 'ensuring', 'the', 'evaluation', 'methods', 'themselves', 'are', 'rigorously', 'assessed', 'we', 'distill', 'these', 'insights', 'into', 'a', 'checklist', 'of', 'actionable', 'recommendations', 'for', 'mllm', 'research', 'and', 'development']",12,134,"['Generation', 'However', 'Additionally', 'Through']"
2504.11820v1,Real-World Depth Recovery via Structure Uncertainty Modeling and   Inaccurate GT Depth Fitting,"The low-quality structure in raw depth maps is prevalent in real-world RGB-D datasets, which makes real-world depth recovery a critical task in recent years. However, the lack of paired raw-ground truth (raw-GT) data in the real world poses challenges for generalized depth recovery. Existing methods insufficiently consider the diversity of structure misalignment in raw depth maps, which leads to poor generalization in real-world depth recovery. Notably, random structure misalignments are not limited to raw depth data but also affect GT depth in real-world datasets. In the proposed method, we tackle the generalization problem from both input and output perspectives. For input, we enrich the diversity of structure misalignment in raw depth maps by designing a new raw depth generation pipeline, which helps the network avoid overfitting to a specific condition. Furthermore, a structure uncertainty module is designed to explicitly identify the misaligned structure for input raw depth maps to better generalize in unseen scenarios. Notably the well-trained depth foundation model (DFM) can help the structure uncertainty module estimate the structure uncertainty better. For output, a robust feature alignment module is designed to precisely align with the accurate structure of RGB images avoiding the interference of inaccurate GT depth. Extensive experiments on multiple datasets demonstrate the proposed method achieves competitive accuracy and generalization capabilities across various challenging raw depth maps.","Delong Suzhang, Meng Yang","cs.CV, cs.AI",2025-04-16T07:14:01Z,http://arxiv.org/abs/2504.11820v1,real world depth recovery via structure uncertainty modeling and inaccurate gt depth fitting,the low quality structure in raw depth maps is prevalent in real world rgb d datasets which makes real world depth recovery a critical task in recent years however the lack of paired raw ground truth raw gt data in the real world poses challenges for generalized depth recovery existing methods insufficiently consider the diversity of structure misalignment in raw depth maps which leads to poor generalization in real world depth recovery notably random structure misalignments are not limited to raw depth data but also affect gt depth in real world datasets in the proposed method we tackle the generalization problem from both input and output perspectives for input we enrich the diversity of structure misalignment in raw depth maps by designing a new raw depth generation pipeline which helps the network avoid overfitting to a specific condition furthermore a structure uncertainty module is designed to explicitly identify the misaligned structure for input raw depth maps to better generalize in unseen scenarios notably the well trained depth foundation model dfm can help the structure uncertainty module estimate the structure uncertainty better for output a robust feature alignment module is designed to precisely align with the accurate structure of rgb images avoiding the interference of inaccurate gt depth extensive experiments on multiple datasets demonstrate the proposed method achieves competitive accuracy and generalization capabilities across various challenging raw depth maps,"['real', 'world', 'depth', 'recovery', 'via', 'structure', 'uncertainty', 'modeling', 'and', 'inaccurate', 'gt', 'depth', 'fitting']","['the', 'low', 'quality', 'structure', 'in', 'raw', 'depth', 'maps', 'is', 'prevalent', 'in', 'real', 'world', 'rgb', 'd', 'datasets', 'which', 'makes', 'real', 'world', 'depth', 'recovery', 'a', 'critical', 'task', 'in', 'recent', 'years', 'however', 'the', 'lack', 'of', 'paired', 'raw', 'ground', 'truth', 'raw', 'gt', 'data', 'in', 'the', 'real', 'world', 'poses', 'challenges', 'for', 'generalized', 'depth', 'recovery', 'existing', 'methods', 'insufficiently', 'consider', 'the', 'diversity', 'of', 'structure', 'misalignment', 'in', 'raw', 'depth', 'maps', 'which', 'leads', 'to', 'poor', 'generalization', 'in', 'real', 'world', 'depth', 'recovery', 'notably', 'random', 'structure', 'misalignments', 'are', 'not', 'limited', 'to', 'raw', 'depth', 'data', 'but', 'also', 'affect', 'gt', 'depth', 'in', 'real', 'world', 'datasets', 'in', 'the', 'proposed', 'method', 'we', 'tackle', 'the', 'generalization', 'problem', 'from', 'both', 'input', 'and', 'output', 'perspectives', 'for', 'input', 'we', 'enrich', 'the', 'diversity', 'of', 'structure', 'misalignment', 'in', 'raw', 'depth', 'maps', 'by', 'designing', 'a', 'new', 'raw', 'depth', 'generation', 'pipeline', 'which', 'helps', 'the', 'network', 'avoid', 'overfitting', 'to', 'a', 'specific', 'condition', 'furthermore', 'a', 'structure', 'uncertainty', 'module', 'is', 'designed', 'to', 'explicitly', 'identify', 'the', 'misaligned', 'structure', 'for', 'input', 'raw', 'depth', 'maps', 'to', 'better', 'generalize', 'in', 'unseen', 'scenarios', 'notably', 'the', 'well', 'trained', 'depth', 'foundation', 'model', 'dfm', 'can', 'help', 'the', 'structure', 'uncertainty', 'module', 'estimate', 'the', 'structure', 'uncertainty', 'better', 'for', 'output', 'a', 'robust', 'feature', 'alignment', 'module', 'is', 'designed', 'to', 'precisely', 'align', 'with', 'the', 'accurate', 'structure', 'of', 'rgb', 'images', 'avoiding', 'the', 'interference', 'of', 'inaccurate', 'gt', 'depth', 'extensive', 'experiments', 'on', 'multiple', 'datasets', 'demonstrate', 'the', 'proposed', 'method', 'achieves', 'competitive', 'accuracy', 'and', 'generalization', 'capabilities', 'across', 'various', 'challenging', 'raw', 'depth', 'maps']",13,228,"['Extensive', 'RGB', 'Existing', 'However', 'Furthermore', 'Notably', 'RGB-D', 'DFM']"
2504.11780v1,Agile Retrospectives: What went well? What didn't go well? What should   we do?,"In Agile/Scrum software development, the idea of retrospective meetings (retros) is one of the core elements of the project process. In this paper, we present our work in progress focusing on two aspects: analysis of potential usage of generative AI for information interaction within retrospective meetings, and visualisation of retros' information to software development teams. We also present our prototype tool RetroAI++, focusing on retros-related functionalities.","Maria Spichkova, Hina Lee, Kevin Iwan, Madeleine Zwart, Yuwon Yoon, Xiaohan Qin","cs.SE, cs.AI",2025-04-16T05:33:35Z,http://arxiv.org/abs/2504.11780v1,agile retrospectives what went well what didn t go well what should we do,in agile scrum software development the idea of retrospective meetings retros is one of the core elements of the project process in this paper we present our work in progress focusing on two aspects analysis of potential usage of generative ai for information interaction within retrospective meetings and visualisation of retros information to software development teams we also present our prototype tool retroai focusing on retros related functionalities,"['agile', 'retrospectives', 'what', 'went', 'well', 'what', 'didn', 't', 'go', 'well', 'what', 'should', 'we', 'do']","['in', 'agile', 'scrum', 'software', 'development', 'the', 'idea', 'of', 'retrospective', 'meetings', 'retros', 'is', 'one', 'of', 'the', 'core', 'elements', 'of', 'the', 'project', 'process', 'in', 'this', 'paper', 'we', 'present', 'our', 'work', 'in', 'progress', 'focusing', 'on', 'two', 'aspects', 'analysis', 'of', 'potential', 'usage', 'of', 'generative', 'ai', 'for', 'information', 'interaction', 'within', 'retrospective', 'meetings', 'and', 'visualisation', 'of', 'retros', 'information', 'to', 'software', 'development', 'teams', 'we', 'also', 'present', 'our', 'prototype', 'tool', 'retroai', 'focusing', 'on', 'retros', 'related', 'functionalities']",14,68,"['Scrum', 'Agile', 'RetroAI']"
2504.11774v1,PCDiff: Proactive Control for Ownership Protection in Diffusion Models   with Watermark Compatibility,"With the growing demand for protecting the intellectual property (IP) of text-to-image diffusion models, we propose PCDiff -- a proactive access control framework that redefines model authorization by regulating generation quality. At its core, PCDIFF integrates a trainable fuser module and hierarchical authentication layers into the decoder architecture, ensuring that only users with valid encrypted credentials can generate high-fidelity images. In the absence of valid keys, the system deliberately degrades output quality, effectively preventing unauthorized exploitation.Importantly, while the primary mechanism enforces active access control through architectural intervention, its decoupled design retains compatibility with existing watermarking techniques. This satisfies the need of model owners to actively control model ownership while preserving the traceability capabilities provided by traditional watermarking approaches.Extensive experimental evaluations confirm a strong dependency between credential verification and image quality across various attack scenarios. Moreover, when combined with typical post-processing operations, PCDIFF demonstrates powerful performance alongside conventional watermarking methods. This work shifts the paradigm from passive detection to proactive enforcement of authorization, laying the groundwork for IP management of diffusion models.","Keke Gai, Ziyue Shen, Jing Yu, Liehuang Zhu, Qi Wu","cs.CR, cs.AI",2025-04-16T05:28:50Z,http://arxiv.org/abs/2504.11774v1,pcdiff proactive control for ownership protection in diffusion models with watermark compatibility,with the growing demand for protecting the intellectual property ip of text to image diffusion models we propose pcdiff a proactive access control framework that redefines model authorization by regulating generation quality at its core pcdiff integrates a trainable fuser module and hierarchical authentication layers into the decoder architecture ensuring that only users with valid encrypted credentials can generate high fidelity images in the absence of valid keys the system deliberately degrades output quality effectively preventing unauthorized exploitation importantly while the primary mechanism enforces active access control through architectural intervention its decoupled design retains compatibility with existing watermarking techniques this satisfies the need of model owners to actively control model ownership while preserving the traceability capabilities provided by traditional watermarking approaches extensive experimental evaluations confirm a strong dependency between credential verification and image quality across various attack scenarios moreover when combined with typical post processing operations pcdiff demonstrates powerful performance alongside conventional watermarking methods this work shifts the paradigm from passive detection to proactive enforcement of authorization laying the groundwork for ip management of diffusion models,"['pcdiff', 'proactive', 'control', 'for', 'ownership', 'protection', 'in', 'diffusion', 'models', 'with', 'watermark', 'compatibility']","['with', 'the', 'growing', 'demand', 'for', 'protecting', 'the', 'intellectual', 'property', 'ip', 'of', 'text', 'to', 'image', 'diffusion', 'models', 'we', 'propose', 'pcdiff', 'a', 'proactive', 'access', 'control', 'framework', 'that', 'redefines', 'model', 'authorization', 'by', 'regulating', 'generation', 'quality', 'at', 'its', 'core', 'pcdiff', 'integrates', 'a', 'trainable', 'fuser', 'module', 'and', 'hierarchical', 'authentication', 'layers', 'into', 'the', 'decoder', 'architecture', 'ensuring', 'that', 'only', 'users', 'with', 'valid', 'encrypted', 'credentials', 'can', 'generate', 'high', 'fidelity', 'images', 'in', 'the', 'absence', 'of', 'valid', 'keys', 'the', 'system', 'deliberately', 'degrades', 'output', 'quality', 'effectively', 'preventing', 'unauthorized', 'exploitation', 'importantly', 'while', 'the', 'primary', 'mechanism', 'enforces', 'active', 'access', 'control', 'through', 'architectural', 'intervention', 'its', 'decoupled', 'design', 'retains', 'compatibility', 'with', 'existing', 'watermarking', 'techniques', 'this', 'satisfies', 'the', 'need', 'of', 'model', 'owners', 'to', 'actively', 'control', 'model', 'ownership', 'while', 'preserving', 'the', 'traceability', 'capabilities', 'provided', 'by', 'traditional', 'watermarking', 'approaches', 'extensive', 'experimental', 'evaluations', 'confirm', 'a', 'strong', 'dependency', 'between', 'credential', 'verification', 'and', 'image', 'quality', 'across', 'various', 'attack', 'scenarios', 'moreover', 'when', 'combined', 'with', 'typical', 'post', 'processing', 'operations', 'pcdiff', 'demonstrates', 'powerful', 'performance', 'alongside', 'conventional', 'watermarking', 'methods', 'this', 'work', 'shifts', 'the', 'paradigm', 'from', 'passive', 'detection', 'to', 'proactive', 'enforcement', 'of', 'authorization', 'laying', 'the', 'groundwork', 'for', 'ip', 'management', 'of', 'diffusion', 'models']",12,176,"['Extensive', 'PCDiff', 'Importantly', 'PCDIFF', 'Moreover']"
2504.11765v1,Shared Disk KV Cache Management for Efficient Multi-Instance Inference   in RAG-Powered LLMs,"Recent large language models (LLMs) face increasing inference latency as input context length and model size continue to grow. In particular, the retrieval-augmented generation (RAG) technique, which enhances LLM responses by incorporating external knowledge, exacerbates this issue by significantly increasing the number of input tokens. This expansion in token length leads to a substantial rise in computational overhead, particularly during the prefill stage, resulting in prolonged time-to-first-token (TTFT). To address this issue, this paper proposes a method to reduce TTFT by leveraging a disk-based key-value (KV) cache to lessen the computational burden during the prefill stage. We also introduce a disk-based shared KV cache management system, called Shared RAG-DCache, for multi-instance LLM RAG service environments. This system, together with an optimal system configuration, improves both throughput and latency under given resource constraints. Shared RAG-DCache exploits the locality of documents related to user queries in RAG, as well as the queueing delay in LLM inference services. It proactively generates and stores disk KV caches for query-related documents and shares them across multiple LLM instances to enhance inference performance. In experiments on a single host equipped with 2 GPUs and 1 CPU, Shared RAG-DCache achieved a 15~71% increase in throughput and up to a 12~65% reduction in latency, depending on the resource configuration.","Hyungwoo Lee, Kihyun Kim, Jinwoo Kim, Jungmin So, Myung-Hoon Cha, Hong-Yeon Kim, James J. Kim, Youngjae Kim",cs.AI,2025-04-16T04:59:18Z,http://arxiv.org/abs/2504.11765v1,shared disk kv cache management for efficient multi instance inference in rag powered llms,recent large language models llms face increasing inference latency as input context length and model size continue to grow in particular the retrieval augmented generation rag technique which enhances llm responses by incorporating external knowledge exacerbates this issue by significantly increasing the number of input tokens this expansion in token length leads to a substantial rise in computational overhead particularly during the prefill stage resulting in prolonged time to first token ttft to address this issue this paper proposes a method to reduce ttft by leveraging a disk based key value kv cache to lessen the computational burden during the prefill stage we also introduce a disk based shared kv cache management system called shared rag dcache for multi instance llm rag service environments this system together with an optimal system configuration improves both throughput and latency under given resource constraints shared rag dcache exploits the locality of documents related to user queries in rag as well as the queueing delay in llm inference services it proactively generates and stores disk kv caches for query related documents and shares them across multiple llm instances to enhance inference performance in experiments on a single host equipped with gpus and cpu shared rag dcache achieved a increase in throughput and up to a reduction in latency depending on the resource configuration,"['shared', 'disk', 'kv', 'cache', 'management', 'for', 'efficient', 'multi', 'instance', 'inference', 'in', 'rag', 'powered', 'llms']","['recent', 'large', 'language', 'models', 'llms', 'face', 'increasing', 'inference', 'latency', 'as', 'input', 'context', 'length', 'and', 'model', 'size', 'continue', 'to', 'grow', 'in', 'particular', 'the', 'retrieval', 'augmented', 'generation', 'rag', 'technique', 'which', 'enhances', 'llm', 'responses', 'by', 'incorporating', 'external', 'knowledge', 'exacerbates', 'this', 'issue', 'by', 'significantly', 'increasing', 'the', 'number', 'of', 'input', 'tokens', 'this', 'expansion', 'in', 'token', 'length', 'leads', 'to', 'a', 'substantial', 'rise', 'in', 'computational', 'overhead', 'particularly', 'during', 'the', 'prefill', 'stage', 'resulting', 'in', 'prolonged', 'time', 'to', 'first', 'token', 'ttft', 'to', 'address', 'this', 'issue', 'this', 'paper', 'proposes', 'a', 'method', 'to', 'reduce', 'ttft', 'by', 'leveraging', 'a', 'disk', 'based', 'key', 'value', 'kv', 'cache', 'to', 'lessen', 'the', 'computational', 'burden', 'during', 'the', 'prefill', 'stage', 'we', 'also', 'introduce', 'a', 'disk', 'based', 'shared', 'kv', 'cache', 'management', 'system', 'called', 'shared', 'rag', 'dcache', 'for', 'multi', 'instance', 'llm', 'rag', 'service', 'environments', 'this', 'system', 'together', 'with', 'an', 'optimal', 'system', 'configuration', 'improves', 'both', 'throughput', 'and', 'latency', 'under', 'given', 'resource', 'constraints', 'shared', 'rag', 'dcache', 'exploits', 'the', 'locality', 'of', 'documents', 'related', 'to', 'user', 'queries', 'in', 'rag', 'as', 'well', 'as', 'the', 'queueing', 'delay', 'in', 'llm', 'inference', 'services', 'it', 'proactively', 'generates', 'and', 'stores', 'disk', 'kv', 'caches', 'for', 'query', 'related', 'documents', 'and', 'shares', 'them', 'across', 'multiple', 'llm', 'instances', 'to', 'enhance', 'inference', 'performance', 'in', 'experiments', 'on', 'a', 'single', 'host', 'equipped', 'with', 'gpus', 'and', 'cpu', 'shared', 'rag', 'dcache', 'achieved', 'a', 'increase', 'in', 'throughput', 'and', 'up', 'to', 'a', 'reduction', 'in', 'latency', 'depending', 'on', 'the', 'resource', 'configuration']",14,219,"['Recent', 'GPUs', 'RAG', 'LLMs', 'TTFT', 'RAG-DCache', 'CPU', 'LLM', 'Shared']"
2504.11754v1,GrabS: Generative Embodied Agent for 3D Object Segmentation without   Scene Supervision,"We study the hard problem of 3D object segmentation in complex point clouds without requiring human labels of 3D scenes for supervision. By relying on the similarity of pretrained 2D features or external signals such as motion to group 3D points as objects, existing unsupervised methods are usually limited to identifying simple objects like cars or their segmented objects are often inferior due to the lack of objectness in pretrained features. In this paper, we propose a new two-stage pipeline called GrabS. The core concept of our method is to learn generative and discriminative object-centric priors as a foundation from object datasets in the first stage, and then design an embodied agent to learn to discover multiple objects by querying against the pretrained generative priors in the second stage. We extensively evaluate our method on two real-world datasets and a newly created synthetic dataset, demonstrating remarkable segmentation performance, clearly surpassing all existing unsupervised methods.","Zihui Zhang, Yafei Yang, Hongtao Wen, Bo Yang","cs.CV, cs.AI, cs.LG, cs.RO",2025-04-16T04:13:53Z,http://arxiv.org/abs/2504.11754v1,grabs generative embodied agent for d object segmentation without scene supervision,we study the hard problem of d object segmentation in complex point clouds without requiring human labels of d scenes for supervision by relying on the similarity of pretrained d features or external signals such as motion to group d points as objects existing unsupervised methods are usually limited to identifying simple objects like cars or their segmented objects are often inferior due to the lack of objectness in pretrained features in this paper we propose a new two stage pipeline called grabs the core concept of our method is to learn generative and discriminative object centric priors as a foundation from object datasets in the first stage and then design an embodied agent to learn to discover multiple objects by querying against the pretrained generative priors in the second stage we extensively evaluate our method on two real world datasets and a newly created synthetic dataset demonstrating remarkable segmentation performance clearly surpassing all existing unsupervised methods,"['grabs', 'generative', 'embodied', 'agent', 'for', 'd', 'object', 'segmentation', 'without', 'scene', 'supervision']","['we', 'study', 'the', 'hard', 'problem', 'of', 'd', 'object', 'segmentation', 'in', 'complex', 'point', 'clouds', 'without', 'requiring', 'human', 'labels', 'of', 'd', 'scenes', 'for', 'supervision', 'by', 'relying', 'on', 'the', 'similarity', 'of', 'pretrained', 'd', 'features', 'or', 'external', 'signals', 'such', 'as', 'motion', 'to', 'group', 'd', 'points', 'as', 'objects', 'existing', 'unsupervised', 'methods', 'are', 'usually', 'limited', 'to', 'identifying', 'simple', 'objects', 'like', 'cars', 'or', 'their', 'segmented', 'objects', 'are', 'often', 'inferior', 'due', 'to', 'the', 'lack', 'of', 'objectness', 'in', 'pretrained', 'features', 'in', 'this', 'paper', 'we', 'propose', 'a', 'new', 'two', 'stage', 'pipeline', 'called', 'grabs', 'the', 'core', 'concept', 'of', 'our', 'method', 'is', 'to', 'learn', 'generative', 'and', 'discriminative', 'object', 'centric', 'priors', 'as', 'a', 'foundation', 'from', 'object', 'datasets', 'in', 'the', 'first', 'stage', 'and', 'then', 'design', 'an', 'embodied', 'agent', 'to', 'learn', 'to', 'discover', 'multiple', 'objects', 'by', 'querying', 'against', 'the', 'pretrained', 'generative', 'priors', 'in', 'the', 'second', 'stage', 'we', 'extensively', 'evaluate', 'our', 'method', 'on', 'two', 'real', 'world', 'datasets', 'and', 'a', 'newly', 'created', 'synthetic', 'dataset', 'demonstrating', 'remarkable', 'segmentation', 'performance', 'clearly', 'surpassing', 'all', 'existing', 'unsupervised', 'methods']",11,157,['GrabS']
2504.11713v1,Adjoint Sampling: Highly Scalable Diffusion Samplers via Adjoint   Matching,"We introduce Adjoint Sampling, a highly scalable and efficient algorithm for learning diffusion processes that sample from unnormalized densities, or energy functions. It is the first on-policy approach that allows significantly more gradient updates than the number of energy evaluations and model samples, allowing us to scale to much larger problem settings than previously explored by similar methods. Our framework is theoretically grounded in stochastic optimal control and shares the same theoretical guarantees as Adjoint Matching, being able to train without the need for corrective measures that push samples towards the target distribution. We show how to incorporate key symmetries, as well as periodic boundary conditions, for modeling molecules in both cartesian and torsional coordinates. We demonstrate the effectiveness of our approach through extensive experiments on classical energy functions, and further scale up to neural network-based energy models where we perform amortized conformer generation across many molecular systems. To encourage further research in developing highly scalable sampling methods, we plan to open source these challenging benchmarks, where successful methods can directly impact progress in computational chemistry.","Aaron Havens, Benjamin Kurt Miller, Bing Yan, Carles Domingo-Enrich, Anuroop Sriram, Brandon Wood, Daniel Levine, Bin Hu, Brandon Amos, Brian Karrer, Xiang Fu, Guan-Horng Liu, Ricky T. Q. Chen","cs.LG, cs.AI",2025-04-16T02:20:06Z,http://arxiv.org/abs/2504.11713v1,adjoint sampling highly scalable diffusion samplers via adjoint matching,we introduce adjoint sampling a highly scalable and efficient algorithm for learning diffusion processes that sample from unnormalized densities or energy functions it is the first on policy approach that allows significantly more gradient updates than the number of energy evaluations and model samples allowing us to scale to much larger problem settings than previously explored by similar methods our framework is theoretically grounded in stochastic optimal control and shares the same theoretical guarantees as adjoint matching being able to train without the need for corrective measures that push samples towards the target distribution we show how to incorporate key symmetries as well as periodic boundary conditions for modeling molecules in both cartesian and torsional coordinates we demonstrate the effectiveness of our approach through extensive experiments on classical energy functions and further scale up to neural network based energy models where we perform amortized conformer generation across many molecular systems to encourage further research in developing highly scalable sampling methods we plan to open source these challenging benchmarks where successful methods can directly impact progress in computational chemistry,"['adjoint', 'sampling', 'highly', 'scalable', 'diffusion', 'samplers', 'via', 'adjoint', 'matching']","['we', 'introduce', 'adjoint', 'sampling', 'a', 'highly', 'scalable', 'and', 'efficient', 'algorithm', 'for', 'learning', 'diffusion', 'processes', 'that', 'sample', 'from', 'unnormalized', 'densities', 'or', 'energy', 'functions', 'it', 'is', 'the', 'first', 'on', 'policy', 'approach', 'that', 'allows', 'significantly', 'more', 'gradient', 'updates', 'than', 'the', 'number', 'of', 'energy', 'evaluations', 'and', 'model', 'samples', 'allowing', 'us', 'to', 'scale', 'to', 'much', 'larger', 'problem', 'settings', 'than', 'previously', 'explored', 'by', 'similar', 'methods', 'our', 'framework', 'is', 'theoretically', 'grounded', 'in', 'stochastic', 'optimal', 'control', 'and', 'shares', 'the', 'same', 'theoretical', 'guarantees', 'as', 'adjoint', 'matching', 'being', 'able', 'to', 'train', 'without', 'the', 'need', 'for', 'corrective', 'measures', 'that', 'push', 'samples', 'towards', 'the', 'target', 'distribution', 'we', 'show', 'how', 'to', 'incorporate', 'key', 'symmetries', 'as', 'well', 'as', 'periodic', 'boundary', 'conditions', 'for', 'modeling', 'molecules', 'in', 'both', 'cartesian', 'and', 'torsional', 'coordinates', 'we', 'demonstrate', 'the', 'effectiveness', 'of', 'our', 'approach', 'through', 'extensive', 'experiments', 'on', 'classical', 'energy', 'functions', 'and', 'further', 'scale', 'up', 'to', 'neural', 'network', 'based', 'energy', 'models', 'where', 'we', 'perform', 'amortized', 'conformer', 'generation', 'across', 'many', 'molecular', 'systems', 'to', 'encourage', 'further', 'research', 'in', 'developing', 'highly', 'scalable', 'sampling', 'methods', 'we', 'plan', 'to', 'open', 'source', 'these', 'challenging', 'benchmarks', 'where', 'successful', 'methods', 'can', 'directly', 'impact', 'progress', 'in', 'computational', 'chemistry']",9,178,"['Our', 'Matching', 'Sampling', 'Adjoint']"
2504.11707v1,Towards Safe Synthetic Image Generation On the Web: A Multimodal Robust   NSFW Defense and Million Scale Dataset,"In the past years, we have witnessed the remarkable success of Text-to-Image (T2I) models and their widespread use on the web. Extensive research in making T2I models produce hyper-realistic images has led to new concerns, such as generating Not-Safe-For-Work (NSFW) web content and polluting the web society. To help prevent misuse of T2I models and create a safer web environment for users features like NSFW filters and post-hoc security checks are used in these models. However, recent work unveiled how these methods can easily fail to prevent misuse. In particular, adversarial attacks on text and image modalities can easily outplay defensive measures. %Exploiting such leads to the growing concern of preventing adversarial attacks on text and image modalities. Moreover, there is currently no robust multimodal NSFW dataset that includes both prompt and image pairs and adversarial examples. This work proposes a million-scale prompt and image dataset generated using open-source diffusion models. Second, we develop a multimodal defense to distinguish safe and NSFW text and images, which is robust against adversarial attacks and directly alleviates current challenges. Our extensive experiments show that our model performs well against existing SOTA NSFW detection methods in terms of accuracy and recall, drastically reducing the Attack Success Rate (ASR) in multimodal adversarial attack scenarios. Code: https://github.com/shahidmuneer/multimodal-nsfw-defense.","Muhammad Shahid Muneer, Simon S. Woo","cs.CV, cs.AI",2025-04-16T02:10:42Z,http://arxiv.org/abs/2504.11707v1,towards safe synthetic image generation on the web a multimodal robust nsfw defense and million scale dataset,in the past years we have witnessed the remarkable success of text to image t i models and their widespread use on the web extensive research in making t i models produce hyper realistic images has led to new concerns such as generating not safe for work nsfw web content and polluting the web society to help prevent misuse of t i models and create a safer web environment for users features like nsfw filters and post hoc security checks are used in these models however recent work unveiled how these methods can easily fail to prevent misuse in particular adversarial attacks on text and image modalities can easily outplay defensive measures exploiting such leads to the growing concern of preventing adversarial attacks on text and image modalities moreover there is currently no robust multimodal nsfw dataset that includes both prompt and image pairs and adversarial examples this work proposes a million scale prompt and image dataset generated using open source diffusion models second we develop a multimodal defense to distinguish safe and nsfw text and images which is robust against adversarial attacks and directly alleviates current challenges our extensive experiments show that our model performs well against existing sota nsfw detection methods in terms of accuracy and recall drastically reducing the attack success rate asr in multimodal adversarial attack scenarios code,"['towards', 'safe', 'synthetic', 'image', 'generation', 'on', 'the', 'web', 'a', 'multimodal', 'robust', 'nsfw', 'defense', 'and', 'million', 'scale', 'dataset']","['in', 'the', 'past', 'years', 'we', 'have', 'witnessed', 'the', 'remarkable', 'success', 'of', 'text', 'to', 'image', 't', 'i', 'models', 'and', 'their', 'widespread', 'use', 'on', 'the', 'web', 'extensive', 'research', 'in', 'making', 't', 'i', 'models', 'produce', 'hyper', 'realistic', 'images', 'has', 'led', 'to', 'new', 'concerns', 'such', 'as', 'generating', 'not', 'safe', 'for', 'work', 'nsfw', 'web', 'content', 'and', 'polluting', 'the', 'web', 'society', 'to', 'help', 'prevent', 'misuse', 'of', 't', 'i', 'models', 'and', 'create', 'a', 'safer', 'web', 'environment', 'for', 'users', 'features', 'like', 'nsfw', 'filters', 'and', 'post', 'hoc', 'security', 'checks', 'are', 'used', 'in', 'these', 'models', 'however', 'recent', 'work', 'unveiled', 'how', 'these', 'methods', 'can', 'easily', 'fail', 'to', 'prevent', 'misuse', 'in', 'particular', 'adversarial', 'attacks', 'on', 'text', 'and', 'image', 'modalities', 'can', 'easily', 'outplay', 'defensive', 'measures', 'exploiting', 'such', 'leads', 'to', 'the', 'growing', 'concern', 'of', 'preventing', 'adversarial', 'attacks', 'on', 'text', 'and', 'image', 'modalities', 'moreover', 'there', 'is', 'currently', 'no', 'robust', 'multimodal', 'nsfw', 'dataset', 'that', 'includes', 'both', 'prompt', 'and', 'image', 'pairs', 'and', 'adversarial', 'examples', 'this', 'work', 'proposes', 'a', 'million', 'scale', 'prompt', 'and', 'image', 'dataset', 'generated', 'using', 'open', 'source', 'diffusion', 'models', 'second', 'we', 'develop', 'a', 'multimodal', 'defense', 'to', 'distinguish', 'safe', 'and', 'nsfw', 'text', 'and', 'images', 'which', 'is', 'robust', 'against', 'adversarial', 'attacks', 'and', 'directly', 'alleviates', 'current', 'challenges', 'our', 'extensive', 'experiments', 'show', 'that', 'our', 'model', 'performs', 'well', 'against', 'existing', 'sota', 'nsfw', 'detection', 'methods', 'in', 'terms', 'of', 'accuracy', 'and', 'recall', 'drastically', 'reducing', 'the', 'attack', 'success', 'rate', 'asr', 'in', 'multimodal', 'adversarial', 'attack', 'scenarios', 'code']",17,222,"['ASR', 'Exploiting', 'Success', 'Work', 'Image', 'Our', 'However', 'Second', 'Moreover', 'Code', 'Rate', 'Text', 'Extensive', 'SOTA', 'T2I', 'Safe', 'NSFW', 'Not', 'Attack']"
2504.11704v1,A Library of LLM Intrinsics for Retrieval-Augmented Generation,"In the developer community for large language models (LLMs), there is not yet a clean pattern analogous to a software library, to support very large scale collaboration. Even for the commonplace use case of Retrieval-Augmented Generation (RAG), it is not currently possible to write a RAG application against a well-defined set of APIs that are agreed upon by different LLM providers. Inspired by the idea of compiler intrinsics, we propose some elements of such a concept through introducing a library of LLM Intrinsics for RAG. An LLM intrinsic is defined as a capability that can be invoked through a well-defined API that is reasonably stable and independent of how the LLM intrinsic itself is implemented. The intrinsics in our library are released as LoRA adapters on HuggingFace, and through a software interface with clear structured input/output characteristics on top of vLLM as an inference platform, accompanied in both places with documentation and code. This article describes the intended usage, training details, and evaluations for each intrinsic, as well as compositions of multiple intrinsics.","Marina Danilevsky, Kristjan Greenewald, Chulaka Gunasekara, Maeda Hanafi, Lihong He, Yannis Katsis, Krishnateja Killamsetty, Yatin Nandwani, Lucian Popa, Dinesh Raghu, Frederick Reiss, Vraj Shah, Khoi-Nguyen Tran, Huaiyu Zhu, Luis Lastras","cs.AI, I.2.7",2025-04-16T02:02:22Z,http://arxiv.org/abs/2504.11704v1,a library of llm intrinsics for retrieval augmented generation,in the developer community for large language models llms there is not yet a clean pattern analogous to a software library to support very large scale collaboration even for the commonplace use case of retrieval augmented generation rag it is not currently possible to write a rag application against a well defined set of apis that are agreed upon by different llm providers inspired by the idea of compiler intrinsics we propose some elements of such a concept through introducing a library of llm intrinsics for rag an llm intrinsic is defined as a capability that can be invoked through a well defined api that is reasonably stable and independent of how the llm intrinsic itself is implemented the intrinsics in our library are released as lora adapters on huggingface and through a software interface with clear structured input output characteristics on top of vllm as an inference platform accompanied in both places with documentation and code this article describes the intended usage training details and evaluations for each intrinsic as well as compositions of multiple intrinsics,"['a', 'library', 'of', 'llm', 'intrinsics', 'for', 'retrieval', 'augmented', 'generation']","['in', 'the', 'developer', 'community', 'for', 'large', 'language', 'models', 'llms', 'there', 'is', 'not', 'yet', 'a', 'clean', 'pattern', 'analogous', 'to', 'a', 'software', 'library', 'to', 'support', 'very', 'large', 'scale', 'collaboration', 'even', 'for', 'the', 'commonplace', 'use', 'case', 'of', 'retrieval', 'augmented', 'generation', 'rag', 'it', 'is', 'not', 'currently', 'possible', 'to', 'write', 'a', 'rag', 'application', 'against', 'a', 'well', 'defined', 'set', 'of', 'apis', 'that', 'are', 'agreed', 'upon', 'by', 'different', 'llm', 'providers', 'inspired', 'by', 'the', 'idea', 'of', 'compiler', 'intrinsics', 'we', 'propose', 'some', 'elements', 'of', 'such', 'a', 'concept', 'through', 'introducing', 'a', 'library', 'of', 'llm', 'intrinsics', 'for', 'rag', 'an', 'llm', 'intrinsic', 'is', 'defined', 'as', 'a', 'capability', 'that', 'can', 'be', 'invoked', 'through', 'a', 'well', 'defined', 'api', 'that', 'is', 'reasonably', 'stable', 'and', 'independent', 'of', 'how', 'the', 'llm', 'intrinsic', 'itself', 'is', 'implemented', 'the', 'intrinsics', 'in', 'our', 'library', 'are', 'released', 'as', 'lora', 'adapters', 'on', 'huggingface', 'and', 'through', 'a', 'software', 'interface', 'with', 'clear', 'structured', 'input', 'output', 'characteristics', 'on', 'top', 'of', 'vllm', 'as', 'an', 'inference', 'platform', 'accompanied', 'in', 'both', 'places', 'with', 'documentation', 'and', 'code', 'this', 'article', 'describes', 'the', 'intended', 'usage', 'training', 'details', 'and', 'evaluations', 'for', 'each', 'intrinsic', 'as', 'well', 'as', 'compositions', 'of', 'multiple', 'intrinsics']",9,177,"['API', 'RAG', 'LLMs', 'Even', 'Intrinsics', 'Augmented', 'LoRA', 'APIs', 'HuggingFace', 'Retrieval', 'Inspired', 'Generation', 'LLM']"
2504.11703v1,Progent: Programmable Privilege Control for LLM Agents,"LLM agents are an emerging form of AI systems where large language models (LLMs) serve as the central component, utilizing a diverse set of tools to complete user-assigned tasks. Despite their great potential, LLM agents pose significant security risks. When interacting with the external world, they may encounter malicious commands from attackers, leading to the execution of dangerous actions. A promising way to address this is by enforcing the principle of least privilege: allowing only essential actions for task completion while blocking unnecessary ones. However, achieving this is challenging, as it requires covering diverse agent scenarios while preserving both security and utility.   We introduce Progent, the first privilege control mechanism for LLM agents. At its core is a domain-specific language for flexibly expressing privilege control policies applied during agent execution. These policies provide fine-grained constraints over tool calls, deciding when tool calls are permissible and specifying fallbacks if they are not. This enables agent developers and users to craft suitable policies for their specific use cases and enforce them deterministically to guarantee security. Thanks to its modular design, integrating Progent does not alter agent internals and requires only minimal changes to agent implementation, enhancing its practicality and potential for widespread adoption. To automate policy writing, we leverage LLMs to generate policies based on user queries, which are then updated dynamically for improved security and utility. Our extensive evaluation shows that it enables strong security while preserving high utility across three distinct scenarios or benchmarks: AgentDojo, ASB, and AgentPoison. Furthermore, we perform an in-depth analysis, showcasing the effectiveness of its core components and the resilience of its automated policy generation against adaptive attacks.","Tianneng Shi, Jingxuan He, Zhun Wang, Linyu Wu, Hongwei Li, Wenbo Guo, Dawn Song","cs.CR, cs.AI",2025-04-16T01:58:40Z,http://arxiv.org/abs/2504.11703v1,progent programmable privilege control for llm agents,llm agents are an emerging form of ai systems where large language models llms serve as the central component utilizing a diverse set of tools to complete user assigned tasks despite their great potential llm agents pose significant security risks when interacting with the external world they may encounter malicious commands from attackers leading to the execution of dangerous actions a promising way to address this is by enforcing the principle of least privilege allowing only essential actions for task completion while blocking unnecessary ones however achieving this is challenging as it requires covering diverse agent scenarios while preserving both security and utility we introduce progent the first privilege control mechanism for llm agents at its core is a domain specific language for flexibly expressing privilege control policies applied during agent execution these policies provide fine grained constraints over tool calls deciding when tool calls are permissible and specifying fallbacks if they are not this enables agent developers and users to craft suitable policies for their specific use cases and enforce them deterministically to guarantee security thanks to its modular design integrating progent does not alter agent internals and requires only minimal changes to agent implementation enhancing its practicality and potential for widespread adoption to automate policy writing we leverage llms to generate policies based on user queries which are then updated dynamically for improved security and utility our extensive evaluation shows that it enables strong security while preserving high utility across three distinct scenarios or benchmarks agentdojo asb and agentpoison furthermore we perform an in depth analysis showcasing the effectiveness of its core components and the resilience of its automated policy generation against adaptive attacks,"['progent', 'programmable', 'privilege', 'control', 'for', 'llm', 'agents']","['llm', 'agents', 'are', 'an', 'emerging', 'form', 'of', 'ai', 'systems', 'where', 'large', 'language', 'models', 'llms', 'serve', 'as', 'the', 'central', 'component', 'utilizing', 'a', 'diverse', 'set', 'of', 'tools', 'to', 'complete', 'user', 'assigned', 'tasks', 'despite', 'their', 'great', 'potential', 'llm', 'agents', 'pose', 'significant', 'security', 'risks', 'when', 'interacting', 'with', 'the', 'external', 'world', 'they', 'may', 'encounter', 'malicious', 'commands', 'from', 'attackers', 'leading', 'to', 'the', 'execution', 'of', 'dangerous', 'actions', 'a', 'promising', 'way', 'to', 'address', 'this', 'is', 'by', 'enforcing', 'the', 'principle', 'of', 'least', 'privilege', 'allowing', 'only', 'essential', 'actions', 'for', 'task', 'completion', 'while', 'blocking', 'unnecessary', 'ones', 'however', 'achieving', 'this', 'is', 'challenging', 'as', 'it', 'requires', 'covering', 'diverse', 'agent', 'scenarios', 'while', 'preserving', 'both', 'security', 'and', 'utility', 'we', 'introduce', 'progent', 'the', 'first', 'privilege', 'control', 'mechanism', 'for', 'llm', 'agents', 'at', 'its', 'core', 'is', 'a', 'domain', 'specific', 'language', 'for', 'flexibly', 'expressing', 'privilege', 'control', 'policies', 'applied', 'during', 'agent', 'execution', 'these', 'policies', 'provide', 'fine', 'grained', 'constraints', 'over', 'tool', 'calls', 'deciding', 'when', 'tool', 'calls', 'are', 'permissible', 'and', 'specifying', 'fallbacks', 'if', 'they', 'are', 'not', 'this', 'enables', 'agent', 'developers', 'and', 'users', 'to', 'craft', 'suitable', 'policies', 'for', 'their', 'specific', 'use', 'cases', 'and', 'enforce', 'them', 'deterministically', 'to', 'guarantee', 'security', 'thanks', 'to', 'its', 'modular', 'design', 'integrating', 'progent', 'does', 'not', 'alter', 'agent', 'internals', 'and', 'requires', 'only', 'minimal', 'changes', 'to', 'agent', 'implementation', 'enhancing', 'its', 'practicality', 'and', 'potential', 'for', 'widespread', 'adoption', 'to', 'automate', 'policy', 'writing', 'we', 'leverage', 'llms', 'to', 'generate', 'policies', 'based', 'on', 'user', 'queries', 'which', 'are', 'then', 'updated', 'dynamically', 'for', 'improved', 'security', 'and', 'utility', 'our', 'extensive', 'evaluation', 'shows', 'that', 'it', 'enables', 'strong', 'security', 'while', 'preserving', 'high', 'utility', 'across', 'three', 'distinct', 'scenarios', 'or', 'benchmarks', 'agentdojo', 'asb', 'and', 'agentpoison', 'furthermore', 'we', 'perform', 'an', 'in', 'depth', 'analysis', 'showcasing', 'the', 'effectiveness', 'of', 'its', 'core', 'components', 'and', 'the', 'resilience', 'of', 'its', 'automated', 'policy', 'generation', 'against', 'adaptive', 'attacks']",7,276,"['Thanks', 'Progent', 'Despite', 'LLMs', 'However', 'These', 'AgentDojo', 'Furthermore', 'When', 'Our', 'ASB', 'AgentPoison', 'LLM']"
2504.11686v1,Can GPT tell us why these images are synthesized? Empowering Multimodal   Large Language Models for Forensics,"The rapid development of generative AI facilitates content creation and makes image manipulation easier and more difficult to detect. While multimodal Large Language Models (LLMs) have encoded rich world knowledge, they are not inherently tailored for combating AI-generated Content (AIGC) and struggle to comprehend local forgery details. In this work, we investigate the application of multimodal LLMs in forgery detection. We propose a framework capable of evaluating image authenticity, localizing tampered regions, providing evidence, and tracing generation methods based on semantic tampering clues. Our method demonstrates that the potential of LLMs in forgery analysis can be effectively unlocked through meticulous prompt engineering and the application of few-shot learning techniques. We conduct qualitative and quantitative experiments and show that GPT4V can achieve an accuracy of 92.1% in Autosplice and 86.3% in LaMa, which is competitive with state-of-the-art AIGC detection methods. We further discuss the limitations of multimodal LLMs in such tasks and propose potential improvements.","Yiran He, Yun Cao, Bowen Yang, Zeyu Zhang","cs.CV, cs.AI",2025-04-16T01:02:46Z,http://arxiv.org/abs/2504.11686v1,can gpt tell us why these images are synthesized empowering multimodal large language models for forensics,the rapid development of generative ai facilitates content creation and makes image manipulation easier and more difficult to detect while multimodal large language models llms have encoded rich world knowledge they are not inherently tailored for combating ai generated content aigc and struggle to comprehend local forgery details in this work we investigate the application of multimodal llms in forgery detection we propose a framework capable of evaluating image authenticity localizing tampered regions providing evidence and tracing generation methods based on semantic tampering clues our method demonstrates that the potential of llms in forgery analysis can be effectively unlocked through meticulous prompt engineering and the application of few shot learning techniques we conduct qualitative and quantitative experiments and show that gpt v can achieve an accuracy of in autosplice and in lama which is competitive with state of the art aigc detection methods we further discuss the limitations of multimodal llms in such tasks and propose potential improvements,"['can', 'gpt', 'tell', 'us', 'why', 'these', 'images', 'are', 'synthesized', 'empowering', 'multimodal', 'large', 'language', 'models', 'for', 'forensics']","['the', 'rapid', 'development', 'of', 'generative', 'ai', 'facilitates', 'content', 'creation', 'and', 'makes', 'image', 'manipulation', 'easier', 'and', 'more', 'difficult', 'to', 'detect', 'while', 'multimodal', 'large', 'language', 'models', 'llms', 'have', 'encoded', 'rich', 'world', 'knowledge', 'they', 'are', 'not', 'inherently', 'tailored', 'for', 'combating', 'ai', 'generated', 'content', 'aigc', 'and', 'struggle', 'to', 'comprehend', 'local', 'forgery', 'details', 'in', 'this', 'work', 'we', 'investigate', 'the', 'application', 'of', 'multimodal', 'llms', 'in', 'forgery', 'detection', 'we', 'propose', 'a', 'framework', 'capable', 'of', 'evaluating', 'image', 'authenticity', 'localizing', 'tampered', 'regions', 'providing', 'evidence', 'and', 'tracing', 'generation', 'methods', 'based', 'on', 'semantic', 'tampering', 'clues', 'our', 'method', 'demonstrates', 'that', 'the', 'potential', 'of', 'llms', 'in', 'forgery', 'analysis', 'can', 'be', 'effectively', 'unlocked', 'through', 'meticulous', 'prompt', 'engineering', 'and', 'the', 'application', 'of', 'few', 'shot', 'learning', 'techniques', 'we', 'conduct', 'qualitative', 'and', 'quantitative', 'experiments', 'and', 'show', 'that', 'gpt', 'v', 'can', 'achieve', 'an', 'accuracy', 'of', 'in', 'autosplice', 'and', 'in', 'lama', 'which', 'is', 'competitive', 'with', 'state', 'of', 'the', 'art', 'aigc', 'detection', 'methods', 'we', 'further', 'discuss', 'the', 'limitations', 'of', 'multimodal', 'llms', 'in', 'such', 'tasks', 'and', 'propose', 'potential', 'improvements']",16,158,"['AIGC', 'LLMs', 'While', 'Models', 'Autosplice', 'LaMa', 'GPT4V', 'Language', 'Our', 'Large', 'Content', 'AI-generated']"
2504.11671v1,Steering Prosocial AI Agents: Computational Basis of LLM's Decision   Making in Social Simulation,"Large language models (LLMs) increasingly serve as human-like decision-making agents in social science and applied settings. These LLM-agents are typically assigned human-like characters and placed in real-life contexts. However, how these characters and contexts shape an LLM's behavior remains underexplored. This study proposes and tests methods for probing, quantifying, and modifying an LLM's internal representations in a Dictator Game -- a classic behavioral experiment on fairness and prosocial behavior. We extract ``vectors of variable variations'' (e.g., ``male'' to ``female'') from the LLM's internal state. Manipulating these vectors during the model's inference can substantially alter how those variables relate to the model's decision-making. This approach offers a principled way to study and regulate how social concepts can be encoded and engineered within transformer-based models, with implications for alignment, debiasing, and designing AI agents for social simulations in both academic and commercial applications.",Ji Ma,"cs.AI, cs.CY, cs.LG, econ.GN, q-fin.EC",2025-04-16T00:02:28Z,http://arxiv.org/abs/2504.11671v1,steering prosocial ai agents computational basis of llm s decision making in social simulation,large language models llms increasingly serve as human like decision making agents in social science and applied settings these llm agents are typically assigned human like characters and placed in real life contexts however how these characters and contexts shape an llm s behavior remains underexplored this study proposes and tests methods for probing quantifying and modifying an llm s internal representations in a dictator game a classic behavioral experiment on fairness and prosocial behavior we extract vectors of variable variations e g male to female from the llm s internal state manipulating these vectors during the model s inference can substantially alter how those variables relate to the model s decision making this approach offers a principled way to study and regulate how social concepts can be encoded and engineered within transformer based models with implications for alignment debiasing and designing ai agents for social simulations in both academic and commercial applications,"['steering', 'prosocial', 'ai', 'agents', 'computational', 'basis', 'of', 'llm', 's', 'decision', 'making', 'in', 'social', 'simulation']","['large', 'language', 'models', 'llms', 'increasingly', 'serve', 'as', 'human', 'like', 'decision', 'making', 'agents', 'in', 'social', 'science', 'and', 'applied', 'settings', 'these', 'llm', 'agents', 'are', 'typically', 'assigned', 'human', 'like', 'characters', 'and', 'placed', 'in', 'real', 'life', 'contexts', 'however', 'how', 'these', 'characters', 'and', 'contexts', 'shape', 'an', 'llm', 's', 'behavior', 'remains', 'underexplored', 'this', 'study', 'proposes', 'and', 'tests', 'methods', 'for', 'probing', 'quantifying', 'and', 'modifying', 'an', 'llm', 's', 'internal', 'representations', 'in', 'a', 'dictator', 'game', 'a', 'classic', 'behavioral', 'experiment', 'on', 'fairness', 'and', 'prosocial', 'behavior', 'we', 'extract', 'vectors', 'of', 'variable', 'variations', 'e', 'g', 'male', 'to', 'female', 'from', 'the', 'llm', 's', 'internal', 'state', 'manipulating', 'these', 'vectors', 'during', 'the', 'model', 's', 'inference', 'can', 'substantially', 'alter', 'how', 'those', 'variables', 'relate', 'to', 'the', 'model', 's', 'decision', 'making', 'this', 'approach', 'offers', 'a', 'principled', 'way', 'to', 'study', 'and', 'regulate', 'how', 'social', 'concepts', 'can', 'be', 'encoded', 'and', 'engineered', 'within', 'transformer', 'based', 'models', 'with', 'implications', 'for', 'alignment', 'debiasing', 'and', 'designing', 'ai', 'agents', 'for', 'social', 'simulations', 'in', 'both', 'academic', 'and', 'commercial', 'applications']",14,153,"['Game', 'LLMs', 'These', 'However', 'Dictator', 'Large', 'LLM', 'LLM-agents', 'Manipulating']"
2504.12354v1,WaterFlow: Learning Fast & Robust Watermarks using Stable Diffusion,"The ability to embed watermarks in images is a fundamental problem of interest for computer vision, and is exacerbated by the rapid rise of generated imagery in recent times. Current state-of-the-art techniques suffer from computational and statistical challenges such as the slow execution speed for practical deployments. In addition, other works trade off fast watermarking speeds but suffer greatly in their robustness or perceptual quality. In this work, we propose WaterFlow (WF), a fast and extremely robust approach for high fidelity visual watermarking based on a learned latent-dependent watermark. Our approach utilizes a pretrained latent diffusion model to encode an arbitrary image into a latent space and produces a learned watermark that is then planted into the Fourier Domain of the latent. The transformation is specified via invertible flow layers that enhance the expressivity of the latent space of the pre-trained model to better preserve image quality while permitting robust and tractable detection. Most notably, WaterFlow demonstrates state-of-the-art performance on general robustness and is the first method capable of effectively defending against difficult combination attacks. We validate our findings on three widely used real and generated datasets: MS-COCO, DiffusionDB, and WikiArt.","Vinay Shukla, Prachee Sharma, Ryan Rossi, Sungchul Kim, Tong Yu, Aditya Grover","eess.IV, cs.AI",2025-04-15T23:27:52Z,http://arxiv.org/abs/2504.12354v1,waterflow learning fast robust watermarks using stable diffusion,the ability to embed watermarks in images is a fundamental problem of interest for computer vision and is exacerbated by the rapid rise of generated imagery in recent times current state of the art techniques suffer from computational and statistical challenges such as the slow execution speed for practical deployments in addition other works trade off fast watermarking speeds but suffer greatly in their robustness or perceptual quality in this work we propose waterflow wf a fast and extremely robust approach for high fidelity visual watermarking based on a learned latent dependent watermark our approach utilizes a pretrained latent diffusion model to encode an arbitrary image into a latent space and produces a learned watermark that is then planted into the fourier domain of the latent the transformation is specified via invertible flow layers that enhance the expressivity of the latent space of the pre trained model to better preserve image quality while permitting robust and tractable detection most notably waterflow demonstrates state of the art performance on general robustness and is the first method capable of effectively defending against difficult combination attacks we validate our findings on three widely used real and generated datasets ms coco diffusiondb and wikiart,"['waterflow', 'learning', 'fast', 'robust', 'watermarks', 'using', 'stable', 'diffusion']","['the', 'ability', 'to', 'embed', 'watermarks', 'in', 'images', 'is', 'a', 'fundamental', 'problem', 'of', 'interest', 'for', 'computer', 'vision', 'and', 'is', 'exacerbated', 'by', 'the', 'rapid', 'rise', 'of', 'generated', 'imagery', 'in', 'recent', 'times', 'current', 'state', 'of', 'the', 'art', 'techniques', 'suffer', 'from', 'computational', 'and', 'statistical', 'challenges', 'such', 'as', 'the', 'slow', 'execution', 'speed', 'for', 'practical', 'deployments', 'in', 'addition', 'other', 'works', 'trade', 'off', 'fast', 'watermarking', 'speeds', 'but', 'suffer', 'greatly', 'in', 'their', 'robustness', 'or', 'perceptual', 'quality', 'in', 'this', 'work', 'we', 'propose', 'waterflow', 'wf', 'a', 'fast', 'and', 'extremely', 'robust', 'approach', 'for', 'high', 'fidelity', 'visual', 'watermarking', 'based', 'on', 'a', 'learned', 'latent', 'dependent', 'watermark', 'our', 'approach', 'utilizes', 'a', 'pretrained', 'latent', 'diffusion', 'model', 'to', 'encode', 'an', 'arbitrary', 'image', 'into', 'a', 'latent', 'space', 'and', 'produces', 'a', 'learned', 'watermark', 'that', 'is', 'then', 'planted', 'into', 'the', 'fourier', 'domain', 'of', 'the', 'latent', 'the', 'transformation', 'is', 'specified', 'via', 'invertible', 'flow', 'layers', 'that', 'enhance', 'the', 'expressivity', 'of', 'the', 'latent', 'space', 'of', 'the', 'pre', 'trained', 'model', 'to', 'better', 'preserve', 'image', 'quality', 'while', 'permitting', 'robust', 'and', 'tractable', 'detection', 'most', 'notably', 'waterflow', 'demonstrates', 'state', 'of', 'the', 'art', 'performance', 'on', 'general', 'robustness', 'and', 'is', 'the', 'first', 'method', 'capable', 'of', 'effectively', 'defending', 'against', 'difficult', 'combination', 'attacks', 'we', 'validate', 'our', 'findings', 'on', 'three', 'widely', 'used', 'real', 'and', 'generated', 'datasets', 'ms', 'coco', 'diffusiondb', 'and', 'wikiart']",8,200,"['Domain', 'Most', 'DiffusionDB', 'WikiArt', 'WaterFlow', 'MS-COCO', 'Our', 'Current', 'Fourier']"
2504.11658v1,Improving LLM Interpretability and Performance via Guided Embedding   Refinement for Sequential Recommendation,"The fast development of Large Language Models (LLMs) offers growing opportunities to further improve sequential recommendation systems. Yet for some practitioners, integrating LLMs to their existing base recommendation systems raises questions about model interpretability, transparency and related safety. To partly alleviate challenges from these questions, we propose guided embedding refinement, a method that carries out a guided and interpretable usage of LLM to enhance the embeddings associated with the base recommendation system. Instead of directly using LLMs as the backbone of sequential recommendation systems, we utilize them as auxiliary tools to emulate the sales logic of recommendation and generate guided embeddings that capture domain-relevant semantic information on interpretable attributes. Benefiting from the strong generalization capabilities of the guided embedding, we construct refined embedding by using the guided embedding and reduced-dimension version of the base embedding. We then integrate the refined embedding into the recommendation module for training and inference. A range of numerical experiments demonstrate that guided embedding is adaptable to various given existing base embedding models, and generalizes well across different recommendation tasks. The numerical results show that the refined embedding not only improves recommendation performance, achieving approximately $10\%$ to $50\%$ gains in Mean Reciprocal Rank (MRR), Recall rate, and Normalized Discounted Cumulative Gain (NDCG), but also enhances interpretability, as evidenced by case studies.","Nanshan Jia, Chenfei Yuan, Yuhang Wu, Zeyu Zheng","cs.IR, cs.AI",2025-04-15T23:03:53Z,http://arxiv.org/abs/2504.11658v1,improving llm interpretability and performance via guided embedding refinement for sequential recommendation,the fast development of large language models llms offers growing opportunities to further improve sequential recommendation systems yet for some practitioners integrating llms to their existing base recommendation systems raises questions about model interpretability transparency and related safety to partly alleviate challenges from these questions we propose guided embedding refinement a method that carries out a guided and interpretable usage of llm to enhance the embeddings associated with the base recommendation system instead of directly using llms as the backbone of sequential recommendation systems we utilize them as auxiliary tools to emulate the sales logic of recommendation and generate guided embeddings that capture domain relevant semantic information on interpretable attributes benefiting from the strong generalization capabilities of the guided embedding we construct refined embedding by using the guided embedding and reduced dimension version of the base embedding we then integrate the refined embedding into the recommendation module for training and inference a range of numerical experiments demonstrate that guided embedding is adaptable to various given existing base embedding models and generalizes well across different recommendation tasks the numerical results show that the refined embedding not only improves recommendation performance achieving approximately to gains in mean reciprocal rank mrr recall rate and normalized discounted cumulative gain ndcg but also enhances interpretability as evidenced by case studies,"['improving', 'llm', 'interpretability', 'and', 'performance', 'via', 'guided', 'embedding', 'refinement', 'for', 'sequential', 'recommendation']","['the', 'fast', 'development', 'of', 'large', 'language', 'models', 'llms', 'offers', 'growing', 'opportunities', 'to', 'further', 'improve', 'sequential', 'recommendation', 'systems', 'yet', 'for', 'some', 'practitioners', 'integrating', 'llms', 'to', 'their', 'existing', 'base', 'recommendation', 'systems', 'raises', 'questions', 'about', 'model', 'interpretability', 'transparency', 'and', 'related', 'safety', 'to', 'partly', 'alleviate', 'challenges', 'from', 'these', 'questions', 'we', 'propose', 'guided', 'embedding', 'refinement', 'a', 'method', 'that', 'carries', 'out', 'a', 'guided', 'and', 'interpretable', 'usage', 'of', 'llm', 'to', 'enhance', 'the', 'embeddings', 'associated', 'with', 'the', 'base', 'recommendation', 'system', 'instead', 'of', 'directly', 'using', 'llms', 'as', 'the', 'backbone', 'of', 'sequential', 'recommendation', 'systems', 'we', 'utilize', 'them', 'as', 'auxiliary', 'tools', 'to', 'emulate', 'the', 'sales', 'logic', 'of', 'recommendation', 'and', 'generate', 'guided', 'embeddings', 'that', 'capture', 'domain', 'relevant', 'semantic', 'information', 'on', 'interpretable', 'attributes', 'benefiting', 'from', 'the', 'strong', 'generalization', 'capabilities', 'of', 'the', 'guided', 'embedding', 'we', 'construct', 'refined', 'embedding', 'by', 'using', 'the', 'guided', 'embedding', 'and', 'reduced', 'dimension', 'version', 'of', 'the', 'base', 'embedding', 'we', 'then', 'integrate', 'the', 'refined', 'embedding', 'into', 'the', 'recommendation', 'module', 'for', 'training', 'and', 'inference', 'a', 'range', 'of', 'numerical', 'experiments', 'demonstrate', 'that', 'guided', 'embedding', 'is', 'adaptable', 'to', 'various', 'given', 'existing', 'base', 'embedding', 'models', 'and', 'generalizes', 'well', 'across', 'different', 'recommendation', 'tasks', 'the', 'numerical', 'results', 'show', 'that', 'the', 'refined', 'embedding', 'not', 'only', 'improves', 'recommendation', 'performance', 'achieving', 'approximately', 'to', 'gains', 'in', 'mean', 'reciprocal', 'rank', 'mrr', 'recall', 'rate', 'and', 'normalized', 'discounted', 'cumulative', 'gain', 'ndcg', 'but', 'also', 'enhances', 'interpretability', 'as', 'evidenced', 'by', 'case', 'studies']",12,215,"['Benefiting', 'Instead', 'MRR', 'Gain', 'LLMs', 'Yet', 'Recall', 'Models', 'Cumulative', 'Rank', 'Discounted', 'Mean', 'Language', 'Reciprocal', 'NDCG', 'Large', 'LLM', 'Normalized']"
2504.11650v1,Data driven approach towards more efficient Newton-Raphson power flow   calculation for distribution grids,"Power flow (PF) calculations are fundamental to power system analysis to ensure stable and reliable grid operation. The Newton-Raphson (NR) method is commonly used for PF analysis due to its rapid convergence when initialized properly. However, as power grids operate closer to their capacity limits, ill-conditioned cases and convergence issues pose significant challenges. This work, therefore, addresses these challenges by proposing strategies to improve NR initialization, hence minimizing iterations and avoiding divergence. We explore three approaches: (i) an analytical method that estimates the basin of attraction using mathematical bounds on voltages, (ii) Two data-driven models leveraging supervised learning or physics-informed neural networks (PINNs) to predict optimal initial guesses, and (iii) a reinforcement learning (RL) approach that incrementally adjusts voltages to accelerate convergence. These methods are tested on benchmark systems. This research is particularly relevant for modern power systems, where high penetration of renewables and decentralized generation require robust and scalable PF solutions. In experiments, all three proposed methods demonstrate a strong ability to provide an initial guess for Newton-Raphson method to converge with fewer steps. The findings provide a pathway for more efficient real-time grid operations, which, in turn, support the transition toward smarter and more resilient electricity networks.","Shengyuan Yan, Farzad Vazinram, Zeynab Kaseb, Lindsay Spoor, Jochen Stiasny, Betul Mamudi, Amirhossein Heydarian Ardakani, Ugochukwu Orji, Pedro P. Vergara, Yu Xiang, Jerry Guo","eess.SY, cs.AI, cs.LG, cs.NA, cs.SY, math.NA, I.2.8",2025-04-15T22:37:55Z,http://arxiv.org/abs/2504.11650v1,data driven approach towards more efficient newton raphson power flow calculation for distribution grids,power flow pf calculations are fundamental to power system analysis to ensure stable and reliable grid operation the newton raphson nr method is commonly used for pf analysis due to its rapid convergence when initialized properly however as power grids operate closer to their capacity limits ill conditioned cases and convergence issues pose significant challenges this work therefore addresses these challenges by proposing strategies to improve nr initialization hence minimizing iterations and avoiding divergence we explore three approaches i an analytical method that estimates the basin of attraction using mathematical bounds on voltages ii two data driven models leveraging supervised learning or physics informed neural networks pinns to predict optimal initial guesses and iii a reinforcement learning rl approach that incrementally adjusts voltages to accelerate convergence these methods are tested on benchmark systems this research is particularly relevant for modern power systems where high penetration of renewables and decentralized generation require robust and scalable pf solutions in experiments all three proposed methods demonstrate a strong ability to provide an initial guess for newton raphson method to converge with fewer steps the findings provide a pathway for more efficient real time grid operations which in turn support the transition toward smarter and more resilient electricity networks,"['data', 'driven', 'approach', 'towards', 'more', 'efficient', 'newton', 'raphson', 'power', 'flow', 'calculation', 'for', 'distribution', 'grids']","['power', 'flow', 'pf', 'calculations', 'are', 'fundamental', 'to', 'power', 'system', 'analysis', 'to', 'ensure', 'stable', 'and', 'reliable', 'grid', 'operation', 'the', 'newton', 'raphson', 'nr', 'method', 'is', 'commonly', 'used', 'for', 'pf', 'analysis', 'due', 'to', 'its', 'rapid', 'convergence', 'when', 'initialized', 'properly', 'however', 'as', 'power', 'grids', 'operate', 'closer', 'to', 'their', 'capacity', 'limits', 'ill', 'conditioned', 'cases', 'and', 'convergence', 'issues', 'pose', 'significant', 'challenges', 'this', 'work', 'therefore', 'addresses', 'these', 'challenges', 'by', 'proposing', 'strategies', 'to', 'improve', 'nr', 'initialization', 'hence', 'minimizing', 'iterations', 'and', 'avoiding', 'divergence', 'we', 'explore', 'three', 'approaches', 'i', 'an', 'analytical', 'method', 'that', 'estimates', 'the', 'basin', 'of', 'attraction', 'using', 'mathematical', 'bounds', 'on', 'voltages', 'ii', 'two', 'data', 'driven', 'models', 'leveraging', 'supervised', 'learning', 'or', 'physics', 'informed', 'neural', 'networks', 'pinns', 'to', 'predict', 'optimal', 'initial', 'guesses', 'and', 'iii', 'a', 'reinforcement', 'learning', 'rl', 'approach', 'that', 'incrementally', 'adjusts', 'voltages', 'to', 'accelerate', 'convergence', 'these', 'methods', 'are', 'tested', 'on', 'benchmark', 'systems', 'this', 'research', 'is', 'particularly', 'relevant', 'for', 'modern', 'power', 'systems', 'where', 'high', 'penetration', 'of', 'renewables', 'and', 'decentralized', 'generation', 'require', 'robust', 'and', 'scalable', 'pf', 'solutions', 'in', 'experiments', 'all', 'three', 'proposed', 'methods', 'demonstrate', 'a', 'strong', 'ability', 'to', 'provide', 'an', 'initial', 'guess', 'for', 'newton', 'raphson', 'method', 'to', 'converge', 'with', 'fewer', 'steps', 'the', 'findings', 'provide', 'a', 'pathway', 'for', 'more', 'efficient', 'real', 'time', 'grid', 'operations', 'which', 'in', 'turn', 'support', 'the', 'transition', 'toward', 'smarter', 'and', 'more', 'resilient', 'electricity', 'networks']",14,205,"['Power', 'However', 'These', 'Raphson', 'PINNs', 'Newton', 'Two']"
2504.11645v1,Achieving Tighter Finite-Time Rates for Heterogeneous Federated   Stochastic Approximation under Markovian Sampling,"Motivated by collaborative reinforcement learning (RL) and optimization with time-correlated data, we study a generic federated stochastic approximation problem involving $M$ agents, where each agent is characterized by an agent-specific (potentially nonlinear) local operator. The goal is for the agents to communicate intermittently via a server to find the root of the average of the agents' local operators. The generality of our setting stems from allowing for (i) Markovian data at each agent and (ii) heterogeneity in the roots of the agents' local operators. The limited recent work that has accounted for both these features in a federated setting fails to guarantee convergence to the desired point or to show any benefit of collaboration; furthermore, they rely on projection steps in their algorithms to guarantee bounded iterates. Our work overcomes each of these limitations. We develop a novel algorithm titled \texttt{FedHSA}, and prove that it guarantees convergence to the correct point, while enjoying an $M$-fold linear speedup in sample-complexity due to collaboration. To our knowledge, \emph{this is the first finite-time result of its kind}, and establishing it (without relying on a projection step) entails a fairly intricate argument that accounts for the interplay between complex temporal correlations due to Markovian sampling, multiple local steps to save communication, and the drift-effects induced by heterogeneous local operators. Our results have implications for a broad class of heterogeneous federated RL problems (e.g., policy evaluation and control) with function approximation, where the agents' Markov decision processes can differ in their probability transition kernels and reward functions.","Feng Zhu, Aritra Mitra, Robert W. Heath","cs.LG, cs.AI, cs.SY, eess.SY, math.OC",2025-04-15T22:13:55Z,http://arxiv.org/abs/2504.11645v1,achieving tighter finite time rates for heterogeneous federated stochastic approximation under markovian sampling,motivated by collaborative reinforcement learning rl and optimization with time correlated data we study a generic federated stochastic approximation problem involving m agents where each agent is characterized by an agent specific potentially nonlinear local operator the goal is for the agents to communicate intermittently via a server to find the root of the average of the agents local operators the generality of our setting stems from allowing for i markovian data at each agent and ii heterogeneity in the roots of the agents local operators the limited recent work that has accounted for both these features in a federated setting fails to guarantee convergence to the desired point or to show any benefit of collaboration furthermore they rely on projection steps in their algorithms to guarantee bounded iterates our work overcomes each of these limitations we develop a novel algorithm titled fedhsa and prove that it guarantees convergence to the correct point while enjoying an m fold linear speedup in sample complexity due to collaboration to our knowledge this is the first finite time result of its kind and establishing it without relying on a projection step entails a fairly intricate argument that accounts for the interplay between complex temporal correlations due to markovian sampling multiple local steps to save communication and the drift effects induced by heterogeneous local operators our results have implications for a broad class of heterogeneous federated rl problems e g policy evaluation and control with function approximation where the agents markov decision processes can differ in their probability transition kernels and reward functions,"['achieving', 'tighter', 'finite', 'time', 'rates', 'for', 'heterogeneous', 'federated', 'stochastic', 'approximation', 'under', 'markovian', 'sampling']","['motivated', 'by', 'collaborative', 'reinforcement', 'learning', 'rl', 'and', 'optimization', 'with', 'time', 'correlated', 'data', 'we', 'study', 'a', 'generic', 'federated', 'stochastic', 'approximation', 'problem', 'involving', 'm', 'agents', 'where', 'each', 'agent', 'is', 'characterized', 'by', 'an', 'agent', 'specific', 'potentially', 'nonlinear', 'local', 'operator', 'the', 'goal', 'is', 'for', 'the', 'agents', 'to', 'communicate', 'intermittently', 'via', 'a', 'server', 'to', 'find', 'the', 'root', 'of', 'the', 'average', 'of', 'the', 'agents', 'local', 'operators', 'the', 'generality', 'of', 'our', 'setting', 'stems', 'from', 'allowing', 'for', 'i', 'markovian', 'data', 'at', 'each', 'agent', 'and', 'ii', 'heterogeneity', 'in', 'the', 'roots', 'of', 'the', 'agents', 'local', 'operators', 'the', 'limited', 'recent', 'work', 'that', 'has', 'accounted', 'for', 'both', 'these', 'features', 'in', 'a', 'federated', 'setting', 'fails', 'to', 'guarantee', 'convergence', 'to', 'the', 'desired', 'point', 'or', 'to', 'show', 'any', 'benefit', 'of', 'collaboration', 'furthermore', 'they', 'rely', 'on', 'projection', 'steps', 'in', 'their', 'algorithms', 'to', 'guarantee', 'bounded', 'iterates', 'our', 'work', 'overcomes', 'each', 'of', 'these', 'limitations', 'we', 'develop', 'a', 'novel', 'algorithm', 'titled', 'fedhsa', 'and', 'prove', 'that', 'it', 'guarantees', 'convergence', 'to', 'the', 'correct', 'point', 'while', 'enjoying', 'an', 'm', 'fold', 'linear', 'speedup', 'in', 'sample', 'complexity', 'due', 'to', 'collaboration', 'to', 'our', 'knowledge', 'this', 'is', 'the', 'first', 'finite', 'time', 'result', 'of', 'its', 'kind', 'and', 'establishing', 'it', 'without', 'relying', 'on', 'a', 'projection', 'step', 'entails', 'a', 'fairly', 'intricate', 'argument', 'that', 'accounts', 'for', 'the', 'interplay', 'between', 'complex', 'temporal', 'correlations', 'due', 'to', 'markovian', 'sampling', 'multiple', 'local', 'steps', 'to', 'save', 'communication', 'and', 'the', 'drift', 'effects', 'induced', 'by', 'heterogeneous', 'local', 'operators', 'our', 'results', 'have', 'implications', 'for', 'a', 'broad', 'class', 'of', 'heterogeneous', 'federated', 'rl', 'problems', 'e', 'g', 'policy', 'evaluation', 'and', 'control', 'with', 'function', 'approximation', 'where', 'the', 'agents', 'markov', 'decision', 'processes', 'can', 'differ', 'in', 'their', 'probability', 'transition', 'kernels', 'and', 'reward', 'functions']",13,259,"['Motivated', 'Markov', 'Our', 'FedHSA', 'Markovian']"
2504.12352v1,Deep Generative Model-Based Generation of Synthetic Individual-Specific   Brain MRI Segmentations,"To the best of our knowledge, all existing methods that can generate synthetic brain magnetic resonance imaging (MRI) scans for a specific individual require detailed structural or volumetric information about the individual's brain. However, such brain information is often scarce, expensive, and difficult to obtain. In this paper, we propose the first approach capable of generating synthetic brain MRI segmentations -- specifically, 3D white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF) segmentations -- for individuals using their easily obtainable and often readily available demographic, interview, and cognitive test information. Our approach features a novel deep generative model, CSegSynth, which outperforms existing prominent generative models, including conditional variational autoencoder (C-VAE), conditional generative adversarial network (C-GAN), and conditional latent diffusion model (C-LDM). We demonstrate the high quality of our synthetic segmentations through extensive evaluations. Also, in assessing the effectiveness of the individual-specific generation, we achieve superior volume prediction, with Pearson correlation coefficients reaching 0.80, 0.82, and 0.70 between the ground-truth WM, GM, and CSF volumes of test individuals and those volumes predicted based on generated individual-specific segmentations, respectively.","Ruijie Wang, Luca Rossetto, Susan M√©rillat, Christina R√∂cke, Mike Martin, Abraham Bernstein","q-bio.NC, cs.AI, eess.IV",2025-04-15T21:25:36Z,http://arxiv.org/abs/2504.12352v1,deep generative model based generation of synthetic individual specific brain mri segmentations,to the best of our knowledge all existing methods that can generate synthetic brain magnetic resonance imaging mri scans for a specific individual require detailed structural or volumetric information about the individual s brain however such brain information is often scarce expensive and difficult to obtain in this paper we propose the first approach capable of generating synthetic brain mri segmentations specifically d white matter wm gray matter gm and cerebrospinal fluid csf segmentations for individuals using their easily obtainable and often readily available demographic interview and cognitive test information our approach features a novel deep generative model csegsynth which outperforms existing prominent generative models including conditional variational autoencoder c vae conditional generative adversarial network c gan and conditional latent diffusion model c ldm we demonstrate the high quality of our synthetic segmentations through extensive evaluations also in assessing the effectiveness of the individual specific generation we achieve superior volume prediction with pearson correlation coefficients reaching and between the ground truth wm gm and csf volumes of test individuals and those volumes predicted based on generated individual specific segmentations respectively,"['deep', 'generative', 'model', 'based', 'generation', 'of', 'synthetic', 'individual', 'specific', 'brain', 'mri', 'segmentations']","['to', 'the', 'best', 'of', 'our', 'knowledge', 'all', 'existing', 'methods', 'that', 'can', 'generate', 'synthetic', 'brain', 'magnetic', 'resonance', 'imaging', 'mri', 'scans', 'for', 'a', 'specific', 'individual', 'require', 'detailed', 'structural', 'or', 'volumetric', 'information', 'about', 'the', 'individual', 's', 'brain', 'however', 'such', 'brain', 'information', 'is', 'often', 'scarce', 'expensive', 'and', 'difficult', 'to', 'obtain', 'in', 'this', 'paper', 'we', 'propose', 'the', 'first', 'approach', 'capable', 'of', 'generating', 'synthetic', 'brain', 'mri', 'segmentations', 'specifically', 'd', 'white', 'matter', 'wm', 'gray', 'matter', 'gm', 'and', 'cerebrospinal', 'fluid', 'csf', 'segmentations', 'for', 'individuals', 'using', 'their', 'easily', 'obtainable', 'and', 'often', 'readily', 'available', 'demographic', 'interview', 'and', 'cognitive', 'test', 'information', 'our', 'approach', 'features', 'a', 'novel', 'deep', 'generative', 'model', 'csegsynth', 'which', 'outperforms', 'existing', 'prominent', 'generative', 'models', 'including', 'conditional', 'variational', 'autoencoder', 'c', 'vae', 'conditional', 'generative', 'adversarial', 'network', 'c', 'gan', 'and', 'conditional', 'latent', 'diffusion', 'model', 'c', 'ldm', 'we', 'demonstrate', 'the', 'high', 'quality', 'of', 'our', 'synthetic', 'segmentations', 'through', 'extensive', 'evaluations', 'also', 'in', 'assessing', 'the', 'effectiveness', 'of', 'the', 'individual', 'specific', 'generation', 'we', 'achieve', 'superior', 'volume', 'prediction', 'with', 'pearson', 'correlation', 'coefficients', 'reaching', 'and', 'between', 'the', 'ground', 'truth', 'wm', 'gm', 'and', 'csf', 'volumes', 'of', 'test', 'individuals', 'and', 'those', 'volumes', 'predicted', 'based', 'on', 'generated', 'individual', 'specific', 'segmentations', 'respectively']",12,180,"['C-LDM', 'MRI', 'CSegSynth', 'Pearson', 'However', 'Also', 'Our', 'C-GAN', 'C-VAE', 'CSF']"
2504.12351v1,Prototype-Guided Diffusion for Digital Pathology: Achieving Foundation   Model Performance with Minimal Clinical Data,"Foundation models in digital pathology use massive datasets to learn useful compact feature representations of complex histology images. However, there is limited transparency into what drives the correlation between dataset size and performance, raising the question of whether simply adding more data to increase performance is always necessary. In this study, we propose a prototype-guided diffusion model to generate high-fidelity synthetic pathology data at scale, enabling large-scale self-supervised learning and reducing reliance on real patient samples while preserving downstream performance. Using guidance from histological prototypes during sampling, our approach ensures biologically and diagnostically meaningful variations in the generated data. We demonstrate that self-supervised features trained on our synthetic dataset achieve competitive performance despite using ~60x-760x less data than models trained on large real-world datasets. Notably, models trained using our synthetic data showed statistically comparable or better performance across multiple evaluation metrics and tasks, even when compared to models trained on orders of magnitude larger datasets. Our hybrid approach, combining synthetic and real data, further enhanced performance, achieving top results in several evaluations. These findings underscore the potential of generative AI to create compelling training data for digital pathology, significantly reducing the reliance on extensive clinical datasets and highlighting the efficiency of our approach.","Ekaterina Redekop, Mara Pleasure, Vedrana Ivezic, Zichen Wang, Kimberly Flores, Anthony Sisk, William Speier, Corey Arnold","cs.GR, cs.AI, eess.IV, q-bio.TO",2025-04-15T21:17:39Z,http://arxiv.org/abs/2504.12351v1,prototype guided diffusion for digital pathology achieving foundation model performance with minimal clinical data,foundation models in digital pathology use massive datasets to learn useful compact feature representations of complex histology images however there is limited transparency into what drives the correlation between dataset size and performance raising the question of whether simply adding more data to increase performance is always necessary in this study we propose a prototype guided diffusion model to generate high fidelity synthetic pathology data at scale enabling large scale self supervised learning and reducing reliance on real patient samples while preserving downstream performance using guidance from histological prototypes during sampling our approach ensures biologically and diagnostically meaningful variations in the generated data we demonstrate that self supervised features trained on our synthetic dataset achieve competitive performance despite using x x less data than models trained on large real world datasets notably models trained using our synthetic data showed statistically comparable or better performance across multiple evaluation metrics and tasks even when compared to models trained on orders of magnitude larger datasets our hybrid approach combining synthetic and real data further enhanced performance achieving top results in several evaluations these findings underscore the potential of generative ai to create compelling training data for digital pathology significantly reducing the reliance on extensive clinical datasets and highlighting the efficiency of our approach,"['prototype', 'guided', 'diffusion', 'for', 'digital', 'pathology', 'achieving', 'foundation', 'model', 'performance', 'with', 'minimal', 'clinical', 'data']","['foundation', 'models', 'in', 'digital', 'pathology', 'use', 'massive', 'datasets', 'to', 'learn', 'useful', 'compact', 'feature', 'representations', 'of', 'complex', 'histology', 'images', 'however', 'there', 'is', 'limited', 'transparency', 'into', 'what', 'drives', 'the', 'correlation', 'between', 'dataset', 'size', 'and', 'performance', 'raising', 'the', 'question', 'of', 'whether', 'simply', 'adding', 'more', 'data', 'to', 'increase', 'performance', 'is', 'always', 'necessary', 'in', 'this', 'study', 'we', 'propose', 'a', 'prototype', 'guided', 'diffusion', 'model', 'to', 'generate', 'high', 'fidelity', 'synthetic', 'pathology', 'data', 'at', 'scale', 'enabling', 'large', 'scale', 'self', 'supervised', 'learning', 'and', 'reducing', 'reliance', 'on', 'real', 'patient', 'samples', 'while', 'preserving', 'downstream', 'performance', 'using', 'guidance', 'from', 'histological', 'prototypes', 'during', 'sampling', 'our', 'approach', 'ensures', 'biologically', 'and', 'diagnostically', 'meaningful', 'variations', 'in', 'the', 'generated', 'data', 'we', 'demonstrate', 'that', 'self', 'supervised', 'features', 'trained', 'on', 'our', 'synthetic', 'dataset', 'achieve', 'competitive', 'performance', 'despite', 'using', 'x', 'x', 'less', 'data', 'than', 'models', 'trained', 'on', 'large', 'real', 'world', 'datasets', 'notably', 'models', 'trained', 'using', 'our', 'synthetic', 'data', 'showed', 'statistically', 'comparable', 'or', 'better', 'performance', 'across', 'multiple', 'evaluation', 'metrics', 'and', 'tasks', 'even', 'when', 'compared', 'to', 'models', 'trained', 'on', 'orders', 'of', 'magnitude', 'larger', 'datasets', 'our', 'hybrid', 'approach', 'combining', 'synthetic', 'and', 'real', 'data', 'further', 'enhanced', 'performance', 'achieving', 'top', 'results', 'in', 'several', 'evaluations', 'these', 'findings', 'underscore', 'the', 'potential', 'of', 'generative', 'ai', 'to', 'create', 'compelling', 'training', 'data', 'for', 'digital', 'pathology', 'significantly', 'reducing', 'the', 'reliance', 'on', 'extensive', 'clinical', 'datasets', 'and', 'highlighting', 'the', 'efficiency', 'of', 'our', 'approach']",14,210,"['60x', '760x', 'Foundation', 'However', 'These', 'Notably', 'Our']"
2504.11609v1,Towards Interpretable Deep Generative Models via Causal Representation   Learning,"Recent developments in generative artificial intelligence (AI) rely on machine learning techniques such as deep learning and generative modeling to achieve state-of-the-art performance across wide-ranging domains. These methods' surprising performance is due in part to their ability to learn implicit ""representations'' of complex, multi-modal data. Unfortunately, deep neural networks are notoriously black boxes that obscure these representations, making them difficult to interpret or analyze. To resolve these difficulties, one approach is to build new interpretable neural network models from the ground up. This is the goal of the emerging field of causal representation learning (CRL) that uses causality as a vector for building flexible, interpretable, and transferable generative AI. CRL can be seen as a culmination of three intrinsically statistical problems: (i) latent variable models such as factor analysis; (ii) causal graphical models with latent variables; and (iii) nonparametric statistics and deep learning. This paper reviews recent progress in CRL from a statistical perspective, focusing on connections to classical models and statistical and causal identifiablity results. This review also highlights key application areas, implementation strategies, and open statistical questions in CRL.","Gemma E. Moran, Bryon Aragam","stat.ML, cs.AI, cs.LG, stat.ME",2025-04-15T20:46:42Z,http://arxiv.org/abs/2504.11609v1,towards interpretable deep generative models via causal representation learning,recent developments in generative artificial intelligence ai rely on machine learning techniques such as deep learning and generative modeling to achieve state of the art performance across wide ranging domains these methods surprising performance is due in part to their ability to learn implicit representations of complex multi modal data unfortunately deep neural networks are notoriously black boxes that obscure these representations making them difficult to interpret or analyze to resolve these difficulties one approach is to build new interpretable neural network models from the ground up this is the goal of the emerging field of causal representation learning crl that uses causality as a vector for building flexible interpretable and transferable generative ai crl can be seen as a culmination of three intrinsically statistical problems i latent variable models such as factor analysis ii causal graphical models with latent variables and iii nonparametric statistics and deep learning this paper reviews recent progress in crl from a statistical perspective focusing on connections to classical models and statistical and causal identifiablity results this review also highlights key application areas implementation strategies and open statistical questions in crl,"['towards', 'interpretable', 'deep', 'generative', 'models', 'via', 'causal', 'representation', 'learning']","['recent', 'developments', 'in', 'generative', 'artificial', 'intelligence', 'ai', 'rely', 'on', 'machine', 'learning', 'techniques', 'such', 'as', 'deep', 'learning', 'and', 'generative', 'modeling', 'to', 'achieve', 'state', 'of', 'the', 'art', 'performance', 'across', 'wide', 'ranging', 'domains', 'these', 'methods', 'surprising', 'performance', 'is', 'due', 'in', 'part', 'to', 'their', 'ability', 'to', 'learn', 'implicit', 'representations', 'of', 'complex', 'multi', 'modal', 'data', 'unfortunately', 'deep', 'neural', 'networks', 'are', 'notoriously', 'black', 'boxes', 'that', 'obscure', 'these', 'representations', 'making', 'them', 'difficult', 'to', 'interpret', 'or', 'analyze', 'to', 'resolve', 'these', 'difficulties', 'one', 'approach', 'is', 'to', 'build', 'new', 'interpretable', 'neural', 'network', 'models', 'from', 'the', 'ground', 'up', 'this', 'is', 'the', 'goal', 'of', 'the', 'emerging', 'field', 'of', 'causal', 'representation', 'learning', 'crl', 'that', 'uses', 'causality', 'as', 'a', 'vector', 'for', 'building', 'flexible', 'interpretable', 'and', 'transferable', 'generative', 'ai', 'crl', 'can', 'be', 'seen', 'as', 'a', 'culmination', 'of', 'three', 'intrinsically', 'statistical', 'problems', 'i', 'latent', 'variable', 'models', 'such', 'as', 'factor', 'analysis', 'ii', 'causal', 'graphical', 'models', 'with', 'latent', 'variables', 'and', 'iii', 'nonparametric', 'statistics', 'and', 'deep', 'learning', 'this', 'paper', 'reviews', 'recent', 'progress', 'in', 'crl', 'from', 'a', 'statistical', 'perspective', 'focusing', 'on', 'connections', 'to', 'classical', 'models', 'and', 'statistical', 'and', 'causal', 'identifiablity', 'results', 'this', 'review', 'also', 'highlights', 'key', 'application', 'areas', 'implementation', 'strategies', 'and', 'open', 'statistical', 'questions', 'in', 'crl']",9,186,"['CRL', 'Recent', 'These', 'Unfortunately']"
2504.11571v1,GraphicBench: A Planning Benchmark for Graphic Design with Language   Agents,"Large Language Model (LLM)-powered agents have unlocked new possibilities for automating human tasks. While prior work has focused on well-defined tasks with specified goals, the capabilities of agents in creative design tasks with open-ended goals remain underexplored. We introduce GraphicBench, a new planning benchmark for graphic design that covers 1,079 user queries and input images across four design types. We further present GraphicTown, an LLM agent framework with three design experts and 46 actions (tools) to choose from for executing each step of the planned workflows in web environments. Experiments with six LLMs demonstrate their ability to generate workflows that integrate both explicit design constraints from user queries and implicit commonsense constraints. However, these workflows often do not lead to successful execution outcomes, primarily due to challenges in: (1) reasoning about spatial relationships, (2) coordinating global dependencies across experts, and (3) retrieving the most appropriate action per step. We envision GraphicBench as a challenging yet valuable testbed for advancing LLM-agent planning and execution in creative design tasks.","Dayeon Ki, Tianyi Zhou, Marine Carpuat, Gang Wu, Puneet Mathur, Viswanathan Swaminathan","cs.AI, cs.CL",2025-04-15T19:26:59Z,http://arxiv.org/abs/2504.11571v1,graphicbench a planning benchmark for graphic design with language agents,large language model llm powered agents have unlocked new possibilities for automating human tasks while prior work has focused on well defined tasks with specified goals the capabilities of agents in creative design tasks with open ended goals remain underexplored we introduce graphicbench a new planning benchmark for graphic design that covers user queries and input images across four design types we further present graphictown an llm agent framework with three design experts and actions tools to choose from for executing each step of the planned workflows in web environments experiments with six llms demonstrate their ability to generate workflows that integrate both explicit design constraints from user queries and implicit commonsense constraints however these workflows often do not lead to successful execution outcomes primarily due to challenges in reasoning about spatial relationships coordinating global dependencies across experts and retrieving the most appropriate action per step we envision graphicbench as a challenging yet valuable testbed for advancing llm agent planning and execution in creative design tasks,"['graphicbench', 'a', 'planning', 'benchmark', 'for', 'graphic', 'design', 'with', 'language', 'agents']","['large', 'language', 'model', 'llm', 'powered', 'agents', 'have', 'unlocked', 'new', 'possibilities', 'for', 'automating', 'human', 'tasks', 'while', 'prior', 'work', 'has', 'focused', 'on', 'well', 'defined', 'tasks', 'with', 'specified', 'goals', 'the', 'capabilities', 'of', 'agents', 'in', 'creative', 'design', 'tasks', 'with', 'open', 'ended', 'goals', 'remain', 'underexplored', 'we', 'introduce', 'graphicbench', 'a', 'new', 'planning', 'benchmark', 'for', 'graphic', 'design', 'that', 'covers', 'user', 'queries', 'and', 'input', 'images', 'across', 'four', 'design', 'types', 'we', 'further', 'present', 'graphictown', 'an', 'llm', 'agent', 'framework', 'with', 'three', 'design', 'experts', 'and', 'actions', 'tools', 'to', 'choose', 'from', 'for', 'executing', 'each', 'step', 'of', 'the', 'planned', 'workflows', 'in', 'web', 'environments', 'experiments', 'with', 'six', 'llms', 'demonstrate', 'their', 'ability', 'to', 'generate', 'workflows', 'that', 'integrate', 'both', 'explicit', 'design', 'constraints', 'from', 'user', 'queries', 'and', 'implicit', 'commonsense', 'constraints', 'however', 'these', 'workflows', 'often', 'do', 'not', 'lead', 'to', 'successful', 'execution', 'outcomes', 'primarily', 'due', 'to', 'challenges', 'in', 'reasoning', 'about', 'spatial', 'relationships', 'coordinating', 'global', 'dependencies', 'across', 'experts', 'and', 'retrieving', 'the', 'most', 'appropriate', 'action', 'per', 'step', 'we', 'envision', 'graphicbench', 'as', 'a', 'challenging', 'yet', 'valuable', 'testbed', 'for', 'advancing', 'llm', 'agent', 'planning', 'and', 'execution', 'in', 'creative', 'design', 'tasks']",10,166,"['LLM-agent', 'GraphicTown', 'Model', '079', 'LLMs', 'While', 'However', 'GraphicBench', 'Language', 'Large', 'LLM', 'Experiments']"
2504.11547v1,Probabilistic causal graphs as categorical data synthesizers: Do they do   better than Gaussian Copulas and Conditional Tabular GANs?,"This study investigates the generation of high-quality synthetic categorical data, such as survey data, using causal graph models. Generating synthetic data aims not only to create a variety of data for training the models but also to preserve privacy while capturing relationships between the data. The research employs Structural Equation Modeling (SEM) followed by Bayesian Networks (BN). We used the categorical data that are based on the survey of accessibility to services for people with disabilities. We created both SEM and BN models to represent causal relationships and to capture joint distributions between variables. In our case studies, such variables include, in particular, demographics, types of disability, types of accessibility barriers and frequencies of encountering those barriers.   The study compared the SEM-based BN method with alternative approaches, including the probabilistic Gaussian copula technique and generative models like the Conditional Tabular Generative Adversarial Network (CTGAN). The proposed method outperformed others in statistical metrics, including the Chi-square test, Kullback-Leibler divergence, and Total Variation Distance (TVD). In particular, the BN model demonstrated superior performance, achieving the highest TVD, indicating alignment with the original data. The Gaussian Copula ranked second, while CTGAN exhibited moderate performance. These analyses confirmed the ability of the SEM-based BN to produce synthetic data that maintain statistical and relational validity while maintaining confidentiality. This approach is particularly beneficial for research on sensitive data, such as accessibility and disability studies.","Olha Shaposhnyk, Noor Abid, Mouri Zakir, Svetlana Yanushkevich",cs.AI,2025-04-15T18:41:54Z,http://arxiv.org/abs/2504.11547v1,probabilistic causal graphs as categorical data synthesizers do they do better than gaussian copulas and conditional tabular gans,this study investigates the generation of high quality synthetic categorical data such as survey data using causal graph models generating synthetic data aims not only to create a variety of data for training the models but also to preserve privacy while capturing relationships between the data the research employs structural equation modeling sem followed by bayesian networks bn we used the categorical data that are based on the survey of accessibility to services for people with disabilities we created both sem and bn models to represent causal relationships and to capture joint distributions between variables in our case studies such variables include in particular demographics types of disability types of accessibility barriers and frequencies of encountering those barriers the study compared the sem based bn method with alternative approaches including the probabilistic gaussian copula technique and generative models like the conditional tabular generative adversarial network ctgan the proposed method outperformed others in statistical metrics including the chi square test kullback leibler divergence and total variation distance tvd in particular the bn model demonstrated superior performance achieving the highest tvd indicating alignment with the original data the gaussian copula ranked second while ctgan exhibited moderate performance these analyses confirmed the ability of the sem based bn to produce synthetic data that maintain statistical and relational validity while maintaining confidentiality this approach is particularly beneficial for research on sensitive data such as accessibility and disability studies,"['probabilistic', 'causal', 'graphs', 'as', 'categorical', 'data', 'synthesizers', 'do', 'they', 'do', 'better', 'than', 'gaussian', 'copulas', 'and', 'conditional', 'tabular', 'gans']","['this', 'study', 'investigates', 'the', 'generation', 'of', 'high', 'quality', 'synthetic', 'categorical', 'data', 'such', 'as', 'survey', 'data', 'using', 'causal', 'graph', 'models', 'generating', 'synthetic', 'data', 'aims', 'not', 'only', 'to', 'create', 'a', 'variety', 'of', 'data', 'for', 'training', 'the', 'models', 'but', 'also', 'to', 'preserve', 'privacy', 'while', 'capturing', 'relationships', 'between', 'the', 'data', 'the', 'research', 'employs', 'structural', 'equation', 'modeling', 'sem', 'followed', 'by', 'bayesian', 'networks', 'bn', 'we', 'used', 'the', 'categorical', 'data', 'that', 'are', 'based', 'on', 'the', 'survey', 'of', 'accessibility', 'to', 'services', 'for', 'people', 'with', 'disabilities', 'we', 'created', 'both', 'sem', 'and', 'bn', 'models', 'to', 'represent', 'causal', 'relationships', 'and', 'to', 'capture', 'joint', 'distributions', 'between', 'variables', 'in', 'our', 'case', 'studies', 'such', 'variables', 'include', 'in', 'particular', 'demographics', 'types', 'of', 'disability', 'types', 'of', 'accessibility', 'barriers', 'and', 'frequencies', 'of', 'encountering', 'those', 'barriers', 'the', 'study', 'compared', 'the', 'sem', 'based', 'bn', 'method', 'with', 'alternative', 'approaches', 'including', 'the', 'probabilistic', 'gaussian', 'copula', 'technique', 'and', 'generative', 'models', 'like', 'the', 'conditional', 'tabular', 'generative', 'adversarial', 'network', 'ctgan', 'the', 'proposed', 'method', 'outperformed', 'others', 'in', 'statistical', 'metrics', 'including', 'the', 'chi', 'square', 'test', 'kullback', 'leibler', 'divergence', 'and', 'total', 'variation', 'distance', 'tvd', 'in', 'particular', 'the', 'bn', 'model', 'demonstrated', 'superior', 'performance', 'achieving', 'the', 'highest', 'tvd', 'indicating', 'alignment', 'with', 'the', 'original', 'data', 'the', 'gaussian', 'copula', 'ranked', 'second', 'while', 'ctgan', 'exhibited', 'moderate', 'performance', 'these', 'analyses', 'confirmed', 'the', 'ability', 'of', 'the', 'sem', 'based', 'bn', 'to', 'produce', 'synthetic', 'data', 'that', 'maintain', 'statistical', 'and', 'relational', 'validity', 'while', 'maintaining', 'confidentiality', 'this', 'approach', 'is', 'particularly', 'beneficial', 'for', 'research', 'on', 'sensitive', 'data', 'such', 'as', 'accessibility', 'and', 'disability', 'studies']",18,234,"['SEM-based', 'Total', 'Variation', 'CTGAN', 'Chi', 'Leibler', 'Distance', 'Generating', 'Copula', 'Modeling', 'Conditional', 'Generative', 'Structural', 'Gaussian', 'Tabular', 'Networks', 'Equation', 'SEM', 'Bayesian', 'Adversarial', 'Kullback', 'These', 'Network', 'TVD']"
2504.11544v1,NodeRAG: Structuring Graph-based RAG with Heterogeneous Nodes,"Retrieval-augmented generation (RAG) empowers large language models to access external and private corpus, enabling factually consistent responses in specific domains. By exploiting the inherent structure of the corpus, graph-based RAG methods further enrich this process by building a knowledge graph index and leveraging the structural nature of graphs. However, current graph-based RAG approaches seldom prioritize the design of graph structures. Inadequately designed graph not only impede the seamless integration of diverse graph algorithms but also result in workflow inconsistencies and degraded performance. To further unleash the potential of graph for RAG, we propose NodeRAG, a graph-centric framework introducing heterogeneous graph structures that enable the seamless and holistic integration of graph-based methodologies into the RAG workflow. By aligning closely with the capabilities of LLMs, this framework ensures a fully cohesive and efficient end-to-end process. Through extensive experiments, we demonstrate that NodeRAG exhibits performance advantages over previous methods, including GraphRAG and LightRAG, not only in indexing time, query time, and storage efficiency but also in delivering superior question-answering performance on multi-hop benchmarks and open-ended head-to-head evaluations with minimal retrieval tokens. Our GitHub repository could be seen at https://github.com/Terry-Xu-666/NodeRAG.","Tianyang Xu, Haojie Zheng, Chengze Li, Haoxiang Chen, Yixin Liu, Ruoxi Chen, Lichao Sun",cs.AI,2025-04-15T18:24:00Z,http://arxiv.org/abs/2504.11544v1,noderag structuring graph based rag with heterogeneous nodes,retrieval augmented generation rag empowers large language models to access external and private corpus enabling factually consistent responses in specific domains by exploiting the inherent structure of the corpus graph based rag methods further enrich this process by building a knowledge graph index and leveraging the structural nature of graphs however current graph based rag approaches seldom prioritize the design of graph structures inadequately designed graph not only impede the seamless integration of diverse graph algorithms but also result in workflow inconsistencies and degraded performance to further unleash the potential of graph for rag we propose noderag a graph centric framework introducing heterogeneous graph structures that enable the seamless and holistic integration of graph based methodologies into the rag workflow by aligning closely with the capabilities of llms this framework ensures a fully cohesive and efficient end to end process through extensive experiments we demonstrate that noderag exhibits performance advantages over previous methods including graphrag and lightrag not only in indexing time query time and storage efficiency but also in delivering superior question answering performance on multi hop benchmarks and open ended head to head evaluations with minimal retrieval tokens our github repository could be seen at,"['noderag', 'structuring', 'graph', 'based', 'rag', 'with', 'heterogeneous', 'nodes']","['retrieval', 'augmented', 'generation', 'rag', 'empowers', 'large', 'language', 'models', 'to', 'access', 'external', 'and', 'private', 'corpus', 'enabling', 'factually', 'consistent', 'responses', 'in', 'specific', 'domains', 'by', 'exploiting', 'the', 'inherent', 'structure', 'of', 'the', 'corpus', 'graph', 'based', 'rag', 'methods', 'further', 'enrich', 'this', 'process', 'by', 'building', 'a', 'knowledge', 'graph', 'index', 'and', 'leveraging', 'the', 'structural', 'nature', 'of', 'graphs', 'however', 'current', 'graph', 'based', 'rag', 'approaches', 'seldom', 'prioritize', 'the', 'design', 'of', 'graph', 'structures', 'inadequately', 'designed', 'graph', 'not', 'only', 'impede', 'the', 'seamless', 'integration', 'of', 'diverse', 'graph', 'algorithms', 'but', 'also', 'result', 'in', 'workflow', 'inconsistencies', 'and', 'degraded', 'performance', 'to', 'further', 'unleash', 'the', 'potential', 'of', 'graph', 'for', 'rag', 'we', 'propose', 'noderag', 'a', 'graph', 'centric', 'framework', 'introducing', 'heterogeneous', 'graph', 'structures', 'that', 'enable', 'the', 'seamless', 'and', 'holistic', 'integration', 'of', 'graph', 'based', 'methodologies', 'into', 'the', 'rag', 'workflow', 'by', 'aligning', 'closely', 'with', 'the', 'capabilities', 'of', 'llms', 'this', 'framework', 'ensures', 'a', 'fully', 'cohesive', 'and', 'efficient', 'end', 'to', 'end', 'process', 'through', 'extensive', 'experiments', 'we', 'demonstrate', 'that', 'noderag', 'exhibits', 'performance', 'advantages', 'over', 'previous', 'methods', 'including', 'graphrag', 'and', 'lightrag', 'not', 'only', 'in', 'indexing', 'time', 'query', 'time', 'and', 'storage', 'efficiency', 'but', 'also', 'in', 'delivering', 'superior', 'question', 'answering', 'performance', 'on', 'multi', 'hop', 'benchmarks', 'and', 'open', 'ended', 'head', 'to', 'head', 'evaluations', 'with', 'minimal', 'retrieval', 'tokens', 'our', 'github', 'repository', 'could', 'be', 'seen', 'at']",8,197,"['LightRAG', 'Terry', 'RAG', 'LLMs', 'GitHub', 'However', 'GraphRAG', 'Retrieval', 'Our', 'Inadequately', 'Xu-666', 'NodeRAG', 'Through']"
2504.11543v2,REAL: Benchmarking Autonomous Agents on Deterministic Simulations of   Real Websites,"We introduce REAL, a benchmark and framework for multi-turn agent evaluations on deterministic simulations of real-world websites. REAL comprises high-fidelity, deterministic replicas of 11 widely-used websites across domains such as e-commerce, travel, communication, and professional networking. We also release a benchmark consisting of 112 practical tasks that mirror everyday complex user interactions requiring both accurate information retrieval and state-changing actions. All interactions occur within this fully controlled setting, eliminating safety risks and enabling robust, reproducible evaluation of agent capability and reliability. Our novel evaluation framework combines programmatic checks of website state for action-based tasks with rubric-guided LLM-based judgments for information retrieval. The framework supports both open-source and proprietary agent systems through a flexible evaluation harness that accommodates black-box commands within browser environments, allowing research labs to test agentic systems without modification. Our empirical results show that frontier language models achieve at most a 41% success rate on REAL, highlighting critical gaps in autonomous web navigation and task completion capabilities. Our framework supports easy integration of new tasks, reproducible evaluation, and scalable post-training data generation, marking a significant step forward in evaluating and advancing agent capabilities.","Divyansh Garg, Shaun VanWeelden, Diego Caples, Andis Draguns, Nikil Ravi, Pranav Putta, Naman Garg, Tomas Abraham, Michael Lara, Federico Lopez, James Liu, Atharva Gundawar, Prannay Hebbar, Youngchul Joo, Jindong Gu, Charles London, Christian Schroeder de Witt, Sumeet Motwani",cs.AI,2025-04-15T18:22:55Z,http://arxiv.org/abs/2504.11543v2,real benchmarking autonomous agents on deterministic simulations of real websites,we introduce real a benchmark and framework for multi turn agent evaluations on deterministic simulations of real world websites real comprises high fidelity deterministic replicas of widely used websites across domains such as e commerce travel communication and professional networking we also release a benchmark consisting of practical tasks that mirror everyday complex user interactions requiring both accurate information retrieval and state changing actions all interactions occur within this fully controlled setting eliminating safety risks and enabling robust reproducible evaluation of agent capability and reliability our novel evaluation framework combines programmatic checks of website state for action based tasks with rubric guided llm based judgments for information retrieval the framework supports both open source and proprietary agent systems through a flexible evaluation harness that accommodates black box commands within browser environments allowing research labs to test agentic systems without modification our empirical results show that frontier language models achieve at most a success rate on real highlighting critical gaps in autonomous web navigation and task completion capabilities our framework supports easy integration of new tasks reproducible evaluation and scalable post training data generation marking a significant step forward in evaluating and advancing agent capabilities,"['real', 'benchmarking', 'autonomous', 'agents', 'on', 'deterministic', 'simulations', 'of', 'real', 'websites']","['we', 'introduce', 'real', 'a', 'benchmark', 'and', 'framework', 'for', 'multi', 'turn', 'agent', 'evaluations', 'on', 'deterministic', 'simulations', 'of', 'real', 'world', 'websites', 'real', 'comprises', 'high', 'fidelity', 'deterministic', 'replicas', 'of', 'widely', 'used', 'websites', 'across', 'domains', 'such', 'as', 'e', 'commerce', 'travel', 'communication', 'and', 'professional', 'networking', 'we', 'also', 'release', 'a', 'benchmark', 'consisting', 'of', 'practical', 'tasks', 'that', 'mirror', 'everyday', 'complex', 'user', 'interactions', 'requiring', 'both', 'accurate', 'information', 'retrieval', 'and', 'state', 'changing', 'actions', 'all', 'interactions', 'occur', 'within', 'this', 'fully', 'controlled', 'setting', 'eliminating', 'safety', 'risks', 'and', 'enabling', 'robust', 'reproducible', 'evaluation', 'of', 'agent', 'capability', 'and', 'reliability', 'our', 'novel', 'evaluation', 'framework', 'combines', 'programmatic', 'checks', 'of', 'website', 'state', 'for', 'action', 'based', 'tasks', 'with', 'rubric', 'guided', 'llm', 'based', 'judgments', 'for', 'information', 'retrieval', 'the', 'framework', 'supports', 'both', 'open', 'source', 'and', 'proprietary', 'agent', 'systems', 'through', 'a', 'flexible', 'evaluation', 'harness', 'that', 'accommodates', 'black', 'box', 'commands', 'within', 'browser', 'environments', 'allowing', 'research', 'labs', 'to', 'test', 'agentic', 'systems', 'without', 'modification', 'our', 'empirical', 'results', 'show', 'that', 'frontier', 'language', 'models', 'achieve', 'at', 'most', 'a', 'success', 'rate', 'on', 'real', 'highlighting', 'critical', 'gaps', 'in', 'autonomous', 'web', 'navigation', 'and', 'task', 'completion', 'capabilities', 'our', 'framework', 'supports', 'easy', 'integration', 'of', 'new', 'tasks', 'reproducible', 'evaluation', 'and', 'scalable', 'post', 'training', 'data', 'generation', 'marking', 'a', 'significant', 'step', 'forward', 'in', 'evaluating', 'and', 'advancing', 'agent', 'capabilities']",10,194,"['All', 'REAL', 'LLM-based', 'Our', '112']"
2504.11536v2,ReTool: Reinforcement Learning for Strategic Tool Use in LLMs,"While reasoning models (e.g., DeepSeek R1) trained with reinforcement learning (RL), excel in textual reasoning, they struggle in scenarios requiring structured problem-solving, such as geometric reasoning, concise computation, or complex equation solving-areas where computational tools like code interpreters (CI) demonstrate distinct advantages. To bridge this gap, we propose ReTool, which enhances long-form reasoning with tool-integrated learning, including two key features: (1) dynamic interleaving of real-time code execution within natural language reasoning processes, and (2) an automated RL paradigm that allows policy rollouts with multi-turn real-time code execution and teaches the model in learning when and how to invoke tools based on outcome feedback. ReTool employs a systematic training framework, beginning with synthetic cold-start data generation to produce code-augmented long-form reasoning traces for fine-tuning base models. Subsequent RL training leverages task outcomes as rewards to iteratively refine the model's tool use strategy, enabling autonomous discovery of optimal tool invocation patterns without human priors. Experiments on the challenging MATH Olympiad benchmark AIME demonstrate ReTool's superiority: Our 32B model achieves 67% accuracy with 400 training steps, outperforming text-based RL baseline (40% accuracy, 1080 steps) in efficiency and performance. Remarkably, ReTool-32B attains 72.5% accuracy in extended settings, surpassing OpenAI's o1-preview by 27.9%. Further analysis reveals emergent behaviors such as code self-correction, signaling an ''aha moment'' in which the model autonomously masters adaptive tool use. These findings highlight the promise of outcome-driven tool integration for advancing complex mathematical reasoning and offer new insights into hybrid neuro-symbolic systems.","Jiazhan Feng, Shijue Huang, Xingwei Qu, Ge Zhang, Yujia Qin, Baoquan Zhong, Chengquan Jiang, Jinxin Chi, Wanjun Zhong","cs.CL, cs.AI",2025-04-15T18:10:22Z,http://arxiv.org/abs/2504.11536v2,retool reinforcement learning for strategic tool use in llms,while reasoning models e g deepseek r trained with reinforcement learning rl excel in textual reasoning they struggle in scenarios requiring structured problem solving such as geometric reasoning concise computation or complex equation solving areas where computational tools like code interpreters ci demonstrate distinct advantages to bridge this gap we propose retool which enhances long form reasoning with tool integrated learning including two key features dynamic interleaving of real time code execution within natural language reasoning processes and an automated rl paradigm that allows policy rollouts with multi turn real time code execution and teaches the model in learning when and how to invoke tools based on outcome feedback retool employs a systematic training framework beginning with synthetic cold start data generation to produce code augmented long form reasoning traces for fine tuning base models subsequent rl training leverages task outcomes as rewards to iteratively refine the model s tool use strategy enabling autonomous discovery of optimal tool invocation patterns without human priors experiments on the challenging math olympiad benchmark aime demonstrate retool s superiority our b model achieves accuracy with training steps outperforming text based rl baseline accuracy steps in efficiency and performance remarkably retool b attains accuracy in extended settings surpassing openai s o preview by further analysis reveals emergent behaviors such as code self correction signaling an aha moment in which the model autonomously masters adaptive tool use these findings highlight the promise of outcome driven tool integration for advancing complex mathematical reasoning and offer new insights into hybrid neuro symbolic systems,"['retool', 'reinforcement', 'learning', 'for', 'strategic', 'tool', 'use', 'in', 'llms']","['while', 'reasoning', 'models', 'e', 'g', 'deepseek', 'r', 'trained', 'with', 'reinforcement', 'learning', 'rl', 'excel', 'in', 'textual', 'reasoning', 'they', 'struggle', 'in', 'scenarios', 'requiring', 'structured', 'problem', 'solving', 'such', 'as', 'geometric', 'reasoning', 'concise', 'computation', 'or', 'complex', 'equation', 'solving', 'areas', 'where', 'computational', 'tools', 'like', 'code', 'interpreters', 'ci', 'demonstrate', 'distinct', 'advantages', 'to', 'bridge', 'this', 'gap', 'we', 'propose', 'retool', 'which', 'enhances', 'long', 'form', 'reasoning', 'with', 'tool', 'integrated', 'learning', 'including', 'two', 'key', 'features', 'dynamic', 'interleaving', 'of', 'real', 'time', 'code', 'execution', 'within', 'natural', 'language', 'reasoning', 'processes', 'and', 'an', 'automated', 'rl', 'paradigm', 'that', 'allows', 'policy', 'rollouts', 'with', 'multi', 'turn', 'real', 'time', 'code', 'execution', 'and', 'teaches', 'the', 'model', 'in', 'learning', 'when', 'and', 'how', 'to', 'invoke', 'tools', 'based', 'on', 'outcome', 'feedback', 'retool', 'employs', 'a', 'systematic', 'training', 'framework', 'beginning', 'with', 'synthetic', 'cold', 'start', 'data', 'generation', 'to', 'produce', 'code', 'augmented', 'long', 'form', 'reasoning', 'traces', 'for', 'fine', 'tuning', 'base', 'models', 'subsequent', 'rl', 'training', 'leverages', 'task', 'outcomes', 'as', 'rewards', 'to', 'iteratively', 'refine', 'the', 'model', 's', 'tool', 'use', 'strategy', 'enabling', 'autonomous', 'discovery', 'of', 'optimal', 'tool', 'invocation', 'patterns', 'without', 'human', 'priors', 'experiments', 'on', 'the', 'challenging', 'math', 'olympiad', 'benchmark', 'aime', 'demonstrate', 'retool', 's', 'superiority', 'our', 'b', 'model', 'achieves', 'accuracy', 'with', 'training', 'steps', 'outperforming', 'text', 'based', 'rl', 'baseline', 'accuracy', 'steps', 'in', 'efficiency', 'and', 'performance', 'remarkably', 'retool', 'b', 'attains', 'accuracy', 'in', 'extended', 'settings', 'surpassing', 'openai', 's', 'o', 'preview', 'by', 'further', 'analysis', 'reveals', 'emergent', 'behaviors', 'such', 'as', 'code', 'self', 'correction', 'signaling', 'an', 'aha', 'moment', 'in', 'which', 'the', 'model', 'autonomously', 'masters', 'adaptive', 'tool', 'use', 'these', 'findings', 'highlight', 'the', 'promise', 'of', 'outcome', 'driven', 'tool', 'integration', 'for', 'advancing', 'complex', 'mathematical', 'reasoning', 'and', 'offer', 'new', 'insights', 'into', 'hybrid', 'neuro', 'symbolic', 'systems']",9,255,"['400', 'DeepSeek', 'While', 'Olympiad', 'Further', 'These', 'Remarkably', 'OpenAI', 'Subsequent', '1080', 'ReTool', 'Our', '32B', 'AIME', 'MATH', 'Experiments']"
2504.11524v1,HypoBench: Towards Systematic and Principled Benchmarking for Hypothesis   Generation,"There is growing interest in hypothesis generation with large language models (LLMs). However, fundamental questions remain: what makes a good hypothesis, and how can we systematically evaluate methods for hypothesis generation? To address this, we introduce HypoBench, a novel benchmark designed to evaluate LLMs and hypothesis generation methods across multiple aspects, including practical utility, generalizability, and hypothesis discovery rate. HypoBench includes 7 real-world tasks and 5 synthetic tasks with 194 distinct datasets. We evaluate four state-of-the-art LLMs combined with six existing hypothesis-generation methods. Overall, our results suggest that existing methods are capable of discovering valid and novel patterns in the data. However, the results from synthetic datasets indicate that there is still significant room for improvement, as current hypothesis generation methods do not fully uncover all relevant or meaningful patterns. Specifically, in synthetic settings, as task difficulty increases, performance significantly drops, with best models and methods only recovering 38.8% of the ground-truth hypotheses. These findings highlight challenges in hypothesis generation and demonstrate that HypoBench serves as a valuable resource for improving AI systems designed to assist scientific discovery.","Haokun Liu, Sicong Huang, Jingyu Hu, Yangqiaoyu Zhou, Chenhao Tan","cs.AI, cs.CL, cs.CY, cs.LG",2025-04-15T18:00:00Z,http://arxiv.org/abs/2504.11524v1,hypobench towards systematic and principled benchmarking for hypothesis generation,there is growing interest in hypothesis generation with large language models llms however fundamental questions remain what makes a good hypothesis and how can we systematically evaluate methods for hypothesis generation to address this we introduce hypobench a novel benchmark designed to evaluate llms and hypothesis generation methods across multiple aspects including practical utility generalizability and hypothesis discovery rate hypobench includes real world tasks and synthetic tasks with distinct datasets we evaluate four state of the art llms combined with six existing hypothesis generation methods overall our results suggest that existing methods are capable of discovering valid and novel patterns in the data however the results from synthetic datasets indicate that there is still significant room for improvement as current hypothesis generation methods do not fully uncover all relevant or meaningful patterns specifically in synthetic settings as task difficulty increases performance significantly drops with best models and methods only recovering of the ground truth hypotheses these findings highlight challenges in hypothesis generation and demonstrate that hypobench serves as a valuable resource for improving ai systems designed to assist scientific discovery,"['hypobench', 'towards', 'systematic', 'and', 'principled', 'benchmarking', 'for', 'hypothesis', 'generation']","['there', 'is', 'growing', 'interest', 'in', 'hypothesis', 'generation', 'with', 'large', 'language', 'models', 'llms', 'however', 'fundamental', 'questions', 'remain', 'what', 'makes', 'a', 'good', 'hypothesis', 'and', 'how', 'can', 'we', 'systematically', 'evaluate', 'methods', 'for', 'hypothesis', 'generation', 'to', 'address', 'this', 'we', 'introduce', 'hypobench', 'a', 'novel', 'benchmark', 'designed', 'to', 'evaluate', 'llms', 'and', 'hypothesis', 'generation', 'methods', 'across', 'multiple', 'aspects', 'including', 'practical', 'utility', 'generalizability', 'and', 'hypothesis', 'discovery', 'rate', 'hypobench', 'includes', 'real', 'world', 'tasks', 'and', 'synthetic', 'tasks', 'with', 'distinct', 'datasets', 'we', 'evaluate', 'four', 'state', 'of', 'the', 'art', 'llms', 'combined', 'with', 'six', 'existing', 'hypothesis', 'generation', 'methods', 'overall', 'our', 'results', 'suggest', 'that', 'existing', 'methods', 'are', 'capable', 'of', 'discovering', 'valid', 'and', 'novel', 'patterns', 'in', 'the', 'data', 'however', 'the', 'results', 'from', 'synthetic', 'datasets', 'indicate', 'that', 'there', 'is', 'still', 'significant', 'room', 'for', 'improvement', 'as', 'current', 'hypothesis', 'generation', 'methods', 'do', 'not', 'fully', 'uncover', 'all', 'relevant', 'or', 'meaningful', 'patterns', 'specifically', 'in', 'synthetic', 'settings', 'as', 'task', 'difficulty', 'increases', 'performance', 'significantly', 'drops', 'with', 'best', 'models', 'and', 'methods', 'only', 'recovering', 'of', 'the', 'ground', 'truth', 'hypotheses', 'these', 'findings', 'highlight', 'challenges', 'in', 'hypothesis', 'generation', 'and', 'demonstrate', 'that', 'hypobench', 'serves', 'as', 'a', 'valuable', 'resource', 'for', 'improving', 'ai', 'systems', 'designed', 'to', 'assist', 'scientific', 'discovery']",9,180,"['Overall', 'HypoBench', 'LLMs', 'However', 'These', 'Specifically', 'There', '194']"
2504.11456v1,"DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and   Verifiable Mathematical Dataset for Advancing Reasoning","The capacity for complex mathematical reasoning is a key benchmark for artificial intelligence. While reinforcement learning (RL) applied to LLMs shows promise, progress is significantly hindered by the lack of large-scale training data that is sufficiently challenging, possesses verifiable answer formats suitable for RL, and is free from contamination with evaluation benchmarks. To address these limitations, we introduce DeepMath-103K, a new, large-scale dataset comprising approximately 103K mathematical problems, specifically designed to train advanced reasoning models via RL. DeepMath-103K is curated through a rigorous pipeline involving source analysis, stringent decontamination against numerous benchmarks, and filtering for high difficulty (primarily Levels 5-9), significantly exceeding existing open resources in challenge. Each problem includes a verifiable final answer, enabling rule-based RL, and three distinct R1-generated solutions suitable for diverse training paradigms like supervised fine-tuning or distillation. Spanning a wide range of mathematical topics, DeepMath-103K promotes the development of generalizable reasoning. We demonstrate that models trained on DeepMath-103K achieve significant improvements on challenging mathematical benchmarks, validating its effectiveness. We release DeepMath-103K publicly to facilitate community progress in building more capable AI reasoning systems: https://github.com/zwhe99/DeepMath.","Zhiwei He, Tian Liang, Jiahao Xu, Qiuzhi Liu, Xingyu Chen, Yue Wang, Linfeng Song, Dian Yu, Zhenwen Liang, Wenxuan Wang, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, Dong Yu","cs.CL, cs.AI",2025-04-15T17:59:51Z,http://arxiv.org/abs/2504.11456v1,deepmath k a large scale challenging decontaminated and verifiable mathematical dataset for advancing reasoning,the capacity for complex mathematical reasoning is a key benchmark for artificial intelligence while reinforcement learning rl applied to llms shows promise progress is significantly hindered by the lack of large scale training data that is sufficiently challenging possesses verifiable answer formats suitable for rl and is free from contamination with evaluation benchmarks to address these limitations we introduce deepmath k a new large scale dataset comprising approximately k mathematical problems specifically designed to train advanced reasoning models via rl deepmath k is curated through a rigorous pipeline involving source analysis stringent decontamination against numerous benchmarks and filtering for high difficulty primarily levels significantly exceeding existing open resources in challenge each problem includes a verifiable final answer enabling rule based rl and three distinct r generated solutions suitable for diverse training paradigms like supervised fine tuning or distillation spanning a wide range of mathematical topics deepmath k promotes the development of generalizable reasoning we demonstrate that models trained on deepmath k achieve significant improvements on challenging mathematical benchmarks validating its effectiveness we release deepmath k publicly to facilitate community progress in building more capable ai reasoning systems,"['deepmath', 'k', 'a', 'large', 'scale', 'challenging', 'decontaminated', 'and', 'verifiable', 'mathematical', 'dataset', 'for', 'advancing', 'reasoning']","['the', 'capacity', 'for', 'complex', 'mathematical', 'reasoning', 'is', 'a', 'key', 'benchmark', 'for', 'artificial', 'intelligence', 'while', 'reinforcement', 'learning', 'rl', 'applied', 'to', 'llms', 'shows', 'promise', 'progress', 'is', 'significantly', 'hindered', 'by', 'the', 'lack', 'of', 'large', 'scale', 'training', 'data', 'that', 'is', 'sufficiently', 'challenging', 'possesses', 'verifiable', 'answer', 'formats', 'suitable', 'for', 'rl', 'and', 'is', 'free', 'from', 'contamination', 'with', 'evaluation', 'benchmarks', 'to', 'address', 'these', 'limitations', 'we', 'introduce', 'deepmath', 'k', 'a', 'new', 'large', 'scale', 'dataset', 'comprising', 'approximately', 'k', 'mathematical', 'problems', 'specifically', 'designed', 'to', 'train', 'advanced', 'reasoning', 'models', 'via', 'rl', 'deepmath', 'k', 'is', 'curated', 'through', 'a', 'rigorous', 'pipeline', 'involving', 'source', 'analysis', 'stringent', 'decontamination', 'against', 'numerous', 'benchmarks', 'and', 'filtering', 'for', 'high', 'difficulty', 'primarily', 'levels', 'significantly', 'exceeding', 'existing', 'open', 'resources', 'in', 'challenge', 'each', 'problem', 'includes', 'a', 'verifiable', 'final', 'answer', 'enabling', 'rule', 'based', 'rl', 'and', 'three', 'distinct', 'r', 'generated', 'solutions', 'suitable', 'for', 'diverse', 'training', 'paradigms', 'like', 'supervised', 'fine', 'tuning', 'or', 'distillation', 'spanning', 'a', 'wide', 'range', 'of', 'mathematical', 'topics', 'deepmath', 'k', 'promotes', 'the', 'development', 'of', 'generalizable', 'reasoning', 'we', 'demonstrate', 'that', 'models', 'trained', 'on', 'deepmath', 'k', 'achieve', 'significant', 'improvements', 'on', 'challenging', 'mathematical', 'benchmarks', 'validating', 'its', 'effectiveness', 'we', 'release', 'deepmath', 'k', 'publicly', 'to', 'facilitate', 'community', 'progress', 'in', 'building', 'more', 'capable', 'ai', 'reasoning', 'systems']",14,187,"['LLMs', 'While', 'DeepMath', '5-9', 'Each', 'R1-generated', '103K', 'Levels', 'Spanning']"
2504.11454v2,Elucidating the Design Space of Multimodal Protein Language Models,"Multimodal protein language models (PLMs) integrate sequence and token-based structural information, serving as a powerful foundation for protein modeling, generation, and design. However, the reliance on tokenizing 3D structures into discrete tokens causes substantial loss of fidelity about fine-grained structural details and correlations. In this paper, we systematically elucidate the design space of multimodal PLMs to overcome their limitations. We identify tokenization loss and inaccurate structure token predictions by the PLMs as major bottlenecks. To address these, our proposed design space covers improved generative modeling, structure-aware architectures and representation learning, and data exploration. Our advancements approach finer-grained supervision, demonstrating that token-based multimodal PLMs can achieve robust structural modeling. The effective design methods dramatically improve the structure generation diversity, and notably, folding abilities of our 650M model by reducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B baselines and on par with the specialized folding models.","Cheng-Yen Hsieh, Xinyou Wang, Daiheng Zhang, Dongyu Xue, Fei Ye, Shujian Huang, Zaixiang Zheng, Quanquan Gu","cs.LG, cs.AI, q-bio.QM",2025-04-15T17:59:43Z,http://arxiv.org/abs/2504.11454v2,elucidating the design space of multimodal protein language models,multimodal protein language models plms integrate sequence and token based structural information serving as a powerful foundation for protein modeling generation and design however the reliance on tokenizing d structures into discrete tokens causes substantial loss of fidelity about fine grained structural details and correlations in this paper we systematically elucidate the design space of multimodal plms to overcome their limitations we identify tokenization loss and inaccurate structure token predictions by the plms as major bottlenecks to address these our proposed design space covers improved generative modeling structure aware architectures and representation learning and data exploration our advancements approach finer grained supervision demonstrating that token based multimodal plms can achieve robust structural modeling the effective design methods dramatically improve the structure generation diversity and notably folding abilities of our m model by reducing the rmsd from to on pdb testset even outperforming b baselines and on par with the specialized folding models,"['elucidating', 'the', 'design', 'space', 'of', 'multimodal', 'protein', 'language', 'models']","['multimodal', 'protein', 'language', 'models', 'plms', 'integrate', 'sequence', 'and', 'token', 'based', 'structural', 'information', 'serving', 'as', 'a', 'powerful', 'foundation', 'for', 'protein', 'modeling', 'generation', 'and', 'design', 'however', 'the', 'reliance', 'on', 'tokenizing', 'd', 'structures', 'into', 'discrete', 'tokens', 'causes', 'substantial', 'loss', 'of', 'fidelity', 'about', 'fine', 'grained', 'structural', 'details', 'and', 'correlations', 'in', 'this', 'paper', 'we', 'systematically', 'elucidate', 'the', 'design', 'space', 'of', 'multimodal', 'plms', 'to', 'overcome', 'their', 'limitations', 'we', 'identify', 'tokenization', 'loss', 'and', 'inaccurate', 'structure', 'token', 'predictions', 'by', 'the', 'plms', 'as', 'major', 'bottlenecks', 'to', 'address', 'these', 'our', 'proposed', 'design', 'space', 'covers', 'improved', 'generative', 'modeling', 'structure', 'aware', 'architectures', 'and', 'representation', 'learning', 'and', 'data', 'exploration', 'our', 'advancements', 'approach', 'finer', 'grained', 'supervision', 'demonstrating', 'that', 'token', 'based', 'multimodal', 'plms', 'can', 'achieve', 'robust', 'structural', 'modeling', 'the', 'effective', 'design', 'methods', 'dramatically', 'improve', 'the', 'structure', 'generation', 'diversity', 'and', 'notably', 'folding', 'abilities', 'of', 'our', 'm', 'model', 'by', 'reducing', 'the', 'rmsd', 'from', 'to', 'on', 'pdb', 'testset', 'even', 'outperforming', 'b', 'baselines', 'and', 'on', 'par', 'with', 'the', 'specialized', 'folding', 'models']",9,152,"['Multimodal', '650M', 'However', 'PDB', 'Our', 'RMSD', 'PLMs']"
2504.11426v1,A Dual-Space Framework for General Knowledge Distillation of Large   Language Models,"Knowledge distillation (KD) is a promising solution to compress large language models (LLMs) by transferring their knowledge to smaller models. During this process, white-box KD methods usually minimize the distance between the output distributions of the teacher model and the student model to transfer more information. However, we reveal that the current white-box KD framework exhibits two limitations: a) bridging probability distributions from different output spaces will limit the similarity between the teacher model and the student model; b) this framework cannot be applied to LLMs with different vocabularies. One of the root causes for these limitations is that the distributions from the teacher and the student for KD are output by different prediction heads, which yield distributions in different output spaces and dimensions. Therefore, in this paper, we propose a dual-space knowledge distillation (DSKD) framework that unifies the prediction heads of the teacher and the student models for KD. Specifically, we first introduce two projectors with ideal initialization to project the teacher/student hidden states into the student/teacher representation spaces. After this, the hidden states from different models can share the same head and unify the output spaces of the distributions. Furthermore, we develop an exact token alignment (ETA) algorithm to align the same tokens in two differently-tokenized sequences. Based on the above, our DSKD framework is a general KD framework that supports both off-policy and on-policy KD, and KD between any two LLMs regardless of their vocabularies. Extensive experiments on instruction-following, mathematical reasoning, and code generation benchmarks show that DSKD significantly outperforms existing methods based on the current white-box KD framework and surpasses other cross-tokenizer KD methods for LLMs with different vocabularies.","Xue Zhang, Songming Zhang, Yunlong Liang, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou","cs.CL, cs.AI, cs.LG",2025-04-15T17:38:47Z,http://arxiv.org/abs/2504.11426v1,a dual space framework for general knowledge distillation of large language models,knowledge distillation kd is a promising solution to compress large language models llms by transferring their knowledge to smaller models during this process white box kd methods usually minimize the distance between the output distributions of the teacher model and the student model to transfer more information however we reveal that the current white box kd framework exhibits two limitations a bridging probability distributions from different output spaces will limit the similarity between the teacher model and the student model b this framework cannot be applied to llms with different vocabularies one of the root causes for these limitations is that the distributions from the teacher and the student for kd are output by different prediction heads which yield distributions in different output spaces and dimensions therefore in this paper we propose a dual space knowledge distillation dskd framework that unifies the prediction heads of the teacher and the student models for kd specifically we first introduce two projectors with ideal initialization to project the teacher student hidden states into the student teacher representation spaces after this the hidden states from different models can share the same head and unify the output spaces of the distributions furthermore we develop an exact token alignment eta algorithm to align the same tokens in two differently tokenized sequences based on the above our dskd framework is a general kd framework that supports both off policy and on policy kd and kd between any two llms regardless of their vocabularies extensive experiments on instruction following mathematical reasoning and code generation benchmarks show that dskd significantly outperforms existing methods based on the current white box kd framework and surpasses other cross tokenizer kd methods for llms with different vocabularies,"['a', 'dual', 'space', 'framework', 'for', 'general', 'knowledge', 'distillation', 'of', 'large', 'language', 'models']","['knowledge', 'distillation', 'kd', 'is', 'a', 'promising', 'solution', 'to', 'compress', 'large', 'language', 'models', 'llms', 'by', 'transferring', 'their', 'knowledge', 'to', 'smaller', 'models', 'during', 'this', 'process', 'white', 'box', 'kd', 'methods', 'usually', 'minimize', 'the', 'distance', 'between', 'the', 'output', 'distributions', 'of', 'the', 'teacher', 'model', 'and', 'the', 'student', 'model', 'to', 'transfer', 'more', 'information', 'however', 'we', 'reveal', 'that', 'the', 'current', 'white', 'box', 'kd', 'framework', 'exhibits', 'two', 'limitations', 'a', 'bridging', 'probability', 'distributions', 'from', 'different', 'output', 'spaces', 'will', 'limit', 'the', 'similarity', 'between', 'the', 'teacher', 'model', 'and', 'the', 'student', 'model', 'b', 'this', 'framework', 'can', 'not', 'be', 'applied', 'to', 'llms', 'with', 'different', 'vocabularies', 'one', 'of', 'the', 'root', 'causes', 'for', 'these', 'limitations', 'is', 'that', 'the', 'distributions', 'from', 'the', 'teacher', 'and', 'the', 'student', 'for', 'kd', 'are', 'output', 'by', 'different', 'prediction', 'heads', 'which', 'yield', 'distributions', 'in', 'different', 'output', 'spaces', 'and', 'dimensions', 'therefore', 'in', 'this', 'paper', 'we', 'propose', 'a', 'dual', 'space', 'knowledge', 'distillation', 'dskd', 'framework', 'that', 'unifies', 'the', 'prediction', 'heads', 'of', 'the', 'teacher', 'and', 'the', 'student', 'models', 'for', 'kd', 'specifically', 'we', 'first', 'introduce', 'two', 'projectors', 'with', 'ideal', 'initialization', 'to', 'project', 'the', 'teacher', 'student', 'hidden', 'states', 'into', 'the', 'student', 'teacher', 'representation', 'spaces', 'after', 'this', 'the', 'hidden', 'states', 'from', 'different', 'models', 'can', 'share', 'the', 'same', 'head', 'and', 'unify', 'the', 'output', 'spaces', 'of', 'the', 'distributions', 'furthermore', 'we', 'develop', 'an', 'exact', 'token', 'alignment', 'eta', 'algorithm', 'to', 'align', 'the', 'same', 'tokens', 'in', 'two', 'differently', 'tokenized', 'sequences', 'based', 'on', 'the', 'above', 'our', 'dskd', 'framework', 'is', 'a', 'general', 'kd', 'framework', 'that', 'supports', 'both', 'off', 'policy', 'and', 'on', 'policy', 'kd', 'and', 'kd', 'between', 'any', 'two', 'llms', 'regardless', 'of', 'their', 'vocabularies', 'extensive', 'experiments', 'on', 'instruction', 'following', 'mathematical', 'reasoning', 'and', 'code', 'generation', 'benchmarks', 'show', 'that', 'dskd', 'significantly', 'outperforms', 'existing', 'methods', 'based', 'on', 'the', 'current', 'white', 'box', 'kd', 'framework', 'and', 'surpasses', 'other', 'cross', 'tokenizer', 'kd', 'methods', 'for', 'llms', 'with', 'different', 'vocabularies']",12,285,"['DSKD', 'Extensive', 'Based', 'LLMs', 'ETA', 'During', 'However', 'One', 'Furthermore', 'After', 'Specifically', 'Knowledge', 'Therefore']"
2504.11423v1,ADT: Tuning Diffusion Models with Adversarial Supervision,"Diffusion models have achieved outstanding image generation by reversing a forward noising process to approximate true data distributions. During training, these models predict diffusion scores from noised versions of true samples in a single forward pass, while inference requires iterative denoising starting from white noise. This training-inference divergences hinder the alignment between inference and training data distributions, due to potential prediction biases and cumulative error accumulation. To address this problem, we propose an intuitive but effective fine-tuning framework, called Adversarial Diffusion Tuning (ADT), by stimulating the inference process during optimization and aligning the final outputs with training data by adversarial supervision. Specifically, to achieve robust adversarial training, ADT features a siamese-network discriminator with a fixed pre-trained backbone and lightweight trainable parameters, incorporates an image-to-image sampling strategy to smooth discriminative difficulties, and preserves the original diffusion loss to prevent discriminator hacking. In addition, we carefully constrain the backward-flowing path for back-propagating gradients along the inference path without incurring memory overload or gradient explosion. Finally, extensive experiments on Stable Diffusion models (v1.5, XL, and v3), demonstrate that ADT significantly improves both distribution alignment and image quality.","Dazhong Shen, Guanglu Song, Yi Zhang, Bingqi Ma, Lujundong Li, Dongzhi Jiang, Zhuofan Zong, Yu Liu","cs.CV, cs.AI",2025-04-15T17:37:50Z,http://arxiv.org/abs/2504.11423v1,adt tuning diffusion models with adversarial supervision,diffusion models have achieved outstanding image generation by reversing a forward noising process to approximate true data distributions during training these models predict diffusion scores from noised versions of true samples in a single forward pass while inference requires iterative denoising starting from white noise this training inference divergences hinder the alignment between inference and training data distributions due to potential prediction biases and cumulative error accumulation to address this problem we propose an intuitive but effective fine tuning framework called adversarial diffusion tuning adt by stimulating the inference process during optimization and aligning the final outputs with training data by adversarial supervision specifically to achieve robust adversarial training adt features a siamese network discriminator with a fixed pre trained backbone and lightweight trainable parameters incorporates an image to image sampling strategy to smooth discriminative difficulties and preserves the original diffusion loss to prevent discriminator hacking in addition we carefully constrain the backward flowing path for back propagating gradients along the inference path without incurring memory overload or gradient explosion finally extensive experiments on stable diffusion models v xl and v demonstrate that adt significantly improves both distribution alignment and image quality,"['adt', 'tuning', 'diffusion', 'models', 'with', 'adversarial', 'supervision']","['diffusion', 'models', 'have', 'achieved', 'outstanding', 'image', 'generation', 'by', 'reversing', 'a', 'forward', 'noising', 'process', 'to', 'approximate', 'true', 'data', 'distributions', 'during', 'training', 'these', 'models', 'predict', 'diffusion', 'scores', 'from', 'noised', 'versions', 'of', 'true', 'samples', 'in', 'a', 'single', 'forward', 'pass', 'while', 'inference', 'requires', 'iterative', 'denoising', 'starting', 'from', 'white', 'noise', 'this', 'training', 'inference', 'divergences', 'hinder', 'the', 'alignment', 'between', 'inference', 'and', 'training', 'data', 'distributions', 'due', 'to', 'potential', 'prediction', 'biases', 'and', 'cumulative', 'error', 'accumulation', 'to', 'address', 'this', 'problem', 'we', 'propose', 'an', 'intuitive', 'but', 'effective', 'fine', 'tuning', 'framework', 'called', 'adversarial', 'diffusion', 'tuning', 'adt', 'by', 'stimulating', 'the', 'inference', 'process', 'during', 'optimization', 'and', 'aligning', 'the', 'final', 'outputs', 'with', 'training', 'data', 'by', 'adversarial', 'supervision', 'specifically', 'to', 'achieve', 'robust', 'adversarial', 'training', 'adt', 'features', 'a', 'siamese', 'network', 'discriminator', 'with', 'a', 'fixed', 'pre', 'trained', 'backbone', 'and', 'lightweight', 'trainable', 'parameters', 'incorporates', 'an', 'image', 'to', 'image', 'sampling', 'strategy', 'to', 'smooth', 'discriminative', 'difficulties', 'and', 'preserves', 'the', 'original', 'diffusion', 'loss', 'to', 'prevent', 'discriminator', 'hacking', 'in', 'addition', 'we', 'carefully', 'constrain', 'the', 'backward', 'flowing', 'path', 'for', 'back', 'propagating', 'gradients', 'along', 'the', 'inference', 'path', 'without', 'incurring', 'memory', 'overload', 'or', 'gradient', 'explosion', 'finally', 'extensive', 'experiments', 'on', 'stable', 'diffusion', 'models', 'v', 'xl', 'and', 'v', 'demonstrate', 'that', 'adt', 'significantly', 'improves', 'both', 'distribution', 'alignment', 'and', 'image', 'quality']",7,192,"['Adversarial', 'ADT', 'Diffusion', 'Finally', 'Stable', 'During', 'Tuning', 'Specifically']"
2504.11419v1,Embodied World Models Emerge from Navigational Task in Open-Ended   Environments,"Understanding how artificial systems can develop spatial awareness and reasoning has long been a challenge in AI research. Traditional models often rely on passive observation, but embodied cognition theory suggests that deeper understanding emerges from active interaction with the environment. This study investigates whether neural networks can autonomously internalize spatial concepts through interaction, focusing on planar navigation tasks. Using Gated Recurrent Units (GRUs) combined with Meta-Reinforcement Learning (Meta-RL), we show that agents can learn to encode spatial properties like direction, distance, and obstacle avoidance. We introduce Hybrid Dynamical Systems (HDS) to model the agent-environment interaction as a closed dynamical system, revealing stable limit cycles that correspond to optimal navigation strategies. Ridge Representation allows us to map navigation paths into a fixed-dimensional behavioral space, enabling comparison with neural states. Canonical Correlation Analysis (CCA) confirms strong alignment between these representations, suggesting that the agent's neural states actively encode spatial knowledge. Intervention experiments further show that specific neural dimensions are causally linked to navigation performance. This work provides an approach to bridging the gap between action and perception in AI, offering new insights into building adaptive, interpretable models that can generalize across complex environments. The causal validation of neural representations also opens new avenues for understanding and controlling the internal mechanisms of AI systems, pushing the boundaries of how machines learn and reason in dynamic, real-world scenarios.","Li Jin, Liu Jia","cs.AI, cs.NE",2025-04-15T17:35:13Z,http://arxiv.org/abs/2504.11419v1,embodied world models emerge from navigational task in open ended environments,understanding how artificial systems can develop spatial awareness and reasoning has long been a challenge in ai research traditional models often rely on passive observation but embodied cognition theory suggests that deeper understanding emerges from active interaction with the environment this study investigates whether neural networks can autonomously internalize spatial concepts through interaction focusing on planar navigation tasks using gated recurrent units grus combined with meta reinforcement learning meta rl we show that agents can learn to encode spatial properties like direction distance and obstacle avoidance we introduce hybrid dynamical systems hds to model the agent environment interaction as a closed dynamical system revealing stable limit cycles that correspond to optimal navigation strategies ridge representation allows us to map navigation paths into a fixed dimensional behavioral space enabling comparison with neural states canonical correlation analysis cca confirms strong alignment between these representations suggesting that the agent s neural states actively encode spatial knowledge intervention experiments further show that specific neural dimensions are causally linked to navigation performance this work provides an approach to bridging the gap between action and perception in ai offering new insights into building adaptive interpretable models that can generalize across complex environments the causal validation of neural representations also opens new avenues for understanding and controlling the internal mechanisms of ai systems pushing the boundaries of how machines learn and reason in dynamic real world scenarios,"['embodied', 'world', 'models', 'emerge', 'from', 'navigational', 'task', 'in', 'open', 'ended', 'environments']","['understanding', 'how', 'artificial', 'systems', 'can', 'develop', 'spatial', 'awareness', 'and', 'reasoning', 'has', 'long', 'been', 'a', 'challenge', 'in', 'ai', 'research', 'traditional', 'models', 'often', 'rely', 'on', 'passive', 'observation', 'but', 'embodied', 'cognition', 'theory', 'suggests', 'that', 'deeper', 'understanding', 'emerges', 'from', 'active', 'interaction', 'with', 'the', 'environment', 'this', 'study', 'investigates', 'whether', 'neural', 'networks', 'can', 'autonomously', 'internalize', 'spatial', 'concepts', 'through', 'interaction', 'focusing', 'on', 'planar', 'navigation', 'tasks', 'using', 'gated', 'recurrent', 'units', 'grus', 'combined', 'with', 'meta', 'reinforcement', 'learning', 'meta', 'rl', 'we', 'show', 'that', 'agents', 'can', 'learn', 'to', 'encode', 'spatial', 'properties', 'like', 'direction', 'distance', 'and', 'obstacle', 'avoidance', 'we', 'introduce', 'hybrid', 'dynamical', 'systems', 'hds', 'to', 'model', 'the', 'agent', 'environment', 'interaction', 'as', 'a', 'closed', 'dynamical', 'system', 'revealing', 'stable', 'limit', 'cycles', 'that', 'correspond', 'to', 'optimal', 'navigation', 'strategies', 'ridge', 'representation', 'allows', 'us', 'to', 'map', 'navigation', 'paths', 'into', 'a', 'fixed', 'dimensional', 'behavioral', 'space', 'enabling', 'comparison', 'with', 'neural', 'states', 'canonical', 'correlation', 'analysis', 'cca', 'confirms', 'strong', 'alignment', 'between', 'these', 'representations', 'suggesting', 'that', 'the', 'agent', 's', 'neural', 'states', 'actively', 'encode', 'spatial', 'knowledge', 'intervention', 'experiments', 'further', 'show', 'that', 'specific', 'neural', 'dimensions', 'are', 'causally', 'linked', 'to', 'navigation', 'performance', 'this', 'work', 'provides', 'an', 'approach', 'to', 'bridging', 'the', 'gap', 'between', 'action', 'and', 'perception', 'in', 'ai', 'offering', 'new', 'insights', 'into', 'building', 'adaptive', 'interpretable', 'models', 'that', 'can', 'generalize', 'across', 'complex', 'environments', 'the', 'causal', 'validation', 'of', 'neural', 'representations', 'also', 'opens', 'new', 'avenues', 'for', 'understanding', 'and', 'controlling', 'the', 'internal', 'mechanisms', 'of', 'ai', 'systems', 'pushing', 'the', 'boundaries', 'of', 'how', 'machines', 'learn', 'and', 'reason', 'in', 'dynamic', 'real', 'world', 'scenarios']",11,230,"['Intervention', 'Learning', 'Reinforcement', 'Representation', 'Correlation', 'GRUs', 'Gated', 'Ridge', 'Understanding', 'Hybrid', 'Dynamical', 'Recurrent', 'Traditional', 'Units', 'CCA', 'Canonical', 'Systems', 'HDS', 'Meta', 'Analysis']"
2504.11389v1,VideoPanda: Video Panoramic Diffusion with Multi-view Attention,"High resolution panoramic video content is paramount for immersive experiences in Virtual Reality, but is non-trivial to collect as it requires specialized equipment and intricate camera setups. In this work, we introduce VideoPanda, a novel approach for synthesizing 360$^\circ$ videos conditioned on text or single-view video data. VideoPanda leverages multi-view attention layers to augment a video diffusion model, enabling it to generate consistent multi-view videos that can be combined into immersive panoramic content. VideoPanda is trained jointly using two conditions: text-only and single-view video, and supports autoregressive generation of long-videos. To overcome the computational burden of multi-view video generation, we randomly subsample the duration and camera views used during training and show that the model is able to gracefully generalize to generating more frames during inference. Extensive evaluations on both real-world and synthetic video datasets demonstrate that VideoPanda generates more realistic and coherent 360$^\circ$ panoramas across all input conditions compared to existing methods. Visit the project website at https://research-staging.nvidia.com/labs/toronto-ai/VideoPanda/ for results.","Kevin Xie, Amirmojtaba Sabour, Jiahui Huang, Despoina Paschalidou, Greg Klar, Umar Iqbal, Sanja Fidler, Xiaohui Zeng","cs.GR, cs.AI, cs.CV",2025-04-15T16:58:15Z,http://arxiv.org/abs/2504.11389v1,videopanda video panoramic diffusion with multi view attention,high resolution panoramic video content is paramount for immersive experiences in virtual reality but is non trivial to collect as it requires specialized equipment and intricate camera setups in this work we introduce videopanda a novel approach for synthesizing videos conditioned on text or single view video data videopanda leverages multi view attention layers to augment a video diffusion model enabling it to generate consistent multi view videos that can be combined into immersive panoramic content videopanda is trained jointly using two conditions text only and single view video and supports autoregressive generation of long videos to overcome the computational burden of multi view video generation we randomly subsample the duration and camera views used during training and show that the model is able to gracefully generalize to generating more frames during inference extensive evaluations on both real world and synthetic video datasets demonstrate that videopanda generates more realistic and coherent panoramas across all input conditions compared to existing methods visit the project website at for results,"['videopanda', 'video', 'panoramic', 'diffusion', 'with', 'multi', 'view', 'attention']","['high', 'resolution', 'panoramic', 'video', 'content', 'is', 'paramount', 'for', 'immersive', 'experiences', 'in', 'virtual', 'reality', 'but', 'is', 'non', 'trivial', 'to', 'collect', 'as', 'it', 'requires', 'specialized', 'equipment', 'and', 'intricate', 'camera', 'setups', 'in', 'this', 'work', 'we', 'introduce', 'videopanda', 'a', 'novel', 'approach', 'for', 'synthesizing', 'videos', 'conditioned', 'on', 'text', 'or', 'single', 'view', 'video', 'data', 'videopanda', 'leverages', 'multi', 'view', 'attention', 'layers', 'to', 'augment', 'a', 'video', 'diffusion', 'model', 'enabling', 'it', 'to', 'generate', 'consistent', 'multi', 'view', 'videos', 'that', 'can', 'be', 'combined', 'into', 'immersive', 'panoramic', 'content', 'videopanda', 'is', 'trained', 'jointly', 'using', 'two', 'conditions', 'text', 'only', 'and', 'single', 'view', 'video', 'and', 'supports', 'autoregressive', 'generation', 'of', 'long', 'videos', 'to', 'overcome', 'the', 'computational', 'burden', 'of', 'multi', 'view', 'video', 'generation', 'we', 'randomly', 'subsample', 'the', 'duration', 'and', 'camera', 'views', 'used', 'during', 'training', 'and', 'show', 'that', 'the', 'model', 'is', 'able', 'to', 'gracefully', 'generalize', 'to', 'generating', 'more', 'frames', 'during', 'inference', 'extensive', 'evaluations', 'on', 'both', 'real', 'world', 'and', 'synthetic', 'video', 'datasets', 'demonstrate', 'that', 'videopanda', 'generates', 'more', 'realistic', 'and', 'coherent', 'panoramas', 'across', 'all', 'input', 'conditions', 'compared', 'to', 'existing', 'methods', 'visit', 'the', 'project', 'website', 'at', 'for', 'results']",8,167,"['Extensive', 'Virtual', '360', 'High', 'VideoPanda', 'Reality', 'Visit']"
2504.11374v1,A Winner-Takes-All Mechanism for Event Generation,"We present a novel framework for central pattern generator design that leverages the intrinsic rebound excitability of neurons in combination with winner-takes-all computation. Our approach unifies decision-making and rhythmic pattern generation within a simple yet powerful network architecture that employs all-to-all inhibitory connections enhanced by designable excitatory interactions. This design offers significant advantages regarding ease of implementation, adaptability, and robustness. We demonstrate its efficacy through a ring oscillator model, which exhibits adaptive phase and frequency modulation, making the framework particularly promising for applications in neuromorphic systems and robotics.","Yongkang Huo, Fuvio Forni, Rodolphe Sepulchre","eess.SY, cs.AI, cs.SY",2025-04-15T16:40:37Z,http://arxiv.org/abs/2504.11374v1,a winner takes all mechanism for event generation,we present a novel framework for central pattern generator design that leverages the intrinsic rebound excitability of neurons in combination with winner takes all computation our approach unifies decision making and rhythmic pattern generation within a simple yet powerful network architecture that employs all to all inhibitory connections enhanced by designable excitatory interactions this design offers significant advantages regarding ease of implementation adaptability and robustness we demonstrate its efficacy through a ring oscillator model which exhibits adaptive phase and frequency modulation making the framework particularly promising for applications in neuromorphic systems and robotics,"['a', 'winner', 'takes', 'all', 'mechanism', 'for', 'event', 'generation']","['we', 'present', 'a', 'novel', 'framework', 'for', 'central', 'pattern', 'generator', 'design', 'that', 'leverages', 'the', 'intrinsic', 'rebound', 'excitability', 'of', 'neurons', 'in', 'combination', 'with', 'winner', 'takes', 'all', 'computation', 'our', 'approach', 'unifies', 'decision', 'making', 'and', 'rhythmic', 'pattern', 'generation', 'within', 'a', 'simple', 'yet', 'powerful', 'network', 'architecture', 'that', 'employs', 'all', 'to', 'all', 'inhibitory', 'connections', 'enhanced', 'by', 'designable', 'excitatory', 'interactions', 'this', 'design', 'offers', 'significant', 'advantages', 'regarding', 'ease', 'of', 'implementation', 'adaptability', 'and', 'robustness', 'we', 'demonstrate', 'its', 'efficacy', 'through', 'a', 'ring', 'oscillator', 'model', 'which', 'exhibits', 'adaptive', 'phase', 'and', 'frequency', 'modulation', 'making', 'the', 'framework', 'particularly', 'promising', 'for', 'applications', 'in', 'neuromorphic', 'systems', 'and', 'robotics']",8,93,['Our']
2504.11369v1,OpenTuringBench: An Open-Model-based Benchmark and Framework for   Machine-Generated Text Detection and Attribution,"Open Large Language Models (OLLMs) are increasingly leveraged in generative AI applications, posing new challenges for detecting their outputs. We propose OpenTuringBench, a new benchmark based on OLLMs, designed to train and evaluate machine-generated text detectors on the Turing Test and Authorship Attribution problems. OpenTuringBench focuses on a representative set of OLLMs, and features a number of challenging evaluation tasks, including human/machine-manipulated texts, out-of-domain texts, and texts from previously unseen models. We also provide OTBDetector, a contrastive learning framework to detect and attribute OLLM-based machine-generated texts. Results highlight the relevance and varying degrees of difficulty of the OpenTuringBench tasks, with our detector achieving remarkable capabilities across the various tasks and outperforming most existing detectors. Resources are available on the OpenTuringBench Hugging Face repository at https://huggingface.co/datasets/MLNTeam-Unical/OpenTuringBench","Lucio La Cava, Andrea Tagarelli","cs.CL, cs.AI, cs.CY, cs.HC, physics.soc-ph",2025-04-15T16:36:14Z,http://arxiv.org/abs/2504.11369v1,openturingbench an open model based benchmark and framework for machine generated text detection and attribution,open large language models ollms are increasingly leveraged in generative ai applications posing new challenges for detecting their outputs we propose openturingbench a new benchmark based on ollms designed to train and evaluate machine generated text detectors on the turing test and authorship attribution problems openturingbench focuses on a representative set of ollms and features a number of challenging evaluation tasks including human machine manipulated texts out of domain texts and texts from previously unseen models we also provide otbdetector a contrastive learning framework to detect and attribute ollm based machine generated texts results highlight the relevance and varying degrees of difficulty of the openturingbench tasks with our detector achieving remarkable capabilities across the various tasks and outperforming most existing detectors resources are available on the openturingbench hugging face repository at,"['openturingbench', 'an', 'open', 'model', 'based', 'benchmark', 'and', 'framework', 'for', 'machine', 'generated', 'text', 'detection', 'and', 'attribution']","['open', 'large', 'language', 'models', 'ollms', 'are', 'increasingly', 'leveraged', 'in', 'generative', 'ai', 'applications', 'posing', 'new', 'challenges', 'for', 'detecting', 'their', 'outputs', 'we', 'propose', 'openturingbench', 'a', 'new', 'benchmark', 'based', 'on', 'ollms', 'designed', 'to', 'train', 'and', 'evaluate', 'machine', 'generated', 'text', 'detectors', 'on', 'the', 'turing', 'test', 'and', 'authorship', 'attribution', 'problems', 'openturingbench', 'focuses', 'on', 'a', 'representative', 'set', 'of', 'ollms', 'and', 'features', 'a', 'number', 'of', 'challenging', 'evaluation', 'tasks', 'including', 'human', 'machine', 'manipulated', 'texts', 'out', 'of', 'domain', 'texts', 'and', 'texts', 'from', 'previously', 'unseen', 'models', 'we', 'also', 'provide', 'otbdetector', 'a', 'contrastive', 'learning', 'framework', 'to', 'detect', 'and', 'attribute', 'ollm', 'based', 'machine', 'generated', 'texts', 'results', 'highlight', 'the', 'relevance', 'and', 'varying', 'degrees', 'of', 'difficulty', 'of', 'the', 'openturingbench', 'tasks', 'with', 'our', 'detector', 'achieving', 'remarkable', 'capabilities', 'across', 'the', 'various', 'tasks', 'and', 'outperforming', 'most', 'existing', 'detectors', 'resources', 'are', 'available', 'on', 'the', 'openturingbench', 'hugging', 'face', 'repository', 'at']",15,131,"['Unical', 'OLLM-based', 'Resources', 'Authorship', 'Turing', 'OLLMs', 'Test', 'OTBDetector', 'Hugging', 'Open', 'MLNTeam', 'Models', 'Face', 'Language', 'Attribution', 'OpenTuringBench', 'Large', 'Results']"
2504.11364v1,Teaching Large Language Models to Reason through Learning and Forgetting,"Leveraging inference-time search in large language models has proven effective in further enhancing a trained model's capability to solve complex mathematical and reasoning problems. However, this approach significantly increases computational costs and inference time, as the model must generate and evaluate multiple candidate solutions to identify a viable reasoning path. To address this, we propose an effective approach that integrates search capabilities directly into the model by fine-tuning it using both successful (learning) and failed reasoning paths (forgetting) derived from diverse search methods. While fine-tuning the model with these data might seem straightforward, we identify a critical issue: the model's search capability tends to degrade rapidly if fine-tuning is performed naively. We show that this degradation can be substantially mitigated by employing a smaller learning rate. Extensive experiments on the challenging Game-of-24 and Countdown mathematical reasoning benchmarks show that our approach not only outperforms both standard fine-tuning and inference-time search baselines but also significantly reduces inference time by 180$\times$.","Tianwei Ni, Allen Nie, Sapana Chaudhary, Yao Liu, Huzefa Rangwala, Rasool Fakoor","cs.LG, cs.AI, cs.CL",2025-04-15T16:30:02Z,http://arxiv.org/abs/2504.11364v1,teaching large language models to reason through learning and forgetting,leveraging inference time search in large language models has proven effective in further enhancing a trained model s capability to solve complex mathematical and reasoning problems however this approach significantly increases computational costs and inference time as the model must generate and evaluate multiple candidate solutions to identify a viable reasoning path to address this we propose an effective approach that integrates search capabilities directly into the model by fine tuning it using both successful learning and failed reasoning paths forgetting derived from diverse search methods while fine tuning the model with these data might seem straightforward we identify a critical issue the model s search capability tends to degrade rapidly if fine tuning is performed naively we show that this degradation can be substantially mitigated by employing a smaller learning rate extensive experiments on the challenging game of and countdown mathematical reasoning benchmarks show that our approach not only outperforms both standard fine tuning and inference time search baselines but also significantly reduces inference time by,"['teaching', 'large', 'language', 'models', 'to', 'reason', 'through', 'learning', 'and', 'forgetting']","['leveraging', 'inference', 'time', 'search', 'in', 'large', 'language', 'models', 'has', 'proven', 'effective', 'in', 'further', 'enhancing', 'a', 'trained', 'model', 's', 'capability', 'to', 'solve', 'complex', 'mathematical', 'and', 'reasoning', 'problems', 'however', 'this', 'approach', 'significantly', 'increases', 'computational', 'costs', 'and', 'inference', 'time', 'as', 'the', 'model', 'must', 'generate', 'and', 'evaluate', 'multiple', 'candidate', 'solutions', 'to', 'identify', 'a', 'viable', 'reasoning', 'path', 'to', 'address', 'this', 'we', 'propose', 'an', 'effective', 'approach', 'that', 'integrates', 'search', 'capabilities', 'directly', 'into', 'the', 'model', 'by', 'fine', 'tuning', 'it', 'using', 'both', 'successful', 'learning', 'and', 'failed', 'reasoning', 'paths', 'forgetting', 'derived', 'from', 'diverse', 'search', 'methods', 'while', 'fine', 'tuning', 'the', 'model', 'with', 'these', 'data', 'might', 'seem', 'straightforward', 'we', 'identify', 'a', 'critical', 'issue', 'the', 'model', 's', 'search', 'capability', 'tends', 'to', 'degrade', 'rapidly', 'if', 'fine', 'tuning', 'is', 'performed', 'naively', 'we', 'show', 'that', 'this', 'degradation', 'can', 'be', 'substantially', 'mitigated', 'by', 'employing', 'a', 'smaller', 'learning', 'rate', 'extensive', 'experiments', 'on', 'the', 'challenging', 'game', 'of', 'and', 'countdown', 'mathematical', 'reasoning', 'benchmarks', 'show', 'that', 'our', 'approach', 'not', 'only', 'outperforms', 'both', 'standard', 'fine', 'tuning', 'and', 'inference', 'time', 'search', 'baselines', 'but', 'also', 'significantly', 'reduces', 'inference', 'time', 'by']",10,167,"['Extensive', 'Leveraging', '180', 'While', 'However', 'Countdown', 'Game']"
2504.11355v1,Neural Networks for on-chip Model Predictive Control: a Method to Build   Optimized Training Datasets and its application to Type-1 Diabetes,"Training Neural Networks (NNs) to behave as Model Predictive Control (MPC) algorithms is an effective way to implement them in constrained embedded devices. By collecting large amounts of input-output data, where inputs represent system states and outputs are MPC-generated control actions, NNs can be trained to replicate MPC behavior at a fraction of the computational cost. However, although the composition of the training data critically influences the final NN accuracy, methods for systematically optimizing it remain underexplored. In this paper, we introduce the concept of Optimally-Sampled Datasets (OSDs) as ideal training sets and present an efficient algorithm for generating them. An OSD is a parametrized subset of all the available data that (i) preserves existing MPC information up to a certain numerical resolution, (ii) avoids duplicate or near-duplicate states, and (iii) becomes saturated or complete. We demonstrate the effectiveness of OSDs by training NNs to replicate the University of Virginia's MPC algorithm for automated insulin delivery in Type-1 Diabetes, achieving a four-fold improvement in final accuracy. Notably, two OSD-trained NNs received regulatory clearance for clinical testing as the first NN-based control algorithm for direct human insulin dosing. This methodology opens new pathways for implementing advanced optimizations on resource-constrained embedded platforms, potentially revolutionizing how complex algorithms are deployed.","Alberto Castillo, Elliot Pryor, Anas El Fathi, Boris Kovatchev, Marc Breton","eess.SY, cs.AI, cs.SY",2025-04-15T16:25:06Z,http://arxiv.org/abs/2504.11355v1,neural networks for on chip model predictive control a method to build optimized training datasets and its application to type diabetes,training neural networks nns to behave as model predictive control mpc algorithms is an effective way to implement them in constrained embedded devices by collecting large amounts of input output data where inputs represent system states and outputs are mpc generated control actions nns can be trained to replicate mpc behavior at a fraction of the computational cost however although the composition of the training data critically influences the final nn accuracy methods for systematically optimizing it remain underexplored in this paper we introduce the concept of optimally sampled datasets osds as ideal training sets and present an efficient algorithm for generating them an osd is a parametrized subset of all the available data that i preserves existing mpc information up to a certain numerical resolution ii avoids duplicate or near duplicate states and iii becomes saturated or complete we demonstrate the effectiveness of osds by training nns to replicate the university of virginia s mpc algorithm for automated insulin delivery in type diabetes achieving a four fold improvement in final accuracy notably two osd trained nns received regulatory clearance for clinical testing as the first nn based control algorithm for direct human insulin dosing this methodology opens new pathways for implementing advanced optimizations on resource constrained embedded platforms potentially revolutionizing how complex algorithms are deployed,"['neural', 'networks', 'for', 'on', 'chip', 'model', 'predictive', 'control', 'a', 'method', 'to', 'build', 'optimized', 'training', 'datasets', 'and', 'its', 'application', 'to', 'type', 'diabetes']","['training', 'neural', 'networks', 'nns', 'to', 'behave', 'as', 'model', 'predictive', 'control', 'mpc', 'algorithms', 'is', 'an', 'effective', 'way', 'to', 'implement', 'them', 'in', 'constrained', 'embedded', 'devices', 'by', 'collecting', 'large', 'amounts', 'of', 'input', 'output', 'data', 'where', 'inputs', 'represent', 'system', 'states', 'and', 'outputs', 'are', 'mpc', 'generated', 'control', 'actions', 'nns', 'can', 'be', 'trained', 'to', 'replicate', 'mpc', 'behavior', 'at', 'a', 'fraction', 'of', 'the', 'computational', 'cost', 'however', 'although', 'the', 'composition', 'of', 'the', 'training', 'data', 'critically', 'influences', 'the', 'final', 'nn', 'accuracy', 'methods', 'for', 'systematically', 'optimizing', 'it', 'remain', 'underexplored', 'in', 'this', 'paper', 'we', 'introduce', 'the', 'concept', 'of', 'optimally', 'sampled', 'datasets', 'osds', 'as', 'ideal', 'training', 'sets', 'and', 'present', 'an', 'efficient', 'algorithm', 'for', 'generating', 'them', 'an', 'osd', 'is', 'a', 'parametrized', 'subset', 'of', 'all', 'the', 'available', 'data', 'that', 'i', 'preserves', 'existing', 'mpc', 'information', 'up', 'to', 'a', 'certain', 'numerical', 'resolution', 'ii', 'avoids', 'duplicate', 'or', 'near', 'duplicate', 'states', 'and', 'iii', 'becomes', 'saturated', 'or', 'complete', 'we', 'demonstrate', 'the', 'effectiveness', 'of', 'osds', 'by', 'training', 'nns', 'to', 'replicate', 'the', 'university', 'of', 'virginia', 's', 'mpc', 'algorithm', 'for', 'automated', 'insulin', 'delivery', 'in', 'type', 'diabetes', 'achieving', 'a', 'four', 'fold', 'improvement', 'in', 'final', 'accuracy', 'notably', 'two', 'osd', 'trained', 'nns', 'received', 'regulatory', 'clearance', 'for', 'clinical', 'testing', 'as', 'the', 'first', 'nn', 'based', 'control', 'algorithm', 'for', 'direct', 'human', 'insulin', 'dosing', 'this', 'methodology', 'opens', 'new', 'pathways', 'for', 'implementing', 'advanced', 'optimizations', 'on', 'resource', 'constrained', 'embedded', 'platforms', 'potentially', 'revolutionizing', 'how', 'complex', 'algorithms', 'are', 'deployed']",21,216,"['Model', 'Neural', 'OSDs', 'OSD-trained', 'Diabetes', 'Notably', 'Control', 'MPC', 'Datasets', 'Type-1', 'However', 'NN-based', 'Virginia', 'Sampled', 'University', 'Networks', 'Predictive', 'NNs', 'OSD', 'MPC-generated', 'Optimally', 'Training']"
2504.11354v1,Kimina-Prover Preview: Towards Large Formal Reasoning Models with   Reinforcement Learning,"We introduce Kimina-Prover Preview, a large language model that pioneers a novel reasoning-driven exploration paradigm for formal theorem proving, as showcased in this preview release. Trained with a large-scale reinforcement learning pipeline from Qwen2.5-72B, Kimina-Prover demonstrates strong performance in Lean 4 proof generation by employing a structured reasoning pattern we term \textit{formal reasoning pattern}. This approach allows the model to emulate human problem-solving strategies in Lean, iteratively generating and refining proof steps. Kimina-Prover sets a new state-of-the-art on the miniF2F benchmark, reaching 80.7% with pass@8192. Beyond improved benchmark performance, our work yields several key insights: (1) Kimina-Prover exhibits high sample efficiency, delivering strong results even with minimal sampling (pass@1) and scaling effectively with computational budget, stemming from its unique reasoning pattern and RL training; (2) we demonstrate clear performance scaling with model size, a trend previously unobserved for neural theorem provers in formal mathematics; (3) the learned reasoning style, distinct from traditional search algorithms, shows potential to bridge the gap between formal verification and informal mathematical intuition. We open source distilled versions with 1.5B and 7B parameters of Kimina-Prover","Haiming Wang, Mert Unsal, Xiaohan Lin, Mantas Baksys, Junqi Liu, Marco Dos Santos, Flood Sung, Marina Vinyes, Zhenzhe Ying, Zekai Zhu, Jianqiao Lu, Hugues de Saxc√©, Bolton Bailey, Chendong Song, Chenjun Xiao, Dehao Zhang, Ebony Zhang, Frederick Pu, Han Zhu, Jiawei Liu, Jonas Bayer, Julien Michel, Longhui Yu, L√©o Dreyfus-Schmidt, Lewis Tunstall, Luigi Pagani, Moreira Machado, Pauline Bourigault, Ran Wang, Stanislas Polu, Thibaut Barroyer, Wen-Ding Li, Yazhe Niu, Yann Fleureau, Yangyang Hu, Zhouliang Yu, Zihan Wang, Zhilin Yang, Zhengying Liu, Jia Li",cs.AI,2025-04-15T16:23:44Z,http://arxiv.org/abs/2504.11354v1,kimina prover preview towards large formal reasoning models with reinforcement learning,we introduce kimina prover preview a large language model that pioneers a novel reasoning driven exploration paradigm for formal theorem proving as showcased in this preview release trained with a large scale reinforcement learning pipeline from qwen b kimina prover demonstrates strong performance in lean proof generation by employing a structured reasoning pattern we term formal reasoning pattern this approach allows the model to emulate human problem solving strategies in lean iteratively generating and refining proof steps kimina prover sets a new state of the art on the minif f benchmark reaching with pass beyond improved benchmark performance our work yields several key insights kimina prover exhibits high sample efficiency delivering strong results even with minimal sampling pass and scaling effectively with computational budget stemming from its unique reasoning pattern and rl training we demonstrate clear performance scaling with model size a trend previously unobserved for neural theorem provers in formal mathematics the learned reasoning style distinct from traditional search algorithms shows potential to bridge the gap between formal verification and informal mathematical intuition we open source distilled versions with b and b parameters of kimina prover,"['kimina', 'prover', 'preview', 'towards', 'large', 'formal', 'reasoning', 'models', 'with', 'reinforcement', 'learning']","['we', 'introduce', 'kimina', 'prover', 'preview', 'a', 'large', 'language', 'model', 'that', 'pioneers', 'a', 'novel', 'reasoning', 'driven', 'exploration', 'paradigm', 'for', 'formal', 'theorem', 'proving', 'as', 'showcased', 'in', 'this', 'preview', 'release', 'trained', 'with', 'a', 'large', 'scale', 'reinforcement', 'learning', 'pipeline', 'from', 'qwen', 'b', 'kimina', 'prover', 'demonstrates', 'strong', 'performance', 'in', 'lean', 'proof', 'generation', 'by', 'employing', 'a', 'structured', 'reasoning', 'pattern', 'we', 'term', 'formal', 'reasoning', 'pattern', 'this', 'approach', 'allows', 'the', 'model', 'to', 'emulate', 'human', 'problem', 'solving', 'strategies', 'in', 'lean', 'iteratively', 'generating', 'and', 'refining', 'proof', 'steps', 'kimina', 'prover', 'sets', 'a', 'new', 'state', 'of', 'the', 'art', 'on', 'the', 'minif', 'f', 'benchmark', 'reaching', 'with', 'pass', 'beyond', 'improved', 'benchmark', 'performance', 'our', 'work', 'yields', 'several', 'key', 'insights', 'kimina', 'prover', 'exhibits', 'high', 'sample', 'efficiency', 'delivering', 'strong', 'results', 'even', 'with', 'minimal', 'sampling', 'pass', 'and', 'scaling', 'effectively', 'with', 'computational', 'budget', 'stemming', 'from', 'its', 'unique', 'reasoning', 'pattern', 'and', 'rl', 'training', 'we', 'demonstrate', 'clear', 'performance', 'scaling', 'with', 'model', 'size', 'a', 'trend', 'previously', 'unobserved', 'for', 'neural', 'theorem', 'provers', 'in', 'formal', 'mathematics', 'the', 'learned', 'reasoning', 'style', 'distinct', 'from', 'traditional', 'search', 'algorithms', 'shows', 'potential', 'to', 'bridge', 'the', 'gap', 'between', 'formal', 'verification', 'and', 'informal', 'mathematical', 'intuition', 'we', 'open', 'source', 'distilled', 'versions', 'with', 'b', 'and', 'b', 'parameters', 'of', 'kimina', 'prover']",11,187,"['Lean', 'Beyond', 'Kimina', 'Preview', '5-72B', 'Prover', 'Qwen2', '8192', 'Trained']"
2504.11344v1,Interpretable Hybrid-Rule Temporal Point Processes,"Temporal Point Processes (TPPs) are widely used for modeling event sequences in various medical domains, such as disease onset prediction, progression analysis, and clinical decision support. Although TPPs effectively capture temporal dynamics, their lack of interpretability remains a critical challenge. Recent advancements have introduced interpretable TPPs. However, these methods fail to incorporate numerical features, thereby limiting their ability to generate precise predictions. To address this issue, we propose Hybrid-Rule Temporal Point Processes (HRTPP), a novel framework that integrates temporal logic rules with numerical features, improving both interpretability and predictive accuracy in event modeling. HRTPP comprises three key components: basic intensity for intrinsic event likelihood, rule-based intensity for structured temporal dependencies, and numerical feature intensity for dynamic probability modulation. To effectively discover valid rules, we introduce a two-phase rule mining strategy with Bayesian optimization. To evaluate our method, we establish a multi-criteria assessment framework, incorporating rule validity, model fitting, and temporal predictive accuracy. Experimental results on real-world medical datasets demonstrate that HRTPP outperforms state-of-the-art interpretable TPPs in terms of predictive performance and clinical interpretability. In case studies, the rules extracted by HRTPP explain the disease progression, offering valuable contributions to medical diagnosis.","Yunyang Cao, Juekai Lin, Hongye Wang, Wenhao Li, Bo Jin","cs.LG, cs.AI, stat.ML",2025-04-15T16:15:16Z,http://arxiv.org/abs/2504.11344v1,interpretable hybrid rule temporal point processes,temporal point processes tpps are widely used for modeling event sequences in various medical domains such as disease onset prediction progression analysis and clinical decision support although tpps effectively capture temporal dynamics their lack of interpretability remains a critical challenge recent advancements have introduced interpretable tpps however these methods fail to incorporate numerical features thereby limiting their ability to generate precise predictions to address this issue we propose hybrid rule temporal point processes hrtpp a novel framework that integrates temporal logic rules with numerical features improving both interpretability and predictive accuracy in event modeling hrtpp comprises three key components basic intensity for intrinsic event likelihood rule based intensity for structured temporal dependencies and numerical feature intensity for dynamic probability modulation to effectively discover valid rules we introduce a two phase rule mining strategy with bayesian optimization to evaluate our method we establish a multi criteria assessment framework incorporating rule validity model fitting and temporal predictive accuracy experimental results on real world medical datasets demonstrate that hrtpp outperforms state of the art interpretable tpps in terms of predictive performance and clinical interpretability in case studies the rules extracted by hrtpp explain the disease progression offering valuable contributions to medical diagnosis,"['interpretable', 'hybrid', 'rule', 'temporal', 'point', 'processes']","['temporal', 'point', 'processes', 'tpps', 'are', 'widely', 'used', 'for', 'modeling', 'event', 'sequences', 'in', 'various', 'medical', 'domains', 'such', 'as', 'disease', 'onset', 'prediction', 'progression', 'analysis', 'and', 'clinical', 'decision', 'support', 'although', 'tpps', 'effectively', 'capture', 'temporal', 'dynamics', 'their', 'lack', 'of', 'interpretability', 'remains', 'a', 'critical', 'challenge', 'recent', 'advancements', 'have', 'introduced', 'interpretable', 'tpps', 'however', 'these', 'methods', 'fail', 'to', 'incorporate', 'numerical', 'features', 'thereby', 'limiting', 'their', 'ability', 'to', 'generate', 'precise', 'predictions', 'to', 'address', 'this', 'issue', 'we', 'propose', 'hybrid', 'rule', 'temporal', 'point', 'processes', 'hrtpp', 'a', 'novel', 'framework', 'that', 'integrates', 'temporal', 'logic', 'rules', 'with', 'numerical', 'features', 'improving', 'both', 'interpretability', 'and', 'predictive', 'accuracy', 'in', 'event', 'modeling', 'hrtpp', 'comprises', 'three', 'key', 'components', 'basic', 'intensity', 'for', 'intrinsic', 'event', 'likelihood', 'rule', 'based', 'intensity', 'for', 'structured', 'temporal', 'dependencies', 'and', 'numerical', 'feature', 'intensity', 'for', 'dynamic', 'probability', 'modulation', 'to', 'effectively', 'discover', 'valid', 'rules', 'we', 'introduce', 'a', 'two', 'phase', 'rule', 'mining', 'strategy', 'with', 'bayesian', 'optimization', 'to', 'evaluate', 'our', 'method', 'we', 'establish', 'a', 'multi', 'criteria', 'assessment', 'framework', 'incorporating', 'rule', 'validity', 'model', 'fitting', 'and', 'temporal', 'predictive', 'accuracy', 'experimental', 'results', 'on', 'real', 'world', 'medical', 'datasets', 'demonstrate', 'that', 'hrtpp', 'outperforms', 'state', 'of', 'the', 'art', 'interpretable', 'tpps', 'in', 'terms', 'of', 'predictive', 'performance', 'and', 'clinical', 'interpretability', 'in', 'case', 'studies', 'the', 'rules', 'extracted', 'by', 'hrtpp', 'explain', 'the', 'disease', 'progression', 'offering', 'valuable', 'contributions', 'to', 'medical', 'diagnosis']",6,199,"['Hybrid', 'Recent', 'Experimental', 'TPPs', 'However', 'Rule', 'Processes', 'Temporal', 'Point', 'Although', 'HRTPP', 'Bayesian']"
2504.11338v1,Transformer-Based Model for Cold Start Mitigation in FaaS Architecture,"Serverless architectures, particularly the Function as a Service (FaaS) model, have become a cornerstone of modern cloud computing due to their ability to simplify resource management and enhance application deployment agility. However, a significant challenge remains: the cold start problem. This phenomenon occurs when an idle FaaS function is invoked, requiring a full initialization process, which increases latency and degrades user experience. Existing solutions for cold start mitigation are limited in terms of invocation pattern generalization and implementation complexity. In this study, we propose an innovative approach leveraging Transformer models to mitigate the impact of cold starts in FaaS architectures. Our solution excels in accurately modeling function initialization delays and optimizing serverless system performance. Experimental evaluation using a public dataset provided by Azure demonstrates a significant reduction in cold start times, reaching up to 79\% compared to conventional methods.","Alexandre Savi Fayam Mbala Mouen, Jerry Lacmou Zeutouo, Vianney Kengne Tchendji","cs.DC, cs.AI",2025-04-15T16:12:07Z,http://arxiv.org/abs/2504.11338v1,transformer based model for cold start mitigation in faas architecture,serverless architectures particularly the function as a service faas model have become a cornerstone of modern cloud computing due to their ability to simplify resource management and enhance application deployment agility however a significant challenge remains the cold start problem this phenomenon occurs when an idle faas function is invoked requiring a full initialization process which increases latency and degrades user experience existing solutions for cold start mitigation are limited in terms of invocation pattern generalization and implementation complexity in this study we propose an innovative approach leveraging transformer models to mitigate the impact of cold starts in faas architectures our solution excels in accurately modeling function initialization delays and optimizing serverless system performance experimental evaluation using a public dataset provided by azure demonstrates a significant reduction in cold start times reaching up to compared to conventional methods,"['transformer', 'based', 'model', 'for', 'cold', 'start', 'mitigation', 'in', 'faas', 'architecture']","['serverless', 'architectures', 'particularly', 'the', 'function', 'as', 'a', 'service', 'faas', 'model', 'have', 'become', 'a', 'cornerstone', 'of', 'modern', 'cloud', 'computing', 'due', 'to', 'their', 'ability', 'to', 'simplify', 'resource', 'management', 'and', 'enhance', 'application', 'deployment', 'agility', 'however', 'a', 'significant', 'challenge', 'remains', 'the', 'cold', 'start', 'problem', 'this', 'phenomenon', 'occurs', 'when', 'an', 'idle', 'faas', 'function', 'is', 'invoked', 'requiring', 'a', 'full', 'initialization', 'process', 'which', 'increases', 'latency', 'and', 'degrades', 'user', 'experience', 'existing', 'solutions', 'for', 'cold', 'start', 'mitigation', 'are', 'limited', 'in', 'terms', 'of', 'invocation', 'pattern', 'generalization', 'and', 'implementation', 'complexity', 'in', 'this', 'study', 'we', 'propose', 'an', 'innovative', 'approach', 'leveraging', 'transformer', 'models', 'to', 'mitigate', 'the', 'impact', 'of', 'cold', 'starts', 'in', 'faas', 'architectures', 'our', 'solution', 'excels', 'in', 'accurately', 'modeling', 'function', 'initialization', 'delays', 'and', 'optimizing', 'serverless', 'system', 'performance', 'experimental', 'evaluation', 'using', 'a', 'public', 'dataset', 'provided', 'by', 'azure', 'demonstrates', 'a', 'significant', 'reduction', 'in', 'cold', 'start', 'times', 'reaching', 'up', 'to', 'compared', 'to', 'conventional', 'methods']",10,138,"['Experimental', 'Existing', 'Service', 'Serverless', 'However', 'FaaS', 'Azure', 'Function', 'Our', 'Transformer']"
2504.11336v1,Looking beyond the next token,"The structure of causal language model training assumes that each token can be accurately predicted from the previous context. This contrasts with humans' natural writing and reasoning process, where goals are typically known before the exact argument or phrasings. While this mismatch has been well studied in the literature, the working assumption has been that architectural changes are needed to address this mismatch. We argue that rearranging and processing the training data sequences can allow models to more accurately imitate the true data-generating process, and does not require any other changes to the architecture or training infrastructure. We demonstrate that this technique, Trelawney, and the inference algorithms derived from it allow us to improve performance on several key benchmarks that span planning, algorithmic reasoning, and story generation tasks. Finally, our method naturally enables the generation of long-term goals at no additional cost. We investigate how using the model's goal-generation capability can further improve planning and reasoning. Additionally, we believe Trelawney could potentially open doors to new capabilities beyond the current language modeling paradigm.","Abitha Thankaraj, Yiding Jiang, J. Zico Kolter, Yonatan Bisk","cs.LG, cs.AI, cs.CL",2025-04-15T16:09:06Z,http://arxiv.org/abs/2504.11336v1,looking beyond the next token,the structure of causal language model training assumes that each token can be accurately predicted from the previous context this contrasts with humans natural writing and reasoning process where goals are typically known before the exact argument or phrasings while this mismatch has been well studied in the literature the working assumption has been that architectural changes are needed to address this mismatch we argue that rearranging and processing the training data sequences can allow models to more accurately imitate the true data generating process and does not require any other changes to the architecture or training infrastructure we demonstrate that this technique trelawney and the inference algorithms derived from it allow us to improve performance on several key benchmarks that span planning algorithmic reasoning and story generation tasks finally our method naturally enables the generation of long term goals at no additional cost we investigate how using the model s goal generation capability can further improve planning and reasoning additionally we believe trelawney could potentially open doors to new capabilities beyond the current language modeling paradigm,"['looking', 'beyond', 'the', 'next', 'token']","['the', 'structure', 'of', 'causal', 'language', 'model', 'training', 'assumes', 'that', 'each', 'token', 'can', 'be', 'accurately', 'predicted', 'from', 'the', 'previous', 'context', 'this', 'contrasts', 'with', 'humans', 'natural', 'writing', 'and', 'reasoning', 'process', 'where', 'goals', 'are', 'typically', 'known', 'before', 'the', 'exact', 'argument', 'or', 'phrasings', 'while', 'this', 'mismatch', 'has', 'been', 'well', 'studied', 'in', 'the', 'literature', 'the', 'working', 'assumption', 'has', 'been', 'that', 'architectural', 'changes', 'are', 'needed', 'to', 'address', 'this', 'mismatch', 'we', 'argue', 'that', 'rearranging', 'and', 'processing', 'the', 'training', 'data', 'sequences', 'can', 'allow', 'models', 'to', 'more', 'accurately', 'imitate', 'the', 'true', 'data', 'generating', 'process', 'and', 'does', 'not', 'require', 'any', 'other', 'changes', 'to', 'the', 'architecture', 'or', 'training', 'infrastructure', 'we', 'demonstrate', 'that', 'this', 'technique', 'trelawney', 'and', 'the', 'inference', 'algorithms', 'derived', 'from', 'it', 'allow', 'us', 'to', 'improve', 'performance', 'on', 'several', 'key', 'benchmarks', 'that', 'span', 'planning', 'algorithmic', 'reasoning', 'and', 'story', 'generation', 'tasks', 'finally', 'our', 'method', 'naturally', 'enables', 'the', 'generation', 'of', 'long', 'term', 'goals', 'at', 'no', 'additional', 'cost', 'we', 'investigate', 'how', 'using', 'the', 'model', 's', 'goal', 'generation', 'capability', 'can', 'further', 'improve', 'planning', 'and', 'reasoning', 'additionally', 'we', 'believe', 'trelawney', 'could', 'potentially', 'open', 'doors', 'to', 'new', 'capabilities', 'beyond', 'the', 'current', 'language', 'modeling', 'paradigm']",5,177,"['Trelawney', 'While', 'Finally', 'Additionally']"
2504.11320v1,Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory   Constraints,"Large Language Models (LLMs) are indispensable in today's applications, but their inference procedure -- generating responses by processing text in segments and using a memory-heavy Key-Value (KV) cache -- demands significant computational resources, particularly under memory constraints. This paper formulates LLM inference optimization as a multi-stage online scheduling problem where sequential prompt arrivals and KV cache growth render conventional scheduling ineffective. We develop a fluid dynamics approximation to provide a tractable benchmark that guides algorithm design. Building on this, we propose the Waiting for Accumulated Inference Threshold (WAIT) algorithm, which uses multiple thresholds to schedule incoming prompts optimally when output lengths are known, and extend it to Nested WAIT for cases with unknown output lengths. Theoretical analysis shows that both algorithms achieve near-optimal performance against the fluid benchmark in heavy traffic conditions, balancing throughput, latency, and Time to First Token (TTFT). Experiments with the Llama-7B model on an A100 GPU using both synthetic and real-world datasets demonstrate improved throughput and reduced latency relative to established baselines like vLLM and Sarathi. This work bridges operations research and machine learning, offering a rigorous framework for the efficient deployment of LLMs under memory constraints.","Ruicheng Ao, Gan Luo, David Simchi-Levi, Xinshang Wang","cs.LG, cs.AI, cs.DC, math.OC, stat.ML",2025-04-15T16:00:21Z,http://arxiv.org/abs/2504.11320v1,optimizing llm inference fluid guided online scheduling with memory constraints,large language models llms are indispensable in today s applications but their inference procedure generating responses by processing text in segments and using a memory heavy key value kv cache demands significant computational resources particularly under memory constraints this paper formulates llm inference optimization as a multi stage online scheduling problem where sequential prompt arrivals and kv cache growth render conventional scheduling ineffective we develop a fluid dynamics approximation to provide a tractable benchmark that guides algorithm design building on this we propose the waiting for accumulated inference threshold wait algorithm which uses multiple thresholds to schedule incoming prompts optimally when output lengths are known and extend it to nested wait for cases with unknown output lengths theoretical analysis shows that both algorithms achieve near optimal performance against the fluid benchmark in heavy traffic conditions balancing throughput latency and time to first token ttft experiments with the llama b model on an a gpu using both synthetic and real world datasets demonstrate improved throughput and reduced latency relative to established baselines like vllm and sarathi this work bridges operations research and machine learning offering a rigorous framework for the efficient deployment of llms under memory constraints,"['optimizing', 'llm', 'inference', 'fluid', 'guided', 'online', 'scheduling', 'with', 'memory', 'constraints']","['large', 'language', 'models', 'llms', 'are', 'indispensable', 'in', 'today', 's', 'applications', 'but', 'their', 'inference', 'procedure', 'generating', 'responses', 'by', 'processing', 'text', 'in', 'segments', 'and', 'using', 'a', 'memory', 'heavy', 'key', 'value', 'kv', 'cache', 'demands', 'significant', 'computational', 'resources', 'particularly', 'under', 'memory', 'constraints', 'this', 'paper', 'formulates', 'llm', 'inference', 'optimization', 'as', 'a', 'multi', 'stage', 'online', 'scheduling', 'problem', 'where', 'sequential', 'prompt', 'arrivals', 'and', 'kv', 'cache', 'growth', 'render', 'conventional', 'scheduling', 'ineffective', 'we', 'develop', 'a', 'fluid', 'dynamics', 'approximation', 'to', 'provide', 'a', 'tractable', 'benchmark', 'that', 'guides', 'algorithm', 'design', 'building', 'on', 'this', 'we', 'propose', 'the', 'waiting', 'for', 'accumulated', 'inference', 'threshold', 'wait', 'algorithm', 'which', 'uses', 'multiple', 'thresholds', 'to', 'schedule', 'incoming', 'prompts', 'optimally', 'when', 'output', 'lengths', 'are', 'known', 'and', 'extend', 'it', 'to', 'nested', 'wait', 'for', 'cases', 'with', 'unknown', 'output', 'lengths', 'theoretical', 'analysis', 'shows', 'that', 'both', 'algorithms', 'achieve', 'near', 'optimal', 'performance', 'against', 'the', 'fluid', 'benchmark', 'in', 'heavy', 'traffic', 'conditions', 'balancing', 'throughput', 'latency', 'and', 'time', 'to', 'first', 'token', 'ttft', 'experiments', 'with', 'the', 'llama', 'b', 'model', 'on', 'an', 'a', 'gpu', 'using', 'both', 'synthetic', 'and', 'real', 'world', 'datasets', 'demonstrate', 'improved', 'throughput', 'and', 'reduced', 'latency', 'relative', 'to', 'established', 'baselines', 'like', 'vllm', 'and', 'sarathi', 'this', 'work', 'bridges', 'operations', 'research', 'and', 'machine', 'learning', 'offering', 'a', 'rigorous', 'framework', 'for', 'the', 'efficient', 'deployment', 'of', 'llms', 'under', 'memory', 'constraints']",10,196,"['Sarathi', 'Token', 'WAIT', 'Language', 'GPU', 'Time', 'LLMs', 'TTFT', 'Building', 'Large', 'Experiments', 'Threshold', 'Inference', 'Accumulated', 'First', 'A100', 'LLM', 'Waiting', 'Llama', 'Value', 'Key', 'Nested', 'Models', 'Theoretical']"
2504.11268v1,Single-Input Multi-Output Model Merging: Leveraging Foundation Models   for Dense Multi-Task Learning,"Model merging is a flexible and computationally tractable approach to merge single-task checkpoints into a multi-task model. Prior work has solely focused on constrained multi-task settings where there is a one-to-one mapping between a sample and a task, overlooking the paradigm where multiple tasks may operate on the same sample, e.g., scene understanding. In this paper, we focus on the multi-task setting with single-input-multiple-outputs (SIMO) and show that it qualitatively differs from the single-input-single-output model merging settings studied in the literature due to the existence of task-specific decoders and diverse loss objectives. We identify that existing model merging methods lead to significant performance degradation, primarily due to representation misalignment between the merged encoder and task-specific decoders. We propose two simple and efficient fixes for the SIMO setting to re-align the feature representation after merging. Compared to joint fine-tuning, our approach is computationally effective and flexible, and sheds light into identifying task relationships in an offline manner. Experiments on NYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) task arithmetic suffices to enable multi-task capabilities; however, the representations generated by the merged encoder has to be re-aligned with the task-specific heads; (2) the proposed architecture rivals traditional multi-task learning in performance but requires fewer samples and training steps by leveraging the existence of task-specific models.","Juan Garcia Giraldo, Nikolaos Dimitriadis, Ke Wang, Pascal Frossard","cs.CV, cs.AI",2025-04-15T15:10:46Z,http://arxiv.org/abs/2504.11268v1,single input multi output model merging leveraging foundation models for dense multi task learning,model merging is a flexible and computationally tractable approach to merge single task checkpoints into a multi task model prior work has solely focused on constrained multi task settings where there is a one to one mapping between a sample and a task overlooking the paradigm where multiple tasks may operate on the same sample e g scene understanding in this paper we focus on the multi task setting with single input multiple outputs simo and show that it qualitatively differs from the single input single output model merging settings studied in the literature due to the existence of task specific decoders and diverse loss objectives we identify that existing model merging methods lead to significant performance degradation primarily due to representation misalignment between the merged encoder and task specific decoders we propose two simple and efficient fixes for the simo setting to re align the feature representation after merging compared to joint fine tuning our approach is computationally effective and flexible and sheds light into identifying task relationships in an offline manner experiments on nyuv cityscapes and a subset of the taskonomy dataset demonstrate task arithmetic suffices to enable multi task capabilities however the representations generated by the merged encoder has to be re aligned with the task specific heads the proposed architecture rivals traditional multi task learning in performance but requires fewer samples and training steps by leveraging the existence of task specific models,"['single', 'input', 'multi', 'output', 'model', 'merging', 'leveraging', 'foundation', 'models', 'for', 'dense', 'multi', 'task', 'learning']","['model', 'merging', 'is', 'a', 'flexible', 'and', 'computationally', 'tractable', 'approach', 'to', 'merge', 'single', 'task', 'checkpoints', 'into', 'a', 'multi', 'task', 'model', 'prior', 'work', 'has', 'solely', 'focused', 'on', 'constrained', 'multi', 'task', 'settings', 'where', 'there', 'is', 'a', 'one', 'to', 'one', 'mapping', 'between', 'a', 'sample', 'and', 'a', 'task', 'overlooking', 'the', 'paradigm', 'where', 'multiple', 'tasks', 'may', 'operate', 'on', 'the', 'same', 'sample', 'e', 'g', 'scene', 'understanding', 'in', 'this', 'paper', 'we', 'focus', 'on', 'the', 'multi', 'task', 'setting', 'with', 'single', 'input', 'multiple', 'outputs', 'simo', 'and', 'show', 'that', 'it', 'qualitatively', 'differs', 'from', 'the', 'single', 'input', 'single', 'output', 'model', 'merging', 'settings', 'studied', 'in', 'the', 'literature', 'due', 'to', 'the', 'existence', 'of', 'task', 'specific', 'decoders', 'and', 'diverse', 'loss', 'objectives', 'we', 'identify', 'that', 'existing', 'model', 'merging', 'methods', 'lead', 'to', 'significant', 'performance', 'degradation', 'primarily', 'due', 'to', 'representation', 'misalignment', 'between', 'the', 'merged', 'encoder', 'and', 'task', 'specific', 'decoders', 'we', 'propose', 'two', 'simple', 'and', 'efficient', 'fixes', 'for', 'the', 'simo', 'setting', 'to', 're', 'align', 'the', 'feature', 'representation', 'after', 'merging', 'compared', 'to', 'joint', 'fine', 'tuning', 'our', 'approach', 'is', 'computationally', 'effective', 'and', 'flexible', 'and', 'sheds', 'light', 'into', 'identifying', 'task', 'relationships', 'in', 'an', 'offline', 'manner', 'experiments', 'on', 'nyuv', 'cityscapes', 'and', 'a', 'subset', 'of', 'the', 'taskonomy', 'dataset', 'demonstrate', 'task', 'arithmetic', 'suffices', 'to', 'enable', 'multi', 'task', 'capabilities', 'however', 'the', 'representations', 'generated', 'by', 'the', 'merged', 'encoder', 'has', 'to', 'be', 're', 'aligned', 'with', 'the', 'task', 'specific', 'heads', 'the', 'proposed', 'architecture', 'rivals', 'traditional', 'multi', 'task', 'learning', 'in', 'performance', 'but', 'requires', 'fewer', 'samples', 'and', 'training', 'steps', 'by', 'leveraging', 'the', 'existence', 'of', 'task', 'specific', 'models']",14,236,"['SIMO', 'Compared', 'Model', 'Taskonomy', 'Cityscapes', 'Prior', 'NYUv2', 'Experiments']"
2504.11246v1,Respiratory Inhaler Sound Event Classification Using Self-Supervised   Learning,"Asthma is a chronic respiratory condition that affects millions of people worldwide. While this condition can be managed by administering controller medications through handheld inhalers, clinical studies have shown low adherence to the correct inhaler usage technique. Consequently, many patients may not receive the full benefit of their medication. Automated classification of inhaler sounds has recently been studied to assess medication adherence. However, the existing classification models were typically trained using data from specific inhaler types, and their ability to generalize to sounds from different inhalers remains unexplored. In this study, we adapted the wav2vec 2.0 self-supervised learning model for inhaler sound classification by pre-training and fine-tuning this model on inhaler sounds. The proposed model shows a balanced accuracy of 98% on a dataset collected using a dry powder inhaler and smartwatch device. The results also demonstrate that re-finetuning this model on minimal data from a target inhaler is a promising approach to adapting a generic inhaler sound classification model to a different inhaler device and audio capture hardware. This is the first study in the field to demonstrate the potential of smartwatches as assistive technologies for the personalized monitoring of inhaler adherence using machine learning models.","Davoud Shariat Panah, Alessandro N Franciosi, Cormac McCarthy, Andrew Hines","eess.AS, cs.AI, cs.LG",2025-04-15T14:44:47Z,http://arxiv.org/abs/2504.11246v1,respiratory inhaler sound event classification using self supervised learning,asthma is a chronic respiratory condition that affects millions of people worldwide while this condition can be managed by administering controller medications through handheld inhalers clinical studies have shown low adherence to the correct inhaler usage technique consequently many patients may not receive the full benefit of their medication automated classification of inhaler sounds has recently been studied to assess medication adherence however the existing classification models were typically trained using data from specific inhaler types and their ability to generalize to sounds from different inhalers remains unexplored in this study we adapted the wav vec self supervised learning model for inhaler sound classification by pre training and fine tuning this model on inhaler sounds the proposed model shows a balanced accuracy of on a dataset collected using a dry powder inhaler and smartwatch device the results also demonstrate that re finetuning this model on minimal data from a target inhaler is a promising approach to adapting a generic inhaler sound classification model to a different inhaler device and audio capture hardware this is the first study in the field to demonstrate the potential of smartwatches as assistive technologies for the personalized monitoring of inhaler adherence using machine learning models,"['respiratory', 'inhaler', 'sound', 'event', 'classification', 'using', 'self', 'supervised', 'learning']","['asthma', 'is', 'a', 'chronic', 'respiratory', 'condition', 'that', 'affects', 'millions', 'of', 'people', 'worldwide', 'while', 'this', 'condition', 'can', 'be', 'managed', 'by', 'administering', 'controller', 'medications', 'through', 'handheld', 'inhalers', 'clinical', 'studies', 'have', 'shown', 'low', 'adherence', 'to', 'the', 'correct', 'inhaler', 'usage', 'technique', 'consequently', 'many', 'patients', 'may', 'not', 'receive', 'the', 'full', 'benefit', 'of', 'their', 'medication', 'automated', 'classification', 'of', 'inhaler', 'sounds', 'has', 'recently', 'been', 'studied', 'to', 'assess', 'medication', 'adherence', 'however', 'the', 'existing', 'classification', 'models', 'were', 'typically', 'trained', 'using', 'data', 'from', 'specific', 'inhaler', 'types', 'and', 'their', 'ability', 'to', 'generalize', 'to', 'sounds', 'from', 'different', 'inhalers', 'remains', 'unexplored', 'in', 'this', 'study', 'we', 'adapted', 'the', 'wav', 'vec', 'self', 'supervised', 'learning', 'model', 'for', 'inhaler', 'sound', 'classification', 'by', 'pre', 'training', 'and', 'fine', 'tuning', 'this', 'model', 'on', 'inhaler', 'sounds', 'the', 'proposed', 'model', 'shows', 'a', 'balanced', 'accuracy', 'of', 'on', 'a', 'dataset', 'collected', 'using', 'a', 'dry', 'powder', 'inhaler', 'and', 'smartwatch', 'device', 'the', 'results', 'also', 'demonstrate', 'that', 're', 'finetuning', 'this', 'model', 'on', 'minimal', 'data', 'from', 'a', 'target', 'inhaler', 'is', 'a', 'promising', 'approach', 'to', 'adapting', 'a', 'generic', 'inhaler', 'sound', 'classification', 'model', 'to', 'a', 'different', 'inhaler', 'device', 'and', 'audio', 'capture', 'hardware', 'this', 'is', 'the', 'first', 'study', 'in', 'the', 'field', 'to', 'demonstrate', 'the', 'potential', 'of', 'smartwatches', 'as', 'assistive', 'technologies', 'for', 'the', 'personalized', 'monitoring', 'of', 'inhaler', 'adherence', 'using', 'machine', 'learning', 'models']",9,200,"['While', 'However', 'Automated', 'Consequently', 'Asthma']"
2504.11243v1,Towards Automated Safety Requirements Derivation Using Agent-based RAG,"We study the automated derivation of safety requirements in a self-driving vehicle use case, leveraging LLMs in combination with agent-based retrieval-augmented generation. Conventional approaches that utilise pre-trained LLMs to assist in safety analyses typically lack domain-specific knowledge. Existing RAG approaches address this issue, yet their performance deteriorates when handling complex queries and it becomes increasingly harder to retrieve the most relevant information. This is particularly relevant for safety-relevant applications. In this paper, we propose the use of agent-based RAG to derive safety requirements and show that the retrieved information is more relevant to the queries. We implement an agent-based approach on a document pool of automotive standards and the Apollo case study, as a representative example of an automated driving perception system. Our solution is tested on a data set of safety requirement questions and answers, extracted from the Apollo data. Evaluating a set of selected RAG metrics, we present and discuss advantages of a agent-based approach compared to default RAG methods.","Balahari Vignesh Balu, Florian Geissler, Francesco Carella, Joao-Vitor Zacchi, Josef Jiru, Nuria Mata, Reinhard Stolle","cs.AI, cs.CL, cs.LG",2025-04-15T14:43:19Z,http://arxiv.org/abs/2504.11243v1,towards automated safety requirements derivation using agent based rag,we study the automated derivation of safety requirements in a self driving vehicle use case leveraging llms in combination with agent based retrieval augmented generation conventional approaches that utilise pre trained llms to assist in safety analyses typically lack domain specific knowledge existing rag approaches address this issue yet their performance deteriorates when handling complex queries and it becomes increasingly harder to retrieve the most relevant information this is particularly relevant for safety relevant applications in this paper we propose the use of agent based rag to derive safety requirements and show that the retrieved information is more relevant to the queries we implement an agent based approach on a document pool of automotive standards and the apollo case study as a representative example of an automated driving perception system our solution is tested on a data set of safety requirement questions and answers extracted from the apollo data evaluating a set of selected rag metrics we present and discuss advantages of a agent based approach compared to default rag methods,"['towards', 'automated', 'safety', 'requirements', 'derivation', 'using', 'agent', 'based', 'rag']","['we', 'study', 'the', 'automated', 'derivation', 'of', 'safety', 'requirements', 'in', 'a', 'self', 'driving', 'vehicle', 'use', 'case', 'leveraging', 'llms', 'in', 'combination', 'with', 'agent', 'based', 'retrieval', 'augmented', 'generation', 'conventional', 'approaches', 'that', 'utilise', 'pre', 'trained', 'llms', 'to', 'assist', 'in', 'safety', 'analyses', 'typically', 'lack', 'domain', 'specific', 'knowledge', 'existing', 'rag', 'approaches', 'address', 'this', 'issue', 'yet', 'their', 'performance', 'deteriorates', 'when', 'handling', 'complex', 'queries', 'and', 'it', 'becomes', 'increasingly', 'harder', 'to', 'retrieve', 'the', 'most', 'relevant', 'information', 'this', 'is', 'particularly', 'relevant', 'for', 'safety', 'relevant', 'applications', 'in', 'this', 'paper', 'we', 'propose', 'the', 'use', 'of', 'agent', 'based', 'rag', 'to', 'derive', 'safety', 'requirements', 'and', 'show', 'that', 'the', 'retrieved', 'information', 'is', 'more', 'relevant', 'to', 'the', 'queries', 'we', 'implement', 'an', 'agent', 'based', 'approach', 'on', 'a', 'document', 'pool', 'of', 'automotive', 'standards', 'and', 'the', 'apollo', 'case', 'study', 'as', 'a', 'representative', 'example', 'of', 'an', 'automated', 'driving', 'perception', 'system', 'our', 'solution', 'is', 'tested', 'on', 'a', 'data', 'set', 'of', 'safety', 'requirement', 'questions', 'and', 'answers', 'extracted', 'from', 'the', 'apollo', 'data', 'evaluating', 'a', 'set', 'of', 'selected', 'rag', 'metrics', 'we', 'present', 'and', 'discuss', 'advantages', 'of', 'a', 'agent', 'based', 'approach', 'compared', 'to', 'default', 'rag', 'methods']",9,171,"['Conventional', 'Existing', 'RAG', 'LLMs', 'Evaluating', 'Our', 'Apollo']"
2504.11239v1,Nondeterministic Polynomial-time Problem Challenge: An Ever-Scaling   Reasoning Benchmark for LLMs,"Reasoning is the fundamental capability of large language models (LLMs). Due to the rapid progress of LLMs, there are two main issues of current benchmarks: i) these benchmarks can be crushed in a short time (less than 1 year), and ii) these benchmarks may be easily hacked. To handle these issues, we propose the ever-scalingness for building the benchmarks which are uncrushable, unhackable, auto-verifiable and general. This paper presents Nondeterministic Polynomial-time Problem Challenge (NPPC), an ever-scaling reasoning benchmark for LLMs. Specifically, the NPPC has three main modules: i) npgym, which provides a unified interface of 25 well-known NP-complete problems and can generate any number of instances with any levels of complexities, ii) npsolver: which provides a unified interface to evaluate the problem instances with both online and offline models via APIs and local deployments, respectively, and iii) npeval: which provides the comprehensive and ready-to-use tools to analyze the performances of LLMs over different problems, the number of tokens, the aha moments, the reasoning errors and the solution errors. Extensive experiments over widely-used LLMs demonstrate: i) NPPC can successfully decrease the performances of advanced LLMs' performances to below 10%, demonstrating that NPPC is uncrushable, ii) DeepSeek-R1, Claude-3.7-Sonnet, and o1/o3-mini are the most powerful LLMs, where DeepSeek-R1 outperforms Claude-3.7-Sonnet and o1/o3-mini in most NP-complete problems considered, and iii) the numbers of tokens, aha moments in the advanced LLMs, e.g., Claude-3.7-Sonnet and DeepSeek-R1, are observed first to increase and then decrease when the problem instances become more and more difficult. We believe that NPPC is the first ever-scaling reasoning benchmark, serving as the uncrushable and unhackable testbed for LLMs toward artificial general intelligence (AGI).","Chang Yang, Ruiyu Wang, Junzhe Jiang, Qi Jiang, Qinggang Zhang, Yanchen Deng, Shuxin Li, Shuyue Hu, Bo Li, Florian T. Pokorny, Xiao Huang, Xinrun Wang","cs.AI, cs.CL",2025-04-15T14:40:29Z,http://arxiv.org/abs/2504.11239v1,nondeterministic polynomial time problem challenge an ever scaling reasoning benchmark for llms,reasoning is the fundamental capability of large language models llms due to the rapid progress of llms there are two main issues of current benchmarks i these benchmarks can be crushed in a short time less than year and ii these benchmarks may be easily hacked to handle these issues we propose the ever scalingness for building the benchmarks which are uncrushable unhackable auto verifiable and general this paper presents nondeterministic polynomial time problem challenge nppc an ever scaling reasoning benchmark for llms specifically the nppc has three main modules i npgym which provides a unified interface of well known np complete problems and can generate any number of instances with any levels of complexities ii npsolver which provides a unified interface to evaluate the problem instances with both online and offline models via apis and local deployments respectively and iii npeval which provides the comprehensive and ready to use tools to analyze the performances of llms over different problems the number of tokens the aha moments the reasoning errors and the solution errors extensive experiments over widely used llms demonstrate i nppc can successfully decrease the performances of advanced llms performances to below demonstrating that nppc is uncrushable ii deepseek r claude sonnet and o o mini are the most powerful llms where deepseek r outperforms claude sonnet and o o mini in most np complete problems considered and iii the numbers of tokens aha moments in the advanced llms e g claude sonnet and deepseek r are observed first to increase and then decrease when the problem instances become more and more difficult we believe that nppc is the first ever scaling reasoning benchmark serving as the uncrushable and unhackable testbed for llms toward artificial general intelligence agi,"['nondeterministic', 'polynomial', 'time', 'problem', 'challenge', 'an', 'ever', 'scaling', 'reasoning', 'benchmark', 'for', 'llms']","['reasoning', 'is', 'the', 'fundamental', 'capability', 'of', 'large', 'language', 'models', 'llms', 'due', 'to', 'the', 'rapid', 'progress', 'of', 'llms', 'there', 'are', 'two', 'main', 'issues', 'of', 'current', 'benchmarks', 'i', 'these', 'benchmarks', 'can', 'be', 'crushed', 'in', 'a', 'short', 'time', 'less', 'than', 'year', 'and', 'ii', 'these', 'benchmarks', 'may', 'be', 'easily', 'hacked', 'to', 'handle', 'these', 'issues', 'we', 'propose', 'the', 'ever', 'scalingness', 'for', 'building', 'the', 'benchmarks', 'which', 'are', 'uncrushable', 'unhackable', 'auto', 'verifiable', 'and', 'general', 'this', 'paper', 'presents', 'nondeterministic', 'polynomial', 'time', 'problem', 'challenge', 'nppc', 'an', 'ever', 'scaling', 'reasoning', 'benchmark', 'for', 'llms', 'specifically', 'the', 'nppc', 'has', 'three', 'main', 'modules', 'i', 'npgym', 'which', 'provides', 'a', 'unified', 'interface', 'of', 'well', 'known', 'np', 'complete', 'problems', 'and', 'can', 'generate', 'any', 'number', 'of', 'instances', 'with', 'any', 'levels', 'of', 'complexities', 'ii', 'npsolver', 'which', 'provides', 'a', 'unified', 'interface', 'to', 'evaluate', 'the', 'problem', 'instances', 'with', 'both', 'online', 'and', 'offline', 'models', 'via', 'apis', 'and', 'local', 'deployments', 'respectively', 'and', 'iii', 'npeval', 'which', 'provides', 'the', 'comprehensive', 'and', 'ready', 'to', 'use', 'tools', 'to', 'analyze', 'the', 'performances', 'of', 'llms', 'over', 'different', 'problems', 'the', 'number', 'of', 'tokens', 'the', 'aha', 'moments', 'the', 'reasoning', 'errors', 'and', 'the', 'solution', 'errors', 'extensive', 'experiments', 'over', 'widely', 'used', 'llms', 'demonstrate', 'i', 'nppc', 'can', 'successfully', 'decrease', 'the', 'performances', 'of', 'advanced', 'llms', 'performances', 'to', 'below', 'demonstrating', 'that', 'nppc', 'is', 'uncrushable', 'ii', 'deepseek', 'r', 'claude', 'sonnet', 'and', 'o', 'o', 'mini', 'are', 'the', 'most', 'powerful', 'llms', 'where', 'deepseek', 'r', 'outperforms', 'claude', 'sonnet', 'and', 'o', 'o', 'mini', 'in', 'most', 'np', 'complete', 'problems', 'considered', 'and', 'iii', 'the', 'numbers', 'of', 'tokens', 'aha', 'moments', 'in', 'the', 'advanced', 'llms', 'e', 'g', 'claude', 'sonnet', 'and', 'deepseek', 'r', 'are', 'observed', 'first', 'to', 'increase', 'and', 'then', 'decrease', 'when', 'the', 'problem', 'instances', 'become', 'more', 'and', 'more', 'difficult', 'we', 'believe', 'that', 'nppc', 'is', 'the', 'first', 'ever', 'scaling', 'reasoning', 'benchmark', 'serving', 'as', 'the', 'uncrushable', 'and', 'unhackable', 'testbed', 'for', 'llms', 'toward', 'artificial', 'general', 'intelligence', 'agi']",12,290,"['Reasoning', 'Extensive', 'Claude-3', 'Challenge', 'NPPC', 'NP-complete', 'DeepSeek', 'LLMs', '7-Sonnet', 'Nondeterministic', 'APIs', 'AGI', 'Polynomial', 'Specifically', 'Problem', 'Due']"
2504.11216v1,Diversity-Driven Learning: Tackling Spurious Correlations and Data   Heterogeneity in Federated Models,"Federated Learning (FL) enables decentralized training of machine learning models on distributed data while preserving privacy. However, in real-world FL settings, client data is often non-identically distributed and imbalanced, resulting in statistical data heterogeneity which impacts the generalization capabilities of the server's model across clients, slows convergence and reduces performance. In this paper, we address this challenge by first proposing a characterization of statistical data heterogeneity by means of 6 metrics of global and client attribute imbalance, class imbalance, and spurious correlations. Next, we create and share 7 computer vision datasets for binary and multiclass image classification tasks in Federated Learning that cover a broad range of statistical data heterogeneity and hence simulate real-world situations. Finally, we propose FedDiverse, a novel client selection algorithm in FL which is designed to manage and leverage data heterogeneity across clients by promoting collaboration between clients with complementary data distributions. Experiments on the seven proposed FL datasets demonstrate FedDiverse's effectiveness in enhancing the performance and robustness of a variety of FL methods while having low communication and computational overhead.","Gergely D. N√©meth, Eros Fan√¨, Yeat Jeng Ng, Barbara Caputo, Miguel √Ångel Lozano, Nuria Oliver, Novi Quadrianto","cs.LG, cs.AI",2025-04-15T14:20:42Z,http://arxiv.org/abs/2504.11216v1,diversity driven learning tackling spurious correlations and data heterogeneity in federated models,federated learning fl enables decentralized training of machine learning models on distributed data while preserving privacy however in real world fl settings client data is often non identically distributed and imbalanced resulting in statistical data heterogeneity which impacts the generalization capabilities of the server s model across clients slows convergence and reduces performance in this paper we address this challenge by first proposing a characterization of statistical data heterogeneity by means of metrics of global and client attribute imbalance class imbalance and spurious correlations next we create and share computer vision datasets for binary and multiclass image classification tasks in federated learning that cover a broad range of statistical data heterogeneity and hence simulate real world situations finally we propose feddiverse a novel client selection algorithm in fl which is designed to manage and leverage data heterogeneity across clients by promoting collaboration between clients with complementary data distributions experiments on the seven proposed fl datasets demonstrate feddiverse s effectiveness in enhancing the performance and robustness of a variety of fl methods while having low communication and computational overhead,"['diversity', 'driven', 'learning', 'tackling', 'spurious', 'correlations', 'and', 'data', 'heterogeneity', 'in', 'federated', 'models']","['federated', 'learning', 'fl', 'enables', 'decentralized', 'training', 'of', 'machine', 'learning', 'models', 'on', 'distributed', 'data', 'while', 'preserving', 'privacy', 'however', 'in', 'real', 'world', 'fl', 'settings', 'client', 'data', 'is', 'often', 'non', 'identically', 'distributed', 'and', 'imbalanced', 'resulting', 'in', 'statistical', 'data', 'heterogeneity', 'which', 'impacts', 'the', 'generalization', 'capabilities', 'of', 'the', 'server', 's', 'model', 'across', 'clients', 'slows', 'convergence', 'and', 'reduces', 'performance', 'in', 'this', 'paper', 'we', 'address', 'this', 'challenge', 'by', 'first', 'proposing', 'a', 'characterization', 'of', 'statistical', 'data', 'heterogeneity', 'by', 'means', 'of', 'metrics', 'of', 'global', 'and', 'client', 'attribute', 'imbalance', 'class', 'imbalance', 'and', 'spurious', 'correlations', 'next', 'we', 'create', 'and', 'share', 'computer', 'vision', 'datasets', 'for', 'binary', 'and', 'multiclass', 'image', 'classification', 'tasks', 'in', 'federated', 'learning', 'that', 'cover', 'a', 'broad', 'range', 'of', 'statistical', 'data', 'heterogeneity', 'and', 'hence', 'simulate', 'real', 'world', 'situations', 'finally', 'we', 'propose', 'feddiverse', 'a', 'novel', 'client', 'selection', 'algorithm', 'in', 'fl', 'which', 'is', 'designed', 'to', 'manage', 'and', 'leverage', 'data', 'heterogeneity', 'across', 'clients', 'by', 'promoting', 'collaboration', 'between', 'clients', 'with', 'complementary', 'data', 'distributions', 'experiments', 'on', 'the', 'seven', 'proposed', 'fl', 'datasets', 'demonstrate', 'feddiverse', 's', 'effectiveness', 'in', 'enhancing', 'the', 'performance', 'and', 'robustness', 'of', 'a', 'variety', 'of', 'fl', 'methods', 'while', 'having', 'low', 'communication', 'and', 'computational', 'overhead']",12,178,"['FedDiverse', 'Finally', 'However', 'Next', 'Learning', 'Federated', 'Experiments']"
2504.11197v2,Efficient Distributed Retrieval-Augmented Generation for Enhancing   Language Model Performance,"Small language models (SLMs) support efficient deployments on resource-constrained edge devices, but their limited capacity compromises inference performance. Retrieval-augmented generation (RAG) is a promising solution to enhance model performance by integrating external databases, without requiring intensive on-device model retraining. However, large-scale public databases and user-specific private contextual documents are typically located on the cloud and the device separately, while existing RAG implementations are primarily centralized. To bridge this gap, we propose DRAGON, a distributed RAG framework to enhance on-device SLMs through both general and personal knowledge without the risk of leaking document privacy. Specifically, DRAGON decomposes multi-document RAG into multiple parallel token generation processes performed independently and locally on the cloud and the device, and employs a newly designed Speculative Aggregation, a dual-side speculative algorithm to avoid frequent output synchronization between the cloud and device. A new scheduling algorithm is further introduced to identify the optimal aggregation side based on real-time network conditions. Evaluations on real-world hardware testbed demonstrate a significant performance improvement of DRAGON-up to 1.9x greater gains over standalone SLM compared to the centralized RAG, substantial reduction in per-token latency, and negligible Time to First Token (TTFT) overhead.","Shangyu Liu, Zhenzhe Zheng, Xiaoyao Huang, Fan Wu, Guihai Chen, Jie Wu","cs.LG, cs.AI, cs.DC, cs.IR",2025-04-15T13:53:08Z,http://arxiv.org/abs/2504.11197v2,efficient distributed retrieval augmented generation for enhancing language model performance,small language models slms support efficient deployments on resource constrained edge devices but their limited capacity compromises inference performance retrieval augmented generation rag is a promising solution to enhance model performance by integrating external databases without requiring intensive on device model retraining however large scale public databases and user specific private contextual documents are typically located on the cloud and the device separately while existing rag implementations are primarily centralized to bridge this gap we propose dragon a distributed rag framework to enhance on device slms through both general and personal knowledge without the risk of leaking document privacy specifically dragon decomposes multi document rag into multiple parallel token generation processes performed independently and locally on the cloud and the device and employs a newly designed speculative aggregation a dual side speculative algorithm to avoid frequent output synchronization between the cloud and device a new scheduling algorithm is further introduced to identify the optimal aggregation side based on real time network conditions evaluations on real world hardware testbed demonstrate a significant performance improvement of dragon up to x greater gains over standalone slm compared to the centralized rag substantial reduction in per token latency and negligible time to first token ttft overhead,"['efficient', 'distributed', 'retrieval', 'augmented', 'generation', 'for', 'enhancing', 'language', 'model', 'performance']","['small', 'language', 'models', 'slms', 'support', 'efficient', 'deployments', 'on', 'resource', 'constrained', 'edge', 'devices', 'but', 'their', 'limited', 'capacity', 'compromises', 'inference', 'performance', 'retrieval', 'augmented', 'generation', 'rag', 'is', 'a', 'promising', 'solution', 'to', 'enhance', 'model', 'performance', 'by', 'integrating', 'external', 'databases', 'without', 'requiring', 'intensive', 'on', 'device', 'model', 'retraining', 'however', 'large', 'scale', 'public', 'databases', 'and', 'user', 'specific', 'private', 'contextual', 'documents', 'are', 'typically', 'located', 'on', 'the', 'cloud', 'and', 'the', 'device', 'separately', 'while', 'existing', 'rag', 'implementations', 'are', 'primarily', 'centralized', 'to', 'bridge', 'this', 'gap', 'we', 'propose', 'dragon', 'a', 'distributed', 'rag', 'framework', 'to', 'enhance', 'on', 'device', 'slms', 'through', 'both', 'general', 'and', 'personal', 'knowledge', 'without', 'the', 'risk', 'of', 'leaking', 'document', 'privacy', 'specifically', 'dragon', 'decomposes', 'multi', 'document', 'rag', 'into', 'multiple', 'parallel', 'token', 'generation', 'processes', 'performed', 'independently', 'and', 'locally', 'on', 'the', 'cloud', 'and', 'the', 'device', 'and', 'employs', 'a', 'newly', 'designed', 'speculative', 'aggregation', 'a', 'dual', 'side', 'speculative', 'algorithm', 'to', 'avoid', 'frequent', 'output', 'synchronization', 'between', 'the', 'cloud', 'and', 'device', 'a', 'new', 'scheduling', 'algorithm', 'is', 'further', 'introduced', 'to', 'identify', 'the', 'optimal', 'aggregation', 'side', 'based', 'on', 'real', 'time', 'network', 'conditions', 'evaluations', 'on', 'real', 'world', 'hardware', 'testbed', 'demonstrate', 'a', 'significant', 'performance', 'improvement', 'of', 'dragon', 'up', 'to', 'x', 'greater', 'gains', 'over', 'standalone', 'slm', 'compared', 'to', 'the', 'centralized', 'rag', 'substantial', 'reduction', 'in', 'per', 'token', 'latency', 'and', 'negligible', 'time', 'to', 'first', 'token', 'ttft', 'overhead']",10,202,"['Speculative', 'Small', 'SLMs', 'Specifically', 'Token', 'RAG', 'DRAGON-up', 'SLM', 'However', 'DRAGON', 'Aggregation', 'TTFT', 'First', 'Evaluations', 'Retrieval', 'Time']"
2504.11514v1,Enhancing Autonomous Driving Systems with On-Board Deployed Large   Language Models,"Neural Networks (NNs) trained through supervised learning struggle with managing edge-case scenarios common in real-world driving due to the intractability of exhaustive datasets covering all edge-cases, making knowledge-driven approaches, akin to how humans intuitively detect unexpected driving behavior, a suitable complement to data-driven methods. This work proposes a hybrid architecture combining low-level Model Predictive Controller (MPC) with locally deployed Large Language Models (LLMs) to enhance decision-making and Human Machine Interaction (HMI). The DecisionxLLM module evaluates robotic state information against natural language instructions to ensure adherence to desired driving behavior. The MPCxLLM module then adjusts MPC parameters based on LLM-generated insights, achieving control adaptability while preserving the safety and constraint guarantees of traditional MPC systems. Further, to enable efficient on-board deployment and to eliminate dependency on cloud connectivity, we shift processing to the on-board computing platform: We propose an approach that exploits Retrieval Augmented Generation (RAG), Low Rank Adaptation (LoRA) fine-tuning, and quantization. Experimental results demonstrate that these enhancements yield significant improvements in reasoning accuracy by up to 10.45%, control adaptability by as much as 52.2%, and up to 10.5x increase in computational efficiency (tokens/s), validating the proposed framework's practicality for real-time deployment even on down-scaled robotic platforms. This work bridges high-level decision-making with low-level control adaptability, offering a synergistic framework for knowledge-driven and adaptive Autonomous Driving Systems (ADS).","Nicolas Baumann, Cheng Hu, Paviththiren Sivasothilingam, Haotong Qin, Lei Xie, Michele Magno, Luca Benini","cs.AI, cs.RO",2025-04-15T13:49:17Z,http://arxiv.org/abs/2504.11514v1,enhancing autonomous driving systems with on board deployed large language models,neural networks nns trained through supervised learning struggle with managing edge case scenarios common in real world driving due to the intractability of exhaustive datasets covering all edge cases making knowledge driven approaches akin to how humans intuitively detect unexpected driving behavior a suitable complement to data driven methods this work proposes a hybrid architecture combining low level model predictive controller mpc with locally deployed large language models llms to enhance decision making and human machine interaction hmi the decisionxllm module evaluates robotic state information against natural language instructions to ensure adherence to desired driving behavior the mpcxllm module then adjusts mpc parameters based on llm generated insights achieving control adaptability while preserving the safety and constraint guarantees of traditional mpc systems further to enable efficient on board deployment and to eliminate dependency on cloud connectivity we shift processing to the on board computing platform we propose an approach that exploits retrieval augmented generation rag low rank adaptation lora fine tuning and quantization experimental results demonstrate that these enhancements yield significant improvements in reasoning accuracy by up to control adaptability by as much as and up to x increase in computational efficiency tokens s validating the proposed framework s practicality for real time deployment even on down scaled robotic platforms this work bridges high level decision making with low level control adaptability offering a synergistic framework for knowledge driven and adaptive autonomous driving systems ads,"['enhancing', 'autonomous', 'driving', 'systems', 'with', 'on', 'board', 'deployed', 'large', 'language', 'models']","['neural', 'networks', 'nns', 'trained', 'through', 'supervised', 'learning', 'struggle', 'with', 'managing', 'edge', 'case', 'scenarios', 'common', 'in', 'real', 'world', 'driving', 'due', 'to', 'the', 'intractability', 'of', 'exhaustive', 'datasets', 'covering', 'all', 'edge', 'cases', 'making', 'knowledge', 'driven', 'approaches', 'akin', 'to', 'how', 'humans', 'intuitively', 'detect', 'unexpected', 'driving', 'behavior', 'a', 'suitable', 'complement', 'to', 'data', 'driven', 'methods', 'this', 'work', 'proposes', 'a', 'hybrid', 'architecture', 'combining', 'low', 'level', 'model', 'predictive', 'controller', 'mpc', 'with', 'locally', 'deployed', 'large', 'language', 'models', 'llms', 'to', 'enhance', 'decision', 'making', 'and', 'human', 'machine', 'interaction', 'hmi', 'the', 'decisionxllm', 'module', 'evaluates', 'robotic', 'state', 'information', 'against', 'natural', 'language', 'instructions', 'to', 'ensure', 'adherence', 'to', 'desired', 'driving', 'behavior', 'the', 'mpcxllm', 'module', 'then', 'adjusts', 'mpc', 'parameters', 'based', 'on', 'llm', 'generated', 'insights', 'achieving', 'control', 'adaptability', 'while', 'preserving', 'the', 'safety', 'and', 'constraint', 'guarantees', 'of', 'traditional', 'mpc', 'systems', 'further', 'to', 'enable', 'efficient', 'on', 'board', 'deployment', 'and', 'to', 'eliminate', 'dependency', 'on', 'cloud', 'connectivity', 'we', 'shift', 'processing', 'to', 'the', 'on', 'board', 'computing', 'platform', 'we', 'propose', 'an', 'approach', 'that', 'exploits', 'retrieval', 'augmented', 'generation', 'rag', 'low', 'rank', 'adaptation', 'lora', 'fine', 'tuning', 'and', 'quantization', 'experimental', 'results', 'demonstrate', 'that', 'these', 'enhancements', 'yield', 'significant', 'improvements', 'in', 'reasoning', 'accuracy', 'by', 'up', 'to', 'control', 'adaptability', 'by', 'as', 'much', 'as', 'and', 'up', 'to', 'x', 'increase', 'in', 'computational', 'efficiency', 'tokens', 's', 'validating', 'the', 'proposed', 'framework', 's', 'practicality', 'for', 'real', 'time', 'deployment', 'even', 'on', 'down', 'scaled', 'robotic', 'platforms', 'this', 'work', 'bridges', 'high', 'level', 'decision', 'making', 'with', 'low', 'level', 'control', 'adaptability', 'offering', 'a', 'synergistic', 'framework', 'for', 'knowledge', 'driven', 'and', 'adaptive', 'autonomous', 'driving', 'systems', 'ads']",11,235,"['HMI', 'ADS', 'Model', 'Neural', 'MPCxLLM', 'Rank', 'Adaptation', 'Language', 'Retrieval', 'MPC', 'Driving', 'Autonomous', 'LLMs', 'Augmented', 'Controller', 'Large', 'Generation', 'Interaction', 'RAG', 'Further', 'DecisionxLLM', 'Networks', 'Predictive', 'Human', 'Low', 'NNs', 'LLM-generated', 'Systems', 'Experimental', 'Models', 'LoRA', 'Machine']"
2504.11190v1,Enhancing multimodal analogical reasoning with Logic Augmented   Generation,"Recent advances in Large Language Models have demonstrated their capabilities across a variety of tasks. However, automatically extracting implicit knowledge from natural language remains a significant challenge, as machines lack active experience with the physical world. Given this scenario, semantic knowledge graphs can serve as conceptual spaces that guide the automated text generation reasoning process to achieve more efficient and explainable results. In this paper, we apply a logic-augmented generation (LAG) framework that leverages the explicit representation of a text through a semantic knowledge graph and applies it in combination with prompt heuristics to elicit implicit analogical connections. This method generates extended knowledge graph triples representing implicit meaning, enabling systems to reason on unlabeled multimodal data regardless of the domain. We validate our work through three metaphor detection and understanding tasks across four datasets, as they require deep analogical reasoning capabilities. The results show that this integrated approach surpasses current baselines, performs better than humans in understanding visual metaphors, and enables more explainable reasoning processes, though still has inherent limitations in metaphor understanding, especially for domain-specific metaphors. Furthermore, we propose a thorough error analysis, discussing issues with metaphorical annotations and current evaluation methods.","Anna Sofia Lippolis, Andrea Giovanni Nuzzolese, Aldo Gangemi","cs.AI, cs.CL",2025-04-15T13:47:55Z,http://arxiv.org/abs/2504.11190v1,enhancing multimodal analogical reasoning with logic augmented generation,recent advances in large language models have demonstrated their capabilities across a variety of tasks however automatically extracting implicit knowledge from natural language remains a significant challenge as machines lack active experience with the physical world given this scenario semantic knowledge graphs can serve as conceptual spaces that guide the automated text generation reasoning process to achieve more efficient and explainable results in this paper we apply a logic augmented generation lag framework that leverages the explicit representation of a text through a semantic knowledge graph and applies it in combination with prompt heuristics to elicit implicit analogical connections this method generates extended knowledge graph triples representing implicit meaning enabling systems to reason on unlabeled multimodal data regardless of the domain we validate our work through three metaphor detection and understanding tasks across four datasets as they require deep analogical reasoning capabilities the results show that this integrated approach surpasses current baselines performs better than humans in understanding visual metaphors and enables more explainable reasoning processes though still has inherent limitations in metaphor understanding especially for domain specific metaphors furthermore we propose a thorough error analysis discussing issues with metaphorical annotations and current evaluation methods,"['enhancing', 'multimodal', 'analogical', 'reasoning', 'with', 'logic', 'augmented', 'generation']","['recent', 'advances', 'in', 'large', 'language', 'models', 'have', 'demonstrated', 'their', 'capabilities', 'across', 'a', 'variety', 'of', 'tasks', 'however', 'automatically', 'extracting', 'implicit', 'knowledge', 'from', 'natural', 'language', 'remains', 'a', 'significant', 'challenge', 'as', 'machines', 'lack', 'active', 'experience', 'with', 'the', 'physical', 'world', 'given', 'this', 'scenario', 'semantic', 'knowledge', 'graphs', 'can', 'serve', 'as', 'conceptual', 'spaces', 'that', 'guide', 'the', 'automated', 'text', 'generation', 'reasoning', 'process', 'to', 'achieve', 'more', 'efficient', 'and', 'explainable', 'results', 'in', 'this', 'paper', 'we', 'apply', 'a', 'logic', 'augmented', 'generation', 'lag', 'framework', 'that', 'leverages', 'the', 'explicit', 'representation', 'of', 'a', 'text', 'through', 'a', 'semantic', 'knowledge', 'graph', 'and', 'applies', 'it', 'in', 'combination', 'with', 'prompt', 'heuristics', 'to', 'elicit', 'implicit', 'analogical', 'connections', 'this', 'method', 'generates', 'extended', 'knowledge', 'graph', 'triples', 'representing', 'implicit', 'meaning', 'enabling', 'systems', 'to', 'reason', 'on', 'unlabeled', 'multimodal', 'data', 'regardless', 'of', 'the', 'domain', 'we', 'validate', 'our', 'work', 'through', 'three', 'metaphor', 'detection', 'and', 'understanding', 'tasks', 'across', 'four', 'datasets', 'as', 'they', 'require', 'deep', 'analogical', 'reasoning', 'capabilities', 'the', 'results', 'show', 'that', 'this', 'integrated', 'approach', 'surpasses', 'current', 'baselines', 'performs', 'better', 'than', 'humans', 'in', 'understanding', 'visual', 'metaphors', 'and', 'enables', 'more', 'explainable', 'reasoning', 'processes', 'though', 'still', 'has', 'inherent', 'limitations', 'in', 'metaphor', 'understanding', 'especially', 'for', 'domain', 'specific', 'metaphors', 'furthermore', 'we', 'propose', 'a', 'thorough', 'error', 'analysis', 'discussing', 'issues', 'with', 'metaphorical', 'annotations', 'and', 'current', 'evaluation', 'methods']",8,195,"['Recent', 'However', 'Models', 'Furthermore', 'LAG', 'Language', 'Given', 'Large']"
2504.11186v1,"Benchmarking Next-Generation Reasoning-Focused Large Language Models in   Ophthalmology: A Head-to-Head Evaluation on 5,888 Items","Recent advances in reasoning-focused large language models (LLMs) mark a shift from general LLMs toward models designed for complex decision-making, a crucial aspect in medicine. However, their performance in specialized domains like ophthalmology remains underexplored. This study comprehensively evaluated and compared the accuracy and reasoning capabilities of four newly developed reasoning-focused LLMs, namely DeepSeek-R1, OpenAI o1, o3-mini, and Gemini 2.0 Flash-Thinking. Each model was assessed using 5,888 multiple-choice ophthalmology exam questions from the MedMCQA dataset in zero-shot setting. Quantitative evaluation included accuracy, Macro-F1, and five text-generation metrics (ROUGE-L, METEOR, BERTScore, BARTScore, and AlignScore), computed against ground-truth reasonings. Average inference time was recorded for a subset of 100 randomly selected questions. Additionally, two board-certified ophthalmologists qualitatively assessed clarity, completeness, and reasoning structure of responses to differential diagnosis questions.O1 (0.902) and DeepSeek-R1 (0.888) achieved the highest accuracy, with o1 also leading in Macro-F1 (0.900). The performance of models across the text-generation metrics varied: O3-mini excelled in ROUGE-L (0.151), o1 in METEOR (0.232), DeepSeek-R1 and o3-mini tied for BERTScore (0.673), DeepSeek-R1 (-4.105) and Gemini 2.0 Flash-Thinking (-4.127) performed best in BARTScore, while o3-mini (0.181) and o1 (0.176) led AlignScore. Inference time across the models varied, with DeepSeek-R1 being slowest (40.4 seconds) and Gemini 2.0 Flash-Thinking fastest (6.7 seconds). Qualitative evaluation revealed that DeepSeek-R1 and Gemini 2.0 Flash-Thinking tended to provide detailed and comprehensive intermediate reasoning, whereas o1 and o3-mini displayed concise and summarized justifications.","Minjie Zou, Sahana Srinivasan, Thaddaeus Wai Soon Lo, Ke Zou, Gabriel Dawei Yang, Xuguang Ai, Hyunjae Kim, Maxwell Singer, Fares Antaki, Kelvin Li, Robert Chang, Marcus Tan, David Ziyou Chen, Dianbo Liu, Qingyu Chen, Yih Chung Tham","cs.CL, cs.AI",2025-04-15T13:42:34Z,http://arxiv.org/abs/2504.11186v1,benchmarking next generation reasoning focused large language models in ophthalmology a head to head evaluation on items,recent advances in reasoning focused large language models llms mark a shift from general llms toward models designed for complex decision making a crucial aspect in medicine however their performance in specialized domains like ophthalmology remains underexplored this study comprehensively evaluated and compared the accuracy and reasoning capabilities of four newly developed reasoning focused llms namely deepseek r openai o o mini and gemini flash thinking each model was assessed using multiple choice ophthalmology exam questions from the medmcqa dataset in zero shot setting quantitative evaluation included accuracy macro f and five text generation metrics rouge l meteor bertscore bartscore and alignscore computed against ground truth reasonings average inference time was recorded for a subset of randomly selected questions additionally two board certified ophthalmologists qualitatively assessed clarity completeness and reasoning structure of responses to differential diagnosis questions o and deepseek r achieved the highest accuracy with o also leading in macro f the performance of models across the text generation metrics varied o mini excelled in rouge l o in meteor deepseek r and o mini tied for bertscore deepseek r and gemini flash thinking performed best in bartscore while o mini and o led alignscore inference time across the models varied with deepseek r being slowest seconds and gemini flash thinking fastest seconds qualitative evaluation revealed that deepseek r and gemini flash thinking tended to provide detailed and comprehensive intermediate reasoning whereas o and o mini displayed concise and summarized justifications,"['benchmarking', 'next', 'generation', 'reasoning', 'focused', 'large', 'language', 'models', 'in', 'ophthalmology', 'a', 'head', 'to', 'head', 'evaluation', 'on', 'items']","['recent', 'advances', 'in', 'reasoning', 'focused', 'large', 'language', 'models', 'llms', 'mark', 'a', 'shift', 'from', 'general', 'llms', 'toward', 'models', 'designed', 'for', 'complex', 'decision', 'making', 'a', 'crucial', 'aspect', 'in', 'medicine', 'however', 'their', 'performance', 'in', 'specialized', 'domains', 'like', 'ophthalmology', 'remains', 'underexplored', 'this', 'study', 'comprehensively', 'evaluated', 'and', 'compared', 'the', 'accuracy', 'and', 'reasoning', 'capabilities', 'of', 'four', 'newly', 'developed', 'reasoning', 'focused', 'llms', 'namely', 'deepseek', 'r', 'openai', 'o', 'o', 'mini', 'and', 'gemini', 'flash', 'thinking', 'each', 'model', 'was', 'assessed', 'using', 'multiple', 'choice', 'ophthalmology', 'exam', 'questions', 'from', 'the', 'medmcqa', 'dataset', 'in', 'zero', 'shot', 'setting', 'quantitative', 'evaluation', 'included', 'accuracy', 'macro', 'f', 'and', 'five', 'text', 'generation', 'metrics', 'rouge', 'l', 'meteor', 'bertscore', 'bartscore', 'and', 'alignscore', 'computed', 'against', 'ground', 'truth', 'reasonings', 'average', 'inference', 'time', 'was', 'recorded', 'for', 'a', 'subset', 'of', 'randomly', 'selected', 'questions', 'additionally', 'two', 'board', 'certified', 'ophthalmologists', 'qualitatively', 'assessed', 'clarity', 'completeness', 'and', 'reasoning', 'structure', 'of', 'responses', 'to', 'differential', 'diagnosis', 'questions', 'o', 'and', 'deepseek', 'r', 'achieved', 'the', 'highest', 'accuracy', 'with', 'o', 'also', 'leading', 'in', 'macro', 'f', 'the', 'performance', 'of', 'models', 'across', 'the', 'text', 'generation', 'metrics', 'varied', 'o', 'mini', 'excelled', 'in', 'rouge', 'l', 'o', 'in', 'meteor', 'deepseek', 'r', 'and', 'o', 'mini', 'tied', 'for', 'bertscore', 'deepseek', 'r', 'and', 'gemini', 'flash', 'thinking', 'performed', 'best', 'in', 'bartscore', 'while', 'o', 'mini', 'and', 'o', 'led', 'alignscore', 'inference', 'time', 'across', 'the', 'models', 'varied', 'with', 'deepseek', 'r', 'being', 'slowest', 'seconds', 'and', 'gemini', 'flash', 'thinking', 'fastest', 'seconds', 'qualitative', 'evaluation', 'revealed', 'that', 'deepseek', 'r', 'and', 'gemini', 'flash', 'thinking', 'tended', 'to', 'provide', 'detailed', 'and', 'comprehensive', 'intermediate', 'reasoning', 'whereas', 'o', 'and', 'o', 'mini', 'displayed', 'concise', 'and', 'summarized', 'justifications']",17,242,"['888', 'DeepSeek', 'ROUGE-L', 'Average', 'BERTScore', 'Flash', '176', 'AlignScore', '181', 'Quantitative', '900', 'LLMs', 'However', 'Gemini', 'O3-mini', 'Recent', 'METEOR', '151', '902', 'Thinking', '232', 'OpenAI', 'Inference', 'Qualitative', 'Each', '127', 'BARTScore', 'MedMCQA', '673', '105', '100', 'Additionally', 'Macro']"
2504.11182v1,Exploring Backdoor Attack and Defense for LLM-empowered Recommendations,"The fusion of Large Language Models (LLMs) with recommender systems (RecSys) has dramatically advanced personalized recommendations and drawn extensive attention. Despite the impressive progress, the safety of LLM-based RecSys against backdoor attacks remains largely under-explored. In this paper, we raise a new problem: Can a backdoor with a specific trigger be injected into LLM-based Recsys, leading to the manipulation of the recommendation responses when the backdoor trigger is appended to an item's title? To investigate the vulnerabilities of LLM-based RecSys under backdoor attacks, we propose a new attack framework termed Backdoor Injection Poisoning for RecSys (BadRec). BadRec perturbs the items' titles with triggers and employs several fake users to interact with these items, effectively poisoning the training set and injecting backdoors into LLM-based RecSys. Comprehensive experiments reveal that poisoning just 1% of the training data with adversarial examples is sufficient to successfully implant backdoors, enabling manipulation of recommendations. To further mitigate such a security threat, we propose a universal defense strategy called Poison Scanner (P-Scanner). Specifically, we introduce an LLM-based poison scanner to detect the poisoned items by leveraging the powerful language understanding and rich knowledge of LLMs. A trigger augmentation agent is employed to generate diverse synthetic triggers to guide the poison scanner in learning domain-specific knowledge of the poisoned item detection task. Extensive experiments on three real-world datasets validate the effectiveness of the proposed P-Scanner.","Liangbo Ning, Wenqi Fan, Qing Li","cs.CR, cs.AI",2025-04-15T13:37:38Z,http://arxiv.org/abs/2504.11182v1,exploring backdoor attack and defense for llm empowered recommendations,the fusion of large language models llms with recommender systems recsys has dramatically advanced personalized recommendations and drawn extensive attention despite the impressive progress the safety of llm based recsys against backdoor attacks remains largely under explored in this paper we raise a new problem can a backdoor with a specific trigger be injected into llm based recsys leading to the manipulation of the recommendation responses when the backdoor trigger is appended to an item s title to investigate the vulnerabilities of llm based recsys under backdoor attacks we propose a new attack framework termed backdoor injection poisoning for recsys badrec badrec perturbs the items titles with triggers and employs several fake users to interact with these items effectively poisoning the training set and injecting backdoors into llm based recsys comprehensive experiments reveal that poisoning just of the training data with adversarial examples is sufficient to successfully implant backdoors enabling manipulation of recommendations to further mitigate such a security threat we propose a universal defense strategy called poison scanner p scanner specifically we introduce an llm based poison scanner to detect the poisoned items by leveraging the powerful language understanding and rich knowledge of llms a trigger augmentation agent is employed to generate diverse synthetic triggers to guide the poison scanner in learning domain specific knowledge of the poisoned item detection task extensive experiments on three real world datasets validate the effectiveness of the proposed p scanner,"['exploring', 'backdoor', 'attack', 'and', 'defense', 'for', 'llm', 'empowered', 'recommendations']","['the', 'fusion', 'of', 'large', 'language', 'models', 'llms', 'with', 'recommender', 'systems', 'recsys', 'has', 'dramatically', 'advanced', 'personalized', 'recommendations', 'and', 'drawn', 'extensive', 'attention', 'despite', 'the', 'impressive', 'progress', 'the', 'safety', 'of', 'llm', 'based', 'recsys', 'against', 'backdoor', 'attacks', 'remains', 'largely', 'under', 'explored', 'in', 'this', 'paper', 'we', 'raise', 'a', 'new', 'problem', 'can', 'a', 'backdoor', 'with', 'a', 'specific', 'trigger', 'be', 'injected', 'into', 'llm', 'based', 'recsys', 'leading', 'to', 'the', 'manipulation', 'of', 'the', 'recommendation', 'responses', 'when', 'the', 'backdoor', 'trigger', 'is', 'appended', 'to', 'an', 'item', 's', 'title', 'to', 'investigate', 'the', 'vulnerabilities', 'of', 'llm', 'based', 'recsys', 'under', 'backdoor', 'attacks', 'we', 'propose', 'a', 'new', 'attack', 'framework', 'termed', 'backdoor', 'injection', 'poisoning', 'for', 'recsys', 'badrec', 'badrec', 'perturbs', 'the', 'items', 'titles', 'with', 'triggers', 'and', 'employs', 'several', 'fake', 'users', 'to', 'interact', 'with', 'these', 'items', 'effectively', 'poisoning', 'the', 'training', 'set', 'and', 'injecting', 'backdoors', 'into', 'llm', 'based', 'recsys', 'comprehensive', 'experiments', 'reveal', 'that', 'poisoning', 'just', 'of', 'the', 'training', 'data', 'with', 'adversarial', 'examples', 'is', 'sufficient', 'to', 'successfully', 'implant', 'backdoors', 'enabling', 'manipulation', 'of', 'recommendations', 'to', 'further', 'mitigate', 'such', 'a', 'security', 'threat', 'we', 'propose', 'a', 'universal', 'defense', 'strategy', 'called', 'poison', 'scanner', 'p', 'scanner', 'specifically', 'we', 'introduce', 'an', 'llm', 'based', 'poison', 'scanner', 'to', 'detect', 'the', 'poisoned', 'items', 'by', 'leveraging', 'the', 'powerful', 'language', 'understanding', 'and', 'rich', 'knowledge', 'of', 'llms', 'a', 'trigger', 'augmentation', 'agent', 'is', 'employed', 'to', 'generate', 'diverse', 'synthetic', 'triggers', 'to', 'guide', 'the', 'poison', 'scanner', 'in', 'learning', 'domain', 'specific', 'knowledge', 'of', 'the', 'poisoned', 'item', 'detection', 'task', 'extensive', 'experiments', 'on', 'three', 'real', 'world', 'datasets', 'validate', 'the', 'effectiveness', 'of', 'the', 'proposed', 'p', 'scanner']",9,237,"['Comprehensive', 'Recsys', 'RecSys', 'Specifically', 'Backdoor', 'Language', 'Poison', 'Poisoning', 'P-Scanner', 'Scanner', 'Despite', 'LLMs', 'Large', 'Injection', 'LLM-based', 'Can', 'Extensive', 'BadRec', 'Models']"
2504.11171v1,TerraMind: Large-Scale Generative Multimodality for Earth Observation,"We present TerraMind, the first any-to-any generative, multimodal foundation model for Earth observation (EO). Unlike other multimodal models, TerraMind is pretrained on dual-scale representations combining both token-level and pixel-level data across modalities. On a token level, TerraMind encodes high-level contextual information to learn cross-modal relationships, while on a pixel level, TerraMind leverages fine-grained representations to capture critical spatial nuances. We pretrained TerraMind on nine geospatial modalities of a global, large-scale dataset. In this paper, we demonstrate that (i) TerraMind's dual-scale early fusion approach unlocks a range of zero-shot and few-shot applications for Earth observation, (ii) TerraMind introduces ""Thinking-in-Modalities"" (TiM) -- the capability of generating additional artificial data during finetuning and inference to improve the model output -- and (iii) TerraMind achieves beyond state-of-the-art performance in community-standard benchmarks for EO like PANGAEA. The pretraining dataset, the model weights, and our code is open-sourced under a permissive license.","Johannes Jakubik, Felix Yang, Benedikt Blumenstiel, Erik Scheurer, Rocco Sedona, Stefano Maurogiovanni, Jente Bosmans, Nikolaos Dionelis, Valerio Marsocci, Niklas Kopp, Rahul Ramachandran, Paolo Fraccaro, Thomas Brunschwiler, Gabriele Cavallaro, Juan Bernabe-Moreno, Nicolas Long√©p√©","cs.CV, cs.AI",2025-04-15T13:17:39Z,http://arxiv.org/abs/2504.11171v1,terramind large scale generative multimodality for earth observation,we present terramind the first any to any generative multimodal foundation model for earth observation eo unlike other multimodal models terramind is pretrained on dual scale representations combining both token level and pixel level data across modalities on a token level terramind encodes high level contextual information to learn cross modal relationships while on a pixel level terramind leverages fine grained representations to capture critical spatial nuances we pretrained terramind on nine geospatial modalities of a global large scale dataset in this paper we demonstrate that i terramind s dual scale early fusion approach unlocks a range of zero shot and few shot applications for earth observation ii terramind introduces thinking in modalities tim the capability of generating additional artificial data during finetuning and inference to improve the model output and iii terramind achieves beyond state of the art performance in community standard benchmarks for eo like pangaea the pretraining dataset the model weights and our code is open sourced under a permissive license,"['terramind', 'large', 'scale', 'generative', 'multimodality', 'for', 'earth', 'observation']","['we', 'present', 'terramind', 'the', 'first', 'any', 'to', 'any', 'generative', 'multimodal', 'foundation', 'model', 'for', 'earth', 'observation', 'eo', 'unlike', 'other', 'multimodal', 'models', 'terramind', 'is', 'pretrained', 'on', 'dual', 'scale', 'representations', 'combining', 'both', 'token', 'level', 'and', 'pixel', 'level', 'data', 'across', 'modalities', 'on', 'a', 'token', 'level', 'terramind', 'encodes', 'high', 'level', 'contextual', 'information', 'to', 'learn', 'cross', 'modal', 'relationships', 'while', 'on', 'a', 'pixel', 'level', 'terramind', 'leverages', 'fine', 'grained', 'representations', 'to', 'capture', 'critical', 'spatial', 'nuances', 'we', 'pretrained', 'terramind', 'on', 'nine', 'geospatial', 'modalities', 'of', 'a', 'global', 'large', 'scale', 'dataset', 'in', 'this', 'paper', 'we', 'demonstrate', 'that', 'i', 'terramind', 's', 'dual', 'scale', 'early', 'fusion', 'approach', 'unlocks', 'a', 'range', 'of', 'zero', 'shot', 'and', 'few', 'shot', 'applications', 'for', 'earth', 'observation', 'ii', 'terramind', 'introduces', 'thinking', 'in', 'modalities', 'tim', 'the', 'capability', 'of', 'generating', 'additional', 'artificial', 'data', 'during', 'finetuning', 'and', 'inference', 'to', 'improve', 'the', 'model', 'output', 'and', 'iii', 'terramind', 'achieves', 'beyond', 'state', 'of', 'the', 'art', 'performance', 'in', 'community', 'standard', 'benchmarks', 'for', 'eo', 'like', 'pangaea', 'the', 'pretraining', 'dataset', 'the', 'model', 'weights', 'and', 'our', 'code', 'is', 'open', 'sourced', 'under', 'a', 'permissive', 'license']",8,164,"['Unlike', 'TerraMind', 'TiM', 'PANGAEA', 'Thinking', 'Earth', 'Modalities']"
2504.11169v1,MuSeD: A Multimodal Spanish Dataset for Sexism Detection in Social Media   Videos,"Sexism is generally defined as prejudice and discrimination based on sex or gender, affecting every sector of society, from social institutions to relationships and individual behavior. Social media platforms amplify the impact of sexism by conveying discriminatory content not only through text but also across multiple modalities, highlighting the critical need for a multimodal approach to the analysis of sexism online. With the rise of social media platforms where users share short videos, sexism is increasingly spreading through video content. Automatically detecting sexism in videos is a challenging task, as it requires analyzing the combination of verbal, audio, and visual elements to identify sexist content. In this study, (1) we introduce MuSeD, a new Multimodal Spanish dataset for Sexism Detection consisting of $\approx$ 11 hours of videos extracted from TikTok and BitChute; (2) we propose an innovative annotation framework for analyzing the contribution of textual and multimodal labels in the classification of sexist and non-sexist content; and (3) we evaluate a range of large language models (LLMs) and multimodal LLMs on the task of sexism detection. We find that visual information plays a key role in labeling sexist content for both humans and models. Models effectively detect explicit sexism; however, they struggle with implicit cases, such as stereotypes, instances where annotators also show low agreement. This highlights the inherent difficulty of the task, as identifying implicit sexism depends on the social and cultural context.","Laura De Grazia, Pol Pastells, Mauro V√°zquez Chas, Desmond Elliott, Danae S√°nchez Villegas, Mireia Farr√∫s, Mariona Taul√©","cs.CL, cs.AI",2025-04-15T13:16:46Z,http://arxiv.org/abs/2504.11169v1,mused a multimodal spanish dataset for sexism detection in social media videos,sexism is generally defined as prejudice and discrimination based on sex or gender affecting every sector of society from social institutions to relationships and individual behavior social media platforms amplify the impact of sexism by conveying discriminatory content not only through text but also across multiple modalities highlighting the critical need for a multimodal approach to the analysis of sexism online with the rise of social media platforms where users share short videos sexism is increasingly spreading through video content automatically detecting sexism in videos is a challenging task as it requires analyzing the combination of verbal audio and visual elements to identify sexist content in this study we introduce mused a new multimodal spanish dataset for sexism detection consisting of hours of videos extracted from tiktok and bitchute we propose an innovative annotation framework for analyzing the contribution of textual and multimodal labels in the classification of sexist and non sexist content and we evaluate a range of large language models llms and multimodal llms on the task of sexism detection we find that visual information plays a key role in labeling sexist content for both humans and models models effectively detect explicit sexism however they struggle with implicit cases such as stereotypes instances where annotators also show low agreement this highlights the inherent difficulty of the task as identifying implicit sexism depends on the social and cultural context,"['mused', 'a', 'multimodal', 'spanish', 'dataset', 'for', 'sexism', 'detection', 'in', 'social', 'media', 'videos']","['sexism', 'is', 'generally', 'defined', 'as', 'prejudice', 'and', 'discrimination', 'based', 'on', 'sex', 'or', 'gender', 'affecting', 'every', 'sector', 'of', 'society', 'from', 'social', 'institutions', 'to', 'relationships', 'and', 'individual', 'behavior', 'social', 'media', 'platforms', 'amplify', 'the', 'impact', 'of', 'sexism', 'by', 'conveying', 'discriminatory', 'content', 'not', 'only', 'through', 'text', 'but', 'also', 'across', 'multiple', 'modalities', 'highlighting', 'the', 'critical', 'need', 'for', 'a', 'multimodal', 'approach', 'to', 'the', 'analysis', 'of', 'sexism', 'online', 'with', 'the', 'rise', 'of', 'social', 'media', 'platforms', 'where', 'users', 'share', 'short', 'videos', 'sexism', 'is', 'increasingly', 'spreading', 'through', 'video', 'content', 'automatically', 'detecting', 'sexism', 'in', 'videos', 'is', 'a', 'challenging', 'task', 'as', 'it', 'requires', 'analyzing', 'the', 'combination', 'of', 'verbal', 'audio', 'and', 'visual', 'elements', 'to', 'identify', 'sexist', 'content', 'in', 'this', 'study', 'we', 'introduce', 'mused', 'a', 'new', 'multimodal', 'spanish', 'dataset', 'for', 'sexism', 'detection', 'consisting', 'of', 'hours', 'of', 'videos', 'extracted', 'from', 'tiktok', 'and', 'bitchute', 'we', 'propose', 'an', 'innovative', 'annotation', 'framework', 'for', 'analyzing', 'the', 'contribution', 'of', 'textual', 'and', 'multimodal', 'labels', 'in', 'the', 'classification', 'of', 'sexist', 'and', 'non', 'sexist', 'content', 'and', 'we', 'evaluate', 'a', 'range', 'of', 'large', 'language', 'models', 'llms', 'and', 'multimodal', 'llms', 'on', 'the', 'task', 'of', 'sexism', 'detection', 'we', 'find', 'that', 'visual', 'information', 'plays', 'a', 'key', 'role', 'in', 'labeling', 'sexist', 'content', 'for', 'both', 'humans', 'and', 'models', 'models', 'effectively', 'detect', 'explicit', 'sexism', 'however', 'they', 'struggle', 'with', 'implicit', 'cases', 'such', 'as', 'stereotypes', 'instances', 'where', 'annotators', 'also', 'show', 'low', 'agreement', 'this', 'highlights', 'the', 'inherent', 'difficulty', 'of', 'the', 'task', 'as', 'identifying', 'implicit', 'sexism', 'depends', 'on', 'the', 'social', 'and', 'cultural', 'context']",12,230,"['Multimodal', 'BitChute', 'LLMs', 'Social', 'Sexism', 'TikTok', 'Models', 'MuSeD', 'Detection', 'Spanish', 'Automatically']"
2504.11159v1,C-SHAP for time series: An approach to high-level temporal explanations,"Time series are ubiquitous in domains such as energy forecasting, healthcare, and industry. Using AI systems, some tasks within these domains can be efficiently handled. Explainable AI (XAI) aims to increase the reliability of AI solutions by explaining model reasoning. For time series, many XAI methods provide point- or sequence-based attribution maps. These methods explain model reasoning in terms of low-level patterns. However, they do not capture high-level patterns that may also influence model reasoning. We propose a concept-based method to provide explanations in terms of these high-level patterns. In this paper, we present C-SHAP for time series, an approach which determines the contribution of concepts to a model outcome. We provide a general definition of C-SHAP and present an example implementation using time series decomposition. Additionally, we demonstrate the effectiveness of the methodology through a use case from the energy domain.","Annemarie Jutte, Faizan Ahmed, Jeroen Linssen, Maurice van Keulen",cs.AI,2025-04-15T13:06:32Z,http://arxiv.org/abs/2504.11159v1,c shap for time series an approach to high level temporal explanations,time series are ubiquitous in domains such as energy forecasting healthcare and industry using ai systems some tasks within these domains can be efficiently handled explainable ai xai aims to increase the reliability of ai solutions by explaining model reasoning for time series many xai methods provide point or sequence based attribution maps these methods explain model reasoning in terms of low level patterns however they do not capture high level patterns that may also influence model reasoning we propose a concept based method to provide explanations in terms of these high level patterns in this paper we present c shap for time series an approach which determines the contribution of concepts to a model outcome we provide a general definition of c shap and present an example implementation using time series decomposition additionally we demonstrate the effectiveness of the methodology through a use case from the energy domain,"['c', 'shap', 'for', 'time', 'series', 'an', 'approach', 'to', 'high', 'level', 'temporal', 'explanations']","['time', 'series', 'are', 'ubiquitous', 'in', 'domains', 'such', 'as', 'energy', 'forecasting', 'healthcare', 'and', 'industry', 'using', 'ai', 'systems', 'some', 'tasks', 'within', 'these', 'domains', 'can', 'be', 'efficiently', 'handled', 'explainable', 'ai', 'xai', 'aims', 'to', 'increase', 'the', 'reliability', 'of', 'ai', 'solutions', 'by', 'explaining', 'model', 'reasoning', 'for', 'time', 'series', 'many', 'xai', 'methods', 'provide', 'point', 'or', 'sequence', 'based', 'attribution', 'maps', 'these', 'methods', 'explain', 'model', 'reasoning', 'in', 'terms', 'of', 'low', 'level', 'patterns', 'however', 'they', 'do', 'not', 'capture', 'high', 'level', 'patterns', 'that', 'may', 'also', 'influence', 'model', 'reasoning', 'we', 'propose', 'a', 'concept', 'based', 'method', 'to', 'provide', 'explanations', 'in', 'terms', 'of', 'these', 'high', 'level', 'patterns', 'in', 'this', 'paper', 'we', 'present', 'c', 'shap', 'for', 'time', 'series', 'an', 'approach', 'which', 'determines', 'the', 'contribution', 'of', 'concepts', 'to', 'a', 'model', 'outcome', 'we', 'provide', 'a', 'general', 'definition', 'of', 'c', 'shap', 'and', 'present', 'an', 'example', 'implementation', 'using', 'time', 'series', 'decomposition', 'additionally', 'we', 'demonstrate', 'the', 'effectiveness', 'of', 'the', 'methodology', 'through', 'a', 'use', 'case', 'from', 'the', 'energy', 'domain']",12,149,"['XAI', 'However', 'These', 'Explainable', 'Additionally', 'C-SHAP', 'Time']"
2504.11109v1,Fine-Tuning Large Language Models on Quantum Optimization Problems for   Circuit Generation,"Large language models (LLM) have achieved remarkable outcomes in addressing complex problems, including math, coding, and analyzing large amounts of scientific reports. Yet few works have explored the potential of LLM in quantum computing. The most challenging problem is how to leverage LLMs to automatically generate quantum circuits at a large scale. In this paper, we address such a challenge by fine-tuning LLMs and injecting the domain-specific knowledge of quantum computing. In particular, we investigate the mechanisms to generate training data sets and construct the end-to-end pipeline to fine-tune pre-trained LLMs that produce parameterized quantum circuits for optimization problems. We have prepared 14,000 quantum circuits covering a substantial part of the quantum optimization landscape: 12 optimization problem instances and their optimized QAOA, VQE, and adaptive VQE circuits. The fine-tuned LLMs can construct syntactically correct parametrized quantum circuits in the most recent OpenQASM 3.0. We have evaluated the quality of the parameters by comparing them to the optimized expectation values and distributions. Our evaluation shows that the fine-tuned LLM outperforms state-of-the-art models and that the parameters are better than random. The LLM-generated parametrized circuits and initial parameters can be used as a starting point for further optimization, \emph{e.g.,} templates in quantum machine learning and the benchmark for compilers and hardware.","Linus Jern, Valter Uotila, Cong Yu, Bo Zhao","quant-ph, cs.AI",2025-04-15T11:56:54Z,http://arxiv.org/abs/2504.11109v1,fine tuning large language models on quantum optimization problems for circuit generation,large language models llm have achieved remarkable outcomes in addressing complex problems including math coding and analyzing large amounts of scientific reports yet few works have explored the potential of llm in quantum computing the most challenging problem is how to leverage llms to automatically generate quantum circuits at a large scale in this paper we address such a challenge by fine tuning llms and injecting the domain specific knowledge of quantum computing in particular we investigate the mechanisms to generate training data sets and construct the end to end pipeline to fine tune pre trained llms that produce parameterized quantum circuits for optimization problems we have prepared quantum circuits covering a substantial part of the quantum optimization landscape optimization problem instances and their optimized qaoa vqe and adaptive vqe circuits the fine tuned llms can construct syntactically correct parametrized quantum circuits in the most recent openqasm we have evaluated the quality of the parameters by comparing them to the optimized expectation values and distributions our evaluation shows that the fine tuned llm outperforms state of the art models and that the parameters are better than random the llm generated parametrized circuits and initial parameters can be used as a starting point for further optimization e g templates in quantum machine learning and the benchmark for compilers and hardware,"['fine', 'tuning', 'large', 'language', 'models', 'on', 'quantum', 'optimization', 'problems', 'for', 'circuit', 'generation']","['large', 'language', 'models', 'llm', 'have', 'achieved', 'remarkable', 'outcomes', 'in', 'addressing', 'complex', 'problems', 'including', 'math', 'coding', 'and', 'analyzing', 'large', 'amounts', 'of', 'scientific', 'reports', 'yet', 'few', 'works', 'have', 'explored', 'the', 'potential', 'of', 'llm', 'in', 'quantum', 'computing', 'the', 'most', 'challenging', 'problem', 'is', 'how', 'to', 'leverage', 'llms', 'to', 'automatically', 'generate', 'quantum', 'circuits', 'at', 'a', 'large', 'scale', 'in', 'this', 'paper', 'we', 'address', 'such', 'a', 'challenge', 'by', 'fine', 'tuning', 'llms', 'and', 'injecting', 'the', 'domain', 'specific', 'knowledge', 'of', 'quantum', 'computing', 'in', 'particular', 'we', 'investigate', 'the', 'mechanisms', 'to', 'generate', 'training', 'data', 'sets', 'and', 'construct', 'the', 'end', 'to', 'end', 'pipeline', 'to', 'fine', 'tune', 'pre', 'trained', 'llms', 'that', 'produce', 'parameterized', 'quantum', 'circuits', 'for', 'optimization', 'problems', 'we', 'have', 'prepared', 'quantum', 'circuits', 'covering', 'a', 'substantial', 'part', 'of', 'the', 'quantum', 'optimization', 'landscape', 'optimization', 'problem', 'instances', 'and', 'their', 'optimized', 'qaoa', 'vqe', 'and', 'adaptive', 'vqe', 'circuits', 'the', 'fine', 'tuned', 'llms', 'can', 'construct', 'syntactically', 'correct', 'parametrized', 'quantum', 'circuits', 'in', 'the', 'most', 'recent', 'openqasm', 'we', 'have', 'evaluated', 'the', 'quality', 'of', 'the', 'parameters', 'by', 'comparing', 'them', 'to', 'the', 'optimized', 'expectation', 'values', 'and', 'distributions', 'our', 'evaluation', 'shows', 'that', 'the', 'fine', 'tuned', 'llm', 'outperforms', 'state', 'of', 'the', 'art', 'models', 'and', 'that', 'the', 'parameters', 'are', 'better', 'than', 'random', 'the', 'llm', 'generated', 'parametrized', 'circuits', 'and', 'initial', 'parameters', 'can', 'be', 'used', 'as', 'a', 'starting', 'point', 'for', 'further', 'optimization', 'e', 'g', 'templates', 'in', 'quantum', 'machine', 'learning', 'and', 'the', 'benchmark', 'for', 'compilers', 'and', 'hardware']",12,219,"['LLM-generated', 'QAOA', '000', 'LLMs', 'Yet', 'VQE', 'OpenQASM', 'Our', 'Large', 'LLM']"
2504.11091v1,AI-guided Antibiotic Discovery Pipeline from Target Selection to   Compound Identification,"Antibiotic resistance presents a growing global health crisis, demanding new therapeutic strategies that target novel bacterial mechanisms. Recent advances in protein structure prediction and machine learning-driven molecule generation offer a promising opportunity to accelerate drug discovery. However, practical guidance on selecting and integrating these models into real-world pipelines remains limited. In this study, we develop an end-to-end, artificial intelligence-guided antibiotic discovery pipeline that spans target identification to compound realization. We leverage structure-based clustering across predicted proteomes of multiple pathogens to identify conserved, essential, and non-human-homologous targets. We then systematically evaluate six leading 3D-structure-aware generative models$\unicode{x2014}$spanning diffusion, autoregressive, graph neural network, and language model architectures$\unicode{x2014}$on their usability, chemical validity, and biological relevance. Rigorous post-processing filters and commercial analogue searches reduce over 100 000 generated compounds to a focused, synthesizable set. Our results highlight DeepBlock and TamGen as top performers across diverse criteria, while also revealing critical trade-offs between model complexity, usability, and output quality. This work provides a comparative benchmark and blueprint for deploying artificial intelligence in early-stage antibiotic development.","Maximilian G. Schuh, Joshua Hesse, Stephan A. Sieber","q-bio.BM, cs.AI, cs.LG",2025-04-15T11:36:27Z,http://arxiv.org/abs/2504.11091v1,ai guided antibiotic discovery pipeline from target selection to compound identification,antibiotic resistance presents a growing global health crisis demanding new therapeutic strategies that target novel bacterial mechanisms recent advances in protein structure prediction and machine learning driven molecule generation offer a promising opportunity to accelerate drug discovery however practical guidance on selecting and integrating these models into real world pipelines remains limited in this study we develop an end to end artificial intelligence guided antibiotic discovery pipeline that spans target identification to compound realization we leverage structure based clustering across predicted proteomes of multiple pathogens to identify conserved essential and non human homologous targets we then systematically evaluate six leading d structure aware generative models x spanning diffusion autoregressive graph neural network and language model architectures x on their usability chemical validity and biological relevance rigorous post processing filters and commercial analogue searches reduce over generated compounds to a focused synthesizable set our results highlight deepblock and tamgen as top performers across diverse criteria while also revealing critical trade offs between model complexity usability and output quality this work provides a comparative benchmark and blueprint for deploying artificial intelligence in early stage antibiotic development,"['ai', 'guided', 'antibiotic', 'discovery', 'pipeline', 'from', 'target', 'selection', 'to', 'compound', 'identification']","['antibiotic', 'resistance', 'presents', 'a', 'growing', 'global', 'health', 'crisis', 'demanding', 'new', 'therapeutic', 'strategies', 'that', 'target', 'novel', 'bacterial', 'mechanisms', 'recent', 'advances', 'in', 'protein', 'structure', 'prediction', 'and', 'machine', 'learning', 'driven', 'molecule', 'generation', 'offer', 'a', 'promising', 'opportunity', 'to', 'accelerate', 'drug', 'discovery', 'however', 'practical', 'guidance', 'on', 'selecting', 'and', 'integrating', 'these', 'models', 'into', 'real', 'world', 'pipelines', 'remains', 'limited', 'in', 'this', 'study', 'we', 'develop', 'an', 'end', 'to', 'end', 'artificial', 'intelligence', 'guided', 'antibiotic', 'discovery', 'pipeline', 'that', 'spans', 'target', 'identification', 'to', 'compound', 'realization', 'we', 'leverage', 'structure', 'based', 'clustering', 'across', 'predicted', 'proteomes', 'of', 'multiple', 'pathogens', 'to', 'identify', 'conserved', 'essential', 'and', 'non', 'human', 'homologous', 'targets', 'we', 'then', 'systematically', 'evaluate', 'six', 'leading', 'd', 'structure', 'aware', 'generative', 'models', 'x', 'spanning', 'diffusion', 'autoregressive', 'graph', 'neural', 'network', 'and', 'language', 'model', 'architectures', 'x', 'on', 'their', 'usability', 'chemical', 'validity', 'and', 'biological', 'relevance', 'rigorous', 'post', 'processing', 'filters', 'and', 'commercial', 'analogue', 'searches', 'reduce', 'over', 'generated', 'compounds', 'to', 'a', 'focused', 'synthesizable', 'set', 'our', 'results', 'highlight', 'deepblock', 'and', 'tamgen', 'as', 'top', 'performers', 'across', 'diverse', 'criteria', 'while', 'also', 'revealing', 'critical', 'trade', 'offs', 'between', 'model', 'complexity', 'usability', 'and', 'output', 'quality', 'this', 'work', 'provides', 'a', 'comparative', 'benchmark', 'and', 'blueprint', 'for', 'deploying', 'artificial', 'intelligence', 'in', 'early', 'stage', 'antibiotic', 'development']",11,184,"['Recent', '000', '3D-structure', 'However', 'TamGen', 'Our', 'DeepBlock', 'Antibiotic', 'Rigorous', '100']"
2504.11075v1,Emergence of Goal-Directed Behaviors via Active Inference with   Self-Prior,"Infants often exhibit goal-directed behaviors, such as reaching for a sensory stimulus, even when no external reward criterion is provided. These intrinsically motivated behaviors facilitate spontaneous exploration and learning of the body and environment during early developmental stages. Although computational modeling can offer insight into the mechanisms underlying such behaviors, many existing studies on intrinsic motivation focus primarily on how exploration contributes to acquiring external rewards. In this paper, we propose a novel density model for an agent's own multimodal sensory experiences, called the ""self-prior,"" and investigate whether it can autonomously induce goal-directed behavior. Integrated within an active inference framework based on the free energy principle, the self-prior generates behavioral references purely from an intrinsic process that minimizes mismatches between average past sensory experiences and current observations. This mechanism is also analogous to the acquisition and utilization of a body schema through continuous interaction with the environment. We examine this approach in a simulated environment and confirm that the agent spontaneously reaches toward a tactile stimulus. Our study implements intrinsically motivated behavior shaped by the agent's own sensory experiences, demonstrating the spontaneous emergence of intentional behavior during early development.","Dongmin Kim, Hoshinori Kanazawa, Naoto Yoshida, Yasuo Kuniyoshi","cs.AI, 68T05, 68T40, 68T42, I.2.0; I.2.6; I.2.9",2025-04-15T11:16:27Z,http://arxiv.org/abs/2504.11075v1,emergence of goal directed behaviors via active inference with self prior,infants often exhibit goal directed behaviors such as reaching for a sensory stimulus even when no external reward criterion is provided these intrinsically motivated behaviors facilitate spontaneous exploration and learning of the body and environment during early developmental stages although computational modeling can offer insight into the mechanisms underlying such behaviors many existing studies on intrinsic motivation focus primarily on how exploration contributes to acquiring external rewards in this paper we propose a novel density model for an agent s own multimodal sensory experiences called the self prior and investigate whether it can autonomously induce goal directed behavior integrated within an active inference framework based on the free energy principle the self prior generates behavioral references purely from an intrinsic process that minimizes mismatches between average past sensory experiences and current observations this mechanism is also analogous to the acquisition and utilization of a body schema through continuous interaction with the environment we examine this approach in a simulated environment and confirm that the agent spontaneously reaches toward a tactile stimulus our study implements intrinsically motivated behavior shaped by the agent s own sensory experiences demonstrating the spontaneous emergence of intentional behavior during early development,"['emergence', 'of', 'goal', 'directed', 'behaviors', 'via', 'active', 'inference', 'with', 'self', 'prior']","['infants', 'often', 'exhibit', 'goal', 'directed', 'behaviors', 'such', 'as', 'reaching', 'for', 'a', 'sensory', 'stimulus', 'even', 'when', 'no', 'external', 'reward', 'criterion', 'is', 'provided', 'these', 'intrinsically', 'motivated', 'behaviors', 'facilitate', 'spontaneous', 'exploration', 'and', 'learning', 'of', 'the', 'body', 'and', 'environment', 'during', 'early', 'developmental', 'stages', 'although', 'computational', 'modeling', 'can', 'offer', 'insight', 'into', 'the', 'mechanisms', 'underlying', 'such', 'behaviors', 'many', 'existing', 'studies', 'on', 'intrinsic', 'motivation', 'focus', 'primarily', 'on', 'how', 'exploration', 'contributes', 'to', 'acquiring', 'external', 'rewards', 'in', 'this', 'paper', 'we', 'propose', 'a', 'novel', 'density', 'model', 'for', 'an', 'agent', 's', 'own', 'multimodal', 'sensory', 'experiences', 'called', 'the', 'self', 'prior', 'and', 'investigate', 'whether', 'it', 'can', 'autonomously', 'induce', 'goal', 'directed', 'behavior', 'integrated', 'within', 'an', 'active', 'inference', 'framework', 'based', 'on', 'the', 'free', 'energy', 'principle', 'the', 'self', 'prior', 'generates', 'behavioral', 'references', 'purely', 'from', 'an', 'intrinsic', 'process', 'that', 'minimizes', 'mismatches', 'between', 'average', 'past', 'sensory', 'experiences', 'and', 'current', 'observations', 'this', 'mechanism', 'is', 'also', 'analogous', 'to', 'the', 'acquisition', 'and', 'utilization', 'of', 'a', 'body', 'schema', 'through', 'continuous', 'interaction', 'with', 'the', 'environment', 'we', 'examine', 'this', 'approach', 'in', 'a', 'simulated', 'environment', 'and', 'confirm', 'that', 'the', 'agent', 'spontaneously', 'reaches', 'toward', 'a', 'tactile', 'stimulus', 'our', 'study', 'implements', 'intrinsically', 'motivated', 'behavior', 'shaped', 'by', 'the', 'agent', 's', 'own', 'sensory', 'experiences', 'demonstrating', 'the', 'spontaneous', 'emergence', 'of', 'intentional', 'behavior', 'during', 'early', 'development']",11,195,"['Integrated', 'These', 'Although', 'Our', 'Infants']"
2504.11038v1,QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models,"In typical multimodal tasks, such as Visual Question Answering (VQA), adversarial attacks targeting a specific image and question can lead large vision-language models (LVLMs) to provide incorrect answers. However, it is common for a single image to be associated with multiple questions, and LVLMs may still answer other questions correctly even for an adversarial image attacked by a specific question. To address this, we introduce the query-agnostic visual attack (QAVA), which aims to create robust adversarial examples that generate incorrect responses to unspecified and unknown questions. Compared to traditional adversarial attacks focused on specific images and questions, QAVA significantly enhances the effectiveness and efficiency of attacks on images when the question is unknown, achieving performance comparable to attacks on known target questions. Our research broadens the scope of visual adversarial attacks on LVLMs in practical settings, uncovering previously overlooked vulnerabilities, particularly in the context of visual adversarial threats. The code is available at https://github.com/btzyd/qava.","Yudong Zhang, Ruobing Xie, Jiansheng Chen, Xingwu Sun, Zhanhui Kang, Yu Wang","cs.CV, cs.AI",2025-04-15T10:00:01Z,http://arxiv.org/abs/2504.11038v1,qava query agnostic visual attack to large vision language models,in typical multimodal tasks such as visual question answering vqa adversarial attacks targeting a specific image and question can lead large vision language models lvlms to provide incorrect answers however it is common for a single image to be associated with multiple questions and lvlms may still answer other questions correctly even for an adversarial image attacked by a specific question to address this we introduce the query agnostic visual attack qava which aims to create robust adversarial examples that generate incorrect responses to unspecified and unknown questions compared to traditional adversarial attacks focused on specific images and questions qava significantly enhances the effectiveness and efficiency of attacks on images when the question is unknown achieving performance comparable to attacks on known target questions our research broadens the scope of visual adversarial attacks on lvlms in practical settings uncovering previously overlooked vulnerabilities particularly in the context of visual adversarial threats the code is available at,"['qava', 'query', 'agnostic', 'visual', 'attack', 'to', 'large', 'vision', 'language', 'models']","['in', 'typical', 'multimodal', 'tasks', 'such', 'as', 'visual', 'question', 'answering', 'vqa', 'adversarial', 'attacks', 'targeting', 'a', 'specific', 'image', 'and', 'question', 'can', 'lead', 'large', 'vision', 'language', 'models', 'lvlms', 'to', 'provide', 'incorrect', 'answers', 'however', 'it', 'is', 'common', 'for', 'a', 'single', 'image', 'to', 'be', 'associated', 'with', 'multiple', 'questions', 'and', 'lvlms', 'may', 'still', 'answer', 'other', 'questions', 'correctly', 'even', 'for', 'an', 'adversarial', 'image', 'attacked', 'by', 'a', 'specific', 'question', 'to', 'address', 'this', 'we', 'introduce', 'the', 'query', 'agnostic', 'visual', 'attack', 'qava', 'which', 'aims', 'to', 'create', 'robust', 'adversarial', 'examples', 'that', 'generate', 'incorrect', 'responses', 'to', 'unspecified', 'and', 'unknown', 'questions', 'compared', 'to', 'traditional', 'adversarial', 'attacks', 'focused', 'on', 'specific', 'images', 'and', 'questions', 'qava', 'significantly', 'enhances', 'the', 'effectiveness', 'and', 'efficiency', 'of', 'attacks', 'on', 'images', 'when', 'the', 'question', 'is', 'unknown', 'achieving', 'performance', 'comparable', 'to', 'attacks', 'on', 'known', 'target', 'questions', 'our', 'research', 'broadens', 'the', 'scope', 'of', 'visual', 'adversarial', 'attacks', 'on', 'lvlms', 'in', 'practical', 'settings', 'uncovering', 'previously', 'overlooked', 'vulnerabilities', 'particularly', 'in', 'the', 'context', 'of', 'visual', 'adversarial', 'threats', 'the', 'code', 'is', 'available', 'at']",10,155,"['QAVA', 'Compared', 'Visual', 'LVLMs', 'However', 'VQA', 'Question', 'Answering', 'Our']"
2504.11014v2,GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*,"The emerging trend in computer vision emphasizes developing universal models capable of simultaneously addressing multiple diverse tasks. Such universality typically requires joint training across multi-domain datasets to ensure effective generalization. However, monocular 3D object detection presents unique challenges in multi-domain training due to the scarcity of datasets annotated with accurate 3D ground-truth labels, especially beyond typical road-based autonomous driving contexts. To address this challenge, we introduce a novel weakly supervised framework leveraging pseudo-labels. Current pretrained models often struggle to accurately detect pedestrians in non-road environments due to inherent dataset biases. Unlike generalized image-based 2D object detection models, achieving similar generalization in monocular 3D detection remains largely unexplored. In this paper, we propose GATE3D, a novel framework designed specifically for generalized monocular 3D object detection via weak supervision. GATE3D effectively bridges domain gaps by employing consistency losses between 2D and 3D predictions. Remarkably, our model achieves competitive performance on the KITTI benchmark as well as on an indoor-office dataset collected by us to evaluate the generalization capabilities of our framework. Our results demonstrate that GATE3D significantly accelerates learning from limited annotated data through effective pre-training strategies, highlighting substantial potential for broader impacts in robotics, augmented reality, and virtual reality applications. Project page: https://ies0411.github.io/GATE3D/","Eunsoo Im, Jung Kwon Lee, Changhyun Jee","cs.CV, cs.AI",2025-04-15T09:37:54Z,http://arxiv.org/abs/2504.11014v2,gate d generalized attention based task synergized estimation in d,the emerging trend in computer vision emphasizes developing universal models capable of simultaneously addressing multiple diverse tasks such universality typically requires joint training across multi domain datasets to ensure effective generalization however monocular d object detection presents unique challenges in multi domain training due to the scarcity of datasets annotated with accurate d ground truth labels especially beyond typical road based autonomous driving contexts to address this challenge we introduce a novel weakly supervised framework leveraging pseudo labels current pretrained models often struggle to accurately detect pedestrians in non road environments due to inherent dataset biases unlike generalized image based d object detection models achieving similar generalization in monocular d detection remains largely unexplored in this paper we propose gate d a novel framework designed specifically for generalized monocular d object detection via weak supervision gate d effectively bridges domain gaps by employing consistency losses between d and d predictions remarkably our model achieves competitive performance on the kitti benchmark as well as on an indoor office dataset collected by us to evaluate the generalization capabilities of our framework our results demonstrate that gate d significantly accelerates learning from limited annotated data through effective pre training strategies highlighting substantial potential for broader impacts in robotics augmented reality and virtual reality applications project page,"['gate', 'd', 'generalized', 'attention', 'based', 'task', 'synergized', 'estimation', 'in', 'd']","['the', 'emerging', 'trend', 'in', 'computer', 'vision', 'emphasizes', 'developing', 'universal', 'models', 'capable', 'of', 'simultaneously', 'addressing', 'multiple', 'diverse', 'tasks', 'such', 'universality', 'typically', 'requires', 'joint', 'training', 'across', 'multi', 'domain', 'datasets', 'to', 'ensure', 'effective', 'generalization', 'however', 'monocular', 'd', 'object', 'detection', 'presents', 'unique', 'challenges', 'in', 'multi', 'domain', 'training', 'due', 'to', 'the', 'scarcity', 'of', 'datasets', 'annotated', 'with', 'accurate', 'd', 'ground', 'truth', 'labels', 'especially', 'beyond', 'typical', 'road', 'based', 'autonomous', 'driving', 'contexts', 'to', 'address', 'this', 'challenge', 'we', 'introduce', 'a', 'novel', 'weakly', 'supervised', 'framework', 'leveraging', 'pseudo', 'labels', 'current', 'pretrained', 'models', 'often', 'struggle', 'to', 'accurately', 'detect', 'pedestrians', 'in', 'non', 'road', 'environments', 'due', 'to', 'inherent', 'dataset', 'biases', 'unlike', 'generalized', 'image', 'based', 'd', 'object', 'detection', 'models', 'achieving', 'similar', 'generalization', 'in', 'monocular', 'd', 'detection', 'remains', 'largely', 'unexplored', 'in', 'this', 'paper', 'we', 'propose', 'gate', 'd', 'a', 'novel', 'framework', 'designed', 'specifically', 'for', 'generalized', 'monocular', 'd', 'object', 'detection', 'via', 'weak', 'supervision', 'gate', 'd', 'effectively', 'bridges', 'domain', 'gaps', 'by', 'employing', 'consistency', 'losses', 'between', 'd', 'and', 'd', 'predictions', 'remarkably', 'our', 'model', 'achieves', 'competitive', 'performance', 'on', 'the', 'kitti', 'benchmark', 'as', 'well', 'as', 'on', 'an', 'indoor', 'office', 'dataset', 'collected', 'by', 'us', 'to', 'evaluate', 'the', 'generalization', 'capabilities', 'of', 'our', 'framework', 'our', 'results', 'demonstrate', 'that', 'gate', 'd', 'significantly', 'accelerates', 'learning', 'from', 'limited', 'annotated', 'data', 'through', 'effective', 'pre', 'training', 'strategies', 'highlighting', 'substantial', 'potential', 'for', 'broader', 'impacts', 'in', 'robotics', 'augmented', 'reality', 'and', 'virtual', 'reality', 'applications', 'project', 'page']",10,213,"['KITTI', 'Unlike', 'Such', 'GATE3D', 'Project', 'However', 'Remarkably', 'Our', 'Current']"
2504.11008v1,MediSee: Reasoning-based Pixel-level Perception in Medical Images,"Despite remarkable advancements in pixel-level medical image perception, existing methods are either limited to specific tasks or heavily rely on accurate bounding boxes or text labels as input prompts. However, the medical knowledge required for input is a huge obstacle for general public, which greatly reduces the universality of these methods. Compared with these domain-specialized auxiliary information, general users tend to rely on oral queries that require logical reasoning. In this paper, we introduce a novel medical vision task: Medical Reasoning Segmentation and Detection (MedSD), which aims to comprehend implicit queries about medical images and generate the corresponding segmentation mask and bounding box for the target object. To accomplish this task, we first introduce a Multi-perspective, Logic-driven Medical Reasoning Segmentation and Detection (MLMR-SD) dataset, which encompasses a substantial collection of medical entity targets along with their corresponding reasoning. Furthermore, we propose MediSee, an effective baseline model designed for medical reasoning segmentation and detection. The experimental results indicate that the proposed method can effectively address MedSD with implicit colloquial queries and outperform traditional medical referring segmentation methods.","Qinyue Tong, Ziqian Lu, Jun Liu, Yangming Zheng, Zheming Lu","cs.CV, cs.AI",2025-04-15T09:28:53Z,http://arxiv.org/abs/2504.11008v1,medisee reasoning based pixel level perception in medical images,despite remarkable advancements in pixel level medical image perception existing methods are either limited to specific tasks or heavily rely on accurate bounding boxes or text labels as input prompts however the medical knowledge required for input is a huge obstacle for general public which greatly reduces the universality of these methods compared with these domain specialized auxiliary information general users tend to rely on oral queries that require logical reasoning in this paper we introduce a novel medical vision task medical reasoning segmentation and detection medsd which aims to comprehend implicit queries about medical images and generate the corresponding segmentation mask and bounding box for the target object to accomplish this task we first introduce a multi perspective logic driven medical reasoning segmentation and detection mlmr sd dataset which encompasses a substantial collection of medical entity targets along with their corresponding reasoning furthermore we propose medisee an effective baseline model designed for medical reasoning segmentation and detection the experimental results indicate that the proposed method can effectively address medsd with implicit colloquial queries and outperform traditional medical referring segmentation methods,"['medisee', 'reasoning', 'based', 'pixel', 'level', 'perception', 'in', 'medical', 'images']","['despite', 'remarkable', 'advancements', 'in', 'pixel', 'level', 'medical', 'image', 'perception', 'existing', 'methods', 'are', 'either', 'limited', 'to', 'specific', 'tasks', 'or', 'heavily', 'rely', 'on', 'accurate', 'bounding', 'boxes', 'or', 'text', 'labels', 'as', 'input', 'prompts', 'however', 'the', 'medical', 'knowledge', 'required', 'for', 'input', 'is', 'a', 'huge', 'obstacle', 'for', 'general', 'public', 'which', 'greatly', 'reduces', 'the', 'universality', 'of', 'these', 'methods', 'compared', 'with', 'these', 'domain', 'specialized', 'auxiliary', 'information', 'general', 'users', 'tend', 'to', 'rely', 'on', 'oral', 'queries', 'that', 'require', 'logical', 'reasoning', 'in', 'this', 'paper', 'we', 'introduce', 'a', 'novel', 'medical', 'vision', 'task', 'medical', 'reasoning', 'segmentation', 'and', 'detection', 'medsd', 'which', 'aims', 'to', 'comprehend', 'implicit', 'queries', 'about', 'medical', 'images', 'and', 'generate', 'the', 'corresponding', 'segmentation', 'mask', 'and', 'bounding', 'box', 'for', 'the', 'target', 'object', 'to', 'accomplish', 'this', 'task', 'we', 'first', 'introduce', 'a', 'multi', 'perspective', 'logic', 'driven', 'medical', 'reasoning', 'segmentation', 'and', 'detection', 'mlmr', 'sd', 'dataset', 'which', 'encompasses', 'a', 'substantial', 'collection', 'of', 'medical', 'entity', 'targets', 'along', 'with', 'their', 'corresponding', 'reasoning', 'furthermore', 'we', 'propose', 'medisee', 'an', 'effective', 'baseline', 'model', 'designed', 'for', 'medical', 'reasoning', 'segmentation', 'and', 'detection', 'the', 'experimental', 'results', 'indicate', 'that', 'the', 'proposed', 'method', 'can', 'effectively', 'address', 'medsd', 'with', 'implicit', 'colloquial', 'queries', 'and', 'outperform', 'traditional', 'medical', 'referring', 'segmentation', 'methods']",9,181,"['Reasoning', 'Compared', 'Multi', 'MLMR-SD', 'Despite', 'Logic', 'However', 'Detection', 'Furthermore', 'Segmentation', 'Medical', 'MedSD', 'MediSee']"
2504.10983v1,ProtFlow: Fast Protein Sequence Design via Flow Matching on Compressed   Protein Language Model Embeddings,"The design of protein sequences with desired functionalities is a fundamental task in protein engineering. Deep generative methods, such as autoregressive models and diffusion models, have greatly accelerated the discovery of novel protein sequences. However, these methods mainly focus on local or shallow residual semantics and suffer from low inference efficiency, large modeling space and high training cost. To address these challenges, we introduce ProtFlow, a fast flow matching-based protein sequence design framework that operates on embeddings derived from semantically meaningful latent space of protein language models. By compressing and smoothing the latent space, ProtFlow enhances performance while training on limited computational resources. Leveraging reflow techniques, ProtFlow enables high-quality single-step sequence generation. Additionally, we develop a joint design pipeline for the design scene of multichain proteins. We evaluate ProtFlow across diverse protein design tasks, including general peptides and long-chain proteins, antimicrobial peptides, and antibodies. Experimental results demonstrate that ProtFlow outperforms task-specific methods in these applications, underscoring its potential and broad applicability in computational protein sequence design and analysis.","Zitai Kong, Yiheng Zhu, Yinlong Xu, Hanjing Zhou, Mingzhe Yin, Jialu Wu, Hongxia Xu, Chang-Yu Hsieh, Tingjun Hou, Jian Wu","cs.LG, cs.AI, q-bio.BM",2025-04-15T08:46:53Z,http://arxiv.org/abs/2504.10983v1,protflow fast protein sequence design via flow matching on compressed protein language model embeddings,the design of protein sequences with desired functionalities is a fundamental task in protein engineering deep generative methods such as autoregressive models and diffusion models have greatly accelerated the discovery of novel protein sequences however these methods mainly focus on local or shallow residual semantics and suffer from low inference efficiency large modeling space and high training cost to address these challenges we introduce protflow a fast flow matching based protein sequence design framework that operates on embeddings derived from semantically meaningful latent space of protein language models by compressing and smoothing the latent space protflow enhances performance while training on limited computational resources leveraging reflow techniques protflow enables high quality single step sequence generation additionally we develop a joint design pipeline for the design scene of multichain proteins we evaluate protflow across diverse protein design tasks including general peptides and long chain proteins antimicrobial peptides and antibodies experimental results demonstrate that protflow outperforms task specific methods in these applications underscoring its potential and broad applicability in computational protein sequence design and analysis,"['protflow', 'fast', 'protein', 'sequence', 'design', 'via', 'flow', 'matching', 'on', 'compressed', 'protein', 'language', 'model', 'embeddings']","['the', 'design', 'of', 'protein', 'sequences', 'with', 'desired', 'functionalities', 'is', 'a', 'fundamental', 'task', 'in', 'protein', 'engineering', 'deep', 'generative', 'methods', 'such', 'as', 'autoregressive', 'models', 'and', 'diffusion', 'models', 'have', 'greatly', 'accelerated', 'the', 'discovery', 'of', 'novel', 'protein', 'sequences', 'however', 'these', 'methods', 'mainly', 'focus', 'on', 'local', 'or', 'shallow', 'residual', 'semantics', 'and', 'suffer', 'from', 'low', 'inference', 'efficiency', 'large', 'modeling', 'space', 'and', 'high', 'training', 'cost', 'to', 'address', 'these', 'challenges', 'we', 'introduce', 'protflow', 'a', 'fast', 'flow', 'matching', 'based', 'protein', 'sequence', 'design', 'framework', 'that', 'operates', 'on', 'embeddings', 'derived', 'from', 'semantically', 'meaningful', 'latent', 'space', 'of', 'protein', 'language', 'models', 'by', 'compressing', 'and', 'smoothing', 'the', 'latent', 'space', 'protflow', 'enhances', 'performance', 'while', 'training', 'on', 'limited', 'computational', 'resources', 'leveraging', 'reflow', 'techniques', 'protflow', 'enables', 'high', 'quality', 'single', 'step', 'sequence', 'generation', 'additionally', 'we', 'develop', 'a', 'joint', 'design', 'pipeline', 'for', 'the', 'design', 'scene', 'of', 'multichain', 'proteins', 'we', 'evaluate', 'protflow', 'across', 'diverse', 'protein', 'design', 'tasks', 'including', 'general', 'peptides', 'and', 'long', 'chain', 'proteins', 'antimicrobial', 'peptides', 'and', 'antibodies', 'experimental', 'results', 'demonstrate', 'that', 'protflow', 'outperforms', 'task', 'specific', 'methods', 'in', 'these', 'applications', 'underscoring', 'its', 'potential', 'and', 'broad', 'applicability', 'in', 'computational', 'protein', 'sequence', 'design', 'and', 'analysis']",14,173,"['Leveraging', 'Experimental', 'ProtFlow', 'However', 'Deep', 'Additionally']"
2504.10982v3,Exploring the Role of Knowledge Graph-Based RAG in Japanese Medical   Question Answering with Small-Scale LLMs,"Large language models (LLMs) perform well in medical QA, but their effectiveness in Japanese contexts is limited due to privacy constraints that prevent the use of commercial models like GPT-4 in clinical settings. As a result, recent efforts focus on instruction-tuning open-source LLMs, though the potential of combining them with retrieval-augmented generation (RAG) remains underexplored. To bridge this gap, we are the first to explore a knowledge graph-based (KG) RAG framework for Japanese medical QA small-scale open-source LLMs. Experimental results show that KG-based RAG has only a limited impact on Japanese medical QA using small-scale open-source LLMs. Further case studies reveal that the effectiveness of the RAG is sensitive to the quality and relevance of the external retrieved content. These findings offer valuable insights into the challenges and potential of applying RAG in Japanese medical QA, while also serving as a reference for other low-resource languages.","Yingjian Chen, Feiyang Li, Xingyu Song, Tianxiao Li, Issey Sukeda, Irene Li","cs.CL, cs.AI",2025-04-15T08:46:39Z,http://arxiv.org/abs/2504.10982v3,exploring the role of knowledge graph based rag in japanese medical question answering with small scale llms,large language models llms perform well in medical qa but their effectiveness in japanese contexts is limited due to privacy constraints that prevent the use of commercial models like gpt in clinical settings as a result recent efforts focus on instruction tuning open source llms though the potential of combining them with retrieval augmented generation rag remains underexplored to bridge this gap we are the first to explore a knowledge graph based kg rag framework for japanese medical qa small scale open source llms experimental results show that kg based rag has only a limited impact on japanese medical qa using small scale open source llms further case studies reveal that the effectiveness of the rag is sensitive to the quality and relevance of the external retrieved content these findings offer valuable insights into the challenges and potential of applying rag in japanese medical qa while also serving as a reference for other low resource languages,"['exploring', 'the', 'role', 'of', 'knowledge', 'graph', 'based', 'rag', 'in', 'japanese', 'medical', 'question', 'answering', 'with', 'small', 'scale', 'llms']","['large', 'language', 'models', 'llms', 'perform', 'well', 'in', 'medical', 'qa', 'but', 'their', 'effectiveness', 'in', 'japanese', 'contexts', 'is', 'limited', 'due', 'to', 'privacy', 'constraints', 'that', 'prevent', 'the', 'use', 'of', 'commercial', 'models', 'like', 'gpt', 'in', 'clinical', 'settings', 'as', 'a', 'result', 'recent', 'efforts', 'focus', 'on', 'instruction', 'tuning', 'open', 'source', 'llms', 'though', 'the', 'potential', 'of', 'combining', 'them', 'with', 'retrieval', 'augmented', 'generation', 'rag', 'remains', 'underexplored', 'to', 'bridge', 'this', 'gap', 'we', 'are', 'the', 'first', 'to', 'explore', 'a', 'knowledge', 'graph', 'based', 'kg', 'rag', 'framework', 'for', 'japanese', 'medical', 'qa', 'small', 'scale', 'open', 'source', 'llms', 'experimental', 'results', 'show', 'that', 'kg', 'based', 'rag', 'has', 'only', 'a', 'limited', 'impact', 'on', 'japanese', 'medical', 'qa', 'using', 'small', 'scale', 'open', 'source', 'llms', 'further', 'case', 'studies', 'reveal', 'that', 'the', 'effectiveness', 'of', 'the', 'rag', 'is', 'sensitive', 'to', 'the', 'quality', 'and', 'relevance', 'of', 'the', 'external', 'retrieved', 'content', 'these', 'findings', 'offer', 'valuable', 'insights', 'into', 'the', 'challenges', 'and', 'potential', 'of', 'applying', 'rag', 'in', 'japanese', 'medical', 'qa', 'while', 'also', 'serving', 'as', 'a', 'reference', 'for', 'other', 'low', 'resource', 'languages']",17,156,"['KG-based', 'Experimental', 'Japanese', 'RAG', 'LLMs', 'Further', 'These', 'GPT-4', 'Large']"
2504.10961v1,"Evaluating Trust in AI, Human, and Co-produced Feedback Among   Undergraduate Students","As generative AI transforms educational feedback practices, understanding students' perceptions of different feedback providers becomes crucial for effective implementation. This study addresses a critical gap by comparing undergraduate students' trust in AI-generated, human-created, and human-AI co-produced feedback, informing how institutions can adapt feedback practices in this new era. Through a within-subject experiment with 91 participants, we investigated factors predicting students' ability to distinguish between feedback types, perception of feedback quality, and potential biases to AI involvement. Findings revealed that students generally preferred AI and co-produced feedback over human feedback in terms of perceived usefulness and objectivity. Only AI feedback suffered a decline in perceived genuineness when feedback sources were revealed, while co-produced feedback maintained its positive perception. Educational AI experience improved students' ability to identify AI feedback and increased their trust in all feedback types, while general AI experience decreased perceived usefulness and credibility. Male students consistently rated all feedback types as less valuable than their female and non-binary counterparts. These insights inform evidence-based guidelines for integrating AI into higher education feedback systems while addressing trust concerns and fostering AI literacy among students.","Audrey Zhang, Yifei Gao, Wannapon Suraworachet, Tanya Nazaretsky, Mutlu Cukurova","cs.HC, cs.AI",2025-04-15T08:06:36Z,http://arxiv.org/abs/2504.10961v1,evaluating trust in ai human and co produced feedback among undergraduate students,as generative ai transforms educational feedback practices understanding students perceptions of different feedback providers becomes crucial for effective implementation this study addresses a critical gap by comparing undergraduate students trust in ai generated human created and human ai co produced feedback informing how institutions can adapt feedback practices in this new era through a within subject experiment with participants we investigated factors predicting students ability to distinguish between feedback types perception of feedback quality and potential biases to ai involvement findings revealed that students generally preferred ai and co produced feedback over human feedback in terms of perceived usefulness and objectivity only ai feedback suffered a decline in perceived genuineness when feedback sources were revealed while co produced feedback maintained its positive perception educational ai experience improved students ability to identify ai feedback and increased their trust in all feedback types while general ai experience decreased perceived usefulness and credibility male students consistently rated all feedback types as less valuable than their female and non binary counterparts these insights inform evidence based guidelines for integrating ai into higher education feedback systems while addressing trust concerns and fostering ai literacy among students,"['evaluating', 'trust', 'in', 'ai', 'human', 'and', 'co', 'produced', 'feedback', 'among', 'undergraduate', 'students']","['as', 'generative', 'ai', 'transforms', 'educational', 'feedback', 'practices', 'understanding', 'students', 'perceptions', 'of', 'different', 'feedback', 'providers', 'becomes', 'crucial', 'for', 'effective', 'implementation', 'this', 'study', 'addresses', 'a', 'critical', 'gap', 'by', 'comparing', 'undergraduate', 'students', 'trust', 'in', 'ai', 'generated', 'human', 'created', 'and', 'human', 'ai', 'co', 'produced', 'feedback', 'informing', 'how', 'institutions', 'can', 'adapt', 'feedback', 'practices', 'in', 'this', 'new', 'era', 'through', 'a', 'within', 'subject', 'experiment', 'with', 'participants', 'we', 'investigated', 'factors', 'predicting', 'students', 'ability', 'to', 'distinguish', 'between', 'feedback', 'types', 'perception', 'of', 'feedback', 'quality', 'and', 'potential', 'biases', 'to', 'ai', 'involvement', 'findings', 'revealed', 'that', 'students', 'generally', 'preferred', 'ai', 'and', 'co', 'produced', 'feedback', 'over', 'human', 'feedback', 'in', 'terms', 'of', 'perceived', 'usefulness', 'and', 'objectivity', 'only', 'ai', 'feedback', 'suffered', 'a', 'decline', 'in', 'perceived', 'genuineness', 'when', 'feedback', 'sources', 'were', 'revealed', 'while', 'co', 'produced', 'feedback', 'maintained', 'its', 'positive', 'perception', 'educational', 'ai', 'experience', 'improved', 'students', 'ability', 'to', 'identify', 'ai', 'feedback', 'and', 'increased', 'their', 'trust', 'in', 'all', 'feedback', 'types', 'while', 'general', 'ai', 'experience', 'decreased', 'perceived', 'usefulness', 'and', 'credibility', 'male', 'students', 'consistently', 'rated', 'all', 'feedback', 'types', 'as', 'less', 'valuable', 'than', 'their', 'female', 'and', 'non', 'binary', 'counterparts', 'these', 'insights', 'inform', 'evidence', 'based', 'guidelines', 'for', 'integrating', 'ai', 'into', 'higher', 'education', 'feedback', 'systems', 'while', 'addressing', 'trust', 'concerns', 'and', 'fostering', 'ai', 'literacy', 'among', 'students']",12,191,"['Only', 'Findings', 'These', 'Educational', 'Male', 'AI-generated', 'Through']"
2504.10917v1,Towards A Universal Graph Structural Encoder,"Recent advancements in large-scale pre-training have shown the potential to learn generalizable representations for downstream tasks. In the graph domain, however, capturing and transferring structural information across different graph domains remains challenging, primarily due to the inherent differences in topological patterns across various contexts. Additionally, most existing models struggle to capture the complexity of rich graph structures, leading to inadequate exploration of the embedding space. To address these challenges, we propose GFSE, a universal graph structural encoder designed to capture transferable structural patterns across diverse domains such as molecular graphs, social networks, and citation networks. GFSE is the first cross-domain graph structural encoder pre-trained with multiple self-supervised learning objectives. Built on a Graph Transformer, GFSE incorporates attention mechanisms informed by graph inductive bias, enabling it to encode intricate multi-level and fine-grained topological features. The pre-trained GFSE produces generic and theoretically expressive positional and structural encoding for graphs, which can be seamlessly integrated with various downstream graph feature encoders, including graph neural networks for vectorized features and Large Language Models for text-attributed graphs. Comprehensive experiments on synthetic and real-world datasets demonstrate GFSE's capability to significantly enhance the model's performance while requiring substantially less task-specific fine-tuning. Notably, GFSE achieves state-of-the-art performance in 81.6% evaluated cases, spanning diverse graph models and datasets, highlighting its potential as a powerful and versatile encoder for graph-structured data.","Jialin Chen, Haolan Zuo, Haoyu Peter Wang, Siqi Miao, Pan Li, Rex Ying","cs.LG, cs.AI",2025-04-15T06:57:26Z,http://arxiv.org/abs/2504.10917v1,towards a universal graph structural encoder,recent advancements in large scale pre training have shown the potential to learn generalizable representations for downstream tasks in the graph domain however capturing and transferring structural information across different graph domains remains challenging primarily due to the inherent differences in topological patterns across various contexts additionally most existing models struggle to capture the complexity of rich graph structures leading to inadequate exploration of the embedding space to address these challenges we propose gfse a universal graph structural encoder designed to capture transferable structural patterns across diverse domains such as molecular graphs social networks and citation networks gfse is the first cross domain graph structural encoder pre trained with multiple self supervised learning objectives built on a graph transformer gfse incorporates attention mechanisms informed by graph inductive bias enabling it to encode intricate multi level and fine grained topological features the pre trained gfse produces generic and theoretically expressive positional and structural encoding for graphs which can be seamlessly integrated with various downstream graph feature encoders including graph neural networks for vectorized features and large language models for text attributed graphs comprehensive experiments on synthetic and real world datasets demonstrate gfse s capability to significantly enhance the model s performance while requiring substantially less task specific fine tuning notably gfse achieves state of the art performance in evaluated cases spanning diverse graph models and datasets highlighting its potential as a powerful and versatile encoder for graph structured data,"['towards', 'a', 'universal', 'graph', 'structural', 'encoder']","['recent', 'advancements', 'in', 'large', 'scale', 'pre', 'training', 'have', 'shown', 'the', 'potential', 'to', 'learn', 'generalizable', 'representations', 'for', 'downstream', 'tasks', 'in', 'the', 'graph', 'domain', 'however', 'capturing', 'and', 'transferring', 'structural', 'information', 'across', 'different', 'graph', 'domains', 'remains', 'challenging', 'primarily', 'due', 'to', 'the', 'inherent', 'differences', 'in', 'topological', 'patterns', 'across', 'various', 'contexts', 'additionally', 'most', 'existing', 'models', 'struggle', 'to', 'capture', 'the', 'complexity', 'of', 'rich', 'graph', 'structures', 'leading', 'to', 'inadequate', 'exploration', 'of', 'the', 'embedding', 'space', 'to', 'address', 'these', 'challenges', 'we', 'propose', 'gfse', 'a', 'universal', 'graph', 'structural', 'encoder', 'designed', 'to', 'capture', 'transferable', 'structural', 'patterns', 'across', 'diverse', 'domains', 'such', 'as', 'molecular', 'graphs', 'social', 'networks', 'and', 'citation', 'networks', 'gfse', 'is', 'the', 'first', 'cross', 'domain', 'graph', 'structural', 'encoder', 'pre', 'trained', 'with', 'multiple', 'self', 'supervised', 'learning', 'objectives', 'built', 'on', 'a', 'graph', 'transformer', 'gfse', 'incorporates', 'attention', 'mechanisms', 'informed', 'by', 'graph', 'inductive', 'bias', 'enabling', 'it', 'to', 'encode', 'intricate', 'multi', 'level', 'and', 'fine', 'grained', 'topological', 'features', 'the', 'pre', 'trained', 'gfse', 'produces', 'generic', 'and', 'theoretically', 'expressive', 'positional', 'and', 'structural', 'encoding', 'for', 'graphs', 'which', 'can', 'be', 'seamlessly', 'integrated', 'with', 'various', 'downstream', 'graph', 'feature', 'encoders', 'including', 'graph', 'neural', 'networks', 'for', 'vectorized', 'features', 'and', 'large', 'language', 'models', 'for', 'text', 'attributed', 'graphs', 'comprehensive', 'experiments', 'on', 'synthetic', 'and', 'real', 'world', 'datasets', 'demonstrate', 'gfse', 's', 'capability', 'to', 'significantly', 'enhance', 'the', 'model', 's', 'performance', 'while', 'requiring', 'substantially', 'less', 'task', 'specific', 'fine', 'tuning', 'notably', 'gfse', 'achieves', 'state', 'of', 'the', 'art', 'performance', 'in', 'evaluated', 'cases', 'spanning', 'diverse', 'graph', 'models', 'and', 'datasets', 'highlighting', 'its', 'potential', 'as', 'a', 'powerful', 'and', 'versatile', 'encoder', 'for', 'graph', 'structured', 'data']",6,238,"['Recent', 'GFSE', 'Comprehensive', 'Built', 'Models', 'Notably', 'Language', 'Transformer', 'Large', 'Graph', 'Additionally']"
2504.10903v1,Efficient Reasoning Models: A Survey,"Reasoning models have demonstrated remarkable progress in solving complex and logic-intensive tasks by generating extended Chain-of-Thoughts (CoTs) prior to arriving at a final answer. Yet, the emergence of this ""slow-thinking"" paradigm, with numerous tokens generated in sequence, inevitably introduces substantial computational overhead. To this end, it highlights an urgent need for effective acceleration. This survey aims to provide a comprehensive overview of recent advances in efficient reasoning. It categorizes existing works into three key directions: (1) shorter - compressing lengthy CoTs into concise yet effective reasoning chains; (2) smaller - developing compact language models with strong reasoning capabilities through techniques such as knowledge distillation, other model compression techniques, and reinforcement learning; and (3) faster - designing efficient decoding strategies to accelerate inference. A curated collection of papers discussed in this survey is available in our GitHub repository.","Sicheng Feng, Gongfan Fang, Xinyin Ma, Xinchao Wang","cs.CL, cs.AI",2025-04-15T06:28:00Z,http://arxiv.org/abs/2504.10903v1,efficient reasoning models a survey,reasoning models have demonstrated remarkable progress in solving complex and logic intensive tasks by generating extended chain of thoughts cots prior to arriving at a final answer yet the emergence of this slow thinking paradigm with numerous tokens generated in sequence inevitably introduces substantial computational overhead to this end it highlights an urgent need for effective acceleration this survey aims to provide a comprehensive overview of recent advances in efficient reasoning it categorizes existing works into three key directions shorter compressing lengthy cots into concise yet effective reasoning chains smaller developing compact language models with strong reasoning capabilities through techniques such as knowledge distillation other model compression techniques and reinforcement learning and faster designing efficient decoding strategies to accelerate inference a curated collection of papers discussed in this survey is available in our github repository,"['efficient', 'reasoning', 'models', 'a', 'survey']","['reasoning', 'models', 'have', 'demonstrated', 'remarkable', 'progress', 'in', 'solving', 'complex', 'and', 'logic', 'intensive', 'tasks', 'by', 'generating', 'extended', 'chain', 'of', 'thoughts', 'cots', 'prior', 'to', 'arriving', 'at', 'a', 'final', 'answer', 'yet', 'the', 'emergence', 'of', 'this', 'slow', 'thinking', 'paradigm', 'with', 'numerous', 'tokens', 'generated', 'in', 'sequence', 'inevitably', 'introduces', 'substantial', 'computational', 'overhead', 'to', 'this', 'end', 'it', 'highlights', 'an', 'urgent', 'need', 'for', 'effective', 'acceleration', 'this', 'survey', 'aims', 'to', 'provide', 'a', 'comprehensive', 'overview', 'of', 'recent', 'advances', 'in', 'efficient', 'reasoning', 'it', 'categorizes', 'existing', 'works', 'into', 'three', 'key', 'directions', 'shorter', 'compressing', 'lengthy', 'cots', 'into', 'concise', 'yet', 'effective', 'reasoning', 'chains', 'smaller', 'developing', 'compact', 'language', 'models', 'with', 'strong', 'reasoning', 'capabilities', 'through', 'techniques', 'such', 'as', 'knowledge', 'distillation', 'other', 'model', 'compression', 'techniques', 'and', 'reinforcement', 'learning', 'and', 'faster', 'designing', 'efficient', 'decoding', 'strategies', 'to', 'accelerate', 'inference', 'a', 'curated', 'collection', 'of', 'papers', 'discussed', 'in', 'this', 'survey', 'is', 'available', 'in', 'our', 'github', 'repository']",5,135,"['Reasoning', 'Chain', 'Yet', 'GitHub', 'Thoughts', 'CoTs']"
2504.10898v1,Xpose: Bi-directional Engineering for Hidden Query Extraction,"Query reverse engineering (QRE) aims to synthesize a SQL query to connect a given database and result instance. A recent variation of QRE is where an additional input, an opaque executable containing a ground-truth query, is provided, and the goal is to non-invasively extract this specific query through only input-output examples. This variant, called Hidden Query Extraction (HQE), has a spectrum of industrial use-cases including query recovery, database security, and vendor migration. The reverse engineering (RE) tools developed for HQE, which are based on database mutation and generation techniques, can only extract flat queries with key-based equi joins and conjunctive arithmetic filter predicates, making them limited wrt both query structure and query operators. In this paper, we present Xpose, a HQE solution that elevates the extraction scope to realistic complex queries, such as those found in the TPCH benchmark. A two-pronged approach is taken: (1) The existing RE scope is substantially extended to incorporate union connectors, algebraic filter predicates, and disjunctions for both values and predicates. (2) The predictive power of LLMs is leveraged to convert business descriptions of the opaque application into extraction guidance, representing ``forward engineering"" (FE). The FE module recognizes common constructs, such as nesting of sub-queries, outer joins, and scalar functions. In essence, FE establishes the broad query contours, while RE fleshes out the fine-grained details. We have evaluated Xpose on (a) E-TPCH, a query suite comprising the complete TPCH benchmark extended with queries featuring unions, diverse join types, and sub-queries; and (b) the real-world STACK benchmark. The experimental results demonstrate that its bi-directional engineering approach accurately extracts these complex queries, representing a significant step forward with regard to HQE coverage.","Ahana Pradhan, Jayant Haritsa","cs.DB, cs.AI, H.2.8",2025-04-15T06:17:58Z,http://arxiv.org/abs/2504.10898v1,xpose bi directional engineering for hidden query extraction,query reverse engineering qre aims to synthesize a sql query to connect a given database and result instance a recent variation of qre is where an additional input an opaque executable containing a ground truth query is provided and the goal is to non invasively extract this specific query through only input output examples this variant called hidden query extraction hqe has a spectrum of industrial use cases including query recovery database security and vendor migration the reverse engineering re tools developed for hqe which are based on database mutation and generation techniques can only extract flat queries with key based equi joins and conjunctive arithmetic filter predicates making them limited wrt both query structure and query operators in this paper we present xpose a hqe solution that elevates the extraction scope to realistic complex queries such as those found in the tpch benchmark a two pronged approach is taken the existing re scope is substantially extended to incorporate union connectors algebraic filter predicates and disjunctions for both values and predicates the predictive power of llms is leveraged to convert business descriptions of the opaque application into extraction guidance representing forward engineering fe the fe module recognizes common constructs such as nesting of sub queries outer joins and scalar functions in essence fe establishes the broad query contours while re fleshes out the fine grained details we have evaluated xpose on a e tpch a query suite comprising the complete tpch benchmark extended with queries featuring unions diverse join types and sub queries and b the real world stack benchmark the experimental results demonstrate that its bi directional engineering approach accurately extracts these complex queries representing a significant step forward with regard to hqe coverage,"['xpose', 'bi', 'directional', 'engineering', 'for', 'hidden', 'query', 'extraction']","['query', 'reverse', 'engineering', 'qre', 'aims', 'to', 'synthesize', 'a', 'sql', 'query', 'to', 'connect', 'a', 'given', 'database', 'and', 'result', 'instance', 'a', 'recent', 'variation', 'of', 'qre', 'is', 'where', 'an', 'additional', 'input', 'an', 'opaque', 'executable', 'containing', 'a', 'ground', 'truth', 'query', 'is', 'provided', 'and', 'the', 'goal', 'is', 'to', 'non', 'invasively', 'extract', 'this', 'specific', 'query', 'through', 'only', 'input', 'output', 'examples', 'this', 'variant', 'called', 'hidden', 'query', 'extraction', 'hqe', 'has', 'a', 'spectrum', 'of', 'industrial', 'use', 'cases', 'including', 'query', 'recovery', 'database', 'security', 'and', 'vendor', 'migration', 'the', 'reverse', 'engineering', 're', 'tools', 'developed', 'for', 'hqe', 'which', 'are', 'based', 'on', 'database', 'mutation', 'and', 'generation', 'techniques', 'can', 'only', 'extract', 'flat', 'queries', 'with', 'key', 'based', 'equi', 'joins', 'and', 'conjunctive', 'arithmetic', 'filter', 'predicates', 'making', 'them', 'limited', 'wrt', 'both', 'query', 'structure', 'and', 'query', 'operators', 'in', 'this', 'paper', 'we', 'present', 'xpose', 'a', 'hqe', 'solution', 'that', 'elevates', 'the', 'extraction', 'scope', 'to', 'realistic', 'complex', 'queries', 'such', 'as', 'those', 'found', 'in', 'the', 'tpch', 'benchmark', 'a', 'two', 'pronged', 'approach', 'is', 'taken', 'the', 'existing', 're', 'scope', 'is', 'substantially', 'extended', 'to', 'incorporate', 'union', 'connectors', 'algebraic', 'filter', 'predicates', 'and', 'disjunctions', 'for', 'both', 'values', 'and', 'predicates', 'the', 'predictive', 'power', 'of', 'llms', 'is', 'leveraged', 'to', 'convert', 'business', 'descriptions', 'of', 'the', 'opaque', 'application', 'into', 'extraction', 'guidance', 'representing', 'forward', 'engineering', 'fe', 'the', 'fe', 'module', 'recognizes', 'common', 'constructs', 'such', 'as', 'nesting', 'of', 'sub', 'queries', 'outer', 'joins', 'and', 'scalar', 'functions', 'in', 'essence', 'fe', 'establishes', 'the', 'broad', 'query', 'contours', 'while', 're', 'fleshes', 'out', 'the', 'fine', 'grained', 'details', 'we', 'have', 'evaluated', 'xpose', 'on', 'a', 'e', 'tpch', 'a', 'query', 'suite', 'comprising', 'the', 'complete', 'tpch', 'benchmark', 'extended', 'with', 'queries', 'featuring', 'unions', 'diverse', 'join', 'types', 'and', 'sub', 'queries', 'and', 'b', 'the', 'real', 'world', 'stack', 'benchmark', 'the', 'experimental', 'results', 'demonstrate', 'that', 'its', 'bi', 'directional', 'engineering', 'approach', 'accurately', 'extracts', 'these', 'complex', 'queries', 'representing', 'a', 'significant', 'step', 'forward', 'with', 'regard', 'to', 'hqe', 'coverage']",8,285,"['QRE', 'Xpose', 'LLMs', 'STACK', 'TPCH', 'Hidden', 'Extraction', 'SQL', 'HQE', 'E-TPCH', 'Query']"
2504.10893v1,ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search,"Large language models (LLMs) have demonstrated impressive capabilities and are receiving increasing attention to enhance their reasoning through scaling test--time compute. However, their application in open--ended, knowledge--intensive, complex reasoning scenarios is still limited. Reasoning--oriented methods struggle to generalize to open--ended scenarios due to implicit assumptions of complete world knowledge. Meanwhile, knowledge--augmented reasoning (KAR) methods fail to address two core challenges: 1) error propagation, where errors in early steps cascade through the chain, and 2) verification bottleneck, where the explore--exploit tradeoff arises in multi--branch decision processes. To overcome these limitations, we introduce ARise, a novel framework that integrates risk assessment of intermediate reasoning states with dynamic retrieval--augmented generation (RAG) within a Monte Carlo tree search paradigm. This approach enables effective construction and optimization of reasoning plans across multiple maintained hypothesis branches. Experimental results show that ARise significantly outperforms the state--of--the--art KAR methods by up to 23.10%, and the latest RAG-equipped large reasoning models by up to 25.37%.","Yize Zhang, Tianshu Wang, Sirui Chen, Kun Wang, Xingyu Zeng, Hongyu Lin, Xianpei Han, Le Sun, Chaochao Lu","cs.AI, cs.CL",2025-04-15T06:06:50Z,http://arxiv.org/abs/2504.10893v1,arise towards knowledge augmented reasoning via risk adaptive search,large language models llms have demonstrated impressive capabilities and are receiving increasing attention to enhance their reasoning through scaling test time compute however their application in open ended knowledge intensive complex reasoning scenarios is still limited reasoning oriented methods struggle to generalize to open ended scenarios due to implicit assumptions of complete world knowledge meanwhile knowledge augmented reasoning kar methods fail to address two core challenges error propagation where errors in early steps cascade through the chain and verification bottleneck where the explore exploit tradeoff arises in multi branch decision processes to overcome these limitations we introduce arise a novel framework that integrates risk assessment of intermediate reasoning states with dynamic retrieval augmented generation rag within a monte carlo tree search paradigm this approach enables effective construction and optimization of reasoning plans across multiple maintained hypothesis branches experimental results show that arise significantly outperforms the state of the art kar methods by up to and the latest rag equipped large reasoning models by up to,"['arise', 'towards', 'knowledge', 'augmented', 'reasoning', 'via', 'risk', 'adaptive', 'search']","['large', 'language', 'models', 'llms', 'have', 'demonstrated', 'impressive', 'capabilities', 'and', 'are', 'receiving', 'increasing', 'attention', 'to', 'enhance', 'their', 'reasoning', 'through', 'scaling', 'test', 'time', 'compute', 'however', 'their', 'application', 'in', 'open', 'ended', 'knowledge', 'intensive', 'complex', 'reasoning', 'scenarios', 'is', 'still', 'limited', 'reasoning', 'oriented', 'methods', 'struggle', 'to', 'generalize', 'to', 'open', 'ended', 'scenarios', 'due', 'to', 'implicit', 'assumptions', 'of', 'complete', 'world', 'knowledge', 'meanwhile', 'knowledge', 'augmented', 'reasoning', 'kar', 'methods', 'fail', 'to', 'address', 'two', 'core', 'challenges', 'error', 'propagation', 'where', 'errors', 'in', 'early', 'steps', 'cascade', 'through', 'the', 'chain', 'and', 'verification', 'bottleneck', 'where', 'the', 'explore', 'exploit', 'tradeoff', 'arises', 'in', 'multi', 'branch', 'decision', 'processes', 'to', 'overcome', 'these', 'limitations', 'we', 'introduce', 'arise', 'a', 'novel', 'framework', 'that', 'integrates', 'risk', 'assessment', 'of', 'intermediate', 'reasoning', 'states', 'with', 'dynamic', 'retrieval', 'augmented', 'generation', 'rag', 'within', 'a', 'monte', 'carlo', 'tree', 'search', 'paradigm', 'this', 'approach', 'enables', 'effective', 'construction', 'and', 'optimization', 'of', 'reasoning', 'plans', 'across', 'multiple', 'maintained', 'hypothesis', 'branches', 'experimental', 'results', 'show', 'that', 'arise', 'significantly', 'outperforms', 'the', 'state', 'of', 'the', 'art', 'kar', 'methods', 'by', 'up', 'to', 'and', 'the', 'latest', 'rag', 'equipped', 'large', 'reasoning', 'models', 'by', 'up', 'to']",9,165,"['Reasoning', 'Experimental', 'Carlo', 'RAG', 'LLMs', 'However', 'Meanwhile', 'ARise', 'KAR', 'Monte', 'RAG-equipped', 'Large']"
2504.10888v1,CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal   Visible-Infrared Detectors,"Adversarial patches are widely used to evaluate the robustness of object detection systems in real-world scenarios. These patches were initially designed to deceive single-modal detectors (e.g., visible or infrared) and have recently been extended to target visible-infrared dual-modal detectors. However, existing dual-modal adversarial patch attacks have limited attack effectiveness across diverse physical scenarios. To address this, we propose CDUPatch, a universal cross-modal patch attack against visible-infrared object detectors across scales, views, and scenarios. Specifically, we observe that color variations lead to different levels of thermal absorption, resulting in temperature differences in infrared imaging. Leveraging this property, we propose an RGB-to-infrared adapter that maps RGB patches to infrared patches, enabling unified optimization of cross-modal patches. By learning an optimal color distribution on the adversarial patch, we can manipulate its thermal response and generate an adversarial infrared texture. Additionally, we introduce a multi-scale clipping strategy and construct a new visible-infrared dataset, MSDrone, which contains aerial vehicle images in varying scales and perspectives. These data augmentation strategies enhance the robustness of our patch in real-world conditions. Experiments on four benchmark datasets (e.g., DroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms existing patch attacks in the digital domain. Extensive physical tests further confirm strong transferability across scales, views, and scenarios.","Jiahuan Long, Wen Yao, Tingsong Jiang, Chao Ma","cs.CV, cs.AI",2025-04-15T05:46:00Z,http://arxiv.org/abs/2504.10888v1,cdupatch color driven universal adversarial patch attack for dual modal visible infrared detectors,adversarial patches are widely used to evaluate the robustness of object detection systems in real world scenarios these patches were initially designed to deceive single modal detectors e g visible or infrared and have recently been extended to target visible infrared dual modal detectors however existing dual modal adversarial patch attacks have limited attack effectiveness across diverse physical scenarios to address this we propose cdupatch a universal cross modal patch attack against visible infrared object detectors across scales views and scenarios specifically we observe that color variations lead to different levels of thermal absorption resulting in temperature differences in infrared imaging leveraging this property we propose an rgb to infrared adapter that maps rgb patches to infrared patches enabling unified optimization of cross modal patches by learning an optimal color distribution on the adversarial patch we can manipulate its thermal response and generate an adversarial infrared texture additionally we introduce a multi scale clipping strategy and construct a new visible infrared dataset msdrone which contains aerial vehicle images in varying scales and perspectives these data augmentation strategies enhance the robustness of our patch in real world conditions experiments on four benchmark datasets e g dronevehicle llvip visdrone msdrone show that our method outperforms existing patch attacks in the digital domain extensive physical tests further confirm strong transferability across scales views and scenarios,"['cdupatch', 'color', 'driven', 'universal', 'adversarial', 'patch', 'attack', 'for', 'dual', 'modal', 'visible', 'infrared', 'detectors']","['adversarial', 'patches', 'are', 'widely', 'used', 'to', 'evaluate', 'the', 'robustness', 'of', 'object', 'detection', 'systems', 'in', 'real', 'world', 'scenarios', 'these', 'patches', 'were', 'initially', 'designed', 'to', 'deceive', 'single', 'modal', 'detectors', 'e', 'g', 'visible', 'or', 'infrared', 'and', 'have', 'recently', 'been', 'extended', 'to', 'target', 'visible', 'infrared', 'dual', 'modal', 'detectors', 'however', 'existing', 'dual', 'modal', 'adversarial', 'patch', 'attacks', 'have', 'limited', 'attack', 'effectiveness', 'across', 'diverse', 'physical', 'scenarios', 'to', 'address', 'this', 'we', 'propose', 'cdupatch', 'a', 'universal', 'cross', 'modal', 'patch', 'attack', 'against', 'visible', 'infrared', 'object', 'detectors', 'across', 'scales', 'views', 'and', 'scenarios', 'specifically', 'we', 'observe', 'that', 'color', 'variations', 'lead', 'to', 'different', 'levels', 'of', 'thermal', 'absorption', 'resulting', 'in', 'temperature', 'differences', 'in', 'infrared', 'imaging', 'leveraging', 'this', 'property', 'we', 'propose', 'an', 'rgb', 'to', 'infrared', 'adapter', 'that', 'maps', 'rgb', 'patches', 'to', 'infrared', 'patches', 'enabling', 'unified', 'optimization', 'of', 'cross', 'modal', 'patches', 'by', 'learning', 'an', 'optimal', 'color', 'distribution', 'on', 'the', 'adversarial', 'patch', 'we', 'can', 'manipulate', 'its', 'thermal', 'response', 'and', 'generate', 'an', 'adversarial', 'infrared', 'texture', 'additionally', 'we', 'introduce', 'a', 'multi', 'scale', 'clipping', 'strategy', 'and', 'construct', 'a', 'new', 'visible', 'infrared', 'dataset', 'msdrone', 'which', 'contains', 'aerial', 'vehicle', 'images', 'in', 'varying', 'scales', 'and', 'perspectives', 'these', 'data', 'augmentation', 'strategies', 'enhance', 'the', 'robustness', 'of', 'our', 'patch', 'in', 'real', 'world', 'conditions', 'experiments', 'on', 'four', 'benchmark', 'datasets', 'e', 'g', 'dronevehicle', 'llvip', 'visdrone', 'msdrone', 'show', 'that', 'our', 'method', 'outperforms', 'existing', 'patch', 'attacks', 'in', 'the', 'digital', 'domain', 'extensive', 'physical', 'tests', 'further', 'confirm', 'strong', 'transferability', 'across', 'scales', 'views', 'and', 'scenarios']",13,222,"['Adversarial', 'Extensive', 'Leveraging', 'RGB', 'VisDrone', 'These', 'However', 'MSDrone', 'DroneVehicle', 'Additionally', 'Specifically', 'CDUPatch', 'LLVIP', 'Experiments', 'RGB-to']"
2504.10885v1,PuzzleBench: A Fully Dynamic Evaluation Framework for Large Multimodal   Models on Puzzle Solving,"Large Multimodal Models (LMMs) have demonstrated impressive capabilities across a wide range of multimodal tasks, achieving ever-increasing performance on various evaluation benchmarks. However, existing benchmarks are typically static and often overlap with pre-training datasets, leading to fixed complexity constraints and substantial data contamination issues. Meanwhile, manually annotated datasets are labor-intensive, time-consuming, and subject to human bias and inconsistency, leading to reliability and reproducibility issues. To address these problems, we propose a fully dynamic multimodal evaluation framework, named Open-ended Visual Puzzle Generation (OVPG), which aims to generate fresh, diverse, and verifiable evaluation data automatically in puzzle-solving tasks. Specifically, the OVPG pipeline consists of a raw material sampling module, a visual content generation module, and a puzzle rule design module, which ensures that each evaluation instance is primitive, highly randomized, and uniquely solvable, enabling continual adaptation to the evolving capabilities of LMMs. Built upon OVPG, we construct PuzzleBench, a dynamic and scalable benchmark comprising 11,840 VQA samples. It features six carefully designed puzzle tasks targeting three core LMM competencies, visual recognition, logical reasoning, and context understanding. PuzzleBench differs from static benchmarks that quickly become outdated. It enables ongoing dataset refreshing through OVPG and a rich set of open-ended puzzle designs, allowing seamless adaptation to the evolving capabilities of LMMs.","Zeyu Zhang, Zijian Chen, Zicheng Zhang, Yuze Sun, Yuan Tian, Ziheng Jia, Chunyi Li, Xiaohong Liu, Xiongkuo Min, Guangtao Zhai","cs.CV, cs.AI",2025-04-15T05:29:31Z,http://arxiv.org/abs/2504.10885v1,puzzlebench a fully dynamic evaluation framework for large multimodal models on puzzle solving,large multimodal models lmms have demonstrated impressive capabilities across a wide range of multimodal tasks achieving ever increasing performance on various evaluation benchmarks however existing benchmarks are typically static and often overlap with pre training datasets leading to fixed complexity constraints and substantial data contamination issues meanwhile manually annotated datasets are labor intensive time consuming and subject to human bias and inconsistency leading to reliability and reproducibility issues to address these problems we propose a fully dynamic multimodal evaluation framework named open ended visual puzzle generation ovpg which aims to generate fresh diverse and verifiable evaluation data automatically in puzzle solving tasks specifically the ovpg pipeline consists of a raw material sampling module a visual content generation module and a puzzle rule design module which ensures that each evaluation instance is primitive highly randomized and uniquely solvable enabling continual adaptation to the evolving capabilities of lmms built upon ovpg we construct puzzlebench a dynamic and scalable benchmark comprising vqa samples it features six carefully designed puzzle tasks targeting three core lmm competencies visual recognition logical reasoning and context understanding puzzlebench differs from static benchmarks that quickly become outdated it enables ongoing dataset refreshing through ovpg and a rich set of open ended puzzle designs allowing seamless adaptation to the evolving capabilities of lmms,"['puzzlebench', 'a', 'fully', 'dynamic', 'evaluation', 'framework', 'for', 'large', 'multimodal', 'models', 'on', 'puzzle', 'solving']","['large', 'multimodal', 'models', 'lmms', 'have', 'demonstrated', 'impressive', 'capabilities', 'across', 'a', 'wide', 'range', 'of', 'multimodal', 'tasks', 'achieving', 'ever', 'increasing', 'performance', 'on', 'various', 'evaluation', 'benchmarks', 'however', 'existing', 'benchmarks', 'are', 'typically', 'static', 'and', 'often', 'overlap', 'with', 'pre', 'training', 'datasets', 'leading', 'to', 'fixed', 'complexity', 'constraints', 'and', 'substantial', 'data', 'contamination', 'issues', 'meanwhile', 'manually', 'annotated', 'datasets', 'are', 'labor', 'intensive', 'time', 'consuming', 'and', 'subject', 'to', 'human', 'bias', 'and', 'inconsistency', 'leading', 'to', 'reliability', 'and', 'reproducibility', 'issues', 'to', 'address', 'these', 'problems', 'we', 'propose', 'a', 'fully', 'dynamic', 'multimodal', 'evaluation', 'framework', 'named', 'open', 'ended', 'visual', 'puzzle', 'generation', 'ovpg', 'which', 'aims', 'to', 'generate', 'fresh', 'diverse', 'and', 'verifiable', 'evaluation', 'data', 'automatically', 'in', 'puzzle', 'solving', 'tasks', 'specifically', 'the', 'ovpg', 'pipeline', 'consists', 'of', 'a', 'raw', 'material', 'sampling', 'module', 'a', 'visual', 'content', 'generation', 'module', 'and', 'a', 'puzzle', 'rule', 'design', 'module', 'which', 'ensures', 'that', 'each', 'evaluation', 'instance', 'is', 'primitive', 'highly', 'randomized', 'and', 'uniquely', 'solvable', 'enabling', 'continual', 'adaptation', 'to', 'the', 'evolving', 'capabilities', 'of', 'lmms', 'built', 'upon', 'ovpg', 'we', 'construct', 'puzzlebench', 'a', 'dynamic', 'and', 'scalable', 'benchmark', 'comprising', 'vqa', 'samples', 'it', 'features', 'six', 'carefully', 'designed', 'puzzle', 'tasks', 'targeting', 'three', 'core', 'lmm', 'competencies', 'visual', 'recognition', 'logical', 'reasoning', 'and', 'context', 'understanding', 'puzzlebench', 'differs', 'from', 'static', 'benchmarks', 'that', 'quickly', 'become', 'outdated', 'it', 'enables', 'ongoing', 'dataset', 'refreshing', 'through', 'ovpg', 'and', 'a', 'rich', 'set', 'of', 'open', 'ended', 'puzzle', 'designs', 'allowing', 'seamless', 'adaptation', 'to', 'the', 'evolving', 'capabilities', 'of', 'lmms']",13,213,"['PuzzleBench', 'LMMs', 'Multimodal', 'Visual', 'OVPG', 'Built', 'However', 'Open', 'Puzzle', 'Models', 'Meanwhile', 'VQA', 'LMM', 'Specifically', 'Generation', 'Large', '840']"
2504.10883v1,Bringing together invertible UNets with invertible attention modules for   memory-efficient diffusion models,"Diffusion models have recently gained state of the art performance on many image generation tasks. However, most models require significant computational resources to achieve this. This becomes apparent in the application of medical image synthesis due to the 3D nature of medical datasets like CT-scans, MRIs, electron microscope, etc. In this paper we propose a novel architecture for a single GPU memory-efficient training for diffusion models for high dimensional medical datasets. The proposed model is built by using an invertible UNet architecture with invertible attention modules. This leads to the following two contributions: 1. denoising diffusion models and thus enabling memory usage to be independent of the dimensionality of the dataset, and 2. reducing the energy usage during training. While this new model can be applied to a multitude of image generation tasks, we showcase its memory-efficiency on the 3D BraTS2020 dataset leading to up to 15\% decrease in peak memory consumption during training with comparable results to SOTA while maintaining the image quality.","Karan Jain, Mohammad Nayeem Teli","cs.CV, cs.AI",2025-04-15T05:26:42Z,http://arxiv.org/abs/2504.10883v1,bringing together invertible unets with invertible attention modules for memory efficient diffusion models,diffusion models have recently gained state of the art performance on many image generation tasks however most models require significant computational resources to achieve this this becomes apparent in the application of medical image synthesis due to the d nature of medical datasets like ct scans mris electron microscope etc in this paper we propose a novel architecture for a single gpu memory efficient training for diffusion models for high dimensional medical datasets the proposed model is built by using an invertible unet architecture with invertible attention modules this leads to the following two contributions denoising diffusion models and thus enabling memory usage to be independent of the dimensionality of the dataset and reducing the energy usage during training while this new model can be applied to a multitude of image generation tasks we showcase its memory efficiency on the d brats dataset leading to up to decrease in peak memory consumption during training with comparable results to sota while maintaining the image quality,"['bringing', 'together', 'invertible', 'unets', 'with', 'invertible', 'attention', 'modules', 'for', 'memory', 'efficient', 'diffusion', 'models']","['diffusion', 'models', 'have', 'recently', 'gained', 'state', 'of', 'the', 'art', 'performance', 'on', 'many', 'image', 'generation', 'tasks', 'however', 'most', 'models', 'require', 'significant', 'computational', 'resources', 'to', 'achieve', 'this', 'this', 'becomes', 'apparent', 'in', 'the', 'application', 'of', 'medical', 'image', 'synthesis', 'due', 'to', 'the', 'd', 'nature', 'of', 'medical', 'datasets', 'like', 'ct', 'scans', 'mris', 'electron', 'microscope', 'etc', 'in', 'this', 'paper', 'we', 'propose', 'a', 'novel', 'architecture', 'for', 'a', 'single', 'gpu', 'memory', 'efficient', 'training', 'for', 'diffusion', 'models', 'for', 'high', 'dimensional', 'medical', 'datasets', 'the', 'proposed', 'model', 'is', 'built', 'by', 'using', 'an', 'invertible', 'unet', 'architecture', 'with', 'invertible', 'attention', 'modules', 'this', 'leads', 'to', 'the', 'following', 'two', 'contributions', 'denoising', 'diffusion', 'models', 'and', 'thus', 'enabling', 'memory', 'usage', 'to', 'be', 'independent', 'of', 'the', 'dimensionality', 'of', 'the', 'dataset', 'and', 'reducing', 'the', 'energy', 'usage', 'during', 'training', 'while', 'this', 'new', 'model', 'can', 'be', 'applied', 'to', 'a', 'multitude', 'of', 'image', 'generation', 'tasks', 'we', 'showcase', 'its', 'memory', 'efficiency', 'on', 'the', 'd', 'brats', 'dataset', 'leading', 'to', 'up', 'to', 'decrease', 'in', 'peak', 'memory', 'consumption', 'during', 'training', 'with', 'comparable', 'results', 'to', 'sota', 'while', 'maintaining', 'the', 'image', 'quality']",13,164,"['Diffusion', 'SOTA', 'UNet', 'While', 'However', 'MRIs', 'BraTS2020', 'CT-scans', 'GPU']"
2504.10873v1,Can Vision-Language Models Understand and Interpret Dynamic Gestures   from Pedestrians? Pilot Datasets and Exploration Towards Instructive   Nonverbal Commands for Cooperative Autonomous Vehicles,"In autonomous driving, it is crucial to correctly interpret traffic gestures (TGs), such as those of an authority figure providing orders or instructions, or a pedestrian signaling the driver, to ensure a safe and pleasant traffic environment for all road users. This study investigates the capabilities of state-of-the-art vision-language models (VLMs) in zero-shot interpretation, focusing on their ability to caption and classify human gestures in traffic contexts. We create and publicly share two custom datasets with varying formal and informal TGs, such as 'Stop', 'Reverse', 'Hail', etc. The datasets are ""Acted TG (ATG)"" and ""Instructive TG In-The-Wild (ITGI)"". They are annotated with natural language, describing the pedestrian's body position and gesture. We evaluate models using three methods utilizing expert-generated captions as baseline and control: (1) caption similarity, (2) gesture classification, and (3) pose sequence reconstruction similarity. Results show that current VLMs struggle with gesture understanding: sentence similarity averages below 0.59, and classification F1 scores reach only 0.14-0.39, well below the expert baseline of 0.70. While pose reconstruction shows potential, it requires more data and refined metrics to be reliable. Our findings reveal that although some SOTA VLMs can interpret zero-shot human traffic gestures, none are accurate and robust enough to be trustworthy, emphasizing the need for further research in this domain.","Tonko E. W. Bossen, Andreas M√∏gelmose, Ross Greer","cs.CV, cs.AI, cs.HC",2025-04-15T05:04:25Z,http://arxiv.org/abs/2504.10873v1,can vision language models understand and interpret dynamic gestures from pedestrians pilot datasets and exploration towards instructive nonverbal commands for cooperative autonomous vehicles,in autonomous driving it is crucial to correctly interpret traffic gestures tgs such as those of an authority figure providing orders or instructions or a pedestrian signaling the driver to ensure a safe and pleasant traffic environment for all road users this study investigates the capabilities of state of the art vision language models vlms in zero shot interpretation focusing on their ability to caption and classify human gestures in traffic contexts we create and publicly share two custom datasets with varying formal and informal tgs such as stop reverse hail etc the datasets are acted tg atg and instructive tg in the wild itgi they are annotated with natural language describing the pedestrian s body position and gesture we evaluate models using three methods utilizing expert generated captions as baseline and control caption similarity gesture classification and pose sequence reconstruction similarity results show that current vlms struggle with gesture understanding sentence similarity averages below and classification f scores reach only well below the expert baseline of while pose reconstruction shows potential it requires more data and refined metrics to be reliable our findings reveal that although some sota vlms can interpret zero shot human traffic gestures none are accurate and robust enough to be trustworthy emphasizing the need for further research in this domain,"['can', 'vision', 'language', 'models', 'understand', 'and', 'interpret', 'dynamic', 'gestures', 'from', 'pedestrians', 'pilot', 'datasets', 'and', 'exploration', 'towards', 'instructive', 'nonverbal', 'commands', 'for', 'cooperative', 'autonomous', 'vehicles']","['in', 'autonomous', 'driving', 'it', 'is', 'crucial', 'to', 'correctly', 'interpret', 'traffic', 'gestures', 'tgs', 'such', 'as', 'those', 'of', 'an', 'authority', 'figure', 'providing', 'orders', 'or', 'instructions', 'or', 'a', 'pedestrian', 'signaling', 'the', 'driver', 'to', 'ensure', 'a', 'safe', 'and', 'pleasant', 'traffic', 'environment', 'for', 'all', 'road', 'users', 'this', 'study', 'investigates', 'the', 'capabilities', 'of', 'state', 'of', 'the', 'art', 'vision', 'language', 'models', 'vlms', 'in', 'zero', 'shot', 'interpretation', 'focusing', 'on', 'their', 'ability', 'to', 'caption', 'and', 'classify', 'human', 'gestures', 'in', 'traffic', 'contexts', 'we', 'create', 'and', 'publicly', 'share', 'two', 'custom', 'datasets', 'with', 'varying', 'formal', 'and', 'informal', 'tgs', 'such', 'as', 'stop', 'reverse', 'hail', 'etc', 'the', 'datasets', 'are', 'acted', 'tg', 'atg', 'and', 'instructive', 'tg', 'in', 'the', 'wild', 'itgi', 'they', 'are', 'annotated', 'with', 'natural', 'language', 'describing', 'the', 'pedestrian', 's', 'body', 'position', 'and', 'gesture', 'we', 'evaluate', 'models', 'using', 'three', 'methods', 'utilizing', 'expert', 'generated', 'captions', 'as', 'baseline', 'and', 'control', 'caption', 'similarity', 'gesture', 'classification', 'and', 'pose', 'sequence', 'reconstruction', 'similarity', 'results', 'show', 'that', 'current', 'vlms', 'struggle', 'with', 'gesture', 'understanding', 'sentence', 'similarity', 'averages', 'below', 'and', 'classification', 'f', 'scores', 'reach', 'only', 'well', 'below', 'the', 'expert', 'baseline', 'of', 'while', 'pose', 'reconstruction', 'shows', 'potential', 'it', 'requires', 'more', 'data', 'and', 'refined', 'metrics', 'to', 'be', 'reliable', 'our', 'findings', 'reveal', 'that', 'although', 'some', 'sota', 'vlms', 'can', 'interpret', 'zero', 'shot', 'human', 'traffic', 'gestures', 'none', 'are', 'accurate', 'and', 'robust', 'enough', 'to', 'be', 'trustworthy', 'emphasizing', 'the', 'need', 'for', 'further', 'research', 'in', 'this', 'domain']",23,215,"['Acted', 'Instructive', 'Our', 'SOTA', 'While', 'TGs', 'Hail', 'Results', '14-0', 'Stop', 'Wild', 'ATG', 'Reverse', 'ITGI', 'VLMs']"
2504.10845v1,Moving Beyond Next-Token Prediction: Transformers are Context-Sensitive   Language Generators,"Large Language Models (LLMs), powered by Transformers, have demonstrated human-like intelligence capabilities, yet their underlying mechanisms remain poorly understood. This paper presents a novel framework for interpreting LLMs as probabilistic left context-sensitive languages (CSLs) generators. We hypothesize that Transformers can be effectively decomposed into three fundamental components: context windows, attention mechanisms, and autoregressive generation frameworks. This decomposition allows for the development of more flexible and interpretable computational models, moving beyond the traditional view of attention and autoregression as inseparable processes. We argue that next-token predictions can be understood as probabilistic, dynamic approximations of left CSL production rules, providing an intuitive explanation for how simple token predictions can yield human-like intelligence outputs. Given that all CSLs are left context-sensitive (Penttonen, 1974), we conclude that Transformers stochastically approximate CSLs, which are widely recognized as models of human-like intelligence. This interpretation bridges the gap between Formal Language Theory and the observed generative power of Transformers, laying a foundation for future advancements in generative AI theory and applications. Our novel perspective on Transformer architectures will foster a deeper understanding of LLMs and their future potentials.",Phill Kyu Rhee,"cs.CL, cs.AI",2025-04-15T04:06:27Z,http://arxiv.org/abs/2504.10845v1,moving beyond next token prediction transformers are context sensitive language generators,large language models llms powered by transformers have demonstrated human like intelligence capabilities yet their underlying mechanisms remain poorly understood this paper presents a novel framework for interpreting llms as probabilistic left context sensitive languages csls generators we hypothesize that transformers can be effectively decomposed into three fundamental components context windows attention mechanisms and autoregressive generation frameworks this decomposition allows for the development of more flexible and interpretable computational models moving beyond the traditional view of attention and autoregression as inseparable processes we argue that next token predictions can be understood as probabilistic dynamic approximations of left csl production rules providing an intuitive explanation for how simple token predictions can yield human like intelligence outputs given that all csls are left context sensitive penttonen we conclude that transformers stochastically approximate csls which are widely recognized as models of human like intelligence this interpretation bridges the gap between formal language theory and the observed generative power of transformers laying a foundation for future advancements in generative ai theory and applications our novel perspective on transformer architectures will foster a deeper understanding of llms and their future potentials,"['moving', 'beyond', 'next', 'token', 'prediction', 'transformers', 'are', 'context', 'sensitive', 'language', 'generators']","['large', 'language', 'models', 'llms', 'powered', 'by', 'transformers', 'have', 'demonstrated', 'human', 'like', 'intelligence', 'capabilities', 'yet', 'their', 'underlying', 'mechanisms', 'remain', 'poorly', 'understood', 'this', 'paper', 'presents', 'a', 'novel', 'framework', 'for', 'interpreting', 'llms', 'as', 'probabilistic', 'left', 'context', 'sensitive', 'languages', 'csls', 'generators', 'we', 'hypothesize', 'that', 'transformers', 'can', 'be', 'effectively', 'decomposed', 'into', 'three', 'fundamental', 'components', 'context', 'windows', 'attention', 'mechanisms', 'and', 'autoregressive', 'generation', 'frameworks', 'this', 'decomposition', 'allows', 'for', 'the', 'development', 'of', 'more', 'flexible', 'and', 'interpretable', 'computational', 'models', 'moving', 'beyond', 'the', 'traditional', 'view', 'of', 'attention', 'and', 'autoregression', 'as', 'inseparable', 'processes', 'we', 'argue', 'that', 'next', 'token', 'predictions', 'can', 'be', 'understood', 'as', 'probabilistic', 'dynamic', 'approximations', 'of', 'left', 'csl', 'production', 'rules', 'providing', 'an', 'intuitive', 'explanation', 'for', 'how', 'simple', 'token', 'predictions', 'can', 'yield', 'human', 'like', 'intelligence', 'outputs', 'given', 'that', 'all', 'csls', 'are', 'left', 'context', 'sensitive', 'penttonen', 'we', 'conclude', 'that', 'transformers', 'stochastically', 'approximate', 'csls', 'which', 'are', 'widely', 'recognized', 'as', 'models', 'of', 'human', 'like', 'intelligence', 'this', 'interpretation', 'bridges', 'the', 'gap', 'between', 'formal', 'language', 'theory', 'and', 'the', 'observed', 'generative', 'power', 'of', 'transformers', 'laying', 'a', 'foundation', 'for', 'future', 'advancements', 'in', 'generative', 'ai', 'theory', 'and', 'applications', 'our', 'novel', 'perspective', 'on', 'transformer', 'architectures', 'will', 'foster', 'a', 'deeper', 'understanding', 'of', 'llms', 'and', 'their', 'future', 'potentials']",11,186,"['CSLs', 'Transformers', '1974', 'Transformer', 'LLMs', 'CSL', 'Theory', 'Models', 'Penttonen', 'Formal', 'Language', 'Our', 'Given', 'Large']"
2504.10833v1,Towards Spatially-Aware and Optimally Faithful Concept-Based   Explanations,"Post-hoc, unsupervised concept-based explanation methods (U-CBEMs) are a promising tool for generating semantic explanations of the decision-making processes in deep neural networks, having applications in both model improvement and understanding. It is vital that the explanation is accurate, or faithful, to the model, yet we identify several limitations of prior faithfulness metrics that inhibit an accurate evaluation; most notably, prior metrics involve only the set of concepts present, ignoring how they may be spatially distributed. We address these limitations with Surrogate Faithfulness (SF), an evaluation method that introduces a spatially-aware surrogate and two novel faithfulness metrics. Using SF, we produce Optimally Faithful (OF) explanations, where concepts are found that maximize faithfulness. Our experiments show that (1) adding spatial-awareness to prior U-CBEMs increases faithfulness in all cases; (2) OF produces significantly more faithful explanations than prior U-CBEMs (30% or higher improvement in error); (3) OF's learned concepts generalize well to out-of-domain data and are more robust to adversarial examples, where prior U-CBEMs struggle.","Shubham Kumar, Dwip Dalal, Narendra Ahuja","cs.LG, cs.AI, cs.CV",2025-04-15T03:24:13Z,http://arxiv.org/abs/2504.10833v1,towards spatially aware and optimally faithful concept based explanations,post hoc unsupervised concept based explanation methods u cbems are a promising tool for generating semantic explanations of the decision making processes in deep neural networks having applications in both model improvement and understanding it is vital that the explanation is accurate or faithful to the model yet we identify several limitations of prior faithfulness metrics that inhibit an accurate evaluation most notably prior metrics involve only the set of concepts present ignoring how they may be spatially distributed we address these limitations with surrogate faithfulness sf an evaluation method that introduces a spatially aware surrogate and two novel faithfulness metrics using sf we produce optimally faithful of explanations where concepts are found that maximize faithfulness our experiments show that adding spatial awareness to prior u cbems increases faithfulness in all cases of produces significantly more faithful explanations than prior u cbems or higher improvement in error of s learned concepts generalize well to out of domain data and are more robust to adversarial examples where prior u cbems struggle,"['towards', 'spatially', 'aware', 'and', 'optimally', 'faithful', 'concept', 'based', 'explanations']","['post', 'hoc', 'unsupervised', 'concept', 'based', 'explanation', 'methods', 'u', 'cbems', 'are', 'a', 'promising', 'tool', 'for', 'generating', 'semantic', 'explanations', 'of', 'the', 'decision', 'making', 'processes', 'in', 'deep', 'neural', 'networks', 'having', 'applications', 'in', 'both', 'model', 'improvement', 'and', 'understanding', 'it', 'is', 'vital', 'that', 'the', 'explanation', 'is', 'accurate', 'or', 'faithful', 'to', 'the', 'model', 'yet', 'we', 'identify', 'several', 'limitations', 'of', 'prior', 'faithfulness', 'metrics', 'that', 'inhibit', 'an', 'accurate', 'evaluation', 'most', 'notably', 'prior', 'metrics', 'involve', 'only', 'the', 'set', 'of', 'concepts', 'present', 'ignoring', 'how', 'they', 'may', 'be', 'spatially', 'distributed', 'we', 'address', 'these', 'limitations', 'with', 'surrogate', 'faithfulness', 'sf', 'an', 'evaluation', 'method', 'that', 'introduces', 'a', 'spatially', 'aware', 'surrogate', 'and', 'two', 'novel', 'faithfulness', 'metrics', 'using', 'sf', 'we', 'produce', 'optimally', 'faithful', 'of', 'explanations', 'where', 'concepts', 'are', 'found', 'that', 'maximize', 'faithfulness', 'our', 'experiments', 'show', 'that', 'adding', 'spatial', 'awareness', 'to', 'prior', 'u', 'cbems', 'increases', 'faithfulness', 'in', 'all', 'cases', 'of', 'produces', 'significantly', 'more', 'faithful', 'explanations', 'than', 'prior', 'u', 'cbems', 'or', 'higher', 'improvement', 'in', 'error', 'of', 's', 'learned', 'concepts', 'generalize', 'well', 'to', 'out', 'of', 'domain', 'data', 'and', 'are', 'more', 'robust', 'to', 'adversarial', 'examples', 'where', 'prior', 'u', 'cbems', 'struggle']",9,170,"['Faithful', 'Our', 'Surrogate', 'Post', 'Optimally', 'Faithfulness', 'U-CBEMs']"
2504.10831v1,Hallucination-Aware Generative Pretrained Transformer for Cooperative   Aerial Mobility Control,"This paper proposes SafeGPT, a two-tiered framework that integrates generative pretrained transformers (GPTs) with reinforcement learning (RL) for efficient and reliable unmanned aerial vehicle (UAV) last-mile deliveries. In the proposed design, a Global GPT module assigns high-level tasks such as sector allocation, while an On-Device GPT manages real-time local route planning. An RL-based safety filter monitors each GPT decision and overrides unsafe actions that could lead to battery depletion or duplicate visits, effectively mitigating hallucinations. Furthermore, a dual replay buffer mechanism helps both the GPT modules and the RL agent refine their strategies over time. Simulation results demonstrate that SafeGPT achieves higher delivery success rates compared to a GPT-only baseline, while substantially reducing battery consumption and travel distance. These findings validate the efficacy of combining GPT-based semantic reasoning with formal safety guarantees, contributing a viable solution for robust and energy-efficient UAV logistics.","Hyojun Ahn, Seungcheol Oh, Gyu Seon Kim, Soyi Jung, Soohyun Park, Joongheon Kim","cs.AI, cs.RO, 68T05",2025-04-15T03:21:08Z,http://arxiv.org/abs/2504.10831v1,hallucination aware generative pretrained transformer for cooperative aerial mobility control,this paper proposes safegpt a two tiered framework that integrates generative pretrained transformers gpts with reinforcement learning rl for efficient and reliable unmanned aerial vehicle uav last mile deliveries in the proposed design a global gpt module assigns high level tasks such as sector allocation while an on device gpt manages real time local route planning an rl based safety filter monitors each gpt decision and overrides unsafe actions that could lead to battery depletion or duplicate visits effectively mitigating hallucinations furthermore a dual replay buffer mechanism helps both the gpt modules and the rl agent refine their strategies over time simulation results demonstrate that safegpt achieves higher delivery success rates compared to a gpt only baseline while substantially reducing battery consumption and travel distance these findings validate the efficacy of combining gpt based semantic reasoning with formal safety guarantees contributing a viable solution for robust and energy efficient uav logistics,"['hallucination', 'aware', 'generative', 'pretrained', 'transformer', 'for', 'cooperative', 'aerial', 'mobility', 'control']","['this', 'paper', 'proposes', 'safegpt', 'a', 'two', 'tiered', 'framework', 'that', 'integrates', 'generative', 'pretrained', 'transformers', 'gpts', 'with', 'reinforcement', 'learning', 'rl', 'for', 'efficient', 'and', 'reliable', 'unmanned', 'aerial', 'vehicle', 'uav', 'last', 'mile', 'deliveries', 'in', 'the', 'proposed', 'design', 'a', 'global', 'gpt', 'module', 'assigns', 'high', 'level', 'tasks', 'such', 'as', 'sector', 'allocation', 'while', 'an', 'on', 'device', 'gpt', 'manages', 'real', 'time', 'local', 'route', 'planning', 'an', 'rl', 'based', 'safety', 'filter', 'monitors', 'each', 'gpt', 'decision', 'and', 'overrides', 'unsafe', 'actions', 'that', 'could', 'lead', 'to', 'battery', 'depletion', 'or', 'duplicate', 'visits', 'effectively', 'mitigating', 'hallucinations', 'furthermore', 'a', 'dual', 'replay', 'buffer', 'mechanism', 'helps', 'both', 'the', 'gpt', 'modules', 'and', 'the', 'rl', 'agent', 'refine', 'their', 'strategies', 'over', 'time', 'simulation', 'results', 'demonstrate', 'that', 'safegpt', 'achieves', 'higher', 'delivery', 'success', 'rates', 'compared', 'to', 'a', 'gpt', 'only', 'baseline', 'while', 'substantially', 'reducing', 'battery', 'consumption', 'and', 'travel', 'distance', 'these', 'findings', 'validate', 'the', 'efficacy', 'of', 'combining', 'gpt', 'based', 'semantic', 'reasoning', 'with', 'formal', 'safety', 'guarantees', 'contributing', 'a', 'viable', 'solution', 'for', 'robust', 'and', 'energy', 'efficient', 'uav', 'logistics']",10,151,"['Simulation', 'Device', 'GPT-based', 'SafeGPT', 'GPT', 'RL-based', 'GPT-only', 'These', 'UAV', 'Furthermore', 'GPTs', 'Global']"
2504.10817v1,FHBench: Towards Efficient and Personalized Federated Learning for   Multimodal Healthcare,"Federated Learning (FL) has emerged as an effective solution for multi-institutional collaborations without sharing patient data, offering a range of methods tailored for diverse applications. However, real-world medical datasets are often multimodal, and computational resources are limited, posing significant challenges for existing FL approaches. Recognizing these limitations, we developed the Federated Healthcare Benchmark(FHBench), a benchmark specifically designed from datasets derived from real-world healthcare applications. FHBench encompasses critical diagnostic tasks across domains such as the nervous, cardiovascular, and respiratory systems and general pathology, providing comprehensive support for multimodal healthcare evaluations and filling a significant gap in existing benchmarks. Building on FHBench, we introduced Efficient Personalized Federated Learning with Adaptive LoRA(EPFL), a personalized FL framework that demonstrates superior efficiency and effectiveness across various healthcare modalities. Our results highlight the robustness of FHBench as a benchmarking tool and the potential of EPFL as an innovative approach to advancing healthcare-focused FL, addressing key limitations of existing methods.","Penghao Wang, Qian Chen, Teng Zhang, Yingwei Zhang, Wang Lu, Yiqiang Chen","cs.LG, cs.AI",2025-04-15T02:38:00Z,http://arxiv.org/abs/2504.10817v1,fhbench towards efficient and personalized federated learning for multimodal healthcare,federated learning fl has emerged as an effective solution for multi institutional collaborations without sharing patient data offering a range of methods tailored for diverse applications however real world medical datasets are often multimodal and computational resources are limited posing significant challenges for existing fl approaches recognizing these limitations we developed the federated healthcare benchmark fhbench a benchmark specifically designed from datasets derived from real world healthcare applications fhbench encompasses critical diagnostic tasks across domains such as the nervous cardiovascular and respiratory systems and general pathology providing comprehensive support for multimodal healthcare evaluations and filling a significant gap in existing benchmarks building on fhbench we introduced efficient personalized federated learning with adaptive lora epfl a personalized fl framework that demonstrates superior efficiency and effectiveness across various healthcare modalities our results highlight the robustness of fhbench as a benchmarking tool and the potential of epfl as an innovative approach to advancing healthcare focused fl addressing key limitations of existing methods,"['fhbench', 'towards', 'efficient', 'and', 'personalized', 'federated', 'learning', 'for', 'multimodal', 'healthcare']","['federated', 'learning', 'fl', 'has', 'emerged', 'as', 'an', 'effective', 'solution', 'for', 'multi', 'institutional', 'collaborations', 'without', 'sharing', 'patient', 'data', 'offering', 'a', 'range', 'of', 'methods', 'tailored', 'for', 'diverse', 'applications', 'however', 'real', 'world', 'medical', 'datasets', 'are', 'often', 'multimodal', 'and', 'computational', 'resources', 'are', 'limited', 'posing', 'significant', 'challenges', 'for', 'existing', 'fl', 'approaches', 'recognizing', 'these', 'limitations', 'we', 'developed', 'the', 'federated', 'healthcare', 'benchmark', 'fhbench', 'a', 'benchmark', 'specifically', 'designed', 'from', 'datasets', 'derived', 'from', 'real', 'world', 'healthcare', 'applications', 'fhbench', 'encompasses', 'critical', 'diagnostic', 'tasks', 'across', 'domains', 'such', 'as', 'the', 'nervous', 'cardiovascular', 'and', 'respiratory', 'systems', 'and', 'general', 'pathology', 'providing', 'comprehensive', 'support', 'for', 'multimodal', 'healthcare', 'evaluations', 'and', 'filling', 'a', 'significant', 'gap', 'in', 'existing', 'benchmarks', 'building', 'on', 'fhbench', 'we', 'introduced', 'efficient', 'personalized', 'federated', 'learning', 'with', 'adaptive', 'lora', 'epfl', 'a', 'personalized', 'fl', 'framework', 'that', 'demonstrates', 'superior', 'efficiency', 'and', 'effectiveness', 'across', 'various', 'healthcare', 'modalities', 'our', 'results', 'highlight', 'the', 'robustness', 'of', 'fhbench', 'as', 'a', 'benchmarking', 'tool', 'and', 'the', 'potential', 'of', 'epfl', 'as', 'an', 'innovative', 'approach', 'to', 'advancing', 'healthcare', 'focused', 'fl', 'addressing', 'key', 'limitations', 'of', 'existing', 'methods']",10,159,"['Efficient', 'Healthcare', 'Personalized', 'Our', 'EPFL', 'However', 'FHBench', 'Benchmark', 'LoRA', 'Recognizing', 'Learning', 'Adaptive', 'Federated', 'Building']"
2504.10812v1,E2E Parking Dataset: An Open Benchmark for End-to-End Autonomous Parking,"End-to-end learning has shown great potential in autonomous parking, yet the lack of publicly available datasets limits reproducibility and benchmarking. While prior work introduced a visual-based parking model and a pipeline for data generation, training, and close-loop test, the dataset itself was not released. To bridge this gap, we create and open-source a high-quality dataset for end-to-end autonomous parking. Using the original model, we achieve an overall success rate of 85.16% with lower average position and orientation errors (0.24 meters and 0.34 degrees).","Kejia Gao, Liguo Zhou, Mingjun Liu, Alois Knoll","cs.RO, cs.AI",2025-04-15T02:21:09Z,http://arxiv.org/abs/2504.10812v1,e e parking dataset an open benchmark for end to end autonomous parking,end to end learning has shown great potential in autonomous parking yet the lack of publicly available datasets limits reproducibility and benchmarking while prior work introduced a visual based parking model and a pipeline for data generation training and close loop test the dataset itself was not released to bridge this gap we create and open source a high quality dataset for end to end autonomous parking using the original model we achieve an overall success rate of with lower average position and orientation errors meters and degrees,"['e', 'e', 'parking', 'dataset', 'an', 'open', 'benchmark', 'for', 'end', 'to', 'end', 'autonomous', 'parking']","['end', 'to', 'end', 'learning', 'has', 'shown', 'great', 'potential', 'in', 'autonomous', 'parking', 'yet', 'the', 'lack', 'of', 'publicly', 'available', 'datasets', 'limits', 'reproducibility', 'and', 'benchmarking', 'while', 'prior', 'work', 'introduced', 'a', 'visual', 'based', 'parking', 'model', 'and', 'a', 'pipeline', 'for', 'data', 'generation', 'training', 'and', 'close', 'loop', 'test', 'the', 'dataset', 'itself', 'was', 'not', 'released', 'to', 'bridge', 'this', 'gap', 'we', 'create', 'and', 'open', 'source', 'a', 'high', 'quality', 'dataset', 'for', 'end', 'to', 'end', 'autonomous', 'parking', 'using', 'the', 'original', 'model', 'we', 'achieve', 'an', 'overall', 'success', 'rate', 'of', 'with', 'lower', 'average', 'position', 'and', 'orientation', 'errors', 'meters', 'and', 'degrees']",13,88,"['While', 'End']"
2504.10784v1,ATLASv2: LLM-Guided Adaptive Landmark Acquisition and Navigation on the   Edge,"Autonomous systems deployed on edge devices face significant challenges, including resource constraints, real-time processing demands, and adapting to dynamic environments. This work introduces ATLASv2, a novel system that integrates a fine-tuned TinyLLM, real-time object detection, and efficient path planning to enable hierarchical, multi-task navigation and manipulation all on the edge device, Jetson Nano. ATLASv2 dynamically expands its navigable landmarks by detecting and localizing objects in the environment which are saved to its internal knowledge base to be used for future task execution. We evaluate ATLASv2 in real-world environments, including a handcrafted home and office setting constructed with diverse objects and landmarks. Results show that ATLASv2 effectively interprets natural language instructions, decomposes them into low-level actions, and executes tasks with high success rates. By leveraging generative AI in a fully on-board framework, ATLASv2 achieves optimized resource utilization with minimal prompting latency and power consumption, bridging the gap between simulated environments and real-world applications.","Mikolaj Walczak, Uttej Kallakuri, Tinoosh Mohsenin","cs.RO, cs.AI",2025-04-15T00:55:57Z,http://arxiv.org/abs/2504.10784v1,atlasv llm guided adaptive landmark acquisition and navigation on the edge,autonomous systems deployed on edge devices face significant challenges including resource constraints real time processing demands and adapting to dynamic environments this work introduces atlasv a novel system that integrates a fine tuned tinyllm real time object detection and efficient path planning to enable hierarchical multi task navigation and manipulation all on the edge device jetson nano atlasv dynamically expands its navigable landmarks by detecting and localizing objects in the environment which are saved to its internal knowledge base to be used for future task execution we evaluate atlasv in real world environments including a handcrafted home and office setting constructed with diverse objects and landmarks results show that atlasv effectively interprets natural language instructions decomposes them into low level actions and executes tasks with high success rates by leveraging generative ai in a fully on board framework atlasv achieves optimized resource utilization with minimal prompting latency and power consumption bridging the gap between simulated environments and real world applications,"['atlasv', 'llm', 'guided', 'adaptive', 'landmark', 'acquisition', 'and', 'navigation', 'on', 'the', 'edge']","['autonomous', 'systems', 'deployed', 'on', 'edge', 'devices', 'face', 'significant', 'challenges', 'including', 'resource', 'constraints', 'real', 'time', 'processing', 'demands', 'and', 'adapting', 'to', 'dynamic', 'environments', 'this', 'work', 'introduces', 'atlasv', 'a', 'novel', 'system', 'that', 'integrates', 'a', 'fine', 'tuned', 'tinyllm', 'real', 'time', 'object', 'detection', 'and', 'efficient', 'path', 'planning', 'to', 'enable', 'hierarchical', 'multi', 'task', 'navigation', 'and', 'manipulation', 'all', 'on', 'the', 'edge', 'device', 'jetson', 'nano', 'atlasv', 'dynamically', 'expands', 'its', 'navigable', 'landmarks', 'by', 'detecting', 'and', 'localizing', 'objects', 'in', 'the', 'environment', 'which', 'are', 'saved', 'to', 'its', 'internal', 'knowledge', 'base', 'to', 'be', 'used', 'for', 'future', 'task', 'execution', 'we', 'evaluate', 'atlasv', 'in', 'real', 'world', 'environments', 'including', 'a', 'handcrafted', 'home', 'and', 'office', 'setting', 'constructed', 'with', 'diverse', 'objects', 'and', 'landmarks', 'results', 'show', 'that', 'atlasv', 'effectively', 'interprets', 'natural', 'language', 'instructions', 'decomposes', 'them', 'into', 'low', 'level', 'actions', 'and', 'executes', 'tasks', 'with', 'high', 'success', 'rates', 'by', 'leveraging', 'generative', 'ai', 'in', 'a', 'fully', 'on', 'board', 'framework', 'atlasv', 'achieves', 'optimized', 'resource', 'utilization', 'with', 'minimal', 'prompting', 'latency', 'and', 'power', 'consumption', 'bridging', 'the', 'gap', 'between', 'simulated', 'environments', 'and', 'real', 'world', 'applications']",11,160,"['Autonomous', 'TinyLLM', 'ATLASv2', 'Nano', 'Jetson', 'Results']"
2504.10753v1,Epistemic Uncertainty-aware Recommendation Systems via Bayesian Deep   Ensemble Learning,"Recommending items to users has long been a fundamental task, and studies have tried to improve it ever since. Most well-known models commonly employ representation learning to map users and items into a unified embedding space for matching assessment. These approaches have primary limitations, especially when dealing with explicit feedback and sparse data contexts. Two primary limitations are their proneness to overfitting and failure to incorporate epistemic uncertainty in predictions. To address these problems, we propose a novel Bayesian Deep Ensemble Collaborative Filtering method named BDECF. To improve model generalization and quality, we utilize Bayesian Neural Networks, which incorporate uncertainty within their weight parameters. In addition, we introduce a new interpretable non-linear matching approach for the user and item embeddings, leveraging the advantages of the attention mechanism. Furthermore, we endorse the implementation of an ensemble-based supermodel to generate more robust and reliable predictions, resulting in a more complete model. Empirical evaluation through extensive experiments and ablation studies across a range of publicly accessible real-world datasets with differing sparsity characteristics confirms our proposed method's effectiveness and the importance of its components.","Radin Cheraghi, Amir Mohammad Mahfoozi, Sepehr Zolfaghari, Mohammadshayan Shabani, Maryam Ramezani, Hamid R. Rabiee","cs.IR, cs.AI, cs.LG",2025-04-14T23:04:35Z,http://arxiv.org/abs/2504.10753v1,epistemic uncertainty aware recommendation systems via bayesian deep ensemble learning,recommending items to users has long been a fundamental task and studies have tried to improve it ever since most well known models commonly employ representation learning to map users and items into a unified embedding space for matching assessment these approaches have primary limitations especially when dealing with explicit feedback and sparse data contexts two primary limitations are their proneness to overfitting and failure to incorporate epistemic uncertainty in predictions to address these problems we propose a novel bayesian deep ensemble collaborative filtering method named bdecf to improve model generalization and quality we utilize bayesian neural networks which incorporate uncertainty within their weight parameters in addition we introduce a new interpretable non linear matching approach for the user and item embeddings leveraging the advantages of the attention mechanism furthermore we endorse the implementation of an ensemble based supermodel to generate more robust and reliable predictions resulting in a more complete model empirical evaluation through extensive experiments and ablation studies across a range of publicly accessible real world datasets with differing sparsity characteristics confirms our proposed method s effectiveness and the importance of its components,"['epistemic', 'uncertainty', 'aware', 'recommendation', 'systems', 'via', 'bayesian', 'deep', 'ensemble', 'learning']","['recommending', 'items', 'to', 'users', 'has', 'long', 'been', 'a', 'fundamental', 'task', 'and', 'studies', 'have', 'tried', 'to', 'improve', 'it', 'ever', 'since', 'most', 'well', 'known', 'models', 'commonly', 'employ', 'representation', 'learning', 'to', 'map', 'users', 'and', 'items', 'into', 'a', 'unified', 'embedding', 'space', 'for', 'matching', 'assessment', 'these', 'approaches', 'have', 'primary', 'limitations', 'especially', 'when', 'dealing', 'with', 'explicit', 'feedback', 'and', 'sparse', 'data', 'contexts', 'two', 'primary', 'limitations', 'are', 'their', 'proneness', 'to', 'overfitting', 'and', 'failure', 'to', 'incorporate', 'epistemic', 'uncertainty', 'in', 'predictions', 'to', 'address', 'these', 'problems', 'we', 'propose', 'a', 'novel', 'bayesian', 'deep', 'ensemble', 'collaborative', 'filtering', 'method', 'named', 'bdecf', 'to', 'improve', 'model', 'generalization', 'and', 'quality', 'we', 'utilize', 'bayesian', 'neural', 'networks', 'which', 'incorporate', 'uncertainty', 'within', 'their', 'weight', 'parameters', 'in', 'addition', 'we', 'introduce', 'a', 'new', 'interpretable', 'non', 'linear', 'matching', 'approach', 'for', 'the', 'user', 'and', 'item', 'embeddings', 'leveraging', 'the', 'advantages', 'of', 'the', 'attention', 'mechanism', 'furthermore', 'we', 'endorse', 'the', 'implementation', 'of', 'an', 'ensemble', 'based', 'supermodel', 'to', 'generate', 'more', 'robust', 'and', 'reliable', 'predictions', 'resulting', 'in', 'a', 'more', 'complete', 'model', 'empirical', 'evaluation', 'through', 'extensive', 'experiments', 'and', 'ablation', 'studies', 'across', 'a', 'range', 'of', 'publicly', 'accessible', 'real', 'world', 'datasets', 'with', 'differing', 'sparsity', 'characteristics', 'confirms', 'our', 'proposed', 'method', 's', 'effectiveness', 'and', 'the', 'importance', 'of', 'its', 'components']",10,185,"['Most', 'Empirical', 'Filtering', 'Recommending', 'Ensemble', 'BDECF', 'These', 'Neural', 'Furthermore', 'Networks', 'Bayesian', 'Deep', 'Collaborative', 'Two']"
2504.10746v1,Hearing Anywhere in Any Environment,"In mixed reality applications, a realistic acoustic experience in spatial environments is as crucial as the visual experience for achieving true immersion. Despite recent advances in neural approaches for Room Impulse Response (RIR) estimation, most existing methods are limited to the single environment on which they are trained, lacking the ability to generalize to new rooms with different geometries and surface materials. We aim to develop a unified model capable of reconstructing the spatial acoustic experience of any environment with minimum additional measurements. To this end, we present xRIR, a framework for cross-room RIR prediction. The core of our generalizable approach lies in combining a geometric feature extractor, which captures spatial context from panorama depth images, with a RIR encoder that extracts detailed acoustic features from only a few reference RIR samples. To evaluate our method, we introduce ACOUSTICROOMS, a new dataset featuring high-fidelity simulation of over 300,000 RIRs from 260 rooms. Experiments show that our method strongly outperforms a series of baselines. Furthermore, we successfully perform sim-to-real transfer by evaluating our model on four real-world environments, demonstrating the generalizability of our approach and the realism of our dataset.","Xiulong Liu, Anurag Kumar, Paul Calamia, Sebastia V. Amengual, Calvin Murdock, Ishwarya Ananthabhotla, Philip Robinson, Eli Shlizerman, Vamsi Krishna Ithapu, Ruohan Gao","cs.CV, cs.AI, cs.LG, cs.SD, eess.AS",2025-04-14T22:37:52Z,http://arxiv.org/abs/2504.10746v1,hearing anywhere in any environment,in mixed reality applications a realistic acoustic experience in spatial environments is as crucial as the visual experience for achieving true immersion despite recent advances in neural approaches for room impulse response rir estimation most existing methods are limited to the single environment on which they are trained lacking the ability to generalize to new rooms with different geometries and surface materials we aim to develop a unified model capable of reconstructing the spatial acoustic experience of any environment with minimum additional measurements to this end we present xrir a framework for cross room rir prediction the core of our generalizable approach lies in combining a geometric feature extractor which captures spatial context from panorama depth images with a rir encoder that extracts detailed acoustic features from only a few reference rir samples to evaluate our method we introduce acousticrooms a new dataset featuring high fidelity simulation of over rirs from rooms experiments show that our method strongly outperforms a series of baselines furthermore we successfully perform sim to real transfer by evaluating our model on four real world environments demonstrating the generalizability of our approach and the realism of our dataset,"['hearing', 'anywhere', 'in', 'any', 'environment']","['in', 'mixed', 'reality', 'applications', 'a', 'realistic', 'acoustic', 'experience', 'in', 'spatial', 'environments', 'is', 'as', 'crucial', 'as', 'the', 'visual', 'experience', 'for', 'achieving', 'true', 'immersion', 'despite', 'recent', 'advances', 'in', 'neural', 'approaches', 'for', 'room', 'impulse', 'response', 'rir', 'estimation', 'most', 'existing', 'methods', 'are', 'limited', 'to', 'the', 'single', 'environment', 'on', 'which', 'they', 'are', 'trained', 'lacking', 'the', 'ability', 'to', 'generalize', 'to', 'new', 'rooms', 'with', 'different', 'geometries', 'and', 'surface', 'materials', 'we', 'aim', 'to', 'develop', 'a', 'unified', 'model', 'capable', 'of', 'reconstructing', 'the', 'spatial', 'acoustic', 'experience', 'of', 'any', 'environment', 'with', 'minimum', 'additional', 'measurements', 'to', 'this', 'end', 'we', 'present', 'xrir', 'a', 'framework', 'for', 'cross', 'room', 'rir', 'prediction', 'the', 'core', 'of', 'our', 'generalizable', 'approach', 'lies', 'in', 'combining', 'a', 'geometric', 'feature', 'extractor', 'which', 'captures', 'spatial', 'context', 'from', 'panorama', 'depth', 'images', 'with', 'a', 'rir', 'encoder', 'that', 'extracts', 'detailed', 'acoustic', 'features', 'from', 'only', 'a', 'few', 'reference', 'rir', 'samples', 'to', 'evaluate', 'our', 'method', 'we', 'introduce', 'acousticrooms', 'a', 'new', 'dataset', 'featuring', 'high', 'fidelity', 'simulation', 'of', 'over', 'rirs', 'from', 'rooms', 'experiments', 'show', 'that', 'our', 'method', 'strongly', 'outperforms', 'a', 'series', 'of', 'baselines', 'furthermore', 'we', 'successfully', 'perform', 'sim', 'to', 'real', 'transfer', 'by', 'evaluating', 'our', 'model', 'on', 'four', 'real', 'world', 'environments', 'demonstrating', 'the', 'generalizability', 'of', 'our', 'approach', 'and', 'the', 'realism', 'of', 'our', 'dataset']",5,192,"['RIRs', 'Room', '000', '260', 'Despite', 'Experiments', '300', 'RIR', 'Impulse', 'Response', 'Furthermore', 'ACOUSTICROOMS']"
2504.10655v1,"MatterTune: An Integrated, User-Friendly Platform for Fine-Tuning   Atomistic Foundation Models to Accelerate Materials Simulation and Discovery","Geometric machine learning models such as graph neural networks have achieved remarkable success in recent years in chemical and materials science research for applications such as high-throughput virtual screening and atomistic simulations. The success of these models can be attributed to their ability to effectively learn latent representations of atomic structures directly from the training data. Conversely, this also results in high data requirements for these models, hindering their application to problems which are data sparse which are common in this domain. To address this limitation, there is a growing development in the area of pre-trained machine learning models which have learned general, fundamental, geometric relationships in atomistic data, and which can then be fine-tuned to much smaller application-specific datasets. In particular, models which are pre-trained on diverse, large-scale atomistic datasets have shown impressive generalizability and flexibility to downstream applications, and are increasingly referred to as atomistic foundation models. To leverage the untapped potential of these foundation models, we introduce MatterTune, a modular and extensible framework that provides advanced fine-tuning capabilities and seamless integration of atomistic foundation models into downstream materials informatics and simulation workflows, thereby lowering the barriers to adoption and facilitating diverse applications in materials science. In its current state, MatterTune supports a number of state-of-the-art foundation models such as ORB, MatterSim, JMP, and EquformerV2, and hosts a wide range of features including a modular and flexible design, distributed and customizable fine-tuning, broad support for downstream informatics tasks, and more.","Lingyu Kong, Nima Shoghi, Guoxiang Hu, Pan Li, Victor Fung","cond-mat.mtrl-sci, cs.AI, cs.LG",2025-04-14T19:12:43Z,http://arxiv.org/abs/2504.10655v1,mattertune an integrated user friendly platform for fine tuning atomistic foundation models to accelerate materials simulation and discovery,geometric machine learning models such as graph neural networks have achieved remarkable success in recent years in chemical and materials science research for applications such as high throughput virtual screening and atomistic simulations the success of these models can be attributed to their ability to effectively learn latent representations of atomic structures directly from the training data conversely this also results in high data requirements for these models hindering their application to problems which are data sparse which are common in this domain to address this limitation there is a growing development in the area of pre trained machine learning models which have learned general fundamental geometric relationships in atomistic data and which can then be fine tuned to much smaller application specific datasets in particular models which are pre trained on diverse large scale atomistic datasets have shown impressive generalizability and flexibility to downstream applications and are increasingly referred to as atomistic foundation models to leverage the untapped potential of these foundation models we introduce mattertune a modular and extensible framework that provides advanced fine tuning capabilities and seamless integration of atomistic foundation models into downstream materials informatics and simulation workflows thereby lowering the barriers to adoption and facilitating diverse applications in materials science in its current state mattertune supports a number of state of the art foundation models such as orb mattersim jmp and equformerv and hosts a wide range of features including a modular and flexible design distributed and customizable fine tuning broad support for downstream informatics tasks and more,"['mattertune', 'an', 'integrated', 'user', 'friendly', 'platform', 'for', 'fine', 'tuning', 'atomistic', 'foundation', 'models', 'to', 'accelerate', 'materials', 'simulation', 'and', 'discovery']","['geometric', 'machine', 'learning', 'models', 'such', 'as', 'graph', 'neural', 'networks', 'have', 'achieved', 'remarkable', 'success', 'in', 'recent', 'years', 'in', 'chemical', 'and', 'materials', 'science', 'research', 'for', 'applications', 'such', 'as', 'high', 'throughput', 'virtual', 'screening', 'and', 'atomistic', 'simulations', 'the', 'success', 'of', 'these', 'models', 'can', 'be', 'attributed', 'to', 'their', 'ability', 'to', 'effectively', 'learn', 'latent', 'representations', 'of', 'atomic', 'structures', 'directly', 'from', 'the', 'training', 'data', 'conversely', 'this', 'also', 'results', 'in', 'high', 'data', 'requirements', 'for', 'these', 'models', 'hindering', 'their', 'application', 'to', 'problems', 'which', 'are', 'data', 'sparse', 'which', 'are', 'common', 'in', 'this', 'domain', 'to', 'address', 'this', 'limitation', 'there', 'is', 'a', 'growing', 'development', 'in', 'the', 'area', 'of', 'pre', 'trained', 'machine', 'learning', 'models', 'which', 'have', 'learned', 'general', 'fundamental', 'geometric', 'relationships', 'in', 'atomistic', 'data', 'and', 'which', 'can', 'then', 'be', 'fine', 'tuned', 'to', 'much', 'smaller', 'application', 'specific', 'datasets', 'in', 'particular', 'models', 'which', 'are', 'pre', 'trained', 'on', 'diverse', 'large', 'scale', 'atomistic', 'datasets', 'have', 'shown', 'impressive', 'generalizability', 'and', 'flexibility', 'to', 'downstream', 'applications', 'and', 'are', 'increasingly', 'referred', 'to', 'as', 'atomistic', 'foundation', 'models', 'to', 'leverage', 'the', 'untapped', 'potential', 'of', 'these', 'foundation', 'models', 'we', 'introduce', 'mattertune', 'a', 'modular', 'and', 'extensible', 'framework', 'that', 'provides', 'advanced', 'fine', 'tuning', 'capabilities', 'and', 'seamless', 'integration', 'of', 'atomistic', 'foundation', 'models', 'into', 'downstream', 'materials', 'informatics', 'and', 'simulation', 'workflows', 'thereby', 'lowering', 'the', 'barriers', 'to', 'adoption', 'and', 'facilitating', 'diverse', 'applications', 'in', 'materials', 'science', 'in', 'its', 'current', 'state', 'mattertune', 'supports', 'a', 'number', 'of', 'state', 'of', 'the', 'art', 'foundation', 'models', 'such', 'as', 'orb', 'mattersim', 'jmp', 'and', 'equformerv', 'and', 'hosts', 'a', 'wide', 'range', 'of', 'features', 'including', 'a', 'modular', 'and', 'flexible', 'design', 'distributed', 'and', 'customizable', 'fine', 'tuning', 'broad', 'support', 'for', 'downstream', 'informatics', 'tasks', 'and', 'more']",18,253,"['Conversely', 'EquformerV2', 'MatterTune', 'Geometric', 'MatterSim', 'JMP', 'ORB']"
2504.10650v1,Will AI shape the way we speak? The emerging sociolinguistic influence   of synthetic voices,"The growing prevalence of conversational voice interfaces, powered by developments in both speech and language technologies, raises important questions about their influence on human communication. While written communication can signal identity through lexical and stylistic choices, voice-based interactions inherently amplify socioindexical elements - such as accent, intonation, and speech style - which more prominently convey social identity and group affiliation. There is evidence that even passive media such as television is likely to influence the audience's linguistic patterns. Unlike passive media, conversational AI is interactive, creating a more immersive and reciprocal dynamic that holds a greater potential to impact how individuals speak in everyday interactions. Such heightened influence can be expected to arise from phenomena such as acoustic-prosodic entrainment and linguistic accommodation, which occur naturally during interaction and enable users to adapt their speech patterns in response to the system. While this phenomenon is still emerging, its potential societal impact could provide organisations, movements, and brands with a subtle yet powerful avenue for shaping and controlling public perception and social identity. We argue that the socioindexical influence of AI-generated speech warrants attention and should become a focus of interdisciplinary research, leveraging new and existing methodologies and technologies to better understand its implications.","√âva Sz√©kely, J≈´ra Miniota, M√≠≈°a, Hejn√°","cs.CY, cs.AI, cs.CL, cs.HC, eess.AS, I.2.7; K.4.2; H.5.2",2025-04-14T19:04:32Z,http://arxiv.org/abs/2504.10650v1,will ai shape the way we speak the emerging sociolinguistic influence of synthetic voices,the growing prevalence of conversational voice interfaces powered by developments in both speech and language technologies raises important questions about their influence on human communication while written communication can signal identity through lexical and stylistic choices voice based interactions inherently amplify socioindexical elements such as accent intonation and speech style which more prominently convey social identity and group affiliation there is evidence that even passive media such as television is likely to influence the audience s linguistic patterns unlike passive media conversational ai is interactive creating a more immersive and reciprocal dynamic that holds a greater potential to impact how individuals speak in everyday interactions such heightened influence can be expected to arise from phenomena such as acoustic prosodic entrainment and linguistic accommodation which occur naturally during interaction and enable users to adapt their speech patterns in response to the system while this phenomenon is still emerging its potential societal impact could provide organisations movements and brands with a subtle yet powerful avenue for shaping and controlling public perception and social identity we argue that the socioindexical influence of ai generated speech warrants attention and should become a focus of interdisciplinary research leveraging new and existing methodologies and technologies to better understand its implications,"['will', 'ai', 'shape', 'the', 'way', 'we', 'speak', 'the', 'emerging', 'sociolinguistic', 'influence', 'of', 'synthetic', 'voices']","['the', 'growing', 'prevalence', 'of', 'conversational', 'voice', 'interfaces', 'powered', 'by', 'developments', 'in', 'both', 'speech', 'and', 'language', 'technologies', 'raises', 'important', 'questions', 'about', 'their', 'influence', 'on', 'human', 'communication', 'while', 'written', 'communication', 'can', 'signal', 'identity', 'through', 'lexical', 'and', 'stylistic', 'choices', 'voice', 'based', 'interactions', 'inherently', 'amplify', 'socioindexical', 'elements', 'such', 'as', 'accent', 'intonation', 'and', 'speech', 'style', 'which', 'more', 'prominently', 'convey', 'social', 'identity', 'and', 'group', 'affiliation', 'there', 'is', 'evidence', 'that', 'even', 'passive', 'media', 'such', 'as', 'television', 'is', 'likely', 'to', 'influence', 'the', 'audience', 's', 'linguistic', 'patterns', 'unlike', 'passive', 'media', 'conversational', 'ai', 'is', 'interactive', 'creating', 'a', 'more', 'immersive', 'and', 'reciprocal', 'dynamic', 'that', 'holds', 'a', 'greater', 'potential', 'to', 'impact', 'how', 'individuals', 'speak', 'in', 'everyday', 'interactions', 'such', 'heightened', 'influence', 'can', 'be', 'expected', 'to', 'arise', 'from', 'phenomena', 'such', 'as', 'acoustic', 'prosodic', 'entrainment', 'and', 'linguistic', 'accommodation', 'which', 'occur', 'naturally', 'during', 'interaction', 'and', 'enable', 'users', 'to', 'adapt', 'their', 'speech', 'patterns', 'in', 'response', 'to', 'the', 'system', 'while', 'this', 'phenomenon', 'is', 'still', 'emerging', 'its', 'potential', 'societal', 'impact', 'could', 'provide', 'organisations', 'movements', 'and', 'brands', 'with', 'a', 'subtle', 'yet', 'powerful', 'avenue', 'for', 'shaping', 'and', 'controlling', 'public', 'perception', 'and', 'social', 'identity', 'we', 'argue', 'that', 'the', 'socioindexical', 'influence', 'of', 'ai', 'generated', 'speech', 'warrants', 'attention', 'and', 'should', 'become', 'a', 'focus', 'of', 'interdisciplinary', 'research', 'leveraging', 'new', 'and', 'existing', 'methodologies', 'and', 'technologies', 'to', 'better', 'understand', 'its', 'implications']",14,204,"['Unlike', 'Such', 'While', 'AI-generated', 'There']"
2504.10636v1,Who is More Bayesian: Humans or ChatGPT?,"We compare the performance of human and artificially intelligent (AI) decision makers in simple binary classification tasks where the optimal decision rule is given by Bayes Rule. We reanalyze choices of human subjects gathered from laboratory experiments conducted by El-Gamal and Grether and Holt and Smith. We confirm that while overall, Bayes Rule represents the single best model for predicting human choices, subjects are heterogeneous and a significant share of them make suboptimal choices that reflect judgement biases described by Kahneman and Tversky that include the ``representativeness heuristic'' (excessive weight on the evidence from the sample relative to the prior) and ``conservatism'' (excessive weight on the prior relative to the sample). We compare the performance of AI subjects gathered from recent versions of large language models (LLMs) including several versions of ChatGPT. These general-purpose generative AI chatbots are not specifically trained to do well in narrow decision making tasks, but are trained instead as ``language predictors'' using a large corpus of textual data from the web. We show that ChatGPT is also subject to biases that result in suboptimal decisions. However we document a rapid evolution in the performance of ChatGPT from sub-human performance for early versions (ChatGPT 3.5) to superhuman and nearly perfect Bayesian classifications in the latest versions (ChatGPT 4o).","Tianshi Mu, Pranjal Rawat, John Rust, Chengjun Zhang, Qixuan Zhong","econ.GN, cs.AI, q-fin.EC, stat.ME",2025-04-14T18:37:54Z,http://arxiv.org/abs/2504.10636v1,who is more bayesian humans or chatgpt,we compare the performance of human and artificially intelligent ai decision makers in simple binary classification tasks where the optimal decision rule is given by bayes rule we reanalyze choices of human subjects gathered from laboratory experiments conducted by el gamal and grether and holt and smith we confirm that while overall bayes rule represents the single best model for predicting human choices subjects are heterogeneous and a significant share of them make suboptimal choices that reflect judgement biases described by kahneman and tversky that include the representativeness heuristic excessive weight on the evidence from the sample relative to the prior and conservatism excessive weight on the prior relative to the sample we compare the performance of ai subjects gathered from recent versions of large language models llms including several versions of chatgpt these general purpose generative ai chatbots are not specifically trained to do well in narrow decision making tasks but are trained instead as language predictors using a large corpus of textual data from the web we show that chatgpt is also subject to biases that result in suboptimal decisions however we document a rapid evolution in the performance of chatgpt from sub human performance for early versions chatgpt to superhuman and nearly perfect bayesian classifications in the latest versions chatgpt o,"['who', 'is', 'more', 'bayesian', 'humans', 'or', 'chatgpt']","['we', 'compare', 'the', 'performance', 'of', 'human', 'and', 'artificially', 'intelligent', 'ai', 'decision', 'makers', 'in', 'simple', 'binary', 'classification', 'tasks', 'where', 'the', 'optimal', 'decision', 'rule', 'is', 'given', 'by', 'bayes', 'rule', 'we', 'reanalyze', 'choices', 'of', 'human', 'subjects', 'gathered', 'from', 'laboratory', 'experiments', 'conducted', 'by', 'el', 'gamal', 'and', 'grether', 'and', 'holt', 'and', 'smith', 'we', 'confirm', 'that', 'while', 'overall', 'bayes', 'rule', 'represents', 'the', 'single', 'best', 'model', 'for', 'predicting', 'human', 'choices', 'subjects', 'are', 'heterogeneous', 'and', 'a', 'significant', 'share', 'of', 'them', 'make', 'suboptimal', 'choices', 'that', 'reflect', 'judgement', 'biases', 'described', 'by', 'kahneman', 'and', 'tversky', 'that', 'include', 'the', 'representativeness', 'heuristic', 'excessive', 'weight', 'on', 'the', 'evidence', 'from', 'the', 'sample', 'relative', 'to', 'the', 'prior', 'and', 'conservatism', 'excessive', 'weight', 'on', 'the', 'prior', 'relative', 'to', 'the', 'sample', 'we', 'compare', 'the', 'performance', 'of', 'ai', 'subjects', 'gathered', 'from', 'recent', 'versions', 'of', 'large', 'language', 'models', 'llms', 'including', 'several', 'versions', 'of', 'chatgpt', 'these', 'general', 'purpose', 'generative', 'ai', 'chatbots', 'are', 'not', 'specifically', 'trained', 'to', 'do', 'well', 'in', 'narrow', 'decision', 'making', 'tasks', 'but', 'are', 'trained', 'instead', 'as', 'language', 'predictors', 'using', 'a', 'large', 'corpus', 'of', 'textual', 'data', 'from', 'the', 'web', 'we', 'show', 'that', 'chatgpt', 'is', 'also', 'subject', 'to', 'biases', 'that', 'result', 'in', 'suboptimal', 'decisions', 'however', 'we', 'document', 'a', 'rapid', 'evolution', 'in', 'the', 'performance', 'of', 'chatgpt', 'from', 'sub', 'human', 'performance', 'for', 'early', 'versions', 'chatgpt', 'to', 'superhuman', 'and', 'nearly', 'perfect', 'bayesian', 'classifications', 'in', 'the', 'latest', 'versions', 'chatgpt', 'o']",7,214,"['Bayes', 'Holt', 'Tversky', 'LLMs', 'Kahneman', 'These', 'Rule', 'However', 'Grether', 'ChatGPT', 'Gamal', 'Smith', 'Bayesian']"
2504.10612v1,Energy Matching: Unifying Flow Matching and Energy-Based Models for   Generative Modeling,"Generative models often map noise to data by matching flows or scores, but these approaches become cumbersome for incorporating partial observations or additional priors. Inspired by recent advances in Wasserstein gradient flows, we propose Energy Matching, a framework that unifies flow-based approaches with the flexibility of energy-based models (EBMs). Far from the data manifold, samples move along curl-free, optimal transport paths from noise to data. As they approach the data manifold, an entropic energy term guides the system into a Boltzmann equilibrium distribution, explicitly capturing the underlying likelihood structure of the data. We parameterize this dynamic with a single time-independent scalar field, which serves as both a powerful generator and a flexible prior for effective regularization of inverse problems. Our method substantially outperforms existing EBMs on CIFAR-10 generation (FID 3.97 compared to 8.61), while retaining the simulation-free training of transport-based approaches away from the data manifold. Additionally, we exploit the flexibility of our method and introduce an interaction energy for diverse mode exploration. Our approach focuses on learning a static scalar potential energy -- without time conditioning, auxiliary generators, or additional networks -- marking a significant departure from recent EBM methods. We believe this simplified framework significantly advances EBM capabilities and paves the way for their broader adoption in generative modeling across diverse domains.","Michal Balcerak, Tamaz Amiranashvili, Suprosanna Shit, Antonio Terpin, Sebastian Kaltenbach, Petros Koumoutsakos, Bjoern Menze","cs.LG, cs.AI, stat.ML",2025-04-14T18:10:58Z,http://arxiv.org/abs/2504.10612v1,energy matching unifying flow matching and energy based models for generative modeling,generative models often map noise to data by matching flows or scores but these approaches become cumbersome for incorporating partial observations or additional priors inspired by recent advances in wasserstein gradient flows we propose energy matching a framework that unifies flow based approaches with the flexibility of energy based models ebms far from the data manifold samples move along curl free optimal transport paths from noise to data as they approach the data manifold an entropic energy term guides the system into a boltzmann equilibrium distribution explicitly capturing the underlying likelihood structure of the data we parameterize this dynamic with a single time independent scalar field which serves as both a powerful generator and a flexible prior for effective regularization of inverse problems our method substantially outperforms existing ebms on cifar generation fid compared to while retaining the simulation free training of transport based approaches away from the data manifold additionally we exploit the flexibility of our method and introduce an interaction energy for diverse mode exploration our approach focuses on learning a static scalar potential energy without time conditioning auxiliary generators or additional networks marking a significant departure from recent ebm methods we believe this simplified framework significantly advances ebm capabilities and paves the way for their broader adoption in generative modeling across diverse domains,"['energy', 'matching', 'unifying', 'flow', 'matching', 'and', 'energy', 'based', 'models', 'for', 'generative', 'modeling']","['generative', 'models', 'often', 'map', 'noise', 'to', 'data', 'by', 'matching', 'flows', 'or', 'scores', 'but', 'these', 'approaches', 'become', 'cumbersome', 'for', 'incorporating', 'partial', 'observations', 'or', 'additional', 'priors', 'inspired', 'by', 'recent', 'advances', 'in', 'wasserstein', 'gradient', 'flows', 'we', 'propose', 'energy', 'matching', 'a', 'framework', 'that', 'unifies', 'flow', 'based', 'approaches', 'with', 'the', 'flexibility', 'of', 'energy', 'based', 'models', 'ebms', 'far', 'from', 'the', 'data', 'manifold', 'samples', 'move', 'along', 'curl', 'free', 'optimal', 'transport', 'paths', 'from', 'noise', 'to', 'data', 'as', 'they', 'approach', 'the', 'data', 'manifold', 'an', 'entropic', 'energy', 'term', 'guides', 'the', 'system', 'into', 'a', 'boltzmann', 'equilibrium', 'distribution', 'explicitly', 'capturing', 'the', 'underlying', 'likelihood', 'structure', 'of', 'the', 'data', 'we', 'parameterize', 'this', 'dynamic', 'with', 'a', 'single', 'time', 'independent', 'scalar', 'field', 'which', 'serves', 'as', 'both', 'a', 'powerful', 'generator', 'and', 'a', 'flexible', 'prior', 'for', 'effective', 'regularization', 'of', 'inverse', 'problems', 'our', 'method', 'substantially', 'outperforms', 'existing', 'ebms', 'on', 'cifar', 'generation', 'fid', 'compared', 'to', 'while', 'retaining', 'the', 'simulation', 'free', 'training', 'of', 'transport', 'based', 'approaches', 'away', 'from', 'the', 'data', 'manifold', 'additionally', 'we', 'exploit', 'the', 'flexibility', 'of', 'our', 'method', 'and', 'introduce', 'an', 'interaction', 'energy', 'for', 'diverse', 'mode', 'exploration', 'our', 'approach', 'focuses', 'on', 'learning', 'a', 'static', 'scalar', 'potential', 'energy', 'without', 'time', 'conditioning', 'auxiliary', 'generators', 'or', 'additional', 'networks', 'marking', 'a', 'significant', 'departure', 'from', 'recent', 'ebm', 'methods', 'we', 'believe', 'this', 'simplified', 'framework', 'significantly', 'advances', 'ebm', 'capabilities', 'and', 'paves', 'the', 'way', 'for', 'their', 'broader', 'adoption', 'in', 'generative', 'modeling', 'across', 'diverse', 'domains']",12,216,"['FID', 'CIFAR-10', 'Our', 'Generative', 'Energy', 'Wasserstein', 'EBMs', 'Far', 'Boltzmann', 'EBM', 'Inspired', 'Matching', 'Additionally']"
2504.10584v1,Visual anemometry of natural vegetation from their leaf motion,"High-resolution, near-ground wind-speed data are critical for improving the accuracy of weather predictions and climate models,$^{1-3}$ supporting wildfire control efforts,$^{4-7}$ and ensuring the safe passage of airplanes during takeoff and landing maneouvers.$^{8,9}$ Quantitative wind speed anemometry generally employs on-site instrumentation for accurate single-position data or sophisticated remote techniques such as Doppler radar for quantitative field measurements. It is widely recognized that the wind-induced motion of vegetation depends in a complex manner on their structure and mechanical properties, obviating their use in quantitative anemometry.$^{10-14}$ We analyze measurements on a host of different vegetation showing that leaf motion can be decoupled from the leaf's branch and support structure, at low-to-moderate wind speed, $U_{wind}$. This wind speed range is characterized by a leaf Reynolds number, enabling the development of a remote, quantitative anemometry method based on the formula, $U_{wind}\approx740\sqrt{{\mu}U_{leaf}/{\rho}D}$, that relies only on the leaf size $D$, its measured fluctuating (RMS) speed $U_{leaf}$, the air viscosity $\mu$, and its mass density $\rho$. This formula is corroborated by a first-principles model and validated using a host of laboratory and field tests on diverse vegetation types, ranging from oak, olive, and magnolia trees through to camphor and bullgrass. The findings of this study open the door to a new paradigm in anemometry, using natural vegetation to enable remote and rapid quantitative field measurements at global locations with minimal cost.","Roni H. Goldshmid, John O. Dabiri, John E. Sader","physics.flu-dyn, cs.AI, cs.CV, physics.ao-ph",2025-04-14T18:00:02Z,http://arxiv.org/abs/2504.10584v1,visual anemometry of natural vegetation from their leaf motion,high resolution near ground wind speed data are critical for improving the accuracy of weather predictions and climate models supporting wildfire control efforts and ensuring the safe passage of airplanes during takeoff and landing maneouvers quantitative wind speed anemometry generally employs on site instrumentation for accurate single position data or sophisticated remote techniques such as doppler radar for quantitative field measurements it is widely recognized that the wind induced motion of vegetation depends in a complex manner on their structure and mechanical properties obviating their use in quantitative anemometry we analyze measurements on a host of different vegetation showing that leaf motion can be decoupled from the leaf s branch and support structure at low to moderate wind speed u_ wind this wind speed range is characterized by a leaf reynolds number enabling the development of a remote quantitative anemometry method based on the formula u_ wind u_ leaf d that relies only on the leaf size d its measured fluctuating rms speed u_ leaf the air viscosity and its mass density this formula is corroborated by a first principles model and validated using a host of laboratory and field tests on diverse vegetation types ranging from oak olive and magnolia trees through to camphor and bullgrass the findings of this study open the door to a new paradigm in anemometry using natural vegetation to enable remote and rapid quantitative field measurements at global locations with minimal cost,"['visual', 'anemometry', 'of', 'natural', 'vegetation', 'from', 'their', 'leaf', 'motion']","['high', 'resolution', 'near', 'ground', 'wind', 'speed', 'data', 'are', 'critical', 'for', 'improving', 'the', 'accuracy', 'of', 'weather', 'predictions', 'and', 'climate', 'models', 'supporting', 'wildfire', 'control', 'efforts', 'and', 'ensuring', 'the', 'safe', 'passage', 'of', 'airplanes', 'during', 'takeoff', 'and', 'landing', 'maneouvers', 'quantitative', 'wind', 'speed', 'anemometry', 'generally', 'employs', 'on', 'site', 'instrumentation', 'for', 'accurate', 'single', 'position', 'data', 'or', 'sophisticated', 'remote', 'techniques', 'such', 'as', 'doppler', 'radar', 'for', 'quantitative', 'field', 'measurements', 'it', 'is', 'widely', 'recognized', 'that', 'the', 'wind', 'induced', 'motion', 'of', 'vegetation', 'depends', 'in', 'a', 'complex', 'manner', 'on', 'their', 'structure', 'and', 'mechanical', 'properties', 'obviating', 'their', 'use', 'in', 'quantitative', 'anemometry', 'we', 'analyze', 'measurements', 'on', 'a', 'host', 'of', 'different', 'vegetation', 'showing', 'that', 'leaf', 'motion', 'can', 'be', 'decoupled', 'from', 'the', 'leaf', 's', 'branch', 'and', 'support', 'structure', 'at', 'low', 'to', 'moderate', 'wind', 'speed', 'u_', 'wind', 'this', 'wind', 'speed', 'range', 'is', 'characterized', 'by', 'a', 'leaf', 'reynolds', 'number', 'enabling', 'the', 'development', 'of', 'a', 'remote', 'quantitative', 'anemometry', 'method', 'based', 'on', 'the', 'formula', 'u_', 'wind', 'u_', 'leaf', 'd', 'that', 'relies', 'only', 'on', 'the', 'leaf', 'size', 'd', 'its', 'measured', 'fluctuating', 'rms', 'speed', 'u_', 'leaf', 'the', 'air', 'viscosity', 'and', 'its', 'mass', 'density', 'this', 'formula', 'is', 'corroborated', 'by', 'a', 'first', 'principles', 'model', 'and', 'validated', 'using', 'a', 'host', 'of', 'laboratory', 'and', 'field', 'tests', 'on', 'diverse', 'vegetation', 'types', 'ranging', 'from', 'oak', 'olive', 'and', 'magnolia', 'trees', 'through', 'to', 'camphor', 'and', 'bullgrass', 'the', 'findings', 'of', 'this', 'study', 'open', 'the', 'door', 'to', 'a', 'new', 'paradigm', 'in', 'anemometry', 'using', 'natural', 'vegetation', 'to', 'enable', 'remote', 'and', 'rapid', 'quantitative', 'field', 'measurements', 'at', 'global', 'locations', 'with', 'minimal', 'cost']",9,238,"['Quantitative', 'RMS', 'Reynolds', '1-3', 'High', '10-14', 'Doppler', '4-7']"
2504.10478v2,Weight Ensembling Improves Reasoning in Language Models,"We investigate a failure mode that arises during the training of reasoning models, where the diversity of generations begins to collapse, leading to suboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during supervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a simple intervention of interpolating the weights of the latest SFT checkpoint with an early checkpoint, otherwise known as WiSE-FT, almost completely recovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves better test-time scaling (Best@k, majority vote) and achieves superior results with less data when tuned further by reinforcement learning. Finally, we find that WiSE-FT provides complementary performance gains that cannot be achieved only through diversity-inducing decoding strategies, like temperature scaling. We formalize a bias-variance tradeoff of Pass@k with respect to the expectation and variance of Pass@1 over the test distribution. We find that WiSE-FT can reduce bias and variance simultaneously, while temperature scaling inherently trades-off between bias and variance.","Xingyu Dang, Christina Baek, Kaiyue Wen, Zico Kolter, Aditi Raghunathan","cs.LG, cs.AI",2025-04-14T17:59:07Z,http://arxiv.org/abs/2504.10478v2,weight ensembling improves reasoning in language models,we investigate a failure mode that arises during the training of reasoning models where the diversity of generations begins to collapse leading to suboptimal test time scaling notably the pass rate reliably improves during supervised finetuning sft but pass k rapidly deteriorates surprisingly a simple intervention of interpolating the weights of the latest sft checkpoint with an early checkpoint otherwise known as wise ft almost completely recovers pass k while also improving pass the wise ft variant achieves better test time scaling best k majority vote and achieves superior results with less data when tuned further by reinforcement learning finally we find that wise ft provides complementary performance gains that cannot be achieved only through diversity inducing decoding strategies like temperature scaling we formalize a bias variance tradeoff of pass k with respect to the expectation and variance of pass over the test distribution we find that wise ft can reduce bias and variance simultaneously while temperature scaling inherently trades off between bias and variance,"['weight', 'ensembling', 'improves', 'reasoning', 'in', 'language', 'models']","['we', 'investigate', 'a', 'failure', 'mode', 'that', 'arises', 'during', 'the', 'training', 'of', 'reasoning', 'models', 'where', 'the', 'diversity', 'of', 'generations', 'begins', 'to', 'collapse', 'leading', 'to', 'suboptimal', 'test', 'time', 'scaling', 'notably', 'the', 'pass', 'rate', 'reliably', 'improves', 'during', 'supervised', 'finetuning', 'sft', 'but', 'pass', 'k', 'rapidly', 'deteriorates', 'surprisingly', 'a', 'simple', 'intervention', 'of', 'interpolating', 'the', 'weights', 'of', 'the', 'latest', 'sft', 'checkpoint', 'with', 'an', 'early', 'checkpoint', 'otherwise', 'known', 'as', 'wise', 'ft', 'almost', 'completely', 'recovers', 'pass', 'k', 'while', 'also', 'improving', 'pass', 'the', 'wise', 'ft', 'variant', 'achieves', 'better', 'test', 'time', 'scaling', 'best', 'k', 'majority', 'vote', 'and', 'achieves', 'superior', 'results', 'with', 'less', 'data', 'when', 'tuned', 'further', 'by', 'reinforcement', 'learning', 'finally', 'we', 'find', 'that', 'wise', 'ft', 'provides', 'complementary', 'performance', 'gains', 'that', 'can', 'not', 'be', 'achieved', 'only', 'through', 'diversity', 'inducing', 'decoding', 'strategies', 'like', 'temperature', 'scaling', 'we', 'formalize', 'a', 'bias', 'variance', 'tradeoff', 'of', 'pass', 'k', 'with', 'respect', 'to', 'the', 'expectation', 'and', 'variance', 'of', 'pass', 'over', 'the', 'test', 'distribution', 'we', 'find', 'that', 'wise', 'ft', 'can', 'reduce', 'bias', 'and', 'variance', 'simultaneously', 'while', 'temperature', 'scaling', 'inherently', 'trades', 'off', 'between', 'bias', 'and', 'variance']",7,166,"['Finally', 'SFT', 'Best', 'Pass', 'Notably', 'Surprisingly', 'WiSE']"
2504.10443v1,Multimodal Long Video Modeling Based on Temporal Dynamic Context,"Recent advances in Large Language Models (LLMs) have led to significant breakthroughs in video understanding. However, existing models still struggle with long video processing due to the context length constraint of LLMs and the vast amount of information within the video. Although some recent methods are designed for long video understanding, they often lose crucial information during token compression and struggle with additional modality like audio. In this work, we propose a dynamic long video encoding method utilizing the temporal relationship between frames, named Temporal Dynamic Context (TDC). Firstly, we segment the video into semantically consistent scenes based on inter-frame similarities, then encode each frame into tokens using visual-audio encoders. Secondly, we propose a novel temporal context compressor to reduce the number of tokens within each segment. Specifically, we employ a query-based Transformer to aggregate video, audio, and instruction text tokens into a limited set of temporal context tokens. Finally, we feed the static frame tokens and the temporal context tokens into the LLM for video understanding. Furthermore, to handle extremely long videos, we propose a training-free chain-of-thought strategy that progressively extracts answers from multiple video segments. These intermediate answers serve as part of the reasoning process and contribute to the final answer. We conduct extensive experiments on general video understanding and audio-video understanding benchmarks, where our method demonstrates strong performance. The code and models are available at https://github.com/Hoar012/TDC-Video.","Haoran Hao, Jiaming Han, Yiyuan Zhang, Xiangyu Yue","cs.CV, cs.AI, cs.CL, cs.LG, cs.MM",2025-04-14T17:34:06Z,http://arxiv.org/abs/2504.10443v1,multimodal long video modeling based on temporal dynamic context,recent advances in large language models llms have led to significant breakthroughs in video understanding however existing models still struggle with long video processing due to the context length constraint of llms and the vast amount of information within the video although some recent methods are designed for long video understanding they often lose crucial information during token compression and struggle with additional modality like audio in this work we propose a dynamic long video encoding method utilizing the temporal relationship between frames named temporal dynamic context tdc firstly we segment the video into semantically consistent scenes based on inter frame similarities then encode each frame into tokens using visual audio encoders secondly we propose a novel temporal context compressor to reduce the number of tokens within each segment specifically we employ a query based transformer to aggregate video audio and instruction text tokens into a limited set of temporal context tokens finally we feed the static frame tokens and the temporal context tokens into the llm for video understanding furthermore to handle extremely long videos we propose a training free chain of thought strategy that progressively extracts answers from multiple video segments these intermediate answers serve as part of the reasoning process and contribute to the final answer we conduct extensive experiments on general video understanding and audio video understanding benchmarks where our method demonstrates strong performance the code and models are available at,"['multimodal', 'long', 'video', 'modeling', 'based', 'on', 'temporal', 'dynamic', 'context']","['recent', 'advances', 'in', 'large', 'language', 'models', 'llms', 'have', 'led', 'to', 'significant', 'breakthroughs', 'in', 'video', 'understanding', 'however', 'existing', 'models', 'still', 'struggle', 'with', 'long', 'video', 'processing', 'due', 'to', 'the', 'context', 'length', 'constraint', 'of', 'llms', 'and', 'the', 'vast', 'amount', 'of', 'information', 'within', 'the', 'video', 'although', 'some', 'recent', 'methods', 'are', 'designed', 'for', 'long', 'video', 'understanding', 'they', 'often', 'lose', 'crucial', 'information', 'during', 'token', 'compression', 'and', 'struggle', 'with', 'additional', 'modality', 'like', 'audio', 'in', 'this', 'work', 'we', 'propose', 'a', 'dynamic', 'long', 'video', 'encoding', 'method', 'utilizing', 'the', 'temporal', 'relationship', 'between', 'frames', 'named', 'temporal', 'dynamic', 'context', 'tdc', 'firstly', 'we', 'segment', 'the', 'video', 'into', 'semantically', 'consistent', 'scenes', 'based', 'on', 'inter', 'frame', 'similarities', 'then', 'encode', 'each', 'frame', 'into', 'tokens', 'using', 'visual', 'audio', 'encoders', 'secondly', 'we', 'propose', 'a', 'novel', 'temporal', 'context', 'compressor', 'to', 'reduce', 'the', 'number', 'of', 'tokens', 'within', 'each', 'segment', 'specifically', 'we', 'employ', 'a', 'query', 'based', 'transformer', 'to', 'aggregate', 'video', 'audio', 'and', 'instruction', 'text', 'tokens', 'into', 'a', 'limited', 'set', 'of', 'temporal', 'context', 'tokens', 'finally', 'we', 'feed', 'the', 'static', 'frame', 'tokens', 'and', 'the', 'temporal', 'context', 'tokens', 'into', 'the', 'llm', 'for', 'video', 'understanding', 'furthermore', 'to', 'handle', 'extremely', 'long', 'videos', 'we', 'propose', 'a', 'training', 'free', 'chain', 'of', 'thought', 'strategy', 'that', 'progressively', 'extracts', 'answers', 'from', 'multiple', 'video', 'segments', 'these', 'intermediate', 'answers', 'serve', 'as', 'part', 'of', 'the', 'reasoning', 'process', 'and', 'contribute', 'to', 'the', 'final', 'answer', 'we', 'conduct', 'extensive', 'experiments', 'on', 'general', 'video', 'understanding', 'and', 'audio', 'video', 'understanding', 'benchmarks', 'where', 'our', 'method', 'demonstrates', 'strong', 'performance', 'the', 'code', 'and', 'models', 'are', 'available', 'at']",9,235,"['Dynamic', 'TDC', 'Hoar012', 'Temporal', 'Specifically', 'Language', 'LLMs', 'However', 'Furthermore', 'Transformer', 'Large', 'Recent', 'Finally', 'Context', 'TDC-Video', 'Secondly', 'LLM', 'Firstly', 'These', 'Models', 'Although']"
2504.10415v1,LLM-SRBench: A New Benchmark for Scientific Equation Discovery with   Large Language Models,"Scientific equation discovery is a fundamental task in the history of scientific progress, enabling the derivation of laws governing natural phenomena. Recently, Large Language Models (LLMs) have gained interest for this task due to their potential to leverage embedded scientific knowledge for hypothesis generation. However, evaluating the true discovery capabilities of these methods remains challenging, as existing benchmarks often rely on common equations that are susceptible to memorization by LLMs, leading to inflated performance metrics that do not reflect discovery. In this paper, we introduce LLM-SRBench, a comprehensive benchmark with 239 challenging problems across four scientific domains specifically designed to evaluate LLM-based scientific equation discovery methods while preventing trivial memorization. Our benchmark comprises two main categories: LSR-Transform, which transforms common physical models into less common mathematical representations to test reasoning beyond memorized forms, and LSR-Synth, which introduces synthetic, discovery-driven problems requiring data-driven reasoning. Through extensive evaluation of several state-of-the-art methods, using both open and closed LLMs, we find that the best-performing system so far achieves only 31.5% symbolic accuracy. These findings highlight the challenges of scientific equation discovery, positioning LLM-SRBench as a valuable resource for future research.","Parshin Shojaee, Ngoc-Hieu Nguyen, Kazem Meidani, Amir Barati Farimani, Khoa D Doan, Chandan K Reddy","cs.CL, cs.AI, cs.LG",2025-04-14T17:00:13Z,http://arxiv.org/abs/2504.10415v1,llm srbench a new benchmark for scientific equation discovery with large language models,scientific equation discovery is a fundamental task in the history of scientific progress enabling the derivation of laws governing natural phenomena recently large language models llms have gained interest for this task due to their potential to leverage embedded scientific knowledge for hypothesis generation however evaluating the true discovery capabilities of these methods remains challenging as existing benchmarks often rely on common equations that are susceptible to memorization by llms leading to inflated performance metrics that do not reflect discovery in this paper we introduce llm srbench a comprehensive benchmark with challenging problems across four scientific domains specifically designed to evaluate llm based scientific equation discovery methods while preventing trivial memorization our benchmark comprises two main categories lsr transform which transforms common physical models into less common mathematical representations to test reasoning beyond memorized forms and lsr synth which introduces synthetic discovery driven problems requiring data driven reasoning through extensive evaluation of several state of the art methods using both open and closed llms we find that the best performing system so far achieves only symbolic accuracy these findings highlight the challenges of scientific equation discovery positioning llm srbench as a valuable resource for future research,"['llm', 'srbench', 'a', 'new', 'benchmark', 'for', 'scientific', 'equation', 'discovery', 'with', 'large', 'language', 'models']","['scientific', 'equation', 'discovery', 'is', 'a', 'fundamental', 'task', 'in', 'the', 'history', 'of', 'scientific', 'progress', 'enabling', 'the', 'derivation', 'of', 'laws', 'governing', 'natural', 'phenomena', 'recently', 'large', 'language', 'models', 'llms', 'have', 'gained', 'interest', 'for', 'this', 'task', 'due', 'to', 'their', 'potential', 'to', 'leverage', 'embedded', 'scientific', 'knowledge', 'for', 'hypothesis', 'generation', 'however', 'evaluating', 'the', 'true', 'discovery', 'capabilities', 'of', 'these', 'methods', 'remains', 'challenging', 'as', 'existing', 'benchmarks', 'often', 'rely', 'on', 'common', 'equations', 'that', 'are', 'susceptible', 'to', 'memorization', 'by', 'llms', 'leading', 'to', 'inflated', 'performance', 'metrics', 'that', 'do', 'not', 'reflect', 'discovery', 'in', 'this', 'paper', 'we', 'introduce', 'llm', 'srbench', 'a', 'comprehensive', 'benchmark', 'with', 'challenging', 'problems', 'across', 'four', 'scientific', 'domains', 'specifically', 'designed', 'to', 'evaluate', 'llm', 'based', 'scientific', 'equation', 'discovery', 'methods', 'while', 'preventing', 'trivial', 'memorization', 'our', 'benchmark', 'comprises', 'two', 'main', 'categories', 'lsr', 'transform', 'which', 'transforms', 'common', 'physical', 'models', 'into', 'less', 'common', 'mathematical', 'representations', 'to', 'test', 'reasoning', 'beyond', 'memorized', 'forms', 'and', 'lsr', 'synth', 'which', 'introduces', 'synthetic', 'discovery', 'driven', 'problems', 'requiring', 'data', 'driven', 'reasoning', 'through', 'extensive', 'evaluation', 'of', 'several', 'state', 'of', 'the', 'art', 'methods', 'using', 'both', 'open', 'and', 'closed', 'llms', 'we', 'find', 'that', 'the', 'best', 'performing', 'system', 'so', 'far', 'achieves', 'only', 'symbolic', 'accuracy', 'these', 'findings', 'highlight', 'the', 'challenges', 'of', 'scientific', 'equation', 'discovery', 'positioning', 'llm', 'srbench', 'as', 'a', 'valuable', 'resource', 'for', 'future', 'research']",13,196,"['Through', 'LSR-Transform', 'Scientific', 'LLMs', 'Recently', 'However', 'These', 'Models', 'LSR-Synth', 'LLM-based', '239', 'Language', 'Our', 'Large', 'LLM-SRBench']"
2504.10397v1,Can LLMs Assist Expert Elicitation for Probabilistic Causal Modeling?,"Objective: This study investigates the potential of Large Language Models (LLMs) as an alternative to human expert elicitation for extracting structured causal knowledge and facilitating causal modeling in biometric and healthcare applications.   Material and Methods: LLM-generated causal structures, specifically Bayesian networks (BNs), were benchmarked against traditional statistical methods (e.g., Bayesian Information Criterion) using healthcare datasets. Validation techniques included structural equation modeling (SEM) to verifying relationships, and measures such as entropy, predictive accuracy, and robustness to compare network structures.   Results and Discussion: LLM-generated BNs demonstrated lower entropy than expert-elicited and statistically generated BNs, suggesting higher confidence and precision in predictions. However, limitations such as contextual constraints, hallucinated dependencies, and potential biases inherited from training data require further investigation.   Conclusion: LLMs represent a novel frontier in expert elicitation for probabilistic causal modeling, promising to improve transparency and reduce uncertainty in the decision-making using such models.","Olha Shaposhnyk, Daria Zahorska, Svetlana Yanushkevich","cs.AI, cs.LG",2025-04-14T16:45:52Z,http://arxiv.org/abs/2504.10397v1,can llms assist expert elicitation for probabilistic causal modeling,objective this study investigates the potential of large language models llms as an alternative to human expert elicitation for extracting structured causal knowledge and facilitating causal modeling in biometric and healthcare applications material and methods llm generated causal structures specifically bayesian networks bns were benchmarked against traditional statistical methods e g bayesian information criterion using healthcare datasets validation techniques included structural equation modeling sem to verifying relationships and measures such as entropy predictive accuracy and robustness to compare network structures results and discussion llm generated bns demonstrated lower entropy than expert elicited and statistically generated bns suggesting higher confidence and precision in predictions however limitations such as contextual constraints hallucinated dependencies and potential biases inherited from training data require further investigation conclusion llms represent a novel frontier in expert elicitation for probabilistic causal modeling promising to improve transparency and reduce uncertainty in the decision making using such models,"['can', 'llms', 'assist', 'expert', 'elicitation', 'for', 'probabilistic', 'causal', 'modeling']","['objective', 'this', 'study', 'investigates', 'the', 'potential', 'of', 'large', 'language', 'models', 'llms', 'as', 'an', 'alternative', 'to', 'human', 'expert', 'elicitation', 'for', 'extracting', 'structured', 'causal', 'knowledge', 'and', 'facilitating', 'causal', 'modeling', 'in', 'biometric', 'and', 'healthcare', 'applications', 'material', 'and', 'methods', 'llm', 'generated', 'causal', 'structures', 'specifically', 'bayesian', 'networks', 'bns', 'were', 'benchmarked', 'against', 'traditional', 'statistical', 'methods', 'e', 'g', 'bayesian', 'information', 'criterion', 'using', 'healthcare', 'datasets', 'validation', 'techniques', 'included', 'structural', 'equation', 'modeling', 'sem', 'to', 'verifying', 'relationships', 'and', 'measures', 'such', 'as', 'entropy', 'predictive', 'accuracy', 'and', 'robustness', 'to', 'compare', 'network', 'structures', 'results', 'and', 'discussion', 'llm', 'generated', 'bns', 'demonstrated', 'lower', 'entropy', 'than', 'expert', 'elicited', 'and', 'statistically', 'generated', 'bns', 'suggesting', 'higher', 'confidence', 'and', 'precision', 'in', 'predictions', 'however', 'limitations', 'such', 'as', 'contextual', 'constraints', 'hallucinated', 'dependencies', 'and', 'potential', 'biases', 'inherited', 'from', 'training', 'data', 'require', 'further', 'investigation', 'conclusion', 'llms', 'represent', 'a', 'novel', 'frontier', 'in', 'expert', 'elicitation', 'for', 'probabilistic', 'causal', 'modeling', 'promising', 'to', 'improve', 'transparency', 'and', 'reduce', 'uncertainty', 'in', 'the', 'decision', 'making', 'using', 'such', 'models']",9,148,"['LLM-generated', 'BNs', 'LLMs', 'Information', 'Criterion', 'Methods', 'Objective', 'Models', 'Validation', 'Discussion', 'However', 'Conclusion', 'Language', 'Bayesian', 'SEM', 'Large', 'Material', 'Results']"
2504.10390v1,Teacher Motion Priors: Enhancing Robot Locomotion over Challenging   Terrain,"Achieving robust locomotion on complex terrains remains a challenge due to high dimensional control and environmental uncertainties. This paper introduces a teacher prior framework based on the teacher student paradigm, integrating imitation and auxiliary task learning to improve learning efficiency and generalization. Unlike traditional paradigms that strongly rely on encoder-based state embeddings, our framework decouples the network design, simplifying the policy network and deployment. A high performance teacher policy is first trained using privileged information to acquire generalizable motion skills. The teacher's motion distribution is transferred to the student policy, which relies only on noisy proprioceptive data, via a generative adversarial mechanism to mitigate performance degradation caused by distributional shifts. Additionally, auxiliary task learning enhances the student policy's feature representation, speeding up convergence and improving adaptability to varying terrains. The framework is validated on a humanoid robot, showing a great improvement in locomotion stability on dynamic terrains and significant reductions in development costs. This work provides a practical solution for deploying robust locomotion strategies in humanoid robots.","Fangcheng Jin, Yuqi Wang, Peixin Ma, Guodong Yang, Pan Zhao, En Li, Zhengtao Zhang","cs.RO, cs.AI, 68T40",2025-04-14T16:36:56Z,http://arxiv.org/abs/2504.10390v1,teacher motion priors enhancing robot locomotion over challenging terrain,achieving robust locomotion on complex terrains remains a challenge due to high dimensional control and environmental uncertainties this paper introduces a teacher prior framework based on the teacher student paradigm integrating imitation and auxiliary task learning to improve learning efficiency and generalization unlike traditional paradigms that strongly rely on encoder based state embeddings our framework decouples the network design simplifying the policy network and deployment a high performance teacher policy is first trained using privileged information to acquire generalizable motion skills the teacher s motion distribution is transferred to the student policy which relies only on noisy proprioceptive data via a generative adversarial mechanism to mitigate performance degradation caused by distributional shifts additionally auxiliary task learning enhances the student policy s feature representation speeding up convergence and improving adaptability to varying terrains the framework is validated on a humanoid robot showing a great improvement in locomotion stability on dynamic terrains and significant reductions in development costs this work provides a practical solution for deploying robust locomotion strategies in humanoid robots,"['teacher', 'motion', 'priors', 'enhancing', 'robot', 'locomotion', 'over', 'challenging', 'terrain']","['achieving', 'robust', 'locomotion', 'on', 'complex', 'terrains', 'remains', 'a', 'challenge', 'due', 'to', 'high', 'dimensional', 'control', 'and', 'environmental', 'uncertainties', 'this', 'paper', 'introduces', 'a', 'teacher', 'prior', 'framework', 'based', 'on', 'the', 'teacher', 'student', 'paradigm', 'integrating', 'imitation', 'and', 'auxiliary', 'task', 'learning', 'to', 'improve', 'learning', 'efficiency', 'and', 'generalization', 'unlike', 'traditional', 'paradigms', 'that', 'strongly', 'rely', 'on', 'encoder', 'based', 'state', 'embeddings', 'our', 'framework', 'decouples', 'the', 'network', 'design', 'simplifying', 'the', 'policy', 'network', 'and', 'deployment', 'a', 'high', 'performance', 'teacher', 'policy', 'is', 'first', 'trained', 'using', 'privileged', 'information', 'to', 'acquire', 'generalizable', 'motion', 'skills', 'the', 'teacher', 's', 'motion', 'distribution', 'is', 'transferred', 'to', 'the', 'student', 'policy', 'which', 'relies', 'only', 'on', 'noisy', 'proprioceptive', 'data', 'via', 'a', 'generative', 'adversarial', 'mechanism', 'to', 'mitigate', 'performance', 'degradation', 'caused', 'by', 'distributional', 'shifts', 'additionally', 'auxiliary', 'task', 'learning', 'enhances', 'the', 'student', 'policy', 's', 'feature', 'representation', 'speeding', 'up', 'convergence', 'and', 'improving', 'adaptability', 'to', 'varying', 'terrains', 'the', 'framework', 'is', 'validated', 'on', 'a', 'humanoid', 'robot', 'showing', 'a', 'great', 'improvement', 'in', 'locomotion', 'stability', 'on', 'dynamic', 'terrains', 'and', 'significant', 'reductions', 'in', 'development', 'costs', 'this', 'work', 'provides', 'a', 'practical', 'solution', 'for', 'deploying', 'robust', 'locomotion', 'strategies', 'in', 'humanoid', 'robots']",9,170,"['Unlike', 'Achieving', 'Additionally']"
2504.10369v1,SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired   Symbolic Reasoning,"Optimizing Register Transfer Level (RTL) code is crucial for improving the power, performance, and area (PPA) of digital circuits in the early stages of synthesis. Manual rewriting, guided by synthesis feedback, can yield high-quality results but is time-consuming and error-prone. Most existing compiler-based approaches have difficulty handling complex design constraints. Large Language Model (LLM)-based methods have emerged as a promising alternative to address these challenges. However, LLM-based approaches often face difficulties in ensuring alignment between the generated code and the provided prompts. This paper presents SymRTLO, a novel neuron-symbolic RTL optimization framework that seamlessly integrates LLM-based code rewriting with symbolic reasoning techniques. Our method incorporates a retrieval-augmented generation (RAG) system of optimization rules and Abstract Syntax Tree (AST)-based templates, enabling LLM-based rewriting that maintains syntactic correctness while minimizing undesired circuit behaviors. A symbolic module is proposed for analyzing and optimizing finite state machine (FSM) logic, allowing fine-grained state merging and partial specification handling beyond the scope of pattern-based compilers. Furthermore, a fast verification pipeline, combining formal equivalence checks with test-driven validation, further reduces the complexity of verification. Experiments on the RTL-Rewriter benchmark with Synopsys Design Compiler and Yosys show that SymRTLO improves power, performance, and area (PPA) by up to 43.9%, 62.5%, and 51.1%, respectively, compared to the state-of-the-art methods.","Yiting Wang, Wanghao Ye, Ping Guo, Yexiao He, Ziyao Wang, Yexiao He, Bowei Tian, Shwai He, Guoheng Sun, Zheyu Shen, Sihan Chen, Ankur Srivastava, Qingfu Zhang, Gang Qu, Ang Li","cs.AR, cs.AI, cs.LG, cs.PL",2025-04-14T16:15:55Z,http://arxiv.org/abs/2504.10369v1,symrtlo enhancing rtl code optimization with llms and neuron inspired symbolic reasoning,optimizing register transfer level rtl code is crucial for improving the power performance and area ppa of digital circuits in the early stages of synthesis manual rewriting guided by synthesis feedback can yield high quality results but is time consuming and error prone most existing compiler based approaches have difficulty handling complex design constraints large language model llm based methods have emerged as a promising alternative to address these challenges however llm based approaches often face difficulties in ensuring alignment between the generated code and the provided prompts this paper presents symrtlo a novel neuron symbolic rtl optimization framework that seamlessly integrates llm based code rewriting with symbolic reasoning techniques our method incorporates a retrieval augmented generation rag system of optimization rules and abstract syntax tree ast based templates enabling llm based rewriting that maintains syntactic correctness while minimizing undesired circuit behaviors a symbolic module is proposed for analyzing and optimizing finite state machine fsm logic allowing fine grained state merging and partial specification handling beyond the scope of pattern based compilers furthermore a fast verification pipeline combining formal equivalence checks with test driven validation further reduces the complexity of verification experiments on the rtl rewriter benchmark with synopsys design compiler and yosys show that symrtlo improves power performance and area ppa by up to and respectively compared to the state of the art methods,"['symrtlo', 'enhancing', 'rtl', 'code', 'optimization', 'with', 'llms', 'and', 'neuron', 'inspired', 'symbolic', 'reasoning']","['optimizing', 'register', 'transfer', 'level', 'rtl', 'code', 'is', 'crucial', 'for', 'improving', 'the', 'power', 'performance', 'and', 'area', 'ppa', 'of', 'digital', 'circuits', 'in', 'the', 'early', 'stages', 'of', 'synthesis', 'manual', 'rewriting', 'guided', 'by', 'synthesis', 'feedback', 'can', 'yield', 'high', 'quality', 'results', 'but', 'is', 'time', 'consuming', 'and', 'error', 'prone', 'most', 'existing', 'compiler', 'based', 'approaches', 'have', 'difficulty', 'handling', 'complex', 'design', 'constraints', 'large', 'language', 'model', 'llm', 'based', 'methods', 'have', 'emerged', 'as', 'a', 'promising', 'alternative', 'to', 'address', 'these', 'challenges', 'however', 'llm', 'based', 'approaches', 'often', 'face', 'difficulties', 'in', 'ensuring', 'alignment', 'between', 'the', 'generated', 'code', 'and', 'the', 'provided', 'prompts', 'this', 'paper', 'presents', 'symrtlo', 'a', 'novel', 'neuron', 'symbolic', 'rtl', 'optimization', 'framework', 'that', 'seamlessly', 'integrates', 'llm', 'based', 'code', 'rewriting', 'with', 'symbolic', 'reasoning', 'techniques', 'our', 'method', 'incorporates', 'a', 'retrieval', 'augmented', 'generation', 'rag', 'system', 'of', 'optimization', 'rules', 'and', 'abstract', 'syntax', 'tree', 'ast', 'based', 'templates', 'enabling', 'llm', 'based', 'rewriting', 'that', 'maintains', 'syntactic', 'correctness', 'while', 'minimizing', 'undesired', 'circuit', 'behaviors', 'a', 'symbolic', 'module', 'is', 'proposed', 'for', 'analyzing', 'and', 'optimizing', 'finite', 'state', 'machine', 'fsm', 'logic', 'allowing', 'fine', 'grained', 'state', 'merging', 'and', 'partial', 'specification', 'handling', 'beyond', 'the', 'scope', 'of', 'pattern', 'based', 'compilers', 'furthermore', 'a', 'fast', 'verification', 'pipeline', 'combining', 'formal', 'equivalence', 'checks', 'with', 'test', 'driven', 'validation', 'further', 'reduces', 'the', 'complexity', 'of', 'verification', 'experiments', 'on', 'the', 'rtl', 'rewriter', 'benchmark', 'with', 'synopsys', 'design', 'compiler', 'and', 'yosys', 'show', 'that', 'symrtlo', 'improves', 'power', 'performance', 'and', 'area', 'ppa', 'by', 'up', 'to', 'and', 'respectively', 'compared', 'to', 'the', 'state', 'of', 'the', 'art', 'methods']",12,225,"['Most', 'Model', 'PPA', 'Manual', 'Language', 'Our', 'FSM', 'SymRTLO', 'Optimizing', 'Syntax', 'AST', 'However', 'Design', 'Abstract', 'Furthermore', 'Large', 'Experiments', 'Compiler', 'Synopsys', 'RAG', 'Yosys', 'LLM-based', 'Register', 'LLM', 'RTL-Rewriter', 'Level', 'Tree', 'RTL', 'Transfer']"
2504.10358v1,FingER: Content Aware Fine-grained Evaluation with Reasoning for   AI-Generated Videos,"Recent advances in video generation have posed great challenges in the assessment of AI-generated content, particularly with the emergence of increasingly sophisticated models. The various inconsistencies and defects observed in such videos are inherently complex, making overall scoring notoriously difficult. In this paper, we emphasize the critical importance of integrating fine-grained reasoning into video evaluation, and we propose $\textbf{F}$ing$\textbf{ER}$, a novel entity-level reasoning evaluation framework that first automatically generates $\textbf{F}$ine-grained $\textbf{E}$ntity-level questions, and then answers those questions by a $\textbf{R}$easoning model with scores, which can be subsequently weighted summed to an overall score for different applications. Specifically, we leverage LLMs to derive entity-level questions across five distinct perspectives, which (i) often focus on some specific entities of the content, thereby making answering or scoring much easier by MLLMs, and (ii) are more interpretable. Then we construct a FingER dataset, consisting of approximately 3.3k videos and corresponding 60k fine-grained QA annotations, each with detailed reasons. Based on that, we further investigate various training protocols to best incentivize the reasoning capability of MLLMs for correct answer prediction. Extensive experiments demonstrate that a reasoning model trained using Group Relative Policy Optimization (GRPO) with a cold-start strategy achieves the best performance. Notably, our model surpasses existing methods by a relative margin of $11.8\%$ on GenAI-Bench and $5.5\%$ on MonetBench with only 3.3k training videos, which is at most one-tenth of the training samples utilized by other methods. Our code and dataset will be released soon.","Rui Chen, Lei Sun, Jing Tang, Geng Li, Xiangxiang Chu","cs.CV, cs.AI",2025-04-14T16:07:16Z,http://arxiv.org/abs/2504.10358v1,finger content aware fine grained evaluation with reasoning for ai generated videos,recent advances in video generation have posed great challenges in the assessment of ai generated content particularly with the emergence of increasingly sophisticated models the various inconsistencies and defects observed in such videos are inherently complex making overall scoring notoriously difficult in this paper we emphasize the critical importance of integrating fine grained reasoning into video evaluation and we propose f ing er a novel entity level reasoning evaluation framework that first automatically generates f ine grained e ntity level questions and then answers those questions by a r easoning model with scores which can be subsequently weighted summed to an overall score for different applications specifically we leverage llms to derive entity level questions across five distinct perspectives which i often focus on some specific entities of the content thereby making answering or scoring much easier by mllms and ii are more interpretable then we construct a finger dataset consisting of approximately k videos and corresponding k fine grained qa annotations each with detailed reasons based on that we further investigate various training protocols to best incentivize the reasoning capability of mllms for correct answer prediction extensive experiments demonstrate that a reasoning model trained using group relative policy optimization grpo with a cold start strategy achieves the best performance notably our model surpasses existing methods by a relative margin of on genai bench and on monetbench with only k training videos which is at most one tenth of the training samples utilized by other methods our code and dataset will be released soon,"['finger', 'content', 'aware', 'fine', 'grained', 'evaluation', 'with', 'reasoning', 'for', 'ai', 'generated', 'videos']","['recent', 'advances', 'in', 'video', 'generation', 'have', 'posed', 'great', 'challenges', 'in', 'the', 'assessment', 'of', 'ai', 'generated', 'content', 'particularly', 'with', 'the', 'emergence', 'of', 'increasingly', 'sophisticated', 'models', 'the', 'various', 'inconsistencies', 'and', 'defects', 'observed', 'in', 'such', 'videos', 'are', 'inherently', 'complex', 'making', 'overall', 'scoring', 'notoriously', 'difficult', 'in', 'this', 'paper', 'we', 'emphasize', 'the', 'critical', 'importance', 'of', 'integrating', 'fine', 'grained', 'reasoning', 'into', 'video', 'evaluation', 'and', 'we', 'propose', 'f', 'ing', 'er', 'a', 'novel', 'entity', 'level', 'reasoning', 'evaluation', 'framework', 'that', 'first', 'automatically', 'generates', 'f', 'ine', 'grained', 'e', 'ntity', 'level', 'questions', 'and', 'then', 'answers', 'those', 'questions', 'by', 'a', 'r', 'easoning', 'model', 'with', 'scores', 'which', 'can', 'be', 'subsequently', 'weighted', 'summed', 'to', 'an', 'overall', 'score', 'for', 'different', 'applications', 'specifically', 'we', 'leverage', 'llms', 'to', 'derive', 'entity', 'level', 'questions', 'across', 'five', 'distinct', 'perspectives', 'which', 'i', 'often', 'focus', 'on', 'some', 'specific', 'entities', 'of', 'the', 'content', 'thereby', 'making', 'answering', 'or', 'scoring', 'much', 'easier', 'by', 'mllms', 'and', 'ii', 'are', 'more', 'interpretable', 'then', 'we', 'construct', 'a', 'finger', 'dataset', 'consisting', 'of', 'approximately', 'k', 'videos', 'and', 'corresponding', 'k', 'fine', 'grained', 'qa', 'annotations', 'each', 'with', 'detailed', 'reasons', 'based', 'on', 'that', 'we', 'further', 'investigate', 'various', 'training', 'protocols', 'to', 'best', 'incentivize', 'the', 'reasoning', 'capability', 'of', 'mllms', 'for', 'correct', 'answer', 'prediction', 'extensive', 'experiments', 'demonstrate', 'that', 'a', 'reasoning', 'model', 'trained', 'using', 'group', 'relative', 'policy', 'optimization', 'grpo', 'with', 'a', 'cold', 'start', 'strategy', 'achieves', 'the', 'best', 'performance', 'notably', 'our', 'model', 'surpasses', 'existing', 'methods', 'by', 'a', 'relative', 'margin', 'of', 'on', 'genai', 'bench', 'and', 'on', 'monetbench', 'with', 'only', 'k', 'training', 'videos', 'which', 'is', 'at', 'most', 'one', 'tenth', 'of', 'the', 'training', 'samples', 'utilized', 'by', 'other', 'methods', 'our', 'code', 'and', 'dataset', 'will', 'be', 'released', 'soon']",12,254,"['GenAI', 'Notably', 'Specifically', 'Our', '60k', 'GRPO', 'LLMs', 'Relative', 'Policy', 'Recent', 'FingER', 'Based', 'MLLMs', 'Then', 'AI-generated', 'Extensive', 'Bench', 'MonetBench', 'Group', 'Optimization']"
2504.10337v2,Heimdall: test-time scaling on the generative verification,"An AI system can create and maintain knowledge only to the extent that it can verify that knowledge itself. Recent work on long Chain-of-Thought reasoning has demonstrated great potential of LLMs on solving competitive problems, but their verification ability remains to be weak and not sufficiently investigated. In this paper, we propose Heimdall, the long CoT verification LLM that can accurately judge the correctness of solutions. With pure reinforcement learning, we boost the verification accuracy from 62.5% to 94.5% on competitive math problems. By scaling with repeated sampling, the accuracy further increases to 97.5%. Through human evaluation, Heimdall demonstrates impressive generalization capabilities, successfully detecting most issues in challenging math proofs, the type of which is not included during training. Furthermore, we propose Pessimistic Verification to extend the functionality of Heimdall to scaling up the problem solving. It calls Heimdall to judge the solutions from a solver model and based on the pessimistic principle, selects the most likely correct solution with the least uncertainty. Taking DeepSeek-R1-Distill-Qwen-32B as the solver model, Pessimistic Verification improves the solution accuracy on AIME2025 from 54.2% to 70.0% with 16x compute budget and to 83.3% with more compute budget. With the stronger solver Gemini 2.5 Pro, the score reaches 93.0%. Finally, we prototype an automatic knowledge discovery system, a ternary system where one poses questions, another provides solutions, and the third verifies the solutions. Using the data synthesis work NuminaMath for the first two components, Heimdall effectively identifies problematic records within the dataset and reveals that nearly half of the data is flawed, which interestingly aligns with the recent ablation studies from NuminaMath.","Wenlei Shi, Xing Jin","cs.AI, I.2.7",2025-04-14T15:46:33Z,http://arxiv.org/abs/2504.10337v2,heimdall test time scaling on the generative verification,an ai system can create and maintain knowledge only to the extent that it can verify that knowledge itself recent work on long chain of thought reasoning has demonstrated great potential of llms on solving competitive problems but their verification ability remains to be weak and not sufficiently investigated in this paper we propose heimdall the long cot verification llm that can accurately judge the correctness of solutions with pure reinforcement learning we boost the verification accuracy from to on competitive math problems by scaling with repeated sampling the accuracy further increases to through human evaluation heimdall demonstrates impressive generalization capabilities successfully detecting most issues in challenging math proofs the type of which is not included during training furthermore we propose pessimistic verification to extend the functionality of heimdall to scaling up the problem solving it calls heimdall to judge the solutions from a solver model and based on the pessimistic principle selects the most likely correct solution with the least uncertainty taking deepseek r distill qwen b as the solver model pessimistic verification improves the solution accuracy on aime from to with x compute budget and to with more compute budget with the stronger solver gemini pro the score reaches finally we prototype an automatic knowledge discovery system a ternary system where one poses questions another provides solutions and the third verifies the solutions using the data synthesis work numinamath for the first two components heimdall effectively identifies problematic records within the dataset and reveals that nearly half of the data is flawed which interestingly aligns with the recent ablation studies from numinamath,"['heimdall', 'test', 'time', 'scaling', 'on', 'the', 'generative', 'verification']","['an', 'ai', 'system', 'can', 'create', 'and', 'maintain', 'knowledge', 'only', 'to', 'the', 'extent', 'that', 'it', 'can', 'verify', 'that', 'knowledge', 'itself', 'recent', 'work', 'on', 'long', 'chain', 'of', 'thought', 'reasoning', 'has', 'demonstrated', 'great', 'potential', 'of', 'llms', 'on', 'solving', 'competitive', 'problems', 'but', 'their', 'verification', 'ability', 'remains', 'to', 'be', 'weak', 'and', 'not', 'sufficiently', 'investigated', 'in', 'this', 'paper', 'we', 'propose', 'heimdall', 'the', 'long', 'cot', 'verification', 'llm', 'that', 'can', 'accurately', 'judge', 'the', 'correctness', 'of', 'solutions', 'with', 'pure', 'reinforcement', 'learning', 'we', 'boost', 'the', 'verification', 'accuracy', 'from', 'to', 'on', 'competitive', 'math', 'problems', 'by', 'scaling', 'with', 'repeated', 'sampling', 'the', 'accuracy', 'further', 'increases', 'to', 'through', 'human', 'evaluation', 'heimdall', 'demonstrates', 'impressive', 'generalization', 'capabilities', 'successfully', 'detecting', 'most', 'issues', 'in', 'challenging', 'math', 'proofs', 'the', 'type', 'of', 'which', 'is', 'not', 'included', 'during', 'training', 'furthermore', 'we', 'propose', 'pessimistic', 'verification', 'to', 'extend', 'the', 'functionality', 'of', 'heimdall', 'to', 'scaling', 'up', 'the', 'problem', 'solving', 'it', 'calls', 'heimdall', 'to', 'judge', 'the', 'solutions', 'from', 'a', 'solver', 'model', 'and', 'based', 'on', 'the', 'pessimistic', 'principle', 'selects', 'the', 'most', 'likely', 'correct', 'solution', 'with', 'the', 'least', 'uncertainty', 'taking', 'deepseek', 'r', 'distill', 'qwen', 'b', 'as', 'the', 'solver', 'model', 'pessimistic', 'verification', 'improves', 'the', 'solution', 'accuracy', 'on', 'aime', 'from', 'to', 'with', 'x', 'compute', 'budget', 'and', 'to', 'with', 'more', 'compute', 'budget', 'with', 'the', 'stronger', 'solver', 'gemini', 'pro', 'the', 'score', 'reaches', 'finally', 'we', 'prototype', 'an', 'automatic', 'knowledge', 'discovery', 'system', 'a', 'ternary', 'system', 'where', 'one', 'poses', 'questions', 'another', 'provides', 'solutions', 'and', 'the', 'third', 'verifies', 'the', 'solutions', 'using', 'the', 'data', 'synthesis', 'work', 'numinamath', 'for', 'the', 'first', 'two', 'components', 'heimdall', 'effectively', 'identifies', 'problematic', 'records', 'within', 'the', 'dataset', 'and', 'reveals', 'that', 'nearly', 'half', 'of', 'the', 'data', 'is', 'flawed', 'which', 'interestingly', 'aligns', 'with', 'the', 'recent', 'ablation', 'studies', 'from', 'numinamath']",8,264,"['Qwen', 'Chain', '16x', 'DeepSeek', 'CoT', 'Pro', 'Through', 'LLMs', 'Gemini', 'Furthermore', 'AIME2025', 'Heimdall', 'Recent', 'NuminaMath', 'Finally', 'Taking', 'R1-Distill', '32B', 'LLM', 'Pessimistic', 'Thought', 'Verification']"
2504.10326v1,AlayaDB: The Data Foundation for Efficient and Effective Long-context   LLM Inference,"AlayaDB is a cutting-edge vector database system natively architected for efficient and effective long-context inference for Large Language Models (LLMs) at AlayaDB AI. Specifically, it decouples the KV cache and attention computation from the LLM inference systems, and encapsulates them into a novel vector database system. For the Model as a Service providers (MaaS), AlayaDB consumes fewer hardware resources and offers higher generation quality for various workloads with different kinds of Service Level Objectives (SLOs), when comparing with the existing alternative solutions (e.g., KV cache disaggregation, retrieval-based sparse attention). The crux of AlayaDB is that it abstracts the attention computation and cache management for LLM inference into a query processing procedure, and optimizes the performance via a native query optimizer. In this work, we demonstrate the effectiveness of AlayaDB via (i) three use cases from our industry partners, and (ii) extensive experimental results on LLM inference benchmarks.","Yangshen Deng, Zhengxin You, Long Xiang, Qilong Li, Peiqi Yuan, Zhaoyang Hong, Yitao Zheng, Wanting Li, Runzhong Li, Haotian Liu, Kyriakos Mouratidis, Man Lung Yiu, Huan Li, Qiaomu Shen, Rui Mao, Bo Tang","cs.AI, cs.DB, cs.IR, H.3.1; H.3.2; H.3.3; H.3.4",2025-04-14T15:34:26Z,http://arxiv.org/abs/2504.10326v1,alayadb the data foundation for efficient and effective long context llm inference,alayadb is a cutting edge vector database system natively architected for efficient and effective long context inference for large language models llms at alayadb ai specifically it decouples the kv cache and attention computation from the llm inference systems and encapsulates them into a novel vector database system for the model as a service providers maas alayadb consumes fewer hardware resources and offers higher generation quality for various workloads with different kinds of service level objectives slos when comparing with the existing alternative solutions e g kv cache disaggregation retrieval based sparse attention the crux of alayadb is that it abstracts the attention computation and cache management for llm inference into a query processing procedure and optimizes the performance via a native query optimizer in this work we demonstrate the effectiveness of alayadb via i three use cases from our industry partners and ii extensive experimental results on llm inference benchmarks,"['alayadb', 'the', 'data', 'foundation', 'for', 'efficient', 'and', 'effective', 'long', 'context', 'llm', 'inference']","['alayadb', 'is', 'a', 'cutting', 'edge', 'vector', 'database', 'system', 'natively', 'architected', 'for', 'efficient', 'and', 'effective', 'long', 'context', 'inference', 'for', 'large', 'language', 'models', 'llms', 'at', 'alayadb', 'ai', 'specifically', 'it', 'decouples', 'the', 'kv', 'cache', 'and', 'attention', 'computation', 'from', 'the', 'llm', 'inference', 'systems', 'and', 'encapsulates', 'them', 'into', 'a', 'novel', 'vector', 'database', 'system', 'for', 'the', 'model', 'as', 'a', 'service', 'providers', 'maas', 'alayadb', 'consumes', 'fewer', 'hardware', 'resources', 'and', 'offers', 'higher', 'generation', 'quality', 'for', 'various', 'workloads', 'with', 'different', 'kinds', 'of', 'service', 'level', 'objectives', 'slos', 'when', 'comparing', 'with', 'the', 'existing', 'alternative', 'solutions', 'e', 'g', 'kv', 'cache', 'disaggregation', 'retrieval', 'based', 'sparse', 'attention', 'the', 'crux', 'of', 'alayadb', 'is', 'that', 'it', 'abstracts', 'the', 'attention', 'computation', 'and', 'cache', 'management', 'for', 'llm', 'inference', 'into', 'a', 'query', 'processing', 'procedure', 'and', 'optimizes', 'the', 'performance', 'via', 'a', 'native', 'query', 'optimizer', 'in', 'this', 'work', 'we', 'demonstrate', 'the', 'effectiveness', 'of', 'alayadb', 'via', 'i', 'three', 'use', 'cases', 'from', 'our', 'industry', 'partners', 'and', 'ii', 'extensive', 'experimental', 'results', 'on', 'llm', 'inference', 'benchmarks']",12,151,"['MaaS', 'Specifically', 'Model', 'Level', 'SLOs', 'LLMs', 'Service', 'Objectives', 'AlayaDB', 'Models', 'Language', 'Large', 'LLM']"
2504.10561v2,Self-Controlled Dynamic Expansion Model for Continual Learning,"Continual Learning (CL) epitomizes an advanced training paradigm wherein prior data samples remain inaccessible during the acquisition of new tasks. Numerous investigations have delved into leveraging a pre-trained Vision Transformer (ViT) to enhance model efficacy in continual learning. Nonetheless, these approaches typically utilize a singular, static backbone, which inadequately adapts to novel tasks, particularly when engaging with diverse data domains, due to a substantial number of inactive parameters. This paper addresses this limitation by introducing an innovative Self-Controlled Dynamic Expansion Model (SCDEM), which orchestrates multiple distinct trainable pre-trained ViT backbones to furnish diverse and semantically enriched representations. Specifically, by employing the multi-backbone architecture as a shared module, the proposed SCDEM dynamically generates a new expert with minimal parameters to accommodate a new task. A novel Collaborative Optimization Mechanism (COM) is introduced to synergistically optimize multiple backbones by harnessing prediction signals from historical experts, thereby facilitating new task learning without erasing previously acquired knowledge. Additionally, a novel Feature Distribution Consistency (FDC) approach is proposed to align semantic similarity between previously and currently learned representations through an optimal transport distance-based mechanism, effectively mitigating negative knowledge transfer effects. Furthermore, to alleviate over-regularization challenges, this paper presents a novel Dynamic Layer-Wise Feature Attention Mechanism (DLWFAM) to autonomously determine the penalization intensity on each trainable representation layer. An extensive series of experiments have been conducted to evaluate the proposed methodology's efficacy, with empirical results corroborating that the approach attains state-of-the-art performance.","Runqing Wu, Kaihui Huang, Hanyi Zhang, Fei Ye","cs.LG, cs.AI",2025-04-14T15:22:51Z,http://arxiv.org/abs/2504.10561v2,self controlled dynamic expansion model for continual learning,continual learning cl epitomizes an advanced training paradigm wherein prior data samples remain inaccessible during the acquisition of new tasks numerous investigations have delved into leveraging a pre trained vision transformer vit to enhance model efficacy in continual learning nonetheless these approaches typically utilize a singular static backbone which inadequately adapts to novel tasks particularly when engaging with diverse data domains due to a substantial number of inactive parameters this paper addresses this limitation by introducing an innovative self controlled dynamic expansion model scdem which orchestrates multiple distinct trainable pre trained vit backbones to furnish diverse and semantically enriched representations specifically by employing the multi backbone architecture as a shared module the proposed scdem dynamically generates a new expert with minimal parameters to accommodate a new task a novel collaborative optimization mechanism com is introduced to synergistically optimize multiple backbones by harnessing prediction signals from historical experts thereby facilitating new task learning without erasing previously acquired knowledge additionally a novel feature distribution consistency fdc approach is proposed to align semantic similarity between previously and currently learned representations through an optimal transport distance based mechanism effectively mitigating negative knowledge transfer effects furthermore to alleviate over regularization challenges this paper presents a novel dynamic layer wise feature attention mechanism dlwfam to autonomously determine the penalization intensity on each trainable representation layer an extensive series of experiments have been conducted to evaluate the proposed methodology s efficacy with empirical results corroborating that the approach attains state of the art performance,"['self', 'controlled', 'dynamic', 'expansion', 'model', 'for', 'continual', 'learning']","['continual', 'learning', 'cl', 'epitomizes', 'an', 'advanced', 'training', 'paradigm', 'wherein', 'prior', 'data', 'samples', 'remain', 'inaccessible', 'during', 'the', 'acquisition', 'of', 'new', 'tasks', 'numerous', 'investigations', 'have', 'delved', 'into', 'leveraging', 'a', 'pre', 'trained', 'vision', 'transformer', 'vit', 'to', 'enhance', 'model', 'efficacy', 'in', 'continual', 'learning', 'nonetheless', 'these', 'approaches', 'typically', 'utilize', 'a', 'singular', 'static', 'backbone', 'which', 'inadequately', 'adapts', 'to', 'novel', 'tasks', 'particularly', 'when', 'engaging', 'with', 'diverse', 'data', 'domains', 'due', 'to', 'a', 'substantial', 'number', 'of', 'inactive', 'parameters', 'this', 'paper', 'addresses', 'this', 'limitation', 'by', 'introducing', 'an', 'innovative', 'self', 'controlled', 'dynamic', 'expansion', 'model', 'scdem', 'which', 'orchestrates', 'multiple', 'distinct', 'trainable', 'pre', 'trained', 'vit', 'backbones', 'to', 'furnish', 'diverse', 'and', 'semantically', 'enriched', 'representations', 'specifically', 'by', 'employing', 'the', 'multi', 'backbone', 'architecture', 'as', 'a', 'shared', 'module', 'the', 'proposed', 'scdem', 'dynamically', 'generates', 'a', 'new', 'expert', 'with', 'minimal', 'parameters', 'to', 'accommodate', 'a', 'new', 'task', 'a', 'novel', 'collaborative', 'optimization', 'mechanism', 'com', 'is', 'introduced', 'to', 'synergistically', 'optimize', 'multiple', 'backbones', 'by', 'harnessing', 'prediction', 'signals', 'from', 'historical', 'experts', 'thereby', 'facilitating', 'new', 'task', 'learning', 'without', 'erasing', 'previously', 'acquired', 'knowledge', 'additionally', 'a', 'novel', 'feature', 'distribution', 'consistency', 'fdc', 'approach', 'is', 'proposed', 'to', 'align', 'semantic', 'similarity', 'between', 'previously', 'and', 'currently', 'learned', 'representations', 'through', 'an', 'optimal', 'transport', 'distance', 'based', 'mechanism', 'effectively', 'mitigating', 'negative', 'knowledge', 'transfer', 'effects', 'furthermore', 'to', 'alleviate', 'over', 'regularization', 'challenges', 'this', 'paper', 'presents', 'a', 'novel', 'dynamic', 'layer', 'wise', 'feature', 'attention', 'mechanism', 'dlwfam', 'to', 'autonomously', 'determine', 'the', 'penalization', 'intensity', 'on', 'each', 'trainable', 'representation', 'layer', 'an', 'extensive', 'series', 'of', 'experiments', 'have', 'been', 'conducted', 'to', 'evaluate', 'the', 'proposed', 'methodology', 's', 'efficacy', 'with', 'empirical', 'results', 'corroborating', 'that', 'the', 'approach', 'attains', 'state', 'of', 'the', 'art', 'performance']",8,247,"['FDC', 'Model', 'Dynamic', 'COM', 'Layer', 'Wise', 'Self', 'Learning', 'Specifically', 'Continual', 'Attention', 'Distribution', 'Furthermore', 'Transformer', 'ViT', 'Consistency', 'Feature', 'SCDEM', 'Mechanism', 'Controlled', 'Collaborative', 'Additionally', 'DLWFAM', 'Numerous', 'Nonetheless', 'Expansion', 'Vision', 'Optimization']"
2504.10309v1,AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style   Matching Text-to-Speech Synthesis,"With the advancement of speech synthesis technology, users have higher expectations for the naturalness and expressiveness of synthesized speech. But previous research ignores the importance of prompt selection. This study proposes a text-to-speech (TTS) framework based on Retrieval-Augmented Generation (RAG) technology, which can dynamically adjust the speech style according to the text content to achieve more natural and vivid communication effects. We have constructed a speech style knowledge database containing high-quality speech samples in various contexts and developed a style matching scheme. This scheme uses embeddings, extracted by Llama, PER-LLM-Embedder,and Moka, to match with samples in the knowledge database, selecting the most appropriate speech style for synthesis. Furthermore, our empirical research validates the effectiveness of the proposed method. Our demo can be viewed at: https://thuhcsi.github.io/icme2025-AutoStyle-TTS","Dan Luo, Chengyuan Ma, Weiqin Li, Jun Wang, Wei Chen, Zhiyong Wu","cs.SD, cs.AI",2025-04-14T15:18:59Z,http://arxiv.org/abs/2504.10309v1,autostyle tts retrieval augmented generation based automatic style matching text to speech synthesis,with the advancement of speech synthesis technology users have higher expectations for the naturalness and expressiveness of synthesized speech but previous research ignores the importance of prompt selection this study proposes a text to speech tts framework based on retrieval augmented generation rag technology which can dynamically adjust the speech style according to the text content to achieve more natural and vivid communication effects we have constructed a speech style knowledge database containing high quality speech samples in various contexts and developed a style matching scheme this scheme uses embeddings extracted by llama per llm embedder and moka to match with samples in the knowledge database selecting the most appropriate speech style for synthesis furthermore our empirical research validates the effectiveness of the proposed method our demo can be viewed at,"['autostyle', 'tts', 'retrieval', 'augmented', 'generation', 'based', 'automatic', 'style', 'matching', 'text', 'to', 'speech', 'synthesis']","['with', 'the', 'advancement', 'of', 'speech', 'synthesis', 'technology', 'users', 'have', 'higher', 'expectations', 'for', 'the', 'naturalness', 'and', 'expressiveness', 'of', 'synthesized', 'speech', 'but', 'previous', 'research', 'ignores', 'the', 'importance', 'of', 'prompt', 'selection', 'this', 'study', 'proposes', 'a', 'text', 'to', 'speech', 'tts', 'framework', 'based', 'on', 'retrieval', 'augmented', 'generation', 'rag', 'technology', 'which', 'can', 'dynamically', 'adjust', 'the', 'speech', 'style', 'according', 'to', 'the', 'text', 'content', 'to', 'achieve', 'more', 'natural', 'and', 'vivid', 'communication', 'effects', 'we', 'have', 'constructed', 'a', 'speech', 'style', 'knowledge', 'database', 'containing', 'high', 'quality', 'speech', 'samples', 'in', 'various', 'contexts', 'and', 'developed', 'a', 'style', 'matching', 'scheme', 'this', 'scheme', 'uses', 'embeddings', 'extracted', 'by', 'llama', 'per', 'llm', 'embedder', 'and', 'moka', 'to', 'match', 'with', 'samples', 'in', 'the', 'knowledge', 'database', 'selecting', 'the', 'most', 'appropriate', 'speech', 'style', 'for', 'synthesis', 'furthermore', 'our', 'empirical', 'research', 'validates', 'the', 'effectiveness', 'of', 'the', 'proposed', 'method', 'our', 'demo', 'can', 'be', 'viewed', 'at']",13,131,"['Llama', 'RAG', 'Embedder', 'Augmented', 'TTS', 'But', 'PER-LLM', 'Moka', 'Furthermore', 'Retrieval', 'Our', 'AutoStyle', 'Generation']"
2504.10286v1,Characterizing LLM-driven Social Network: The Chirper.ai Case,"Large language models (LLMs) demonstrate the ability to simulate human decision-making processes, enabling their use as agents in modeling sophisticated social networks, both offline and online. Recent research has explored collective behavioral patterns and structural characteristics of LLM agents within simulated networks. However, empirical comparisons between LLM-driven and human-driven online social networks remain scarce, limiting our understanding of how LLM agents differ from human users. This paper presents a large-scale analysis of Chirper.ai, an X/Twitter-like social network entirely populated by LLM agents, comprising over 65,000 agents and 7.7 million AI-generated posts. For comparison, we collect a parallel dataset from Mastodon, a human-driven decentralized social network, with over 117,000 users and 16 million posts. We examine key differences between LLM agents and humans in posting behaviors, abusive content, and social network structures. Our findings provide critical insights into the evolving landscape of online social network analysis in the AI era, offering a comprehensive profile of LLM agents in social simulations.","Yiming Zhu, Yupeng He, Ehsan-Ul Haq, Gareth Tyson, Pan Hui","cs.SI, cs.AI",2025-04-14T14:53:31Z,http://arxiv.org/abs/2504.10286v1,characterizing llm driven social network the chirper ai case,large language models llms demonstrate the ability to simulate human decision making processes enabling their use as agents in modeling sophisticated social networks both offline and online recent research has explored collective behavioral patterns and structural characteristics of llm agents within simulated networks however empirical comparisons between llm driven and human driven online social networks remain scarce limiting our understanding of how llm agents differ from human users this paper presents a large scale analysis of chirper ai an x twitter like social network entirely populated by llm agents comprising over agents and million ai generated posts for comparison we collect a parallel dataset from mastodon a human driven decentralized social network with over users and million posts we examine key differences between llm agents and humans in posting behaviors abusive content and social network structures our findings provide critical insights into the evolving landscape of online social network analysis in the ai era offering a comprehensive profile of llm agents in social simulations,"['characterizing', 'llm', 'driven', 'social', 'network', 'the', 'chirper', 'ai', 'case']","['large', 'language', 'models', 'llms', 'demonstrate', 'the', 'ability', 'to', 'simulate', 'human', 'decision', 'making', 'processes', 'enabling', 'their', 'use', 'as', 'agents', 'in', 'modeling', 'sophisticated', 'social', 'networks', 'both', 'offline', 'and', 'online', 'recent', 'research', 'has', 'explored', 'collective', 'behavioral', 'patterns', 'and', 'structural', 'characteristics', 'of', 'llm', 'agents', 'within', 'simulated', 'networks', 'however', 'empirical', 'comparisons', 'between', 'llm', 'driven', 'and', 'human', 'driven', 'online', 'social', 'networks', 'remain', 'scarce', 'limiting', 'our', 'understanding', 'of', 'how', 'llm', 'agents', 'differ', 'from', 'human', 'users', 'this', 'paper', 'presents', 'a', 'large', 'scale', 'analysis', 'of', 'chirper', 'ai', 'an', 'x', 'twitter', 'like', 'social', 'network', 'entirely', 'populated', 'by', 'llm', 'agents', 'comprising', 'over', 'agents', 'and', 'million', 'ai', 'generated', 'posts', 'for', 'comparison', 'we', 'collect', 'a', 'parallel', 'dataset', 'from', 'mastodon', 'a', 'human', 'driven', 'decentralized', 'social', 'network', 'with', 'over', 'users', 'and', 'million', 'posts', 'we', 'examine', 'key', 'differences', 'between', 'llm', 'agents', 'and', 'humans', 'in', 'posting', 'behaviors', 'abusive', 'content', 'and', 'social', 'network', 'structures', 'our', 'findings', 'provide', 'critical', 'insights', 'into', 'the', 'evolving', 'landscape', 'of', 'online', 'social', 'network', 'analysis', 'in', 'the', 'ai', 'era', 'offering', 'a', 'comprehensive', 'profile', 'of', 'llm', 'agents', 'in', 'social', 'simulations']",9,164,"['Twitter', 'Recent', '000', '117', 'LLMs', 'Mastodon', 'However', 'Chirper', 'LLM-driven', 'Our', 'Large', 'LLM', 'AI-generated']"
2504.10254v1,MASSeg : 2nd Technical Report for 4th PVUW MOSE Track,"Complex video object segmentation continues to face significant challenges in small object recognition, occlusion handling, and dynamic scene modeling. This report presents our solution, which ranked second in the MOSE track of CVPR 2025 PVUW Challenge. Based on an existing segmentation framework, we propose an improved model named MASSeg for complex video object segmentation, and construct an enhanced dataset, MOSE+, which includes typical scenarios with occlusions, cluttered backgrounds, and small target instances. During training, we incorporate a combination of inter-frame consistent and inconsistent data augmentation strategies to improve robustness and generalization. During inference, we design a mask output scaling strategy to better adapt to varying object sizes and occlusion levels. As a result, MASSeg achieves a J score of 0.8250, F score of 0.9007, and a J&F score of 0.8628 on the MOSE test set.","Xuqiang Cao, Linnan Zhao, Jiaxuan Zhao, Fang Liu, Puhua Chen, Wenping Ma","cs.CV, cs.AI",2025-04-14T14:15:46Z,http://arxiv.org/abs/2504.10254v1,masseg nd technical report for th pvuw mose track,complex video object segmentation continues to face significant challenges in small object recognition occlusion handling and dynamic scene modeling this report presents our solution which ranked second in the mose track of cvpr pvuw challenge based on an existing segmentation framework we propose an improved model named masseg for complex video object segmentation and construct an enhanced dataset mose which includes typical scenarios with occlusions cluttered backgrounds and small target instances during training we incorporate a combination of inter frame consistent and inconsistent data augmentation strategies to improve robustness and generalization during inference we design a mask output scaling strategy to better adapt to varying object sizes and occlusion levels as a result masseg achieves a j score of f score of and a j f score of on the mose test set,"['masseg', 'nd', 'technical', 'report', 'for', 'th', 'pvuw', 'mose', 'track']","['complex', 'video', 'object', 'segmentation', 'continues', 'to', 'face', 'significant', 'challenges', 'in', 'small', 'object', 'recognition', 'occlusion', 'handling', 'and', 'dynamic', 'scene', 'modeling', 'this', 'report', 'presents', 'our', 'solution', 'which', 'ranked', 'second', 'in', 'the', 'mose', 'track', 'of', 'cvpr', 'pvuw', 'challenge', 'based', 'on', 'an', 'existing', 'segmentation', 'framework', 'we', 'propose', 'an', 'improved', 'model', 'named', 'masseg', 'for', 'complex', 'video', 'object', 'segmentation', 'and', 'construct', 'an', 'enhanced', 'dataset', 'mose', 'which', 'includes', 'typical', 'scenarios', 'with', 'occlusions', 'cluttered', 'backgrounds', 'and', 'small', 'target', 'instances', 'during', 'training', 'we', 'incorporate', 'a', 'combination', 'of', 'inter', 'frame', 'consistent', 'and', 'inconsistent', 'data', 'augmentation', 'strategies', 'to', 'improve', 'robustness', 'and', 'generalization', 'during', 'inference', 'we', 'design', 'a', 'mask', 'output', 'scaling', 'strategy', 'to', 'better', 'adapt', 'to', 'varying', 'object', 'sizes', 'and', 'occlusion', 'levels', 'as', 'a', 'result', 'masseg', 'achieves', 'a', 'j', 'score', 'of', 'f', 'score', 'of', 'and', 'a', 'j', 'f', 'score', 'of', 'on', 'the', 'mose', 'test', 'set']",9,133,"['MOSE', '8628', 'Complex', 'Challenge', 'Based', '9007', 'During', '8250', 'MASSeg', 'CVPR', '2025', 'PVUW']"
2504.10557v1,The Code Barrier: What LLMs Actually Understand?,"Understanding code represents a core ability needed for automating software development tasks. While foundation models like LLMs show impressive results across many software engineering challenges, the extent of their true semantic understanding beyond simple token recognition remains unclear. This research uses code obfuscation as a structured testing framework to evaluate LLMs' semantic understanding capabilities. We methodically apply controlled obfuscation changes to source code and measure comprehension through two complementary tasks: generating accurate descriptions of obfuscated code and performing deobfuscation, a skill with important implications for reverse engineering applications.   Our testing approach includes 13 cutting-edge models, covering both code-specialized (e.g., StarCoder2) and general-purpose (e.g., GPT-4o) architectures, evaluated on a benchmark created from CodeNet and consisting of filtered 250 Java programming problems and their solutions. Findings show a statistically significant performance decline as obfuscation complexity increases, with unexpected resilience shown by general-purpose models compared to their code-focused counterparts. While some models successfully identify obfuscation techniques, their ability to reconstruct the underlying program logic remains constrained, suggesting limitations in their semantic representation mechanisms. This research introduces a new evaluation approach for assessing code comprehension in language models and establishes empirical baselines for advancing research in security-critical code analysis applications such as reverse engineering and adversarial code analysis.","Serge Lionel Nikiema, Jordan Samhi, Abdoul Kader Kabor√©, Jacques Klein, Tegawend√© F. Bissyand√©","cs.SE, cs.AI",2025-04-14T14:11:26Z,http://arxiv.org/abs/2504.10557v1,the code barrier what llms actually understand,understanding code represents a core ability needed for automating software development tasks while foundation models like llms show impressive results across many software engineering challenges the extent of their true semantic understanding beyond simple token recognition remains unclear this research uses code obfuscation as a structured testing framework to evaluate llms semantic understanding capabilities we methodically apply controlled obfuscation changes to source code and measure comprehension through two complementary tasks generating accurate descriptions of obfuscated code and performing deobfuscation a skill with important implications for reverse engineering applications our testing approach includes cutting edge models covering both code specialized e g starcoder and general purpose e g gpt o architectures evaluated on a benchmark created from codenet and consisting of filtered java programming problems and their solutions findings show a statistically significant performance decline as obfuscation complexity increases with unexpected resilience shown by general purpose models compared to their code focused counterparts while some models successfully identify obfuscation techniques their ability to reconstruct the underlying program logic remains constrained suggesting limitations in their semantic representation mechanisms this research introduces a new evaluation approach for assessing code comprehension in language models and establishes empirical baselines for advancing research in security critical code analysis applications such as reverse engineering and adversarial code analysis,"['the', 'code', 'barrier', 'what', 'llms', 'actually', 'understand']","['understanding', 'code', 'represents', 'a', 'core', 'ability', 'needed', 'for', 'automating', 'software', 'development', 'tasks', 'while', 'foundation', 'models', 'like', 'llms', 'show', 'impressive', 'results', 'across', 'many', 'software', 'engineering', 'challenges', 'the', 'extent', 'of', 'their', 'true', 'semantic', 'understanding', 'beyond', 'simple', 'token', 'recognition', 'remains', 'unclear', 'this', 'research', 'uses', 'code', 'obfuscation', 'as', 'a', 'structured', 'testing', 'framework', 'to', 'evaluate', 'llms', 'semantic', 'understanding', 'capabilities', 'we', 'methodically', 'apply', 'controlled', 'obfuscation', 'changes', 'to', 'source', 'code', 'and', 'measure', 'comprehension', 'through', 'two', 'complementary', 'tasks', 'generating', 'accurate', 'descriptions', 'of', 'obfuscated', 'code', 'and', 'performing', 'deobfuscation', 'a', 'skill', 'with', 'important', 'implications', 'for', 'reverse', 'engineering', 'applications', 'our', 'testing', 'approach', 'includes', 'cutting', 'edge', 'models', 'covering', 'both', 'code', 'specialized', 'e', 'g', 'starcoder', 'and', 'general', 'purpose', 'e', 'g', 'gpt', 'o', 'architectures', 'evaluated', 'on', 'a', 'benchmark', 'created', 'from', 'codenet', 'and', 'consisting', 'of', 'filtered', 'java', 'programming', 'problems', 'and', 'their', 'solutions', 'findings', 'show', 'a', 'statistically', 'significant', 'performance', 'decline', 'as', 'obfuscation', 'complexity', 'increases', 'with', 'unexpected', 'resilience', 'shown', 'by', 'general', 'purpose', 'models', 'compared', 'to', 'their', 'code', 'focused', 'counterparts', 'while', 'some', 'models', 'successfully', 'identify', 'obfuscation', 'techniques', 'their', 'ability', 'to', 'reconstruct', 'the', 'underlying', 'program', 'logic', 'remains', 'constrained', 'suggesting', 'limitations', 'in', 'their', 'semantic', 'representation', 'mechanisms', 'this', 'research', 'introduces', 'a', 'new', 'evaluation', 'approach', 'for', 'assessing', 'code', 'comprehension', 'in', 'language', 'models', 'and', 'establishes', 'empirical', 'baselines', 'for', 'advancing', 'research', 'in', 'security', 'critical', 'code', 'analysis', 'applications', 'such', 'as', 'reverse', 'engineering', 'and', 'adversarial', 'code', 'analysis']",7,211,"['GPT-4o', '250', 'LLMs', 'While', 'StarCoder2', 'Findings', 'CodeNet', 'Java', 'Our', 'Understanding']"
2504.10556v1,VAE-based Feature Disentanglement for Data Augmentation and Compression   in Generalized GNSS Interference Classification,"Distributed learning and Edge AI necessitate efficient data processing, low-latency communication, decentralized model training, and stringent data privacy to facilitate real-time intelligence on edge devices while reducing dependency on centralized infrastructure and ensuring high model performance. In the context of global navigation satellite system (GNSS) applications, the primary objective is to accurately monitor and classify interferences that degrade system performance in distributed environments, thereby enhancing situational awareness. To achieve this, machine learning (ML) models can be deployed on low-resource devices, ensuring minimal communication latency and preserving data privacy. The key challenge is to compress ML models while maintaining high classification accuracy. In this paper, we propose variational autoencoders (VAEs) for disentanglement to extract essential latent features that enable accurate classification of interferences. We demonstrate that the disentanglement approach can be leveraged for both data compression and data augmentation by interpolating the lower-dimensional latent representations of signal power. To validate our approach, we evaluate three VAE variants - vanilla, factorized, and conditional generative - on four distinct datasets, including two collected in controlled indoor environments and two real-world highway datasets. Additionally, we conduct extensive hyperparameter searches to optimize performance. Our proposed VAE achieves a data compression rate ranging from 512 to 8,192 and achieves an accuracy up to 99.92%.","Lucas Heublein, Simon Kocher, Tobias Feigl, Alexander R√ºgamer, Christopher Mutschler, Felix Ott","cs.LG, cs.AI, cs.IT, math.IT, 94-05, 82-11, E.0; I.2.0; I.5.4; I.5.1",2025-04-14T13:38:00Z,http://arxiv.org/abs/2504.10556v1,vae based feature disentanglement for data augmentation and compression in generalized gnss interference classification,distributed learning and edge ai necessitate efficient data processing low latency communication decentralized model training and stringent data privacy to facilitate real time intelligence on edge devices while reducing dependency on centralized infrastructure and ensuring high model performance in the context of global navigation satellite system gnss applications the primary objective is to accurately monitor and classify interferences that degrade system performance in distributed environments thereby enhancing situational awareness to achieve this machine learning ml models can be deployed on low resource devices ensuring minimal communication latency and preserving data privacy the key challenge is to compress ml models while maintaining high classification accuracy in this paper we propose variational autoencoders vaes for disentanglement to extract essential latent features that enable accurate classification of interferences we demonstrate that the disentanglement approach can be leveraged for both data compression and data augmentation by interpolating the lower dimensional latent representations of signal power to validate our approach we evaluate three vae variants vanilla factorized and conditional generative on four distinct datasets including two collected in controlled indoor environments and two real world highway datasets additionally we conduct extensive hyperparameter searches to optimize performance our proposed vae achieves a data compression rate ranging from to and achieves an accuracy up to,"['vae', 'based', 'feature', 'disentanglement', 'for', 'data', 'augmentation', 'and', 'compression', 'in', 'generalized', 'gnss', 'interference', 'classification']","['distributed', 'learning', 'and', 'edge', 'ai', 'necessitate', 'efficient', 'data', 'processing', 'low', 'latency', 'communication', 'decentralized', 'model', 'training', 'and', 'stringent', 'data', 'privacy', 'to', 'facilitate', 'real', 'time', 'intelligence', 'on', 'edge', 'devices', 'while', 'reducing', 'dependency', 'on', 'centralized', 'infrastructure', 'and', 'ensuring', 'high', 'model', 'performance', 'in', 'the', 'context', 'of', 'global', 'navigation', 'satellite', 'system', 'gnss', 'applications', 'the', 'primary', 'objective', 'is', 'to', 'accurately', 'monitor', 'and', 'classify', 'interferences', 'that', 'degrade', 'system', 'performance', 'in', 'distributed', 'environments', 'thereby', 'enhancing', 'situational', 'awareness', 'to', 'achieve', 'this', 'machine', 'learning', 'ml', 'models', 'can', 'be', 'deployed', 'on', 'low', 'resource', 'devices', 'ensuring', 'minimal', 'communication', 'latency', 'and', 'preserving', 'data', 'privacy', 'the', 'key', 'challenge', 'is', 'to', 'compress', 'ml', 'models', 'while', 'maintaining', 'high', 'classification', 'accuracy', 'in', 'this', 'paper', 'we', 'propose', 'variational', 'autoencoders', 'vaes', 'for', 'disentanglement', 'to', 'extract', 'essential', 'latent', 'features', 'that', 'enable', 'accurate', 'classification', 'of', 'interferences', 'we', 'demonstrate', 'that', 'the', 'disentanglement', 'approach', 'can', 'be', 'leveraged', 'for', 'both', 'data', 'compression', 'and', 'data', 'augmentation', 'by', 'interpolating', 'the', 'lower', 'dimensional', 'latent', 'representations', 'of', 'signal', 'power', 'to', 'validate', 'our', 'approach', 'we', 'evaluate', 'three', 'vae', 'variants', 'vanilla', 'factorized', 'and', 'conditional', 'generative', 'on', 'four', 'distinct', 'datasets', 'including', 'two', 'collected', 'in', 'controlled', 'indoor', 'environments', 'and', 'two', 'real', 'world', 'highway', 'datasets', 'additionally', 'we', 'conduct', 'extensive', 'hyperparameter', 'searches', 'to', 'optimize', 'performance', 'our', 'proposed', 'vae', 'achieves', 'a', 'data', 'compression', 'rate', 'ranging', 'from', 'to', 'and', 'achieves', 'an', 'accuracy', 'up', 'to']",14,208,"['Edge', '192', '512', 'Distributed', 'VAE', 'VAEs', 'Our', 'GNSS', 'Additionally']"
2504.10210v1,Can Competition Enhance the Proficiency of Agents Powered by Large   Language Models in the Realm of News-driven Time Series Forecasting?,"Multi-agents-based news-driven time series forecasting is considered as a potential paradigm shift in the era of large language models (LLMs). The challenge of this task lies in measuring the influences of different news events towards the fluctuations of time series. This requires agents to possess stronger abilities of innovative thinking and the identifying misleading logic. However, the existing multi-agent discussion framework has limited enhancement on time series prediction in terms of optimizing these two capabilities. Inspired by the role of competition in fostering innovation, this study embeds a competition mechanism within the multi-agent discussion to enhance agents' capability of generating innovative thoughts. Furthermore, to bolster the model's proficiency in identifying misleading information, we incorporate a fine-tuned small-scale LLM model within the reflective stage, offering auxiliary decision-making support. Experimental results confirm that the competition can boost agents' capacity for innovative thinking, which can significantly improve the performances of time series prediction. Similar to the findings of social science, the intensity of competition within this framework can influence the performances of agents, providing a new perspective for studying LLMs-based multi-agent systems.","Yuxuan Zhang, Yangyang Feng, Daifeng Li, Kexin Zhang, Junlan Chen, Bowen Deng",cs.AI,2025-04-14T13:25:50Z,http://arxiv.org/abs/2504.10210v1,can competition enhance the proficiency of agents powered by large language models in the realm of news driven time series forecasting,multi agents based news driven time series forecasting is considered as a potential paradigm shift in the era of large language models llms the challenge of this task lies in measuring the influences of different news events towards the fluctuations of time series this requires agents to possess stronger abilities of innovative thinking and the identifying misleading logic however the existing multi agent discussion framework has limited enhancement on time series prediction in terms of optimizing these two capabilities inspired by the role of competition in fostering innovation this study embeds a competition mechanism within the multi agent discussion to enhance agents capability of generating innovative thoughts furthermore to bolster the model s proficiency in identifying misleading information we incorporate a fine tuned small scale llm model within the reflective stage offering auxiliary decision making support experimental results confirm that the competition can boost agents capacity for innovative thinking which can significantly improve the performances of time series prediction similar to the findings of social science the intensity of competition within this framework can influence the performances of agents providing a new perspective for studying llms based multi agent systems,"['can', 'competition', 'enhance', 'the', 'proficiency', 'of', 'agents', 'powered', 'by', 'large', 'language', 'models', 'in', 'the', 'realm', 'of', 'news', 'driven', 'time', 'series', 'forecasting']","['multi', 'agents', 'based', 'news', 'driven', 'time', 'series', 'forecasting', 'is', 'considered', 'as', 'a', 'potential', 'paradigm', 'shift', 'in', 'the', 'era', 'of', 'large', 'language', 'models', 'llms', 'the', 'challenge', 'of', 'this', 'task', 'lies', 'in', 'measuring', 'the', 'influences', 'of', 'different', 'news', 'events', 'towards', 'the', 'fluctuations', 'of', 'time', 'series', 'this', 'requires', 'agents', 'to', 'possess', 'stronger', 'abilities', 'of', 'innovative', 'thinking', 'and', 'the', 'identifying', 'misleading', 'logic', 'however', 'the', 'existing', 'multi', 'agent', 'discussion', 'framework', 'has', 'limited', 'enhancement', 'on', 'time', 'series', 'prediction', 'in', 'terms', 'of', 'optimizing', 'these', 'two', 'capabilities', 'inspired', 'by', 'the', 'role', 'of', 'competition', 'in', 'fostering', 'innovation', 'this', 'study', 'embeds', 'a', 'competition', 'mechanism', 'within', 'the', 'multi', 'agent', 'discussion', 'to', 'enhance', 'agents', 'capability', 'of', 'generating', 'innovative', 'thoughts', 'furthermore', 'to', 'bolster', 'the', 'model', 's', 'proficiency', 'in', 'identifying', 'misleading', 'information', 'we', 'incorporate', 'a', 'fine', 'tuned', 'small', 'scale', 'llm', 'model', 'within', 'the', 'reflective', 'stage', 'offering', 'auxiliary', 'decision', 'making', 'support', 'experimental', 'results', 'confirm', 'that', 'the', 'competition', 'can', 'boost', 'agents', 'capacity', 'for', 'innovative', 'thinking', 'which', 'can', 'significantly', 'improve', 'the', 'performances', 'of', 'time', 'series', 'prediction', 'similar', 'to', 'the', 'findings', 'of', 'social', 'science', 'the', 'intensity', 'of', 'competition', 'within', 'this', 'framework', 'can', 'influence', 'the', 'performances', 'of', 'agents', 'providing', 'a', 'new', 'perspective', 'for', 'studying', 'llms', 'based', 'multi', 'agent', 'systems']",21,190,"['Experimental', 'Multi', 'Similar', 'LLMs', 'However', 'Furthermore', 'Inspired', 'LLM']"
2504.10555v1,Beyond the Generative Learning Trilemma: Generative Model Assessment in   Data Scarcity Domains,"Data scarcity remains a critical bottleneck impeding technological advancements across various domains, including but not limited to medicine and precision agriculture. To address this challenge, we explore the potential of Deep Generative Models (DGMs) in producing synthetic data that satisfies the Generative Learning Trilemma: fidelity, diversity, and sampling efficiency. However, recognizing that these criteria alone are insufficient for practical applications, we extend the trilemma to include utility, robustness, and privacy, factors crucial for ensuring the applicability of DGMs in real-world scenarios. Evaluating these metrics becomes particularly challenging in data-scarce environments, as DGMs traditionally rely on large datasets to perform optimally. This limitation is especially pronounced in domains like medicine and precision agriculture, where ensuring acceptable model performance under data constraints is vital. To address these challenges, we assess the Generative Learning Trilemma in data-scarcity settings using state-of-the-art evaluation metrics, comparing three prominent DGMs: Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and Diffusion Models (DMs). Furthermore, we propose a comprehensive framework to assess utility, robustness, and privacy in synthetic data generated by DGMs. Our findings demonstrate varying strengths among DGMs, with each model exhibiting unique advantages based on the application context. This study broadens the scope of the Generative Learning Trilemma, aligning it with real-world demands and providing actionable guidance for selecting DGMs tailored to specific applications.","Marco Salm√®, Lorenzo Tronchin, Rosa Sicilia, Paolo Soda, Valerio Guarrasi","cs.LG, cs.AI, cs.CV",2025-04-14T13:15:44Z,http://arxiv.org/abs/2504.10555v1,beyond the generative learning trilemma generative model assessment in data scarcity domains,data scarcity remains a critical bottleneck impeding technological advancements across various domains including but not limited to medicine and precision agriculture to address this challenge we explore the potential of deep generative models dgms in producing synthetic data that satisfies the generative learning trilemma fidelity diversity and sampling efficiency however recognizing that these criteria alone are insufficient for practical applications we extend the trilemma to include utility robustness and privacy factors crucial for ensuring the applicability of dgms in real world scenarios evaluating these metrics becomes particularly challenging in data scarce environments as dgms traditionally rely on large datasets to perform optimally this limitation is especially pronounced in domains like medicine and precision agriculture where ensuring acceptable model performance under data constraints is vital to address these challenges we assess the generative learning trilemma in data scarcity settings using state of the art evaluation metrics comparing three prominent dgms variational autoencoders vaes generative adversarial networks gans and diffusion models dms furthermore we propose a comprehensive framework to assess utility robustness and privacy in synthetic data generated by dgms our findings demonstrate varying strengths among dgms with each model exhibiting unique advantages based on the application context this study broadens the scope of the generative learning trilemma aligning it with real world demands and providing actionable guidance for selecting dgms tailored to specific applications,"['beyond', 'the', 'generative', 'learning', 'trilemma', 'generative', 'model', 'assessment', 'in', 'data', 'scarcity', 'domains']","['data', 'scarcity', 'remains', 'a', 'critical', 'bottleneck', 'impeding', 'technological', 'advancements', 'across', 'various', 'domains', 'including', 'but', 'not', 'limited', 'to', 'medicine', 'and', 'precision', 'agriculture', 'to', 'address', 'this', 'challenge', 'we', 'explore', 'the', 'potential', 'of', 'deep', 'generative', 'models', 'dgms', 'in', 'producing', 'synthetic', 'data', 'that', 'satisfies', 'the', 'generative', 'learning', 'trilemma', 'fidelity', 'diversity', 'and', 'sampling', 'efficiency', 'however', 'recognizing', 'that', 'these', 'criteria', 'alone', 'are', 'insufficient', 'for', 'practical', 'applications', 'we', 'extend', 'the', 'trilemma', 'to', 'include', 'utility', 'robustness', 'and', 'privacy', 'factors', 'crucial', 'for', 'ensuring', 'the', 'applicability', 'of', 'dgms', 'in', 'real', 'world', 'scenarios', 'evaluating', 'these', 'metrics', 'becomes', 'particularly', 'challenging', 'in', 'data', 'scarce', 'environments', 'as', 'dgms', 'traditionally', 'rely', 'on', 'large', 'datasets', 'to', 'perform', 'optimally', 'this', 'limitation', 'is', 'especially', 'pronounced', 'in', 'domains', 'like', 'medicine', 'and', 'precision', 'agriculture', 'where', 'ensuring', 'acceptable', 'model', 'performance', 'under', 'data', 'constraints', 'is', 'vital', 'to', 'address', 'these', 'challenges', 'we', 'assess', 'the', 'generative', 'learning', 'trilemma', 'in', 'data', 'scarcity', 'settings', 'using', 'state', 'of', 'the', 'art', 'evaluation', 'metrics', 'comparing', 'three', 'prominent', 'dgms', 'variational', 'autoencoders', 'vaes', 'generative', 'adversarial', 'networks', 'gans', 'and', 'diffusion', 'models', 'dms', 'furthermore', 'we', 'propose', 'a', 'comprehensive', 'framework', 'to', 'assess', 'utility', 'robustness', 'and', 'privacy', 'in', 'synthetic', 'data', 'generated', 'by', 'dgms', 'our', 'findings', 'demonstrate', 'varying', 'strengths', 'among', 'dgms', 'with', 'each', 'model', 'exhibiting', 'unique', 'advantages', 'based', 'on', 'the', 'application', 'context', 'this', 'study', 'broadens', 'the', 'scope', 'of', 'the', 'generative', 'learning', 'trilemma', 'aligning', 'it', 'with', 'real', 'world', 'demands', 'and', 'providing', 'actionable', 'guidance', 'for', 'selecting', 'dgms', 'tailored', 'to', 'specific', 'applications']",12,223,"['DMs', 'Variational', 'Learning', 'Our', 'Data', 'Evaluating', 'However', 'DGMs', 'Furthermore', 'Trilemma', 'Diffusion', 'Generative', 'VAEs', 'Networks', 'Adversarial', 'Autoencoders', 'GANs', 'Models', 'Deep']"
2504.10191v1,Localized Cultural Knowledge is Conserved and Controllable in Large   Language Models,"Just as humans display language patterns influenced by their native tongue when speaking new languages, LLMs often default to English-centric responses even when generating in other languages. Nevertheless, we observe that local cultural information persists within the models and can be readily activated for cultural customization. We first demonstrate that explicitly providing cultural context in prompts significantly improves the models' ability to generate culturally localized responses. We term the disparity in model performance with versus without explicit cultural context the explicit-implicit localization gap, indicating that while cultural knowledge exists within LLMs, it may not naturally surface in multilingual interactions if cultural context is not explicitly provided. Despite the explicit prompting benefit, however, the answers reduce in diversity and tend toward stereotypes. Second, we identify an explicit cultural customization vector, conserved across all non-English languages we explore, which enables LLMs to be steered from the synthetic English cultural world-model toward each non-English cultural world. Steered responses retain the diversity of implicit prompting and reduce stereotypes to dramatically improve the potential for customization. We discuss the implications of explicit cultural customization for understanding the conservation of alternative cultural world models within LLMs, and their controllable utility for translation, cultural customization, and the possibility of making the explicit implicit through soft control for expanded LLM function and appeal.","Veniamin Veselovsky, Berke Argin, Benedikt Stroebl, Chris Wendler, Robert West, James Evans, Thomas L. Griffiths, Arvind Narayanan","cs.CL, cs.AI",2025-04-14T12:53:58Z,http://arxiv.org/abs/2504.10191v1,localized cultural knowledge is conserved and controllable in large language models,just as humans display language patterns influenced by their native tongue when speaking new languages llms often default to english centric responses even when generating in other languages nevertheless we observe that local cultural information persists within the models and can be readily activated for cultural customization we first demonstrate that explicitly providing cultural context in prompts significantly improves the models ability to generate culturally localized responses we term the disparity in model performance with versus without explicit cultural context the explicit implicit localization gap indicating that while cultural knowledge exists within llms it may not naturally surface in multilingual interactions if cultural context is not explicitly provided despite the explicit prompting benefit however the answers reduce in diversity and tend toward stereotypes second we identify an explicit cultural customization vector conserved across all non english languages we explore which enables llms to be steered from the synthetic english cultural world model toward each non english cultural world steered responses retain the diversity of implicit prompting and reduce stereotypes to dramatically improve the potential for customization we discuss the implications of explicit cultural customization for understanding the conservation of alternative cultural world models within llms and their controllable utility for translation cultural customization and the possibility of making the explicit implicit through soft control for expanded llm function and appeal,"['localized', 'cultural', 'knowledge', 'is', 'conserved', 'and', 'controllable', 'in', 'large', 'language', 'models']","['just', 'as', 'humans', 'display', 'language', 'patterns', 'influenced', 'by', 'their', 'native', 'tongue', 'when', 'speaking', 'new', 'languages', 'llms', 'often', 'default', 'to', 'english', 'centric', 'responses', 'even', 'when', 'generating', 'in', 'other', 'languages', 'nevertheless', 'we', 'observe', 'that', 'local', 'cultural', 'information', 'persists', 'within', 'the', 'models', 'and', 'can', 'be', 'readily', 'activated', 'for', 'cultural', 'customization', 'we', 'first', 'demonstrate', 'that', 'explicitly', 'providing', 'cultural', 'context', 'in', 'prompts', 'significantly', 'improves', 'the', 'models', 'ability', 'to', 'generate', 'culturally', 'localized', 'responses', 'we', 'term', 'the', 'disparity', 'in', 'model', 'performance', 'with', 'versus', 'without', 'explicit', 'cultural', 'context', 'the', 'explicit', 'implicit', 'localization', 'gap', 'indicating', 'that', 'while', 'cultural', 'knowledge', 'exists', 'within', 'llms', 'it', 'may', 'not', 'naturally', 'surface', 'in', 'multilingual', 'interactions', 'if', 'cultural', 'context', 'is', 'not', 'explicitly', 'provided', 'despite', 'the', 'explicit', 'prompting', 'benefit', 'however', 'the', 'answers', 'reduce', 'in', 'diversity', 'and', 'tend', 'toward', 'stereotypes', 'second', 'we', 'identify', 'an', 'explicit', 'cultural', 'customization', 'vector', 'conserved', 'across', 'all', 'non', 'english', 'languages', 'we', 'explore', 'which', 'enables', 'llms', 'to', 'be', 'steered', 'from', 'the', 'synthetic', 'english', 'cultural', 'world', 'model', 'toward', 'each', 'non', 'english', 'cultural', 'world', 'steered', 'responses', 'retain', 'the', 'diversity', 'of', 'implicit', 'prompting', 'and', 'reduce', 'stereotypes', 'to', 'dramatically', 'improve', 'the', 'potential', 'for', 'customization', 'we', 'discuss', 'the', 'implications', 'of', 'explicit', 'cultural', 'customization', 'for', 'understanding', 'the', 'conservation', 'of', 'alternative', 'cultural', 'world', 'models', 'within', 'llms', 'and', 'their', 'controllable', 'utility', 'for', 'translation', 'cultural', 'customization', 'and', 'the', 'possibility', 'of', 'making', 'the', 'explicit', 'implicit', 'through', 'soft', 'control', 'for', 'expanded', 'llm', 'function', 'and', 'appeal']",11,220,"['Steered', 'Despite', 'LLMs', 'LLM', 'English', 'Just', 'Nevertheless', 'Second']"
2504.10188v1,Efficient Generative Model Training via Embedded Representation Warmup,"Diffusion models excel at generating high-dimensional data but fall short in training efficiency and representation quality compared to self-supervised methods. We identify a key bottleneck: the underutilization of high-quality, semantically rich representations during training notably slows down convergence. Our systematic analysis reveals a critical representation processing region -- primarily in the early layers -- where semantic and structural pattern learning takes place before generation can occur. To address this, we propose Embedded Representation Warmup (ERW), a plug-and-play framework where in the first stage we get the ERW module serves as a warmup that initializes the early layers of the diffusion model with high-quality, pretrained representations. This warmup minimizes the burden of learning representations from scratch, thereby accelerating convergence and boosting performance. Our theoretical analysis demonstrates that ERW's efficacy depends on its precise integration into specific neural network layers -- termed the representation processing region -- where the model primarily processes and transforms feature representations for later generation. We further establish that ERW not only accelerates training convergence but also enhances representation quality: empirically, our method achieves a 40$\times$ acceleration in training speed compared to REPA, the current state-of-the-art methods. Code is available at https://github.com/LINs-lab/ERW.","Deyuan Liu, Peng Sun, Xufeng Li, Tao Lin","cs.LG, cs.AI",2025-04-14T12:43:17Z,http://arxiv.org/abs/2504.10188v1,efficient generative model training via embedded representation warmup,diffusion models excel at generating high dimensional data but fall short in training efficiency and representation quality compared to self supervised methods we identify a key bottleneck the underutilization of high quality semantically rich representations during training notably slows down convergence our systematic analysis reveals a critical representation processing region primarily in the early layers where semantic and structural pattern learning takes place before generation can occur to address this we propose embedded representation warmup erw a plug and play framework where in the first stage we get the erw module serves as a warmup that initializes the early layers of the diffusion model with high quality pretrained representations this warmup minimizes the burden of learning representations from scratch thereby accelerating convergence and boosting performance our theoretical analysis demonstrates that erw s efficacy depends on its precise integration into specific neural network layers termed the representation processing region where the model primarily processes and transforms feature representations for later generation we further establish that erw not only accelerates training convergence but also enhances representation quality empirically our method achieves a acceleration in training speed compared to repa the current state of the art methods code is available at,"['efficient', 'generative', 'model', 'training', 'via', 'embedded', 'representation', 'warmup']","['diffusion', 'models', 'excel', 'at', 'generating', 'high', 'dimensional', 'data', 'but', 'fall', 'short', 'in', 'training', 'efficiency', 'and', 'representation', 'quality', 'compared', 'to', 'self', 'supervised', 'methods', 'we', 'identify', 'a', 'key', 'bottleneck', 'the', 'underutilization', 'of', 'high', 'quality', 'semantically', 'rich', 'representations', 'during', 'training', 'notably', 'slows', 'down', 'convergence', 'our', 'systematic', 'analysis', 'reveals', 'a', 'critical', 'representation', 'processing', 'region', 'primarily', 'in', 'the', 'early', 'layers', 'where', 'semantic', 'and', 'structural', 'pattern', 'learning', 'takes', 'place', 'before', 'generation', 'can', 'occur', 'to', 'address', 'this', 'we', 'propose', 'embedded', 'representation', 'warmup', 'erw', 'a', 'plug', 'and', 'play', 'framework', 'where', 'in', 'the', 'first', 'stage', 'we', 'get', 'the', 'erw', 'module', 'serves', 'as', 'a', 'warmup', 'that', 'initializes', 'the', 'early', 'layers', 'of', 'the', 'diffusion', 'model', 'with', 'high', 'quality', 'pretrained', 'representations', 'this', 'warmup', 'minimizes', 'the', 'burden', 'of', 'learning', 'representations', 'from', 'scratch', 'thereby', 'accelerating', 'convergence', 'and', 'boosting', 'performance', 'our', 'theoretical', 'analysis', 'demonstrates', 'that', 'erw', 's', 'efficacy', 'depends', 'on', 'its', 'precise', 'integration', 'into', 'specific', 'neural', 'network', 'layers', 'termed', 'the', 'representation', 'processing', 'region', 'where', 'the', 'model', 'primarily', 'processes', 'and', 'transforms', 'feature', 'representations', 'for', 'later', 'generation', 'we', 'further', 'establish', 'that', 'erw', 'not', 'only', 'accelerates', 'training', 'convergence', 'but', 'also', 'enhances', 'representation', 'quality', 'empirically', 'our', 'method', 'achieves', 'a', 'acceleration', 'in', 'training', 'speed', 'compared', 'to', 'repa', 'the', 'current', 'state', 'of', 'the', 'art', 'methods', 'code', 'is', 'available', 'at']",8,198,"['REPA', 'Warmup', 'Diffusion', 'LINs', 'Code', 'ERW', 'Embedded', 'Our', 'Representation']"
2504.10185v2,LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in   Current Benchmarks,"Large language model unlearning has become a critical challenge in ensuring safety and controlled model behavior by removing undesired data-model influences from the pretrained model while preserving general utility. Significant recent efforts have been dedicated to developing LLM unlearning benchmarks such as WMDP (Weapons of Mass Destruction Proxy) and MUSE (Machine Unlearning Six-way Evaluation), facilitating standardized unlearning performance assessment and method comparison. Despite their usefulness, we uncover for the first time a novel coreset effect within these benchmarks. Specifically, we find that LLM unlearning achieved with the original (full) forget set can be effectively maintained using a significantly smaller subset (functioning as a ""coreset""), e.g., as little as 5% of the forget set, even when selected at random. This suggests that LLM unlearning in these benchmarks can be performed surprisingly easily, even in an extremely low-data regime. We demonstrate that this coreset effect remains strong, regardless of the LLM unlearning method used, such as NPO (Negative Preference Optimization) and RMU (Representation Misdirection Unlearning), the popular ones in these benchmarks. The surprisingly strong coreset effect is also robust across various data selection methods, ranging from random selection to more sophisticated heuristic approaches. We explain the coreset effect in LLM unlearning through a keyword-based perspective, showing that keywords extracted from the forget set alone contribute significantly to unlearning effectiveness and indicating that current unlearning is driven by a compact set of high-impact tokens rather than the entire dataset. We further justify the faithfulness of coreset-unlearned models along additional dimensions, such as mode connectivity and robustness to jailbreaking attacks. Codes are available at https://github.com/OPTML-Group/MU-Coreset.","Soumyadeep Pal, Changsheng Wang, James Diffenderfer, Bhavya Kailkhura, Sijia Liu","cs.CL, cs.AI, cs.LG",2025-04-14T12:38:37Z,http://arxiv.org/abs/2504.10185v2,llm unlearning reveals a stronger than expected coreset effect in current benchmarks,large language model unlearning has become a critical challenge in ensuring safety and controlled model behavior by removing undesired data model influences from the pretrained model while preserving general utility significant recent efforts have been dedicated to developing llm unlearning benchmarks such as wmdp weapons of mass destruction proxy and muse machine unlearning six way evaluation facilitating standardized unlearning performance assessment and method comparison despite their usefulness we uncover for the first time a novel coreset effect within these benchmarks specifically we find that llm unlearning achieved with the original full forget set can be effectively maintained using a significantly smaller subset functioning as a coreset e g as little as of the forget set even when selected at random this suggests that llm unlearning in these benchmarks can be performed surprisingly easily even in an extremely low data regime we demonstrate that this coreset effect remains strong regardless of the llm unlearning method used such as npo negative preference optimization and rmu representation misdirection unlearning the popular ones in these benchmarks the surprisingly strong coreset effect is also robust across various data selection methods ranging from random selection to more sophisticated heuristic approaches we explain the coreset effect in llm unlearning through a keyword based perspective showing that keywords extracted from the forget set alone contribute significantly to unlearning effectiveness and indicating that current unlearning is driven by a compact set of high impact tokens rather than the entire dataset we further justify the faithfulness of coreset unlearned models along additional dimensions such as mode connectivity and robustness to jailbreaking attacks codes are available at,"['llm', 'unlearning', 'reveals', 'a', 'stronger', 'than', 'expected', 'coreset', 'effect', 'in', 'current', 'benchmarks']","['large', 'language', 'model', 'unlearning', 'has', 'become', 'a', 'critical', 'challenge', 'in', 'ensuring', 'safety', 'and', 'controlled', 'model', 'behavior', 'by', 'removing', 'undesired', 'data', 'model', 'influences', 'from', 'the', 'pretrained', 'model', 'while', 'preserving', 'general', 'utility', 'significant', 'recent', 'efforts', 'have', 'been', 'dedicated', 'to', 'developing', 'llm', 'unlearning', 'benchmarks', 'such', 'as', 'wmdp', 'weapons', 'of', 'mass', 'destruction', 'proxy', 'and', 'muse', 'machine', 'unlearning', 'six', 'way', 'evaluation', 'facilitating', 'standardized', 'unlearning', 'performance', 'assessment', 'and', 'method', 'comparison', 'despite', 'their', 'usefulness', 'we', 'uncover', 'for', 'the', 'first', 'time', 'a', 'novel', 'coreset', 'effect', 'within', 'these', 'benchmarks', 'specifically', 'we', 'find', 'that', 'llm', 'unlearning', 'achieved', 'with', 'the', 'original', 'full', 'forget', 'set', 'can', 'be', 'effectively', 'maintained', 'using', 'a', 'significantly', 'smaller', 'subset', 'functioning', 'as', 'a', 'coreset', 'e', 'g', 'as', 'little', 'as', 'of', 'the', 'forget', 'set', 'even', 'when', 'selected', 'at', 'random', 'this', 'suggests', 'that', 'llm', 'unlearning', 'in', 'these', 'benchmarks', 'can', 'be', 'performed', 'surprisingly', 'easily', 'even', 'in', 'an', 'extremely', 'low', 'data', 'regime', 'we', 'demonstrate', 'that', 'this', 'coreset', 'effect', 'remains', 'strong', 'regardless', 'of', 'the', 'llm', 'unlearning', 'method', 'used', 'such', 'as', 'npo', 'negative', 'preference', 'optimization', 'and', 'rmu', 'representation', 'misdirection', 'unlearning', 'the', 'popular', 'ones', 'in', 'these', 'benchmarks', 'the', 'surprisingly', 'strong', 'coreset', 'effect', 'is', 'also', 'robust', 'across', 'various', 'data', 'selection', 'methods', 'ranging', 'from', 'random', 'selection', 'to', 'more', 'sophisticated', 'heuristic', 'approaches', 'we', 'explain', 'the', 'coreset', 'effect', 'in', 'llm', 'unlearning', 'through', 'a', 'keyword', 'based', 'perspective', 'showing', 'that', 'keywords', 'extracted', 'from', 'the', 'forget', 'set', 'alone', 'contribute', 'significantly', 'to', 'unlearning', 'effectiveness', 'and', 'indicating', 'that', 'current', 'unlearning', 'is', 'driven', 'by', 'a', 'compact', 'set', 'of', 'high', 'impact', 'tokens', 'rather', 'than', 'the', 'entire', 'dataset', 'we', 'further', 'justify', 'the', 'faithfulness', 'of', 'coreset', 'unlearned', 'models', 'along', 'additional', 'dimensions', 'such', 'as', 'mode', 'connectivity', 'and', 'robustness', 'to', 'jailbreaking', 'attacks', 'codes', 'are', 'available', 'at']",12,266,"['Six', 'NPO', 'Specifically', 'Weapons', 'Codes', 'Representation', 'Despite', 'Unlearning', 'Proxy', 'WMDP', 'Large', 'Evaluation', 'Destruction', 'MU-Coreset', 'Negative', 'Misdirection', 'MUSE', 'LLM', 'Significant', 'RMU', 'OPTML-Group', 'Mass', 'Preference', 'Machine', 'Optimization']"
2504.10179v1,The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental   Evaluation of Prompt Engineering Methods for Robust Multimodal Performance,"Multimodal Large Language Models (MLLMs) are set to transform how machines process and generate human-like responses by integrating diverse modalities such as text, images, and code. Yet, effectively harnessing their capabilities hinges on optimal prompt engineering. We present a comprehensive experimental evaluation of seven prompt engineering methods applied to 13 open-source MLLMs over 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding and Alignment, Complex Code Generation and Execution, and Knowledge Retrieval and Integration. Our approach stratifies models by parameter count into Small (<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting techniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought, Analogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel in structured tasks such as code generation, achieving accuracies up to 96.88% under Few-Shot prompting, all models struggle with complex reasoning and abstract understanding, often yielding accuracies below 60% and high hallucination rates. Structured reasoning prompts frequently increased hallucination up to 75% in small models and led to longer response times (over 20 seconds in Large MLLMs), while simpler prompting methods provided more concise and efficient outputs. No single prompting method uniformly optimises all task types. Instead, adaptive strategies combining example-based guidance with selective structured reasoning are essential to enhance robustness, efficiency, and factual accuracy. Our findings offer practical recommendations for prompt engineering and support more reliable deployment of MLLMs across applications including AI-assisted coding, knowledge retrieval, and multimodal content understanding.","Anwesha Mohanty, Venkatesh Balavadhani Parthasarathy, Arsalan Shahid","cs.AI, cs.CL, cs.ET",2025-04-14T12:31:39Z,http://arxiv.org/abs/2504.10179v1,the future of mllm prompting is adaptive a comprehensive experimental evaluation of prompt engineering methods for robust multimodal performance,multimodal large language models mllms are set to transform how machines process and generate human like responses by integrating diverse modalities such as text images and code yet effectively harnessing their capabilities hinges on optimal prompt engineering we present a comprehensive experimental evaluation of seven prompt engineering methods applied to open source mllms over tasks spanning reasoning and compositionality multimodal understanding and alignment complex code generation and execution and knowledge retrieval and integration our approach stratifies models by parameter count into small b medium b b and large b categories and compares prompting techniques including zero shot one shot few shot chain of thought analogical generated knowledge and tree of thought while large mllms excel in structured tasks such as code generation achieving accuracies up to under few shot prompting all models struggle with complex reasoning and abstract understanding often yielding accuracies below and high hallucination rates structured reasoning prompts frequently increased hallucination up to in small models and led to longer response times over seconds in large mllms while simpler prompting methods provided more concise and efficient outputs no single prompting method uniformly optimises all task types instead adaptive strategies combining example based guidance with selective structured reasoning are essential to enhance robustness efficiency and factual accuracy our findings offer practical recommendations for prompt engineering and support more reliable deployment of mllms across applications including ai assisted coding knowledge retrieval and multimodal content understanding,"['the', 'future', 'of', 'mllm', 'prompting', 'is', 'adaptive', 'a', 'comprehensive', 'experimental', 'evaluation', 'of', 'prompt', 'engineering', 'methods', 'for', 'robust', 'multimodal', 'performance']","['multimodal', 'large', 'language', 'models', 'mllms', 'are', 'set', 'to', 'transform', 'how', 'machines', 'process', 'and', 'generate', 'human', 'like', 'responses', 'by', 'integrating', 'diverse', 'modalities', 'such', 'as', 'text', 'images', 'and', 'code', 'yet', 'effectively', 'harnessing', 'their', 'capabilities', 'hinges', 'on', 'optimal', 'prompt', 'engineering', 'we', 'present', 'a', 'comprehensive', 'experimental', 'evaluation', 'of', 'seven', 'prompt', 'engineering', 'methods', 'applied', 'to', 'open', 'source', 'mllms', 'over', 'tasks', 'spanning', 'reasoning', 'and', 'compositionality', 'multimodal', 'understanding', 'and', 'alignment', 'complex', 'code', 'generation', 'and', 'execution', 'and', 'knowledge', 'retrieval', 'and', 'integration', 'our', 'approach', 'stratifies', 'models', 'by', 'parameter', 'count', 'into', 'small', 'b', 'medium', 'b', 'b', 'and', 'large', 'b', 'categories', 'and', 'compares', 'prompting', 'techniques', 'including', 'zero', 'shot', 'one', 'shot', 'few', 'shot', 'chain', 'of', 'thought', 'analogical', 'generated', 'knowledge', 'and', 'tree', 'of', 'thought', 'while', 'large', 'mllms', 'excel', 'in', 'structured', 'tasks', 'such', 'as', 'code', 'generation', 'achieving', 'accuracies', 'up', 'to', 'under', 'few', 'shot', 'prompting', 'all', 'models', 'struggle', 'with', 'complex', 'reasoning', 'and', 'abstract', 'understanding', 'often', 'yielding', 'accuracies', 'below', 'and', 'high', 'hallucination', 'rates', 'structured', 'reasoning', 'prompts', 'frequently', 'increased', 'hallucination', 'up', 'to', 'in', 'small', 'models', 'and', 'led', 'to', 'longer', 'response', 'times', 'over', 'seconds', 'in', 'large', 'mllms', 'while', 'simpler', 'prompting', 'methods', 'provided', 'more', 'concise', 'and', 'efficient', 'outputs', 'no', 'single', 'prompting', 'method', 'uniformly', 'optimises', 'all', 'task', 'types', 'instead', 'adaptive', 'strategies', 'combining', 'example', 'based', 'guidance', 'with', 'selective', 'structured', 'reasoning', 'are', 'essential', 'to', 'enhance', 'robustness', 'efficiency', 'and', 'factual', 'accuracy', 'our', 'findings', 'offer', 'practical', 'recommendations', 'for', 'prompt', 'engineering', 'and', 'support', 'more', 'reliable', 'deployment', 'of', 'mllms', 'across', 'applications', 'including', 'ai', 'assisted', 'coding', 'knowledge', 'retrieval', 'and', 'multimodal', 'content', 'understanding']",19,235,"['Generated', 'Small', '4B-10B', 'Multimodal', 'Chain', 'Instead', 'Analogical', 'AI-assisted', 'Language', 'Our', 'Retrieval', 'Reasoning', 'Compositionality', '10B', 'Yet', 'While', 'Structured', 'Medium', 'Shot', 'Generation', 'Large', 'Understanding', 'Integration', 'Complex', 'Execution', 'MLLMs', 'Code', 'One', 'Tree', 'Zero', 'Thought', 'Few', 'Models', 'Alignment', 'Knowledge']"
2504.10168v1,HalluSearch at SemEval-2025 Task 3: A Search-Enhanced RAG Pipeline for   Hallucination Detection,"In this paper, we present HalluSearch, a multilingual pipeline designed to detect fabricated text spans in Large Language Model (LLM) outputs. Developed as part of Mu-SHROOM, the Multilingual Shared-task on Hallucinations and Related Observable Overgeneration Mistakes, HalluSearch couples retrieval-augmented verification with fine-grained factual splitting to identify and localize hallucinations in fourteen different languages. Empirical evaluations show that HalluSearch performs competitively, placing fourth in both English (within the top ten percent) and Czech. While the system's retrieval-based strategy generally proves robust, it faces challenges in languages with limited online coverage, underscoring the need for further research to ensure consistent hallucination detection across diverse linguistic contexts.","Mohamed A. Abdallah, Samhaa R. El-Beltagy","cs.CL, cs.AI",2025-04-14T12:22:30Z,http://arxiv.org/abs/2504.10168v1,hallusearch at semeval task a search enhanced rag pipeline for hallucination detection,in this paper we present hallusearch a multilingual pipeline designed to detect fabricated text spans in large language model llm outputs developed as part of mu shroom the multilingual shared task on hallucinations and related observable overgeneration mistakes hallusearch couples retrieval augmented verification with fine grained factual splitting to identify and localize hallucinations in fourteen different languages empirical evaluations show that hallusearch performs competitively placing fourth in both english within the top ten percent and czech while the system s retrieval based strategy generally proves robust it faces challenges in languages with limited online coverage underscoring the need for further research to ensure consistent hallucination detection across diverse linguistic contexts,"['hallusearch', 'at', 'semeval', 'task', 'a', 'search', 'enhanced', 'rag', 'pipeline', 'for', 'hallucination', 'detection']","['in', 'this', 'paper', 'we', 'present', 'hallusearch', 'a', 'multilingual', 'pipeline', 'designed', 'to', 'detect', 'fabricated', 'text', 'spans', 'in', 'large', 'language', 'model', 'llm', 'outputs', 'developed', 'as', 'part', 'of', 'mu', 'shroom', 'the', 'multilingual', 'shared', 'task', 'on', 'hallucinations', 'and', 'related', 'observable', 'overgeneration', 'mistakes', 'hallusearch', 'couples', 'retrieval', 'augmented', 'verification', 'with', 'fine', 'grained', 'factual', 'splitting', 'to', 'identify', 'and', 'localize', 'hallucinations', 'in', 'fourteen', 'different', 'languages', 'empirical', 'evaluations', 'show', 'that', 'hallusearch', 'performs', 'competitively', 'placing', 'fourth', 'in', 'both', 'english', 'within', 'the', 'top', 'ten', 'percent', 'and', 'czech', 'while', 'the', 'system', 's', 'retrieval', 'based', 'strategy', 'generally', 'proves', 'robust', 'it', 'faces', 'challenges', 'in', 'languages', 'with', 'limited', 'online', 'coverage', 'underscoring', 'the', 'need', 'for', 'further', 'research', 'to', 'ensure', 'consistent', 'hallucination', 'detection', 'across', 'diverse', 'linguistic', 'contexts']",12,110,"['Overgeneration', 'Mistakes', 'Observable', 'HalluSearch', 'Model', 'Empirical', 'SHROOM', 'Czech', 'While', 'Multilingual', 'English', 'Related', 'Developed', 'Hallucinations', 'Language', 'Large', 'LLM', 'Shared']"
2504.10167v1,C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination   Evaluation,"Despite the rapid advancement of large language models, they remain highly susceptible to generating hallucinations, which significantly hinders their widespread application. Hallucination research requires dynamic and fine-grained evaluation. However, most existing hallucination benchmarks (especially in Chinese language) rely on human annotations, making automatical and cost-effective hallucination evaluation challenging. To address this, we introduce HaluAgent, an agentic framework that automatically constructs fine-grained QA dataset based on some knowledge documents. Our experiments demonstrate that the manually designed rules and prompt optimization can improve the quality of generated data. Using HaluAgent, we construct C-FAITH, a Chinese QA hallucination benchmark created from 1,399 knowledge documents obtained from web scraping, totaling 60,702 entries. We comprehensively evaluate 16 mainstream LLMs with our proposed C-FAITH, providing detailed experimental results and analysis.","Xu Zhang, Zhifei Liu, Jiahao Wang, Huixuan Zhang, Fan Xu, Junzhe Zhang, Xiaojun Wan","cs.CL, cs.AI",2025-04-14T12:21:55Z,http://arxiv.org/abs/2504.10167v1,c faith a chinese fine grained benchmark for automated hallucination evaluation,despite the rapid advancement of large language models they remain highly susceptible to generating hallucinations which significantly hinders their widespread application hallucination research requires dynamic and fine grained evaluation however most existing hallucination benchmarks especially in chinese language rely on human annotations making automatical and cost effective hallucination evaluation challenging to address this we introduce haluagent an agentic framework that automatically constructs fine grained qa dataset based on some knowledge documents our experiments demonstrate that the manually designed rules and prompt optimization can improve the quality of generated data using haluagent we construct c faith a chinese qa hallucination benchmark created from knowledge documents obtained from web scraping totaling entries we comprehensively evaluate mainstream llms with our proposed c faith providing detailed experimental results and analysis,"['c', 'faith', 'a', 'chinese', 'fine', 'grained', 'benchmark', 'for', 'automated', 'hallucination', 'evaluation']","['despite', 'the', 'rapid', 'advancement', 'of', 'large', 'language', 'models', 'they', 'remain', 'highly', 'susceptible', 'to', 'generating', 'hallucinations', 'which', 'significantly', 'hinders', 'their', 'widespread', 'application', 'hallucination', 'research', 'requires', 'dynamic', 'and', 'fine', 'grained', 'evaluation', 'however', 'most', 'existing', 'hallucination', 'benchmarks', 'especially', 'in', 'chinese', 'language', 'rely', 'on', 'human', 'annotations', 'making', 'automatical', 'and', 'cost', 'effective', 'hallucination', 'evaluation', 'challenging', 'to', 'address', 'this', 'we', 'introduce', 'haluagent', 'an', 'agentic', 'framework', 'that', 'automatically', 'constructs', 'fine', 'grained', 'qa', 'dataset', 'based', 'on', 'some', 'knowledge', 'documents', 'our', 'experiments', 'demonstrate', 'that', 'the', 'manually', 'designed', 'rules', 'and', 'prompt', 'optimization', 'can', 'improve', 'the', 'quality', 'of', 'generated', 'data', 'using', 'haluagent', 'we', 'construct', 'c', 'faith', 'a', 'chinese', 'qa', 'hallucination', 'benchmark', 'created', 'from', 'knowledge', 'documents', 'obtained', 'from', 'web', 'scraping', 'totaling', 'entries', 'we', 'comprehensively', 'evaluate', 'mainstream', 'llms', 'with', 'our', 'proposed', 'c', 'faith', 'providing', 'detailed', 'experimental', 'results', 'and', 'analysis']",11,126,"['Despite', 'LLMs', 'C-FAITH', 'However', '702', 'Our', '399', 'Hallucination', 'Chinese', 'HaluAgent']"
2504.10160v1,MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like   Reinforcement Learning,"Large-scale reinforcement learning (RL) methods have proven highly effective in enhancing the reasoning abilities of large language models (LLMs), particularly for tasks with verifiable solutions such as mathematics and coding. However, applying this idea to machine translation (MT), where outputs are flexibly formatted and difficult to automatically evaluate with explicit rules, remains underexplored. In this work, we introduce MT-R1-Zero, the first open-source adaptation of the R1-Zero RL framework for MT without supervised fine-tuning or cold-start. We propose a rule-metric mixed reward mechanism to guide LLMs towards improved translation quality via emergent reasoning. On the WMT 24 English-Chinese benchmark, our MT-R1-Zero-3B-Mix achieves competitive performance, surpassing TowerInstruct-7B-v0.2 by an average of 1.26 points. Meanwhile, our MT-R1-Zero-7B-Mix attains a high average score of 62.25 across all metrics, placing it on par with advanced proprietary models such as GPT-4o and Claude-3.5-Sonnet, while the MT-R1-Zero-7B-Sem variant achieves state-of-the-art scores on semantic metrics. Moreover, our work exhibits strong generalization capabilities on out-of-distribution MT tasks, robustly supporting multilingual and low-resource settings. Extensive analysis of model behavior across different initializations and reward metrics offers pioneering insight into the critical role of reward design, LLM adaptability, training dynamics, and emergent reasoning patterns within the R1-Zero paradigm for MT. Our code is available at https://github.com/fzp0424/MT-R1-Zero.","Zhaopeng Feng, Shaosheng Cao, Jiahan Ren, Jiayuan Su, Ruizhe Chen, Yan Zhang, Zhe Xu, Yao Hu, Jian Wu, Zuozhu Liu","cs.CL, cs.AI, cs.LG",2025-04-14T12:14:18Z,http://arxiv.org/abs/2504.10160v1,mt r zero advancing llm based machine translation via r zero like reinforcement learning,large scale reinforcement learning rl methods have proven highly effective in enhancing the reasoning abilities of large language models llms particularly for tasks with verifiable solutions such as mathematics and coding however applying this idea to machine translation mt where outputs are flexibly formatted and difficult to automatically evaluate with explicit rules remains underexplored in this work we introduce mt r zero the first open source adaptation of the r zero rl framework for mt without supervised fine tuning or cold start we propose a rule metric mixed reward mechanism to guide llms towards improved translation quality via emergent reasoning on the wmt english chinese benchmark our mt r zero b mix achieves competitive performance surpassing towerinstruct b v by an average of points meanwhile our mt r zero b mix attains a high average score of across all metrics placing it on par with advanced proprietary models such as gpt o and claude sonnet while the mt r zero b sem variant achieves state of the art scores on semantic metrics moreover our work exhibits strong generalization capabilities on out of distribution mt tasks robustly supporting multilingual and low resource settings extensive analysis of model behavior across different initializations and reward metrics offers pioneering insight into the critical role of reward design llm adaptability training dynamics and emergent reasoning patterns within the r zero paradigm for mt our code is available at,"['mt', 'r', 'zero', 'advancing', 'llm', 'based', 'machine', 'translation', 'via', 'r', 'zero', 'like', 'reinforcement', 'learning']","['large', 'scale', 'reinforcement', 'learning', 'rl', 'methods', 'have', 'proven', 'highly', 'effective', 'in', 'enhancing', 'the', 'reasoning', 'abilities', 'of', 'large', 'language', 'models', 'llms', 'particularly', 'for', 'tasks', 'with', 'verifiable', 'solutions', 'such', 'as', 'mathematics', 'and', 'coding', 'however', 'applying', 'this', 'idea', 'to', 'machine', 'translation', 'mt', 'where', 'outputs', 'are', 'flexibly', 'formatted', 'and', 'difficult', 'to', 'automatically', 'evaluate', 'with', 'explicit', 'rules', 'remains', 'underexplored', 'in', 'this', 'work', 'we', 'introduce', 'mt', 'r', 'zero', 'the', 'first', 'open', 'source', 'adaptation', 'of', 'the', 'r', 'zero', 'rl', 'framework', 'for', 'mt', 'without', 'supervised', 'fine', 'tuning', 'or', 'cold', 'start', 'we', 'propose', 'a', 'rule', 'metric', 'mixed', 'reward', 'mechanism', 'to', 'guide', 'llms', 'towards', 'improved', 'translation', 'quality', 'via', 'emergent', 'reasoning', 'on', 'the', 'wmt', 'english', 'chinese', 'benchmark', 'our', 'mt', 'r', 'zero', 'b', 'mix', 'achieves', 'competitive', 'performance', 'surpassing', 'towerinstruct', 'b', 'v', 'by', 'an', 'average', 'of', 'points', 'meanwhile', 'our', 'mt', 'r', 'zero', 'b', 'mix', 'attains', 'a', 'high', 'average', 'score', 'of', 'across', 'all', 'metrics', 'placing', 'it', 'on', 'par', 'with', 'advanced', 'proprietary', 'models', 'such', 'as', 'gpt', 'o', 'and', 'claude', 'sonnet', 'while', 'the', 'mt', 'r', 'zero', 'b', 'sem', 'variant', 'achieves', 'state', 'of', 'the', 'art', 'scores', 'on', 'semantic', 'metrics', 'moreover', 'our', 'work', 'exhibits', 'strong', 'generalization', 'capabilities', 'on', 'out', 'of', 'distribution', 'mt', 'tasks', 'robustly', 'supporting', 'multilingual', 'and', 'low', 'resource', 'settings', 'extensive', 'analysis', 'of', 'model', 'behavior', 'across', 'different', 'initializations', 'and', 'reward', 'metrics', 'offers', 'pioneering', 'insight', 'into', 'the', 'critical', 'role', 'of', 'reward', 'design', 'llm', 'adaptability', 'training', 'dynamics', 'and', 'emergent', 'reasoning', 'patterns', 'within', 'the', 'r', 'zero', 'paradigm', 'for', 'mt', 'our', 'code', 'is', 'available', 'at']",14,233,"['Claude-3', 'TowerInstruct', '7B-v0', 'Our', 'GPT-4o', '5-Sonnet', '7B-Sem', 'LLMs', 'However', 'WMT', 'Large', 'Moreover', 'English', '7B-Mix', 'Meanwhile', '3B-Mix', 'LLM', 'Extensive', 'R1-Zero', 'Zero', 'Chinese', 'MT-R1']"
2504.10158v1,COUNTS: Benchmarking Object Detectors and Multimodal Large Language   Models under Distribution Shifts,"Current object detectors often suffer significant perfor-mance degradation in real-world applications when encountering distributional shifts. Consequently, the out-of-distribution (OOD) generalization capability of object detectors has garnered increasing attention from researchers. Despite this growing interest, there remains a lack of a large-scale, comprehensive dataset and evaluation benchmark with fine-grained annotations tailored to assess the OOD generalization on more intricate tasks like object detection and grounding. To address this gap, we introduce COUNTS, a large-scale OOD dataset with object-level annotations. COUNTS encompasses 14 natural distributional shifts, over 222K samples, and more than 1,196K labeled bounding boxes. Leveraging COUNTS, we introduce two novel benchmarks: O(OD)2 and OODG. O(OD)2 is designed to comprehensively evaluate the OOD generalization capabilities of object detectors by utilizing controlled distribution shifts between training and testing data. OODG, on the other hand, aims to assess the OOD generalization of grounding abilities in multimodal large language models (MLLMs). Our findings reveal that, while large models and extensive pre-training data substantially en hance performance in in-distribution (IID) scenarios, significant limitations and opportunities for improvement persist in OOD contexts for both object detectors and MLLMs. In visual grounding tasks, even the advanced GPT-4o and Gemini-1.5 only achieve 56.7% and 28.0% accuracy, respectively. We hope COUNTS facilitates advancements in the development and assessment of robust object detectors and MLLMs capable of maintaining high performance under distributional shifts.","Jiansheng Li, Xingxuan Zhang, Hao Zou, Yige Guo, Renzhe Xu, Yilong Liu, Chuzhao Zhu, Yue He, Peng Cui","cs.CV, cs.AI",2025-04-14T12:13:33Z,http://arxiv.org/abs/2504.10158v1,counts benchmarking object detectors and multimodal large language models under distribution shifts,current object detectors often suffer significant perfor mance degradation in real world applications when encountering distributional shifts consequently the out of distribution ood generalization capability of object detectors has garnered increasing attention from researchers despite this growing interest there remains a lack of a large scale comprehensive dataset and evaluation benchmark with fine grained annotations tailored to assess the ood generalization on more intricate tasks like object detection and grounding to address this gap we introduce counts a large scale ood dataset with object level annotations counts encompasses natural distributional shifts over k samples and more than k labeled bounding boxes leveraging counts we introduce two novel benchmarks o od and oodg o od is designed to comprehensively evaluate the ood generalization capabilities of object detectors by utilizing controlled distribution shifts between training and testing data oodg on the other hand aims to assess the ood generalization of grounding abilities in multimodal large language models mllms our findings reveal that while large models and extensive pre training data substantially en hance performance in in distribution iid scenarios significant limitations and opportunities for improvement persist in ood contexts for both object detectors and mllms in visual grounding tasks even the advanced gpt o and gemini only achieve and accuracy respectively we hope counts facilitates advancements in the development and assessment of robust object detectors and mllms capable of maintaining high performance under distributional shifts,"['counts', 'benchmarking', 'object', 'detectors', 'and', 'multimodal', 'large', 'language', 'models', 'under', 'distribution', 'shifts']","['current', 'object', 'detectors', 'often', 'suffer', 'significant', 'perfor', 'mance', 'degradation', 'in', 'real', 'world', 'applications', 'when', 'encountering', 'distributional', 'shifts', 'consequently', 'the', 'out', 'of', 'distribution', 'ood', 'generalization', 'capability', 'of', 'object', 'detectors', 'has', 'garnered', 'increasing', 'attention', 'from', 'researchers', 'despite', 'this', 'growing', 'interest', 'there', 'remains', 'a', 'lack', 'of', 'a', 'large', 'scale', 'comprehensive', 'dataset', 'and', 'evaluation', 'benchmark', 'with', 'fine', 'grained', 'annotations', 'tailored', 'to', 'assess', 'the', 'ood', 'generalization', 'on', 'more', 'intricate', 'tasks', 'like', 'object', 'detection', 'and', 'grounding', 'to', 'address', 'this', 'gap', 'we', 'introduce', 'counts', 'a', 'large', 'scale', 'ood', 'dataset', 'with', 'object', 'level', 'annotations', 'counts', 'encompasses', 'natural', 'distributional', 'shifts', 'over', 'k', 'samples', 'and', 'more', 'than', 'k', 'labeled', 'bounding', 'boxes', 'leveraging', 'counts', 'we', 'introduce', 'two', 'novel', 'benchmarks', 'o', 'od', 'and', 'oodg', 'o', 'od', 'is', 'designed', 'to', 'comprehensively', 'evaluate', 'the', 'ood', 'generalization', 'capabilities', 'of', 'object', 'detectors', 'by', 'utilizing', 'controlled', 'distribution', 'shifts', 'between', 'training', 'and', 'testing', 'data', 'oodg', 'on', 'the', 'other', 'hand', 'aims', 'to', 'assess', 'the', 'ood', 'generalization', 'of', 'grounding', 'abilities', 'in', 'multimodal', 'large', 'language', 'models', 'mllms', 'our', 'findings', 'reveal', 'that', 'while', 'large', 'models', 'and', 'extensive', 'pre', 'training', 'data', 'substantially', 'en', 'hance', 'performance', 'in', 'in', 'distribution', 'iid', 'scenarios', 'significant', 'limitations', 'and', 'opportunities', 'for', 'improvement', 'persist', 'in', 'ood', 'contexts', 'for', 'both', 'object', 'detectors', 'and', 'mllms', 'in', 'visual', 'grounding', 'tasks', 'even', 'the', 'advanced', 'gpt', 'o', 'and', 'gemini', 'only', 'achieve', 'and', 'accuracy', 'respectively', 'we', 'hope', 'counts', 'facilitates', 'advancements', 'in', 'the', 'development', 'and', 'assessment', 'of', 'robust', 'object', 'detectors', 'and', 'mllms', 'capable', 'of', 'maintaining', 'high', 'performance', 'under', 'distributional', 'shifts']",12,233,"['222K', 'OODG', 'Leveraging', 'Gemini-1', 'Despite', 'OOD', '196K', 'MLLMs', 'Consequently', 'IID', 'Our', 'Current', 'COUNTS', 'GPT-4o']"
2504.10149v2,BoTTA: Benchmarking on-device Test Time Adaptation,"The performance of deep learning models depends heavily on test samples at runtime, and shifts from the training data distribution can significantly reduce accuracy. Test-time adaptation (TTA) addresses this by adapting models during inference without requiring labeled test data or access to the original training set. While research has explored TTA from various perspectives like algorithmic complexity, data and class distribution shifts, model architectures, and offline versus continuous learning, constraints specific to mobile and edge devices remain underexplored. We propose BoTTA, a benchmark designed to evaluate TTA methods under practical constraints on mobile and edge devices. Our evaluation targets four key challenges caused by limited resources and usage conditions: (i) limited test samples, (ii) limited exposure to categories, (iii) diverse distribution shifts, and (iv) overlapping shifts within a sample. We assess state-of-the-art TTA methods under these scenarios using benchmark datasets and report system-level metrics on a real testbed. Furthermore, unlike prior work, we align with on-device requirements by advocating periodic adaptation instead of continuous inference-time adaptation. Experiments reveal key insights: many recent TTA algorithms struggle with small datasets, fail to generalize to unseen categories, and depend on the diversity and complexity of distribution shifts. BoTTA also reports device-specific resource use. For example, while SHOT improves accuracy by $2.25\times$ with $512$ adaptation samples, it uses $1.08\times$ peak memory on Raspberry Pi versus the base model. BoTTA offers actionable guidance for TTA in real-world, resource-constrained deployments.","Michal Danilowski, Soumyajit Chatterjee, Abhirup Ghosh","cs.LG, cs.AI",2025-04-14T12:00:00Z,http://arxiv.org/abs/2504.10149v2,botta benchmarking on device test time adaptation,the performance of deep learning models depends heavily on test samples at runtime and shifts from the training data distribution can significantly reduce accuracy test time adaptation tta addresses this by adapting models during inference without requiring labeled test data or access to the original training set while research has explored tta from various perspectives like algorithmic complexity data and class distribution shifts model architectures and offline versus continuous learning constraints specific to mobile and edge devices remain underexplored we propose botta a benchmark designed to evaluate tta methods under practical constraints on mobile and edge devices our evaluation targets four key challenges caused by limited resources and usage conditions i limited test samples ii limited exposure to categories iii diverse distribution shifts and iv overlapping shifts within a sample we assess state of the art tta methods under these scenarios using benchmark datasets and report system level metrics on a real testbed furthermore unlike prior work we align with on device requirements by advocating periodic adaptation instead of continuous inference time adaptation experiments reveal key insights many recent tta algorithms struggle with small datasets fail to generalize to unseen categories and depend on the diversity and complexity of distribution shifts botta also reports device specific resource use for example while shot improves accuracy by with adaptation samples it uses peak memory on raspberry pi versus the base model botta offers actionable guidance for tta in real world resource constrained deployments,"['botta', 'benchmarking', 'on', 'device', 'test', 'time', 'adaptation']","['the', 'performance', 'of', 'deep', 'learning', 'models', 'depends', 'heavily', 'on', 'test', 'samples', 'at', 'runtime', 'and', 'shifts', 'from', 'the', 'training', 'data', 'distribution', 'can', 'significantly', 'reduce', 'accuracy', 'test', 'time', 'adaptation', 'tta', 'addresses', 'this', 'by', 'adapting', 'models', 'during', 'inference', 'without', 'requiring', 'labeled', 'test', 'data', 'or', 'access', 'to', 'the', 'original', 'training', 'set', 'while', 'research', 'has', 'explored', 'tta', 'from', 'various', 'perspectives', 'like', 'algorithmic', 'complexity', 'data', 'and', 'class', 'distribution', 'shifts', 'model', 'architectures', 'and', 'offline', 'versus', 'continuous', 'learning', 'constraints', 'specific', 'to', 'mobile', 'and', 'edge', 'devices', 'remain', 'underexplored', 'we', 'propose', 'botta', 'a', 'benchmark', 'designed', 'to', 'evaluate', 'tta', 'methods', 'under', 'practical', 'constraints', 'on', 'mobile', 'and', 'edge', 'devices', 'our', 'evaluation', 'targets', 'four', 'key', 'challenges', 'caused', 'by', 'limited', 'resources', 'and', 'usage', 'conditions', 'i', 'limited', 'test', 'samples', 'ii', 'limited', 'exposure', 'to', 'categories', 'iii', 'diverse', 'distribution', 'shifts', 'and', 'iv', 'overlapping', 'shifts', 'within', 'a', 'sample', 'we', 'assess', 'state', 'of', 'the', 'art', 'tta', 'methods', 'under', 'these', 'scenarios', 'using', 'benchmark', 'datasets', 'and', 'report', 'system', 'level', 'metrics', 'on', 'a', 'real', 'testbed', 'furthermore', 'unlike', 'prior', 'work', 'we', 'align', 'with', 'on', 'device', 'requirements', 'by', 'advocating', 'periodic', 'adaptation', 'instead', 'of', 'continuous', 'inference', 'time', 'adaptation', 'experiments', 'reveal', 'key', 'insights', 'many', 'recent', 'tta', 'algorithms', 'struggle', 'with', 'small', 'datasets', 'fail', 'to', 'generalize', 'to', 'unseen', 'categories', 'and', 'depend', 'on', 'the', 'diversity', 'and', 'complexity', 'of', 'distribution', 'shifts', 'botta', 'also', 'reports', 'device', 'specific', 'resource', 'use', 'for', 'example', 'while', 'shot', 'improves', 'accuracy', 'by', 'with', 'adaptation', 'samples', 'it', 'uses', 'peak', 'memory', 'on', 'raspberry', 'pi', 'versus', 'the', 'base', 'model', 'botta', 'offers', 'actionable', 'guidance', 'for', 'tta', 'in', 'real', 'world', 'resource', 'constrained', 'deployments']",7,241,"['SHOT', '512', 'Test', 'While', 'Raspberry', 'Furthermore', 'Our', 'TTA', 'BoTTA', 'Experiments']"
2504.10146v1,"GeoUni: A Unified Model for Generating Geometry Diagrams, Problems and   Problem Solutions","We propose GeoUni, the first unified geometry expert model capable of generating problem solutions and diagrams within a single framework in a way that enables the creation of unique and individualized geometry problems. Traditionally, solving geometry problems and generating diagrams have been treated as separate tasks in machine learning, with no models successfully integrating both to support problem creation. However, we believe that mastery in geometry requires frictionless integration of all of these skills, from solving problems to visualizing geometric relationships, and finally, crafting tailored problems. Our extensive experiments demonstrate that GeoUni, with only 1.5B parameters, achieves performance comparable to larger models such as DeepSeek-R1 with 671B parameters in geometric reasoning tasks. GeoUni also excels in generating precise geometric diagrams, surpassing both text-to-image models and unified models, including the GPT-4o image generation. Most importantly, GeoUni is the only model capable of successfully generating textual problems with matching diagrams based on specific knowledge points, thus offering a wider range of capabilities that extend beyond current models.","Jo-Ku Cheng, Zeren Zhang, Ran Chen, Jingyang Deng, Ziran Qin, Jinwen Ma","cs.LG, cs.AI",2025-04-14T11:56:55Z,http://arxiv.org/abs/2504.10146v1,geouni a unified model for generating geometry diagrams problems and problem solutions,we propose geouni the first unified geometry expert model capable of generating problem solutions and diagrams within a single framework in a way that enables the creation of unique and individualized geometry problems traditionally solving geometry problems and generating diagrams have been treated as separate tasks in machine learning with no models successfully integrating both to support problem creation however we believe that mastery in geometry requires frictionless integration of all of these skills from solving problems to visualizing geometric relationships and finally crafting tailored problems our extensive experiments demonstrate that geouni with only b parameters achieves performance comparable to larger models such as deepseek r with b parameters in geometric reasoning tasks geouni also excels in generating precise geometric diagrams surpassing both text to image models and unified models including the gpt o image generation most importantly geouni is the only model capable of successfully generating textual problems with matching diagrams based on specific knowledge points thus offering a wider range of capabilities that extend beyond current models,"['geouni', 'a', 'unified', 'model', 'for', 'generating', 'geometry', 'diagrams', 'problems', 'and', 'problem', 'solutions']","['we', 'propose', 'geouni', 'the', 'first', 'unified', 'geometry', 'expert', 'model', 'capable', 'of', 'generating', 'problem', 'solutions', 'and', 'diagrams', 'within', 'a', 'single', 'framework', 'in', 'a', 'way', 'that', 'enables', 'the', 'creation', 'of', 'unique', 'and', 'individualized', 'geometry', 'problems', 'traditionally', 'solving', 'geometry', 'problems', 'and', 'generating', 'diagrams', 'have', 'been', 'treated', 'as', 'separate', 'tasks', 'in', 'machine', 'learning', 'with', 'no', 'models', 'successfully', 'integrating', 'both', 'to', 'support', 'problem', 'creation', 'however', 'we', 'believe', 'that', 'mastery', 'in', 'geometry', 'requires', 'frictionless', 'integration', 'of', 'all', 'of', 'these', 'skills', 'from', 'solving', 'problems', 'to', 'visualizing', 'geometric', 'relationships', 'and', 'finally', 'crafting', 'tailored', 'problems', 'our', 'extensive', 'experiments', 'demonstrate', 'that', 'geouni', 'with', 'only', 'b', 'parameters', 'achieves', 'performance', 'comparable', 'to', 'larger', 'models', 'such', 'as', 'deepseek', 'r', 'with', 'b', 'parameters', 'in', 'geometric', 'reasoning', 'tasks', 'geouni', 'also', 'excels', 'in', 'generating', 'precise', 'geometric', 'diagrams', 'surpassing', 'both', 'text', 'to', 'image', 'models', 'and', 'unified', 'models', 'including', 'the', 'gpt', 'o', 'image', 'generation', 'most', 'importantly', 'geouni', 'is', 'the', 'only', 'model', 'capable', 'of', 'successfully', 'generating', 'textual', 'problems', 'with', 'matching', 'diagrams', 'based', 'on', 'specific', 'knowledge', 'points', 'thus', 'offering', 'a', 'wider', 'range', 'of', 'capabilities', 'that', 'extend', 'beyond', 'current', 'models']",12,169,"['Most', 'DeepSeek', 'However', 'GeoUni', 'Traditionally', 'Our', '671B', 'GPT-4o']"
2504.10127v2,Breaking the Data Barrier -- Building GUI Agents Through Task   Generalization,"Graphical User Interface (GUI) agents offer cross-platform solutions for automating complex digital tasks, with significant potential to transform productivity workflows. However, their performance is often constrained by the scarcity of high-quality trajectory data. To address this limitation, we propose training Vision Language Models (VLMs) on data-rich, reasoning-intensive tasks during a dedicated mid-training stage, and then examine how incorporating these tasks facilitates generalization to GUI planning scenarios. Specifically, we explore a range of tasks with readily available instruction-tuning data, including GUI perception, multimodal reasoning, and textual reasoning. Through extensive experiments across 11 mid-training tasks, we demonstrate that: (1) Task generalization proves highly effective, yielding substantial improvements across most settings. For instance, multimodal mathematical reasoning enhances performance on AndroidWorld by an absolute 6.3%. Remarkably, text-only mathematical data significantly boosts GUI web agent performance, achieving a 5.6% improvement on WebArena and 5.4% improvement on AndroidWorld, underscoring notable cross-modal generalization from text-based to visual domains; (2) Contrary to prior assumptions, GUI perception data - previously considered closely aligned with GUI agent tasks and widely utilized for training - has a comparatively limited impact on final performance; (3) Building on these insights, we identify the most effective mid-training tasks and curate optimized mixture datasets, resulting in absolute performance gains of 8.0% on WebArena and 12.2% on AndroidWorld. Our work provides valuable insights into cross-domain knowledge transfer for GUI agents and offers a practical approach to addressing data scarcity challenges in this emerging field. The code, data and models will be available at https://github.com/hkust-nlp/GUIMid.","Junlei Zhang, Zichen Ding, Chang Ma, Zijie Chen, Qiushi Sun, Zhenzhong Lan, Junxian He","cs.AI, cs.CL, cs.CV",2025-04-14T11:35:02Z,http://arxiv.org/abs/2504.10127v2,breaking the data barrier building gui agents through task generalization,graphical user interface gui agents offer cross platform solutions for automating complex digital tasks with significant potential to transform productivity workflows however their performance is often constrained by the scarcity of high quality trajectory data to address this limitation we propose training vision language models vlms on data rich reasoning intensive tasks during a dedicated mid training stage and then examine how incorporating these tasks facilitates generalization to gui planning scenarios specifically we explore a range of tasks with readily available instruction tuning data including gui perception multimodal reasoning and textual reasoning through extensive experiments across mid training tasks we demonstrate that task generalization proves highly effective yielding substantial improvements across most settings for instance multimodal mathematical reasoning enhances performance on androidworld by an absolute remarkably text only mathematical data significantly boosts gui web agent performance achieving a improvement on webarena and improvement on androidworld underscoring notable cross modal generalization from text based to visual domains contrary to prior assumptions gui perception data previously considered closely aligned with gui agent tasks and widely utilized for training has a comparatively limited impact on final performance building on these insights we identify the most effective mid training tasks and curate optimized mixture datasets resulting in absolute performance gains of on webarena and on androidworld our work provides valuable insights into cross domain knowledge transfer for gui agents and offers a practical approach to addressing data scarcity challenges in this emerging field the code data and models will be available at,"['breaking', 'the', 'data', 'barrier', 'building', 'gui', 'agents', 'through', 'task', 'generalization']","['graphical', 'user', 'interface', 'gui', 'agents', 'offer', 'cross', 'platform', 'solutions', 'for', 'automating', 'complex', 'digital', 'tasks', 'with', 'significant', 'potential', 'to', 'transform', 'productivity', 'workflows', 'however', 'their', 'performance', 'is', 'often', 'constrained', 'by', 'the', 'scarcity', 'of', 'high', 'quality', 'trajectory', 'data', 'to', 'address', 'this', 'limitation', 'we', 'propose', 'training', 'vision', 'language', 'models', 'vlms', 'on', 'data', 'rich', 'reasoning', 'intensive', 'tasks', 'during', 'a', 'dedicated', 'mid', 'training', 'stage', 'and', 'then', 'examine', 'how', 'incorporating', 'these', 'tasks', 'facilitates', 'generalization', 'to', 'gui', 'planning', 'scenarios', 'specifically', 'we', 'explore', 'a', 'range', 'of', 'tasks', 'with', 'readily', 'available', 'instruction', 'tuning', 'data', 'including', 'gui', 'perception', 'multimodal', 'reasoning', 'and', 'textual', 'reasoning', 'through', 'extensive', 'experiments', 'across', 'mid', 'training', 'tasks', 'we', 'demonstrate', 'that', 'task', 'generalization', 'proves', 'highly', 'effective', 'yielding', 'substantial', 'improvements', 'across', 'most', 'settings', 'for', 'instance', 'multimodal', 'mathematical', 'reasoning', 'enhances', 'performance', 'on', 'androidworld', 'by', 'an', 'absolute', 'remarkably', 'text', 'only', 'mathematical', 'data', 'significantly', 'boosts', 'gui', 'web', 'agent', 'performance', 'achieving', 'a', 'improvement', 'on', 'webarena', 'and', 'improvement', 'on', 'androidworld', 'underscoring', 'notable', 'cross', 'modal', 'generalization', 'from', 'text', 'based', 'to', 'visual', 'domains', 'contrary', 'to', 'prior', 'assumptions', 'gui', 'perception', 'data', 'previously', 'considered', 'closely', 'aligned', 'with', 'gui', 'agent', 'tasks', 'and', 'widely', 'utilized', 'for', 'training', 'has', 'a', 'comparatively', 'limited', 'impact', 'on', 'final', 'performance', 'building', 'on', 'these', 'insights', 'we', 'identify', 'the', 'most', 'effective', 'mid', 'training', 'tasks', 'and', 'curate', 'optimized', 'mixture', 'datasets', 'resulting', 'in', 'absolute', 'performance', 'gains', 'of', 'on', 'webarena', 'and', 'on', 'androidworld', 'our', 'work', 'provides', 'valuable', 'insights', 'into', 'cross', 'domain', 'knowledge', 'transfer', 'for', 'gui', 'agents', 'and', 'offers', 'a', 'practical', 'approach', 'to', 'addressing', 'data', 'scarcity', 'challenges', 'in', 'this', 'emerging', 'field', 'the', 'code', 'data', 'and', 'models', 'will', 'be', 'available', 'at']",10,248,"['Specifically', 'Language', 'Our', 'Through', 'Interface', 'GUIMid', 'However', 'WebArena', 'User', 'Building', 'VLMs', 'GUI', 'Contrary', 'Task', 'Graphical', 'Models', 'Remarkably', 'Vision', 'AndroidWorld']"
2504.10106v1,SoccerNet-v3D: Leveraging Sports Broadcast Replays for 3D Scene   Understanding,"Sports video analysis is a key domain in computer vision, enabling detailed spatial understanding through multi-view correspondences. In this work, we introduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasets designed for 3D scene understanding in soccer broadcast analysis. These datasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based camera calibration and multi-view synchronization, enabling 3D object localization through triangulation. We propose a monocular 3D ball localization task built upon the triangulation of ground-truth 2D ball annotations, along with several calibration and reprojection metrics to assess annotation quality on demand. Additionally, we present a single-image 3D ball localization method as a baseline, leveraging camera calibration and ball size priors to estimate the ball's position from a monocular viewpoint. To further refine 2D annotations, we introduce a bounding box optimization technique that ensures alignment with the 3D scene representation. Our proposed datasets establish new benchmarks for 3D soccer scene understanding, enhancing both spatial and temporal analysis in sports analytics. Finally, we provide code to facilitate access to our annotations and the generation pipelines for the datasets.","Marc Guti√©rrez-P√©rez, Antonio Agudo","cs.CV, cs.AI, I.2; I.4; I.5",2025-04-14T11:15:13Z,http://arxiv.org/abs/2504.10106v1,soccernet v d leveraging sports broadcast replays for d scene understanding,sports video analysis is a key domain in computer vision enabling detailed spatial understanding through multi view correspondences in this work we introduce soccernet v d and issia d two enhanced and scalable datasets designed for d scene understanding in soccer broadcast analysis these datasets extend soccernet v and issia by incorporating field line based camera calibration and multi view synchronization enabling d object localization through triangulation we propose a monocular d ball localization task built upon the triangulation of ground truth d ball annotations along with several calibration and reprojection metrics to assess annotation quality on demand additionally we present a single image d ball localization method as a baseline leveraging camera calibration and ball size priors to estimate the ball s position from a monocular viewpoint to further refine d annotations we introduce a bounding box optimization technique that ensures alignment with the d scene representation our proposed datasets establish new benchmarks for d soccer scene understanding enhancing both spatial and temporal analysis in sports analytics finally we provide code to facilitate access to our annotations and the generation pipelines for the datasets,"['soccernet', 'v', 'd', 'leveraging', 'sports', 'broadcast', 'replays', 'for', 'd', 'scene', 'understanding']","['sports', 'video', 'analysis', 'is', 'a', 'key', 'domain', 'in', 'computer', 'vision', 'enabling', 'detailed', 'spatial', 'understanding', 'through', 'multi', 'view', 'correspondences', 'in', 'this', 'work', 'we', 'introduce', 'soccernet', 'v', 'd', 'and', 'issia', 'd', 'two', 'enhanced', 'and', 'scalable', 'datasets', 'designed', 'for', 'd', 'scene', 'understanding', 'in', 'soccer', 'broadcast', 'analysis', 'these', 'datasets', 'extend', 'soccernet', 'v', 'and', 'issia', 'by', 'incorporating', 'field', 'line', 'based', 'camera', 'calibration', 'and', 'multi', 'view', 'synchronization', 'enabling', 'd', 'object', 'localization', 'through', 'triangulation', 'we', 'propose', 'a', 'monocular', 'd', 'ball', 'localization', 'task', 'built', 'upon', 'the', 'triangulation', 'of', 'ground', 'truth', 'd', 'ball', 'annotations', 'along', 'with', 'several', 'calibration', 'and', 'reprojection', 'metrics', 'to', 'assess', 'annotation', 'quality', 'on', 'demand', 'additionally', 'we', 'present', 'a', 'single', 'image', 'd', 'ball', 'localization', 'method', 'as', 'a', 'baseline', 'leveraging', 'camera', 'calibration', 'and', 'ball', 'size', 'priors', 'to', 'estimate', 'the', 'ball', 's', 'position', 'from', 'a', 'monocular', 'viewpoint', 'to', 'further', 'refine', 'd', 'annotations', 'we', 'introduce', 'a', 'bounding', 'box', 'optimization', 'technique', 'that', 'ensures', 'alignment', 'with', 'the', 'd', 'scene', 'representation', 'our', 'proposed', 'datasets', 'establish', 'new', 'benchmarks', 'for', 'd', 'soccer', 'scene', 'understanding', 'enhancing', 'both', 'spatial', 'and', 'temporal', 'analysis', 'in', 'sports', 'analytics', 'finally', 'we', 'provide', 'code', 'to', 'facilitate', 'access', 'to', 'our', 'annotations', 'and', 'the', 'generation', 'pipelines', 'for', 'the', 'datasets']",11,185,"['Finally', 'These', 'Sports', 'ISSIA-3D', 'SoccerNet', 'ISSIA', 'Our', 'Additionally']"
2504.10081v1,RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning   Capability,"Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have been rapidly progressing and achieving breakthrough performance on complex reasoning tasks such as mathematics and coding. However, the open-source R1 models have raised safety concerns in wide applications, such as the tendency to comply with malicious queries, which greatly impacts the utility of these powerful models in their applications. In this paper, we introduce RealSafe-R1 as safety-aligned versions of DeepSeek-R1 distilled models. To train these models, we construct a dataset of 15k safety-aware reasoning trajectories generated by DeepSeek-R1, under explicit instructions for expected refusal behavior. Both quantitative experiments and qualitative case studies demonstrate the models' improvements, which are shown in their safety guardrails against both harmful queries and jailbreak attacks. Importantly, unlike prior safety alignment efforts that often compromise reasoning performance, our method preserves the models' reasoning capabilities by maintaining the training data within the original distribution of generation. Model weights of RealSafe-R1 are open-source at https://huggingface.co/RealSafe.","Yichi Zhang, Zihao Zeng, Dongbai Li, Yao Huang, Zhijie Deng, Yinpeng Dong","cs.AI, cs.CL",2025-04-14T10:26:37Z,http://arxiv.org/abs/2504.10081v1,realsafe r safety aligned deepseek r without compromising reasoning capability,large reasoning models lrms such as openai o and deepseek r have been rapidly progressing and achieving breakthrough performance on complex reasoning tasks such as mathematics and coding however the open source r models have raised safety concerns in wide applications such as the tendency to comply with malicious queries which greatly impacts the utility of these powerful models in their applications in this paper we introduce realsafe r as safety aligned versions of deepseek r distilled models to train these models we construct a dataset of k safety aware reasoning trajectories generated by deepseek r under explicit instructions for expected refusal behavior both quantitative experiments and qualitative case studies demonstrate the models improvements which are shown in their safety guardrails against both harmful queries and jailbreak attacks importantly unlike prior safety alignment efforts that often compromise reasoning performance our method preserves the models reasoning capabilities by maintaining the training data within the original distribution of generation model weights of realsafe r are open source at,"['realsafe', 'r', 'safety', 'aligned', 'deepseek', 'r', 'without', 'compromising', 'reasoning', 'capability']","['large', 'reasoning', 'models', 'lrms', 'such', 'as', 'openai', 'o', 'and', 'deepseek', 'r', 'have', 'been', 'rapidly', 'progressing', 'and', 'achieving', 'breakthrough', 'performance', 'on', 'complex', 'reasoning', 'tasks', 'such', 'as', 'mathematics', 'and', 'coding', 'however', 'the', 'open', 'source', 'r', 'models', 'have', 'raised', 'safety', 'concerns', 'in', 'wide', 'applications', 'such', 'as', 'the', 'tendency', 'to', 'comply', 'with', 'malicious', 'queries', 'which', 'greatly', 'impacts', 'the', 'utility', 'of', 'these', 'powerful', 'models', 'in', 'their', 'applications', 'in', 'this', 'paper', 'we', 'introduce', 'realsafe', 'r', 'as', 'safety', 'aligned', 'versions', 'of', 'deepseek', 'r', 'distilled', 'models', 'to', 'train', 'these', 'models', 'we', 'construct', 'a', 'dataset', 'of', 'k', 'safety', 'aware', 'reasoning', 'trajectories', 'generated', 'by', 'deepseek', 'r', 'under', 'explicit', 'instructions', 'for', 'expected', 'refusal', 'behavior', 'both', 'quantitative', 'experiments', 'and', 'qualitative', 'case', 'studies', 'demonstrate', 'the', 'models', 'improvements', 'which', 'are', 'shown', 'in', 'their', 'safety', 'guardrails', 'against', 'both', 'harmful', 'queries', 'and', 'jailbreak', 'attacks', 'importantly', 'unlike', 'prior', 'safety', 'alignment', 'efforts', 'that', 'often', 'compromise', 'reasoning', 'performance', 'our', 'method', 'preserves', 'the', 'models', 'reasoning', 'capabilities', 'by', 'maintaining', 'the', 'training', 'data', 'within', 'the', 'original', 'distribution', 'of', 'generation', 'model', 'weights', 'of', 'realsafe', 'r', 'are', 'open', 'source', 'at']",10,166,"['Reasoning', 'DeepSeek', 'Both', 'Importantly', 'Model', 'RealSafe', 'LRMs', 'However', 'Models', 'OpenAI', 'Large', '15k']"
2504.10077v1,Towards Quantifying Commonsense Reasoning with Mechanistic Insights,"Commonsense reasoning deals with the implicit knowledge that is well understood by humans and typically acquired via interactions with the world. In recent times, commonsense reasoning and understanding of various LLMs have been evaluated using text-based tasks. In this work, we argue that a proxy of this understanding can be maintained as a graphical structure that can further help to perform a rigorous evaluation of commonsense reasoning abilities about various real-world activities. We create an annotation scheme for capturing this implicit knowledge in the form of a graphical structure for 37 daily human activities. We find that the created resource can be used to frame an enormous number of commonsense queries (~ 10^{17}), facilitating rigorous evaluation of commonsense reasoning in LLMs. Moreover, recently, the remarkable performance of LLMs has raised questions about whether these models are truly capable of reasoning in the wild and, in general, how reasoning occurs inside these models. In this resource paper, we bridge this gap by proposing design mechanisms that facilitate research in a similar direction. Our findings suggest that the reasoning components are localized in LLMs that play a prominent role in decision-making when prompted with a commonsense query.","Abhinav Joshi, Areeb Ahmad, Divyaksh Shukla, Ashutosh Modi","cs.CL, cs.AI, cs.LG",2025-04-14T10:21:59Z,http://arxiv.org/abs/2504.10077v1,towards quantifying commonsense reasoning with mechanistic insights,commonsense reasoning deals with the implicit knowledge that is well understood by humans and typically acquired via interactions with the world in recent times commonsense reasoning and understanding of various llms have been evaluated using text based tasks in this work we argue that a proxy of this understanding can be maintained as a graphical structure that can further help to perform a rigorous evaluation of commonsense reasoning abilities about various real world activities we create an annotation scheme for capturing this implicit knowledge in the form of a graphical structure for daily human activities we find that the created resource can be used to frame an enormous number of commonsense queries facilitating rigorous evaluation of commonsense reasoning in llms moreover recently the remarkable performance of llms has raised questions about whether these models are truly capable of reasoning in the wild and in general how reasoning occurs inside these models in this resource paper we bridge this gap by proposing design mechanisms that facilitate research in a similar direction our findings suggest that the reasoning components are localized in llms that play a prominent role in decision making when prompted with a commonsense query,"['towards', 'quantifying', 'commonsense', 'reasoning', 'with', 'mechanistic', 'insights']","['commonsense', 'reasoning', 'deals', 'with', 'the', 'implicit', 'knowledge', 'that', 'is', 'well', 'understood', 'by', 'humans', 'and', 'typically', 'acquired', 'via', 'interactions', 'with', 'the', 'world', 'in', 'recent', 'times', 'commonsense', 'reasoning', 'and', 'understanding', 'of', 'various', 'llms', 'have', 'been', 'evaluated', 'using', 'text', 'based', 'tasks', 'in', 'this', 'work', 'we', 'argue', 'that', 'a', 'proxy', 'of', 'this', 'understanding', 'can', 'be', 'maintained', 'as', 'a', 'graphical', 'structure', 'that', 'can', 'further', 'help', 'to', 'perform', 'a', 'rigorous', 'evaluation', 'of', 'commonsense', 'reasoning', 'abilities', 'about', 'various', 'real', 'world', 'activities', 'we', 'create', 'an', 'annotation', 'scheme', 'for', 'capturing', 'this', 'implicit', 'knowledge', 'in', 'the', 'form', 'of', 'a', 'graphical', 'structure', 'for', 'daily', 'human', 'activities', 'we', 'find', 'that', 'the', 'created', 'resource', 'can', 'be', 'used', 'to', 'frame', 'an', 'enormous', 'number', 'of', 'commonsense', 'queries', 'facilitating', 'rigorous', 'evaluation', 'of', 'commonsense', 'reasoning', 'in', 'llms', 'moreover', 'recently', 'the', 'remarkable', 'performance', 'of', 'llms', 'has', 'raised', 'questions', 'about', 'whether', 'these', 'models', 'are', 'truly', 'capable', 'of', 'reasoning', 'in', 'the', 'wild', 'and', 'in', 'general', 'how', 'reasoning', 'occurs', 'inside', 'these', 'models', 'in', 'this', 'resource', 'paper', 'we', 'bridge', 'this', 'gap', 'by', 'proposing', 'design', 'mechanisms', 'that', 'facilitate', 'research', 'in', 'a', 'similar', 'direction', 'our', 'findings', 'suggest', 'that', 'the', 'reasoning', 'components', 'are', 'localized', 'in', 'llms', 'that', 'play', 'a', 'prominent', 'role', 'in', 'decision', 'making', 'when', 'prompted', 'with', 'a', 'commonsense', 'query']",7,195,"['Commonsense', 'LLMs', 'Our', 'Moreover']"
2504.10074v2,MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation   Framework,"Recent advancements in large language models (LLMs) and multi-modal LLMs have been remarkable. However, these models still rely solely on their parametric knowledge, which limits their ability to generate up-to-date information and increases the risk of producing erroneous content. Retrieval-Augmented Generation (RAG) partially mitigates these challenges by incorporating external data sources, yet the reliance on databases and retrieval systems can introduce irrelevant or inaccurate documents, ultimately undermining both performance and reasoning quality. In this paper, we propose Multi-Modal Knowledge-Based Retrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework that leverages the inherent knowledge boundaries of models to dynamically generate semantic tags for the retrieval process. This strategy enables the joint filtering of retrieved documents, retaining only the most relevant and accurate references. Extensive experiments on knowledge-based visual question-answering tasks demonstrate the efficacy of our approach: on the E-VQA dataset, our method improves performance by +4.2% on the Single-Hop subset and +0.4% on the full dataset, while on the InfoSeek dataset, it achieves gains of +7.8% on the Unseen-Q subset, +8.2% on the Unseen-E subset, and +8.1% on the full dataset. These results highlight significant enhancements in both accuracy and robustness over the current state-of-the-art MLLM and RAG frameworks.","Zihan Ling, Zhiyao Guo, Yixuan Huang, Yi An, Shuai Xiao, Jinsong Lan, Xiaoyong Zhu, Bo Zheng",cs.AI,2025-04-14T10:19:47Z,http://arxiv.org/abs/2504.10074v2,mmkb rag a multi modal knowledge based retrieval augmented generation framework,recent advancements in large language models llms and multi modal llms have been remarkable however these models still rely solely on their parametric knowledge which limits their ability to generate up to date information and increases the risk of producing erroneous content retrieval augmented generation rag partially mitigates these challenges by incorporating external data sources yet the reliance on databases and retrieval systems can introduce irrelevant or inaccurate documents ultimately undermining both performance and reasoning quality in this paper we propose multi modal knowledge based retrieval augmented generation mmkb rag a novel multi modal rag framework that leverages the inherent knowledge boundaries of models to dynamically generate semantic tags for the retrieval process this strategy enables the joint filtering of retrieved documents retaining only the most relevant and accurate references extensive experiments on knowledge based visual question answering tasks demonstrate the efficacy of our approach on the e vqa dataset our method improves performance by on the single hop subset and on the full dataset while on the infoseek dataset it achieves gains of on the unseen q subset on the unseen e subset and on the full dataset these results highlight significant enhancements in both accuracy and robustness over the current state of the art mllm and rag frameworks,"['mmkb', 'rag', 'a', 'multi', 'modal', 'knowledge', 'based', 'retrieval', 'augmented', 'generation', 'framework']","['recent', 'advancements', 'in', 'large', 'language', 'models', 'llms', 'and', 'multi', 'modal', 'llms', 'have', 'been', 'remarkable', 'however', 'these', 'models', 'still', 'rely', 'solely', 'on', 'their', 'parametric', 'knowledge', 'which', 'limits', 'their', 'ability', 'to', 'generate', 'up', 'to', 'date', 'information', 'and', 'increases', 'the', 'risk', 'of', 'producing', 'erroneous', 'content', 'retrieval', 'augmented', 'generation', 'rag', 'partially', 'mitigates', 'these', 'challenges', 'by', 'incorporating', 'external', 'data', 'sources', 'yet', 'the', 'reliance', 'on', 'databases', 'and', 'retrieval', 'systems', 'can', 'introduce', 'irrelevant', 'or', 'inaccurate', 'documents', 'ultimately', 'undermining', 'both', 'performance', 'and', 'reasoning', 'quality', 'in', 'this', 'paper', 'we', 'propose', 'multi', 'modal', 'knowledge', 'based', 'retrieval', 'augmented', 'generation', 'mmkb', 'rag', 'a', 'novel', 'multi', 'modal', 'rag', 'framework', 'that', 'leverages', 'the', 'inherent', 'knowledge', 'boundaries', 'of', 'models', 'to', 'dynamically', 'generate', 'semantic', 'tags', 'for', 'the', 'retrieval', 'process', 'this', 'strategy', 'enables', 'the', 'joint', 'filtering', 'of', 'retrieved', 'documents', 'retaining', 'only', 'the', 'most', 'relevant', 'and', 'accurate', 'references', 'extensive', 'experiments', 'on', 'knowledge', 'based', 'visual', 'question', 'answering', 'tasks', 'demonstrate', 'the', 'efficacy', 'of', 'our', 'approach', 'on', 'the', 'e', 'vqa', 'dataset', 'our', 'method', 'improves', 'performance', 'by', 'on', 'the', 'single', 'hop', 'subset', 'and', 'on', 'the', 'full', 'dataset', 'while', 'on', 'the', 'infoseek', 'dataset', 'it', 'achieves', 'gains', 'of', 'on', 'the', 'unseen', 'q', 'subset', 'on', 'the', 'unseen', 'e', 'subset', 'and', 'on', 'the', 'full', 'dataset', 'these', 'results', 'highlight', 'significant', 'enhancements', 'in', 'both', 'accuracy', 'and', 'robustness', 'over', 'the', 'current', 'state', 'of', 'the', 'art', 'mllm', 'and', 'rag', 'frameworks']",11,210,"['MMKB-RAG', 'Retrieval', 'Single', 'LLMs', 'However', 'Augmented', 'Modal', 'Hop', 'Generation', 'Recent', 'Multi', 'Based', 'InfoSeek', 'RAG', 'E-VQA', 'Unseen', 'MLLM', 'Extensive', 'These', 'Knowledge']"
2504.10071v1,Pay Attention to What and Where? Interpretable Feature Extractor in   Vision-based Deep Reinforcement Learning,"Current approaches in Explainable Deep Reinforcement Learning have limitations in which the attention mask has a displacement with the objects in visual input. This work addresses a spatial problem within traditional Convolutional Neural Networks (CNNs). We propose the Interpretable Feature Extractor (IFE) architecture, aimed at generating an accurate attention mask to illustrate both ""what"" and ""where"" the agent concentrates on in the spatial domain. Our design incorporates a Human-Understandable Encoding module to generate a fully interpretable attention mask, followed by an Agent-Friendly Encoding module to enhance the agent's learning efficiency. These two components together form the Interpretable Feature Extractor for vision-based deep reinforcement learning to enable the model's interpretability. The resulting attention mask is consistent, highly understandable by humans, accurate in spatial dimension, and effectively highlights important objects or locations in visual input. The Interpretable Feature Extractor is integrated into the Fast and Data-efficient Rainbow framework, and evaluated on 57 ATARI games to show the effectiveness of the proposed approach on Spatial Preservation, Interpretability, and Data-efficiency. Finally, we showcase the versatility of our approach by incorporating the IFE into the Asynchronous Advantage Actor-Critic Model.","Tien Pham, Angelo Cangelosi",cs.AI,2025-04-14T10:18:34Z,http://arxiv.org/abs/2504.10071v1,pay attention to what and where interpretable feature extractor in vision based deep reinforcement learning,current approaches in explainable deep reinforcement learning have limitations in which the attention mask has a displacement with the objects in visual input this work addresses a spatial problem within traditional convolutional neural networks cnns we propose the interpretable feature extractor ife architecture aimed at generating an accurate attention mask to illustrate both what and where the agent concentrates on in the spatial domain our design incorporates a human understandable encoding module to generate a fully interpretable attention mask followed by an agent friendly encoding module to enhance the agent s learning efficiency these two components together form the interpretable feature extractor for vision based deep reinforcement learning to enable the model s interpretability the resulting attention mask is consistent highly understandable by humans accurate in spatial dimension and effectively highlights important objects or locations in visual input the interpretable feature extractor is integrated into the fast and data efficient rainbow framework and evaluated on atari games to show the effectiveness of the proposed approach on spatial preservation interpretability and data efficiency finally we showcase the versatility of our approach by incorporating the ife into the asynchronous advantage actor critic model,"['pay', 'attention', 'to', 'what', 'and', 'where', 'interpretable', 'feature', 'extractor', 'in', 'vision', 'based', 'deep', 'reinforcement', 'learning']","['current', 'approaches', 'in', 'explainable', 'deep', 'reinforcement', 'learning', 'have', 'limitations', 'in', 'which', 'the', 'attention', 'mask', 'has', 'a', 'displacement', 'with', 'the', 'objects', 'in', 'visual', 'input', 'this', 'work', 'addresses', 'a', 'spatial', 'problem', 'within', 'traditional', 'convolutional', 'neural', 'networks', 'cnns', 'we', 'propose', 'the', 'interpretable', 'feature', 'extractor', 'ife', 'architecture', 'aimed', 'at', 'generating', 'an', 'accurate', 'attention', 'mask', 'to', 'illustrate', 'both', 'what', 'and', 'where', 'the', 'agent', 'concentrates', 'on', 'in', 'the', 'spatial', 'domain', 'our', 'design', 'incorporates', 'a', 'human', 'understandable', 'encoding', 'module', 'to', 'generate', 'a', 'fully', 'interpretable', 'attention', 'mask', 'followed', 'by', 'an', 'agent', 'friendly', 'encoding', 'module', 'to', 'enhance', 'the', 'agent', 's', 'learning', 'efficiency', 'these', 'two', 'components', 'together', 'form', 'the', 'interpretable', 'feature', 'extractor', 'for', 'vision', 'based', 'deep', 'reinforcement', 'learning', 'to', 'enable', 'the', 'model', 's', 'interpretability', 'the', 'resulting', 'attention', 'mask', 'is', 'consistent', 'highly', 'understandable', 'by', 'humans', 'accurate', 'in', 'spatial', 'dimension', 'and', 'effectively', 'highlights', 'important', 'objects', 'or', 'locations', 'in', 'visual', 'input', 'the', 'interpretable', 'feature', 'extractor', 'is', 'integrated', 'into', 'the', 'fast', 'and', 'data', 'efficient', 'rainbow', 'framework', 'and', 'evaluated', 'on', 'atari', 'games', 'to', 'show', 'the', 'effectiveness', 'of', 'the', 'proposed', 'approach', 'on', 'spatial', 'preservation', 'interpretability', 'and', 'data', 'efficiency', 'finally', 'we', 'showcase', 'the', 'versatility', 'of', 'our', 'approach', 'by', 'incorporating', 'the', 'ife', 'into', 'the', 'asynchronous', 'advantage', 'actor', 'critic', 'model']",15,191,"['Model', 'Actor', 'Neural', 'Spatial', 'Friendly', 'Extractor', 'Convolutional', 'Understandable', 'Learning', 'Our', 'Reinforcement', 'Data', 'Agent', 'Fast', 'IFE', 'ATARI', 'Rainbow', 'Preservation', 'Finally', 'Feature', 'Explainable', 'Networks', 'Human', 'Current', 'Asynchronous', 'Encoding', 'Critic', 'CNNs', 'These', 'Advantage', 'Interpretable', 'Interpretability', 'Deep']"
2504.10063v1,Hallucination Detection in LLMs via Topological Divergence on Attention   Graphs,"Hallucination, i.e., generating factually incorrect content, remains a critical challenge for large language models (LLMs). We introduce TOHA, a TOpology-based HAllucination detector in the RAG setting, which leverages a topological divergence metric to quantify the structural properties of graphs induced by attention matrices. Examining the topological divergence between prompt and response subgraphs reveals consistent patterns: higher divergence values in specific attention heads correlate with hallucinated outputs, independent of the dataset. Extensive experiments, including evaluation on question answering and data-to-text tasks, show that our approach achieves state-of-the-art or competitive results on several benchmarks, two of which were annotated by us and are being publicly released to facilitate further research. Beyond its strong in-domain performance, TOHA maintains remarkable domain transferability across multiple open-source LLMs. Our findings suggest that analyzing the topological structure of attention matrices can serve as an efficient and robust indicator of factual reliability in LLMs.","Alexandra Bazarova, Aleksandr Yugay, Andrey Shulga, Alina Ermilova, Andrei Volodichev, Konstantin Polev, Julia Belikova, Rauf Parchiev, Dmitry Simakov, Maxim Savchenko, Andrey Savchenko, Serguei Barannikov, Alexey Zaytsev","cs.CL, cs.AI",2025-04-14T10:06:27Z,http://arxiv.org/abs/2504.10063v1,hallucination detection in llms via topological divergence on attention graphs,hallucination i e generating factually incorrect content remains a critical challenge for large language models llms we introduce toha a topology based hallucination detector in the rag setting which leverages a topological divergence metric to quantify the structural properties of graphs induced by attention matrices examining the topological divergence between prompt and response subgraphs reveals consistent patterns higher divergence values in specific attention heads correlate with hallucinated outputs independent of the dataset extensive experiments including evaluation on question answering and data to text tasks show that our approach achieves state of the art or competitive results on several benchmarks two of which were annotated by us and are being publicly released to facilitate further research beyond its strong in domain performance toha maintains remarkable domain transferability across multiple open source llms our findings suggest that analyzing the topological structure of attention matrices can serve as an efficient and robust indicator of factual reliability in llms,"['hallucination', 'detection', 'in', 'llms', 'via', 'topological', 'divergence', 'on', 'attention', 'graphs']","['hallucination', 'i', 'e', 'generating', 'factually', 'incorrect', 'content', 'remains', 'a', 'critical', 'challenge', 'for', 'large', 'language', 'models', 'llms', 'we', 'introduce', 'toha', 'a', 'topology', 'based', 'hallucination', 'detector', 'in', 'the', 'rag', 'setting', 'which', 'leverages', 'a', 'topological', 'divergence', 'metric', 'to', 'quantify', 'the', 'structural', 'properties', 'of', 'graphs', 'induced', 'by', 'attention', 'matrices', 'examining', 'the', 'topological', 'divergence', 'between', 'prompt', 'and', 'response', 'subgraphs', 'reveals', 'consistent', 'patterns', 'higher', 'divergence', 'values', 'in', 'specific', 'attention', 'heads', 'correlate', 'with', 'hallucinated', 'outputs', 'independent', 'of', 'the', 'dataset', 'extensive', 'experiments', 'including', 'evaluation', 'on', 'question', 'answering', 'and', 'data', 'to', 'text', 'tasks', 'show', 'that', 'our', 'approach', 'achieves', 'state', 'of', 'the', 'art', 'or', 'competitive', 'results', 'on', 'several', 'benchmarks', 'two', 'of', 'which', 'were', 'annotated', 'by', 'us', 'and', 'are', 'being', 'publicly', 'released', 'to', 'facilitate', 'further', 'research', 'beyond', 'its', 'strong', 'in', 'domain', 'performance', 'toha', 'maintains', 'remarkable', 'domain', 'transferability', 'across', 'multiple', 'open', 'source', 'llms', 'our', 'findings', 'suggest', 'that', 'analyzing', 'the', 'topological', 'structure', 'of', 'attention', 'matrices', 'can', 'serve', 'as', 'an', 'efficient', 'and', 'robust', 'indicator', 'of', 'factual', 'reliability', 'in', 'llms']",10,155,"['Extensive', 'HAllucination', 'Beyond', 'RAG', 'LLMs', 'TOHA', 'Examining', 'Our', 'Hallucination', 'TOpology']"
2504.10018v1,RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset   and An Asymmetric RWKV Fusion Framework,"Existing pedestrian attribute recognition methods are generally developed based on RGB frame cameras. However, these approaches are constrained by the limitations of RGB cameras, such as sensitivity to lighting conditions and motion blur, which hinder their performance. Furthermore, current attribute recognition primarily focuses on analyzing pedestrians' external appearance and clothing, lacking an exploration of emotional dimensions. In this paper, we revisit these issues and propose a novel multi-modal RGB-Event attribute recognition task by drawing inspiration from the advantages of event cameras in low-light, high-speed, and low-power consumption. Specifically, we introduce the first large-scale multi-modal pedestrian attribute recognition dataset, termed EventPAR, comprising 100K paired RGB-Event samples that cover 50 attributes related to both appearance and six human emotions, diverse scenes, and various seasons. By retraining and evaluating mainstream PAR models on this dataset, we establish a comprehensive benchmark and provide a solid foundation for future research in terms of data and algorithmic baselines. In addition, we propose a novel RWKV-based multi-modal pedestrian attribute recognition framework, featuring an RWKV visual encoder and an asymmetric RWKV fusion module. Extensive experiments are conducted on our proposed dataset as well as two simulated datasets (MARS-Attribute and DukeMTMC-VID-Attribute), achieving state-of-the-art results. The source code and dataset will be released on https://github.com/Event-AHU/OpenPAR","Xiao Wang, Haiyang Wang, Shiao Wang, Qiang Chen, Jiandong Jin, Haoyu Song, Bo Jiang, Chenglong Li","cs.CV, cs.AI",2025-04-14T09:22:16Z,http://arxiv.org/abs/2504.10018v1,rgb event based pedestrian attribute recognition a benchmark dataset and an asymmetric rwkv fusion framework,existing pedestrian attribute recognition methods are generally developed based on rgb frame cameras however these approaches are constrained by the limitations of rgb cameras such as sensitivity to lighting conditions and motion blur which hinder their performance furthermore current attribute recognition primarily focuses on analyzing pedestrians external appearance and clothing lacking an exploration of emotional dimensions in this paper we revisit these issues and propose a novel multi modal rgb event attribute recognition task by drawing inspiration from the advantages of event cameras in low light high speed and low power consumption specifically we introduce the first large scale multi modal pedestrian attribute recognition dataset termed eventpar comprising k paired rgb event samples that cover attributes related to both appearance and six human emotions diverse scenes and various seasons by retraining and evaluating mainstream par models on this dataset we establish a comprehensive benchmark and provide a solid foundation for future research in terms of data and algorithmic baselines in addition we propose a novel rwkv based multi modal pedestrian attribute recognition framework featuring an rwkv visual encoder and an asymmetric rwkv fusion module extensive experiments are conducted on our proposed dataset as well as two simulated datasets mars attribute and dukemtmc vid attribute achieving state of the art results the source code and dataset will be released on,"['rgb', 'event', 'based', 'pedestrian', 'attribute', 'recognition', 'a', 'benchmark', 'dataset', 'and', 'an', 'asymmetric', 'rwkv', 'fusion', 'framework']","['existing', 'pedestrian', 'attribute', 'recognition', 'methods', 'are', 'generally', 'developed', 'based', 'on', 'rgb', 'frame', 'cameras', 'however', 'these', 'approaches', 'are', 'constrained', 'by', 'the', 'limitations', 'of', 'rgb', 'cameras', 'such', 'as', 'sensitivity', 'to', 'lighting', 'conditions', 'and', 'motion', 'blur', 'which', 'hinder', 'their', 'performance', 'furthermore', 'current', 'attribute', 'recognition', 'primarily', 'focuses', 'on', 'analyzing', 'pedestrians', 'external', 'appearance', 'and', 'clothing', 'lacking', 'an', 'exploration', 'of', 'emotional', 'dimensions', 'in', 'this', 'paper', 'we', 'revisit', 'these', 'issues', 'and', 'propose', 'a', 'novel', 'multi', 'modal', 'rgb', 'event', 'attribute', 'recognition', 'task', 'by', 'drawing', 'inspiration', 'from', 'the', 'advantages', 'of', 'event', 'cameras', 'in', 'low', 'light', 'high', 'speed', 'and', 'low', 'power', 'consumption', 'specifically', 'we', 'introduce', 'the', 'first', 'large', 'scale', 'multi', 'modal', 'pedestrian', 'attribute', 'recognition', 'dataset', 'termed', 'eventpar', 'comprising', 'k', 'paired', 'rgb', 'event', 'samples', 'that', 'cover', 'attributes', 'related', 'to', 'both', 'appearance', 'and', 'six', 'human', 'emotions', 'diverse', 'scenes', 'and', 'various', 'seasons', 'by', 'retraining', 'and', 'evaluating', 'mainstream', 'par', 'models', 'on', 'this', 'dataset', 'we', 'establish', 'a', 'comprehensive', 'benchmark', 'and', 'provide', 'a', 'solid', 'foundation', 'for', 'future', 'research', 'in', 'terms', 'of', 'data', 'and', 'algorithmic', 'baselines', 'in', 'addition', 'we', 'propose', 'a', 'novel', 'rwkv', 'based', 'multi', 'modal', 'pedestrian', 'attribute', 'recognition', 'framework', 'featuring', 'an', 'rwkv', 'visual', 'encoder', 'and', 'an', 'asymmetric', 'rwkv', 'fusion', 'module', 'extensive', 'experiments', 'are', 'conducted', 'on', 'our', 'proposed', 'dataset', 'as', 'well', 'as', 'two', 'simulated', 'datasets', 'mars', 'attribute', 'and', 'dukemtmc', 'vid', 'attribute', 'achieving', 'state', 'of', 'the', 'art', 'results', 'the', 'source', 'code', 'and', 'dataset', 'will', 'be', 'released', 'on']",15,219,"['Extensive', 'EventPAR', 'RGB', 'RWKV-based', 'Existing', 'RWKV', '100K', 'MARS-Attribute', 'RGB-Event', 'OpenPAR', 'However', 'Furthermore', 'Specifically', 'PAR', 'VID-Attribute', 'DukeMTMC', 'Event', 'AHU']"
2504.10552v1,LEMUR Neural Network Dataset: Towards Seamless AutoML,"Neural networks are fundamental in artificial intelligence, driving progress in computer vision and natural language processing. High-quality datasets are crucial for their development, and there is growing interest in datasets composed of neural networks themselves to support benchmarking, automated machine learning (AutoML), and model analysis. We introduce LEMUR, an open source dataset of neural network models with well-structured code for diverse architectures across tasks such as object detection, image classification, segmentation, and natural language processing. LEMUR is primarily designed to enable fine-tuning of large language models (LLMs) for AutoML tasks, providing a rich source of structured model representations and associated performance data. Leveraging Python and PyTorch, LEMUR enables seamless extension to new datasets and models while maintaining consistency. It integrates an Optuna-powered framework for evaluation, hyperparameter optimization, statistical analysis, and graphical insights. LEMUR provides an extension that enables models to run efficiently on edge devices, facilitating deployment in resource-constrained environments. Providing tools for model evaluation, preprocessing, and database management, LEMUR supports researchers and practitioners in developing, testing, and analyzing neural networks. Additionally, it offers an API that delivers comprehensive information about neural network models and their complete performance statistics with a single request, which can be used in experiments with code-generating large language models. The LEMUR will be released as an open source project under the MIT license upon acceptance of the paper.","Arash Torabi Goodarzi, Roman Kochnev, Waleed Khalid, Furui Qin, Tolgay Atinc Uzun, Yashkumar Sanjaybhai Dhameliya, Yash Kanubhai Kathiriya, Zofia Antonina Bentyn, Dmitry Ignatov, Radu Timofte","cs.LG, cs.AI, cs.CV, cs.DL",2025-04-14T09:08:00Z,http://arxiv.org/abs/2504.10552v1,lemur neural network dataset towards seamless automl,neural networks are fundamental in artificial intelligence driving progress in computer vision and natural language processing high quality datasets are crucial for their development and there is growing interest in datasets composed of neural networks themselves to support benchmarking automated machine learning automl and model analysis we introduce lemur an open source dataset of neural network models with well structured code for diverse architectures across tasks such as object detection image classification segmentation and natural language processing lemur is primarily designed to enable fine tuning of large language models llms for automl tasks providing a rich source of structured model representations and associated performance data leveraging python and pytorch lemur enables seamless extension to new datasets and models while maintaining consistency it integrates an optuna powered framework for evaluation hyperparameter optimization statistical analysis and graphical insights lemur provides an extension that enables models to run efficiently on edge devices facilitating deployment in resource constrained environments providing tools for model evaluation preprocessing and database management lemur supports researchers and practitioners in developing testing and analyzing neural networks additionally it offers an api that delivers comprehensive information about neural network models and their complete performance statistics with a single request which can be used in experiments with code generating large language models the lemur will be released as an open source project under the mit license upon acceptance of the paper,"['lemur', 'neural', 'network', 'dataset', 'towards', 'seamless', 'automl']","['neural', 'networks', 'are', 'fundamental', 'in', 'artificial', 'intelligence', 'driving', 'progress', 'in', 'computer', 'vision', 'and', 'natural', 'language', 'processing', 'high', 'quality', 'datasets', 'are', 'crucial', 'for', 'their', 'development', 'and', 'there', 'is', 'growing', 'interest', 'in', 'datasets', 'composed', 'of', 'neural', 'networks', 'themselves', 'to', 'support', 'benchmarking', 'automated', 'machine', 'learning', 'automl', 'and', 'model', 'analysis', 'we', 'introduce', 'lemur', 'an', 'open', 'source', 'dataset', 'of', 'neural', 'network', 'models', 'with', 'well', 'structured', 'code', 'for', 'diverse', 'architectures', 'across', 'tasks', 'such', 'as', 'object', 'detection', 'image', 'classification', 'segmentation', 'and', 'natural', 'language', 'processing', 'lemur', 'is', 'primarily', 'designed', 'to', 'enable', 'fine', 'tuning', 'of', 'large', 'language', 'models', 'llms', 'for', 'automl', 'tasks', 'providing', 'a', 'rich', 'source', 'of', 'structured', 'model', 'representations', 'and', 'associated', 'performance', 'data', 'leveraging', 'python', 'and', 'pytorch', 'lemur', 'enables', 'seamless', 'extension', 'to', 'new', 'datasets', 'and', 'models', 'while', 'maintaining', 'consistency', 'it', 'integrates', 'an', 'optuna', 'powered', 'framework', 'for', 'evaluation', 'hyperparameter', 'optimization', 'statistical', 'analysis', 'and', 'graphical', 'insights', 'lemur', 'provides', 'an', 'extension', 'that', 'enables', 'models', 'to', 'run', 'efficiently', 'on', 'edge', 'devices', 'facilitating', 'deployment', 'in', 'resource', 'constrained', 'environments', 'providing', 'tools', 'for', 'model', 'evaluation', 'preprocessing', 'and', 'database', 'management', 'lemur', 'supports', 'researchers', 'and', 'practitioners', 'in', 'developing', 'testing', 'and', 'analyzing', 'neural', 'networks', 'additionally', 'it', 'offers', 'an', 'api', 'that', 'delivers', 'comprehensive', 'information', 'about', 'neural', 'network', 'models', 'and', 'their', 'complete', 'performance', 'statistics', 'with', 'a', 'single', 'request', 'which', 'can', 'be', 'used', 'in', 'experiments', 'with', 'code', 'generating', 'large', 'language', 'models', 'the', 'lemur', 'will', 'be', 'released', 'as', 'an', 'open', 'source', 'project', 'under', 'the', 'mit', 'license', 'upon', 'acceptance', 'of', 'the', 'paper']",7,229,"['Optuna', 'Leveraging', 'API', 'LLMs', 'High', 'Neural', 'Providing', 'PyTorch', 'Python', 'MIT', 'LEMUR', 'AutoML', 'Additionally']"
2504.10000v1,Do We Really Need Curated Malicious Data for Safety Alignment in   Multi-modal Large Language Models?,"Multi-modal large language models (MLLMs) have made significant progress, yet their safety alignment remains limited. Typically, current open-source MLLMs rely on the alignment inherited from their language module to avoid harmful generations. However, the lack of safety measures specifically designed for multi-modal inputs creates an alignment gap, leaving MLLMs vulnerable to vision-domain attacks such as typographic manipulation. Current methods utilize a carefully designed safety dataset to enhance model defense capability, while the specific knowledge or patterns acquired from the high-quality dataset remain unclear. Through comparison experiments, we find that the alignment gap primarily arises from data distribution biases, while image content, response quality, or the contrastive behavior of the dataset makes little contribution to boosting multi-modal safety. To further investigate this and identify the key factors in improving MLLM safety, we propose finetuning MLLMs on a small set of benign instruct-following data with responses replaced by simple, clear rejection sentences. Experiments show that, without the need for labor-intensive collection of high-quality malicious data, model safety can still be significantly improved, as long as a specific fraction of rejection data exists in the finetuning set, indicating the security alignment is not lost but rather obscured during multi-modal pretraining or instruction finetuning. Simply correcting the underlying data bias could narrow the safety gap in the vision domain.","Yanbo Wang, Jiyang Guan, Jian Liang, Ran He","cs.CR, cs.AI, cs.CL, cs.CV, cs.LG",2025-04-14T09:03:51Z,http://arxiv.org/abs/2504.10000v1,do we really need curated malicious data for safety alignment in multi modal large language models,multi modal large language models mllms have made significant progress yet their safety alignment remains limited typically current open source mllms rely on the alignment inherited from their language module to avoid harmful generations however the lack of safety measures specifically designed for multi modal inputs creates an alignment gap leaving mllms vulnerable to vision domain attacks such as typographic manipulation current methods utilize a carefully designed safety dataset to enhance model defense capability while the specific knowledge or patterns acquired from the high quality dataset remain unclear through comparison experiments we find that the alignment gap primarily arises from data distribution biases while image content response quality or the contrastive behavior of the dataset makes little contribution to boosting multi modal safety to further investigate this and identify the key factors in improving mllm safety we propose finetuning mllms on a small set of benign instruct following data with responses replaced by simple clear rejection sentences experiments show that without the need for labor intensive collection of high quality malicious data model safety can still be significantly improved as long as a specific fraction of rejection data exists in the finetuning set indicating the security alignment is not lost but rather obscured during multi modal pretraining or instruction finetuning simply correcting the underlying data bias could narrow the safety gap in the vision domain,"['do', 'we', 'really', 'need', 'curated', 'malicious', 'data', 'for', 'safety', 'alignment', 'in', 'multi', 'modal', 'large', 'language', 'models']","['multi', 'modal', 'large', 'language', 'models', 'mllms', 'have', 'made', 'significant', 'progress', 'yet', 'their', 'safety', 'alignment', 'remains', 'limited', 'typically', 'current', 'open', 'source', 'mllms', 'rely', 'on', 'the', 'alignment', 'inherited', 'from', 'their', 'language', 'module', 'to', 'avoid', 'harmful', 'generations', 'however', 'the', 'lack', 'of', 'safety', 'measures', 'specifically', 'designed', 'for', 'multi', 'modal', 'inputs', 'creates', 'an', 'alignment', 'gap', 'leaving', 'mllms', 'vulnerable', 'to', 'vision', 'domain', 'attacks', 'such', 'as', 'typographic', 'manipulation', 'current', 'methods', 'utilize', 'a', 'carefully', 'designed', 'safety', 'dataset', 'to', 'enhance', 'model', 'defense', 'capability', 'while', 'the', 'specific', 'knowledge', 'or', 'patterns', 'acquired', 'from', 'the', 'high', 'quality', 'dataset', 'remain', 'unclear', 'through', 'comparison', 'experiments', 'we', 'find', 'that', 'the', 'alignment', 'gap', 'primarily', 'arises', 'from', 'data', 'distribution', 'biases', 'while', 'image', 'content', 'response', 'quality', 'or', 'the', 'contrastive', 'behavior', 'of', 'the', 'dataset', 'makes', 'little', 'contribution', 'to', 'boosting', 'multi', 'modal', 'safety', 'to', 'further', 'investigate', 'this', 'and', 'identify', 'the', 'key', 'factors', 'in', 'improving', 'mllm', 'safety', 'we', 'propose', 'finetuning', 'mllms', 'on', 'a', 'small', 'set', 'of', 'benign', 'instruct', 'following', 'data', 'with', 'responses', 'replaced', 'by', 'simple', 'clear', 'rejection', 'sentences', 'experiments', 'show', 'that', 'without', 'the', 'need', 'for', 'labor', 'intensive', 'collection', 'of', 'high', 'quality', 'malicious', 'data', 'model', 'safety', 'can', 'still', 'be', 'significantly', 'improved', 'as', 'long', 'as', 'a', 'specific', 'fraction', 'of', 'rejection', 'data', 'exists', 'in', 'the', 'finetuning', 'set', 'indicating', 'the', 'security', 'alignment', 'is', 'not', 'lost', 'but', 'rather', 'obscured', 'during', 'multi', 'modal', 'pretraining', 'or', 'instruction', 'finetuning', 'simply', 'correcting', 'the', 'underlying', 'data', 'bias', 'could', 'narrow', 'the', 'safety', 'gap', 'in', 'the', 'vision', 'domain']",16,225,"['Simply', 'Multi', 'Typically', 'However', 'MLLMs', 'Current', 'MLLM', 'Experiments', 'Through']"
2504.09998v1,Metric-Guided Synthesis of Class Activation Mapping,"Class activation mapping (CAM) is a widely adopted class of saliency methods used to explain the behavior of convolutional neural networks (CNNs). These methods generate heatmaps that highlight the parts of the input most relevant to the CNN output. Various CAM methods have been proposed, each distinguished by the expressions used to derive heatmaps. In general, users look for heatmaps with specific properties that reflect different aspects of CNN functionality. These may include similarity to ground truth, robustness, equivariance, and more. Although existing CAM methods implicitly encode some of these properties in their expressions, they do not allow for variability in heatmap generation following the user's intent or domain knowledge. In this paper, we address this limitation by introducing SyCAM, a metric-based approach for synthesizing CAM expressions. Given a predefined evaluation metric for saliency maps, SyCAM automatically generates CAM expressions optimized for that metric. We specifically explore a syntax-guided synthesis instantiation of SyCAM, where CAM expressions are derived based on predefined syntactic constraints and the given metric. Using several established evaluation metrics, we demonstrate the efficacy and flexibility of our approach in generating targeted heatmaps. We compare SyCAM with other well-known CAM methods on three prominent models: ResNet50, VGG16, and VGG19.","Alejandro Luque-Cerpa, Elizabeth Polgreen, Ajitha Rajan, Hazem Torfah","cs.CV, cs.AI",2025-04-14T09:01:49Z,http://arxiv.org/abs/2504.09998v1,metric guided synthesis of class activation mapping,class activation mapping cam is a widely adopted class of saliency methods used to explain the behavior of convolutional neural networks cnns these methods generate heatmaps that highlight the parts of the input most relevant to the cnn output various cam methods have been proposed each distinguished by the expressions used to derive heatmaps in general users look for heatmaps with specific properties that reflect different aspects of cnn functionality these may include similarity to ground truth robustness equivariance and more although existing cam methods implicitly encode some of these properties in their expressions they do not allow for variability in heatmap generation following the user s intent or domain knowledge in this paper we address this limitation by introducing sycam a metric based approach for synthesizing cam expressions given a predefined evaluation metric for saliency maps sycam automatically generates cam expressions optimized for that metric we specifically explore a syntax guided synthesis instantiation of sycam where cam expressions are derived based on predefined syntactic constraints and the given metric using several established evaluation metrics we demonstrate the efficacy and flexibility of our approach in generating targeted heatmaps we compare sycam with other well known cam methods on three prominent models resnet vgg and vgg,"['metric', 'guided', 'synthesis', 'of', 'class', 'activation', 'mapping']","['class', 'activation', 'mapping', 'cam', 'is', 'a', 'widely', 'adopted', 'class', 'of', 'saliency', 'methods', 'used', 'to', 'explain', 'the', 'behavior', 'of', 'convolutional', 'neural', 'networks', 'cnns', 'these', 'methods', 'generate', 'heatmaps', 'that', 'highlight', 'the', 'parts', 'of', 'the', 'input', 'most', 'relevant', 'to', 'the', 'cnn', 'output', 'various', 'cam', 'methods', 'have', 'been', 'proposed', 'each', 'distinguished', 'by', 'the', 'expressions', 'used', 'to', 'derive', 'heatmaps', 'in', 'general', 'users', 'look', 'for', 'heatmaps', 'with', 'specific', 'properties', 'that', 'reflect', 'different', 'aspects', 'of', 'cnn', 'functionality', 'these', 'may', 'include', 'similarity', 'to', 'ground', 'truth', 'robustness', 'equivariance', 'and', 'more', 'although', 'existing', 'cam', 'methods', 'implicitly', 'encode', 'some', 'of', 'these', 'properties', 'in', 'their', 'expressions', 'they', 'do', 'not', 'allow', 'for', 'variability', 'in', 'heatmap', 'generation', 'following', 'the', 'user', 's', 'intent', 'or', 'domain', 'knowledge', 'in', 'this', 'paper', 'we', 'address', 'this', 'limitation', 'by', 'introducing', 'sycam', 'a', 'metric', 'based', 'approach', 'for', 'synthesizing', 'cam', 'expressions', 'given', 'a', 'predefined', 'evaluation', 'metric', 'for', 'saliency', 'maps', 'sycam', 'automatically', 'generates', 'cam', 'expressions', 'optimized', 'for', 'that', 'metric', 'we', 'specifically', 'explore', 'a', 'syntax', 'guided', 'synthesis', 'instantiation', 'of', 'sycam', 'where', 'cam', 'expressions', 'are', 'derived', 'based', 'on', 'predefined', 'syntactic', 'constraints', 'and', 'the', 'given', 'metric', 'using', 'several', 'established', 'evaluation', 'metrics', 'we', 'demonstrate', 'the', 'efficacy', 'and', 'flexibility', 'of', 'our', 'approach', 'in', 'generating', 'targeted', 'heatmaps', 'we', 'compare', 'sycam', 'with', 'other', 'well', 'known', 'cam', 'methods', 'on', 'three', 'prominent', 'models', 'resnet', 'vgg', 'and', 'vgg']",7,205,"['CAM', 'VGG19', 'CNN', 'VGG16', 'These', 'CNNs', 'Class', 'ResNet50', 'Although', 'SyCAM', 'Given', 'Various']"
